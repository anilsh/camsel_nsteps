{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as spio\n",
    "#from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from ttictoc import TicToc\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from IPython import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#import cv2 as cv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "import time, math\n",
    " \n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if use_cuda:\n",
    "    print ('CUDA is available')\n",
    "#use_cuda=False   #uncomment this if you dont want to use cuda variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import collections\n",
    "import hickle as hkl\n",
    "\n",
    "sys.path.insert(0, '../data/')\n",
    "import get_pid_train_test as db\n",
    "import auxiliary as af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.path.insert(0,'../py-MDNet/modules')\n",
    "#from sample_generator import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "def plot_current_state(ped, c,fno):\n",
    "    # load image for current location\n",
    "    img,bb = load_image(ped,c,fno,db_no)\n",
    "\n",
    "    dpi = 80.0\n",
    "    #figsize = (img.size[0]/dpi, img.size[1]/dpi)\n",
    "    figsize = (img.shape[0]/dpi, img.shape[1]/dpi)\n",
    "    fig = plt.figure(frameon=False, figsize=figsize, dpi=dpi)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "\n",
    "    # get image and rect handle\n",
    "    imAX = ax.imshow(img, aspect='normal')\n",
    "    rect = plt.Rectangle(tuple(bb[0,:2]),bb[0,2],bb[0,3], \n",
    "        linewidth=3, edgecolor=\"#ff0000\", zorder=1, fill=False)\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    plt.pause(.01)\n",
    "    plt.draw()\n",
    "    #fig.savefig(os.path.join(savefig_dir,'0000.jpg'),dpi=dpi)\n",
    "    \n",
    "    return imAX, rect\n",
    "    \n",
    "def plot_second(ped,c,curr_frame, imAX,rect):\n",
    "    img,bb =  load_image(ped,c,curr_frame,db_no)\n",
    "    #if np.array(img).shape[0] > 0:\n",
    "    if img != []:\n",
    "        imAX.set_data(img)\n",
    "    #print (bb)\n",
    "\n",
    "    #if bb.shape[0] > 0:\n",
    "    if bb != []:\n",
    "        rect.set_xy(bb[0,:2])\n",
    "        rect.set_width(bb[0,2])\n",
    "        rect.set_height(bb[0,3])\n",
    "        print ('Correct camera')\n",
    "    elif c!= num_camera-1:\n",
    "        print ('Wrong camera')\n",
    "\n",
    "    \n",
    "    display.display(plt.gcf())\n",
    "    plt.pause(1)\n",
    "    plt.draw()\n",
    "    #fig.savefig(os.path.join(savefig_dir,'%04d.jpg'%(i)),dpi=dpi)\n",
    "\n",
    "def get_reward_gt(ped, curr_frame, c):\n",
    "    y = afc.find_target_camera(ped,curr_frame)\n",
    "    # get reward (give reward at end of episode)\n",
    "    if y == num_camera-1 and y == c:\n",
    "        reward = 0.1\n",
    "    elif y == c:\n",
    "        reward = 1\n",
    "    else:\n",
    "        reward = -1\n",
    "        \n",
    "    return reward,y\n",
    "\n",
    "def get_next_step(ped,c,curr_frame, state):\n",
    "    # update current state and history\n",
    "    ispresent,this_state = get_state_vector(ped, c,curr_frame)\n",
    "    if ispresent:\n",
    "        next_state = this_state\n",
    "    else:\n",
    "        # use previous state\n",
    "        next_state = state\n",
    "    \n",
    "    # get correct label from ground truth\n",
    "    reward,y = get_reward_gt(ped, curr_frame,c)\n",
    "\n",
    "    return next_state,reward,y,ispresent\n",
    "\n",
    "def test_func(pTest, iloc='first', eloc='last', fixLoc=-1, isdebug=0, req_inc=1):\n",
    "    policy_net.eval()\n",
    "    rsT,accT = [],[]\n",
    "    \n",
    "    for p in range(pTest.shape[0]): \n",
    "        reward_sum = 0\n",
    "        accP = []\n",
    "        inc = 1\n",
    "        \n",
    "        # load p'th person data\n",
    "        ped = np.copy(pTest[p])\n",
    "        # camera index and frame index starts from zero\n",
    "        ped[:,0] -= 1\n",
    "        ped[:,1] -= 1\n",
    "        \n",
    "        # Initialize with current state with start frame\n",
    "        if iloc == 'first':\n",
    "            startIDX = 0\n",
    "        elif iloc == 'rand':\n",
    "            startIDX = np.random.randint( 0,ped.shape[0]-20 )\n",
    "        elif iloc == 'fix':\n",
    "            startIDX = fixLoc\n",
    "        myPos = ped[startIDX,0:]\n",
    "        print ('Initial position: ',myPos)\n",
    "        \n",
    "        curr_camera = myPos[0]\n",
    "        curr_frame = myPos[1]\n",
    "        \n",
    "        # Initialize history variable (one-hot encoding)\n",
    "        ch = np.zeros((h_len,num_camera))\n",
    "        ch[:,curr_camera] = 1\n",
    "        occ_len = 0.0001\n",
    "        # Make initial state\n",
    "        _,state,rt = make_state_vector(ped, curr_camera,curr_frame, ch,occ_len)\n",
    "        #print (state.size())\n",
    "        num_steps = 0\n",
    "        #prev_camera = curr_camera\n",
    "        count_curr_c = 0\n",
    "        \n",
    "        if render: # show current location\n",
    "            plot_current_state(ped, curr_camera,curr_frame)\n",
    "\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(plt.gcf())\n",
    "\n",
    "\n",
    "        while(curr_frame <= ped[-1,1]): # alltime-6):\n",
    "            if use_cuda:\n",
    "                state_in = Variable(state)\n",
    "                value_c = policy_net(state_in)\n",
    "            else:\n",
    "                state_in = Variable(state)\n",
    "                value_c = policy_net(state_in)\n",
    "                \n",
    "            # Only exploitation for testing\n",
    "            camera_index = torch.argmax(value_c)\n",
    "            c = camera_index.detach().cpu().numpy()\n",
    "\n",
    "            # find target for the next frame\n",
    "            curr_frame += fpsc\n",
    "            num_steps += 1\n",
    "            \n",
    "            # get correct label from ground truth\n",
    "            reward,y = get_reward_gt(ped, curr_frame,c)\n",
    "            if req_inc:\n",
    "                if inc==1 and y!=num_camera-1:\n",
    "                     # inside a camera\n",
    "                    accP.append((y,y))\n",
    "                elif inc==0 and y==c.item(0) and y!=num_camera-1:\n",
    "                    # transitioning to second camera\n",
    "                    accP.append((y,c.item(0)))\n",
    "                    inc = 1\n",
    "                elif inc==1 and y==num_camera-1:\n",
    "                    # moving out of a camera FOV\n",
    "                    inc = 0\n",
    "                    accP.append((y,c.item(0)))\n",
    "                else:\n",
    "                    # Making transition\n",
    "                    accP.append((y,c.item(0)))\n",
    "                    #print ('Another case',y,c.item(0))\n",
    "                    \n",
    "            else:\n",
    "                    accP.append((y,c.item(0)))\n",
    "            \n",
    "            # get the current bounding box\n",
    "            bbox = ped[ np.logical_and(ped[:,0]==c,ped[:,1]==curr_frame),2:]\n",
    "            if bbox.shape[0] > 0: # and np.random.rand < 0.95:\n",
    "                bbox = bbox[0]\n",
    "                rt = np.zeros((4))\n",
    "                rt[0] = bbox[0]/320\n",
    "                rt[1] = bbox[1]/240\n",
    "                rt[2] = bbox[2]/320\n",
    "                rt[3] = bbox[3]/240\n",
    "                curr_camera = c\n",
    "                \n",
    "                ispresent = 1\n",
    "                \n",
    "            else:\n",
    "                ispresent = 0\n",
    "                \n",
    "            # count the time of prev_camera selection\n",
    "            if ispresent:\n",
    "                occ_len = 0.0001\n",
    "            else:\n",
    "                occ_len += 0.1\n",
    "            #if occ_len > occ_max_val:\n",
    "            #    occ_len = occ_max_val+1\n",
    "                \n",
    "            #hcount = np.array(-2 + (occ_len/occ_max_val)*(2-(-2)))\n",
    "            hcount = occ_len #np.array(np.log(occ_len))\n",
    "            # update current state and history\n",
    "            ch[1:,] = ch[0:-1,]\n",
    "            ch[0,0:] = afc.make_one_hot_camera(c)\n",
    "                \n",
    "            if isdebug:\n",
    "                print ('x_t: ', curr_camera,rt)\n",
    "                print ( np.where(ch))\n",
    "                print ('Q values: ', value_c)\n",
    "                print (c, curr_frame, hcount)\n",
    "                print ('isPresent', ispresent)\n",
    "                print ('')\n",
    "            \n",
    "            # get next camera using policy network\n",
    "            this_cam = np.zeros((num_camera+1))\n",
    "            this_cam[0:num_camera] = afc.make_one_hot_camera(curr_camera)\n",
    "            this_cam[num_camera] = hcount\n",
    "            # make next_state vector\n",
    "            next_state = np.concatenate((this_cam, rt.ravel()))\n",
    "            #next_state = np.concatenate((next_state, hcount)) #.ravel()))\n",
    "            next_state = np.concatenate((next_state, ch.ravel()))\n",
    "#             next_state[next_state==0] = -1\n",
    "#             next_state[next_state==1] = 1\n",
    "            if use_cuda:\n",
    "                next_state = torch.from_numpy(next_state.astype(np.float32)).unsqueeze(0).cuda()\n",
    "            else:\n",
    "                next_state = torch.from_numpy(next_state.astype(np.float32)).unsqueeze(0)\n",
    "                \n",
    "            # get next state\n",
    "            #next_state,reward,y,ispresent = get_next_step(ped,c,curr_frame, state)\n",
    "            \n",
    "            # store current reward\n",
    "            reward_sum += reward\n",
    "                        \n",
    "            state = next_state\n",
    "            prev_camera = c\n",
    "            \n",
    "            if render:\n",
    "                plot_second()\n",
    "            if eloc != 'last':\n",
    "                if num_steps > eloc:\n",
    "                    break\n",
    "            \n",
    "        # stack episodic reward \n",
    "        rsT.append((reward_sum,num_steps))\n",
    "        accT.append(accP)\n",
    "        \n",
    "    return rsT, accT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "batch_size = 500\n",
    "replay_memory_size = 4000\n",
    "#epsilon = 0.1\n",
    "gamma = 0.98\n",
    "\n",
    "resume = False # resume from previous checkpoint?\n",
    "render = False\n",
    "eps = np.finfo(np.float32).eps.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of person in data set:  (1, 49)\n",
      "Total number of person in data set:  (1, 49)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "db_no = 4\n",
    "[pALL,num_camera,alltime,fps] = db.get_pid(set_no=db_no, train_flag='train')\n",
    "num_camera += 1  # occlusion is also considered as a FOV\n",
    "fpsc = 2\n",
    "pALL = np.array(pALL)\n",
    "\n",
    "# load test set for current data set\n",
    "[pTest,num_camera,alltime,fps] = db.get_pid(set_no=db_no, train_flag='test')\n",
    "num_camera += 1  # occlusion is also considered as a FOV\n",
    "fpsc = 2\n",
    "pTest = np.array(pTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpoch = 100000\n",
    "d = 10\n",
    "region_size = (d,d)\n",
    "\n",
    "h_len = 50\n",
    "input_size = h_len*(num_camera) + num_camera+4+1\n",
    "\n",
    "# Load auxiliary functions using an object\n",
    "afc = af.AuxiliaryFunction(num_camera=num_camera, d=d, h_len=h_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize required parameters\n",
    "hidden_size1 = 4096\n",
    "hidden_size2 = 2048\n",
    "hidden_size3 = 256+256\n",
    "hidden_size4 = 256\n",
    "\n",
    "# Required network\n",
    "class NextCamera(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NextCamera, self).__init__()\n",
    "        \n",
    "        # make decoder layers\n",
    "        self.fch1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fch2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fch3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.fch4 = nn.Linear(hidden_size3, hidden_size4)\n",
    "        self.fco = nn.Linear(hidden_size4, num_camera)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        \n",
    "        # Activation function \n",
    "        #self.tanh = nn.Tanh() #ReLU()\n",
    "        self.relu = nn.ReLU() #ReLU()\n",
    "        #self.linear = nn.Linear() \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.relu(self.fch1(x))\n",
    "        x = self.relu(self.fch2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fch3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fch4(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fco(x)\n",
    "            \n",
    "        return x # nn.functional.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "if use_cuda:\n",
    "    policy_net = NextCamera().cuda()\n",
    "    policy_net.float().cuda()\n",
    "    criterion = nn.MSELoss().cuda()\n",
    "else:\n",
    "    policy_net = NextCamera()\n",
    "    policy_net.float()\n",
    "    criterion = nn.MSELoss()\n",
    "# use ADAM as optimizer since we can load the whole data to train\n",
    "#cls_weights = [1.0,1.0,1.0,1.0,0.1 ]\n",
    "#cls_weights = torch.FloatTensor(cls_weights).cuda()\n",
    "#criterion = nn.CrossEntropyLoss(weight=cls_weights)\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_network(replay_memory):\n",
    "    # sample random minibatch\n",
    "    minibatch = random.sample(replay_memory, min(len(replay_memory), batch_size))\n",
    "    \n",
    "    # unpack minibatch\n",
    "    state = torch.cat(tuple(d[0] for d in minibatch))\n",
    "    action = torch.cat(tuple(d[1] for d in minibatch))\n",
    "    reward = torch.cat(tuple(d[2] for d in minibatch))\n",
    "    next_state = torch.cat(tuple(d[3] for d in minibatch))\n",
    "    nSteps_boot = tuple(d[4] for d in minibatch)\n",
    "    \n",
    "    #print (state.size(), next_state.size(), reward.size(), action.size())\n",
    "\n",
    "    if use_cuda:  # put on GPU if CUDA is available\n",
    "        state = state.cuda()\n",
    "        action = action.cuda()\n",
    "        reward = reward.cuda()\n",
    "        next_state = next_state.cuda()\n",
    "\n",
    "    # get output for the next state\n",
    "    next_output = policy_net(next_state)\n",
    "\n",
    "    # set y_j to r_j for terminal state, otherwise to r_j + gamma*max(Q)\n",
    "    y = torch.cat(tuple(reward[i] if minibatch[i][4]\n",
    "                              else reward[i] + (gamma**(nSteps_boot[i])) * torch.max(next_output[i])\n",
    "                              for i in range(len(minibatch))))\n",
    "\n",
    "    # extract Q-value\n",
    "    q_value = torch.sum(policy_net(state) * action, dim=1)\n",
    "\n",
    "    # PyTorch accumulates gradients by default, so they need to be reset in each pass\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # returns a new Tensor, detached from the current graph, the result will never require gradient\n",
    "    y = y.detach()\n",
    "\n",
    "    #print (y, q_value)\n",
    "    # calculate loss\n",
    "    loss = criterion(q_value, y)\n",
    "\n",
    "    # do backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_sum = 0\n",
    "running_reward = None\n",
    "xs,rs,cprs = [],[],[]\n",
    "episode_number = 0\n",
    "episode_durations = []\n",
    "episode_reward = []\n",
    "validation_reward= []\n",
    "replay_memory = []\n",
    "M = np.zeros((num_camera,num_camera))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model if required\n",
    "resume = False\n",
    "backup_fname = './models/Q_db4_xywh_10log'\n",
    "if resume:\n",
    "    policy_net = torch.load(backup_fname)\n",
    "    policy_net.eval()\n",
    "    print ('Model loaded')\n",
    "    #episode_reward,running_reward = hkl.load(backup_fname+'_variables.hkl')\n",
    "    print ('episodic reward loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_state_vector(ped, curr_camera,curr_frame, ch,occ_len):\n",
    "    numSamples = 30\n",
    "    overlap_thres = [0.9, 1]\n",
    "        \n",
    "    # read image\n",
    "    img,bbox,p = afc.load_image(ped,curr_camera,curr_frame,db_no)\n",
    "    imw, imh = (320,240) #img.size\n",
    "    #print (img.size)\n",
    "    #print (bbox,p)\n",
    "    #hc = np.array(-occ_max_val + (occ_len/500)*(occ_max_val-(-occ_max_val)))\n",
    "    #hc = np.array(-2 + (occ_len/occ_max_val)*(2-(-2)))\n",
    "    hc = occ_len #np.array(np.log(occ_len))\n",
    "    \n",
    "    if p:\n",
    "        ## Draw samples\n",
    "        #examples = gen_samples(SampleGenerator('gaussian', img.size, 0.1, 1.2),\n",
    "        #                       bbox, numSamples, overlap_thres)  # 50 samples with 0.8 overlap\n",
    "        ##print (examples.shape)\n",
    "        #samples = examples[np.random.randint(len(examples))].reshape(1,4)\n",
    "        ##print (samples)\n",
    "        ##rt = afc.find_curr_rt(samples[0])\n",
    "        #bbox = samples[0]\n",
    "        rt = np.zeros((4))\n",
    "        rt[0] = bbox[0]/imw\n",
    "        rt[1] = bbox[1]/imh\n",
    "        rt[2] = bbox[2]/imw\n",
    "        rt[3] = bbox[3]/imh\n",
    "        #print (np.where(rt.ravel()))\n",
    "        \n",
    "        # make next_state vector\n",
    "        this_cam = np.zeros((num_camera+1))\n",
    "        this_cam[0:num_camera] = afc.make_one_hot_camera(curr_camera)\n",
    "        this_cam[num_camera] = hc\n",
    "        state = np.concatenate((this_cam, rt.ravel()))\n",
    "        #state = np.concatenate((state, hc)) #.ravel()))\n",
    "        state = np.concatenate((state, ch.ravel()))\n",
    "        state = state.reshape(1,-1)\n",
    "        \n",
    "        if use_cuda:\n",
    "            state = torch.from_numpy(state).float().cuda()\n",
    "        else:\n",
    "            state = torch.from_numpy(state).float()\n",
    "    else:\n",
    "        print ('Target is not present in ',c,curr_frame)\n",
    "        state = []\n",
    "    \n",
    "    return p,state,rt\n",
    "\n",
    "def append_reward(rs,num_steps):\n",
    "    if len(rs) > 0:\n",
    "        # stack episodic reward \n",
    "        epR = np.vstack(rs)\n",
    "        rs = []\n",
    "\n",
    "        # append the episodic reward\n",
    "        #episode_number += 1\n",
    "        #episode_durations.append(num_steps)\n",
    "        reward_stat = [num_steps,np.std(epR),np.sum(epR)]\n",
    "        episode_reward.append(reward_stat)\n",
    "    \n",
    "    return rs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "occ_max_val = 100\n",
    "NBoot = 20\n",
    "t = TicToc('episodic')\n",
    "t.tic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  708\n",
      "0 0 False\n",
      "x_t:  2 [0.015625   0.40833333 0.08125    0.275     ]\n",
      "Q values:  tensor([[-0.2446, -0.0034,  0.1151, -0.0739, -0.0031,  0.0538]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8871 853 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 0: ep_len:853 episode reward: total was -536.400000. running mean: -536.400000\n",
      "startIDX:  1032\n",
      "ep 0: ep_len:245 episode reward: total was -241.000000. running mean: -533.446000\n",
      "startIDX:  2565\n",
      "0 5 False\n",
      "x_t:  2 [0.003125   0.4        0.075      0.25833333]\n",
      "Q values:  tensor([[-0.6436, -0.3040, -0.1937, -0.4830, -0.7739, -1.0441]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21545 782 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 0: ep_len:782 episode reward: total was -780.000000. running mean: -535.911540\n",
      "startIDX:  735\n",
      "0 10 False\n",
      "x_t:  1 [0.003125   0.3625     0.13125    0.37916667]\n",
      "Q values:  tensor([[-0.2710, -0.0736, -0.2721, -0.2331, -0.2893, -0.4890]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7106 221 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 0: ep_len:221 episode reward: total was -199.900000. running mean: -532.551425\n",
      "startIDX:  1802\n",
      "0 12 False\n",
      "x_t:  0 [0.815625 0.4125   0.115625 0.35    ]\n",
      "Q values:  tensor([[-0.3549, -0.8264, -0.5829, -0.6031, -0.9005, -1.5620]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21101 586 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 0: ep_len:586 episode reward: total was -580.900000. running mean: -533.034910\n",
      "startIDX:  788\n",
      "0 15 False\n",
      "x_t:  2 [0.79375 0.4125  0.08125 0.2875 ]\n",
      "Q values:  tensor([[-1.1160, -0.8505, -0.3977, -0.5155, -1.2499, -0.8488]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5967 346 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 0: ep_len:346 episode reward: total was -340.700000. running mean: -531.111561\n",
      "startIDX:  811\n",
      "0 22 False\n",
      "x_t:  1 [0.003125   0.375      0.078125   0.38333333]\n",
      "Q values:  tensor([[-1.0788, -0.4080, -0.7730, -0.8312, -0.7644, -1.1423]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9479 292 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 0: ep_len:292 episode reward: total was -242.500000. running mean: -528.225446\n",
      "startIDX:  2147\n",
      "1 0 True\n",
      "x_t:  1 [0.859375   0.3        0.134375   0.54166667]\n",
      "Q values:  tensor([[-6.6438, -7.1759, -3.1350, -5.4600, -5.9082, -4.7155]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22917 1121 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  386\n",
      "1 1 True\n",
      "x_t:  1 [0.496875 0.3      0.240625 0.575   ]\n",
      "Q values:  tensor([[-1.5653, -1.3999, -2.1765, -1.5023, -1.2576, -2.5093]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28099 272 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  574\n",
      "1 5 True\n",
      "x_t:  2 [0.871875   0.34583333 0.078125   0.26666667]\n",
      "Q values:  tensor([[-4.4226, -3.5176, -2.8216, -3.5520, -3.9071, -4.6176]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6020 453 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2607\n",
      "startIDX:  1330\n",
      "1 12 True\n",
      "x_t:  3 [0.80625    0.38333333 0.178125   0.40833333]\n",
      "Q values:  tensor([[-2.1505, -1.2992, -2.3215, -1.6358, -1.1757, -2.2840]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17846 218 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1349\n",
      "1 15 True\n",
      "x_t:  3 [0.6625     0.3125     0.075      0.35416667]\n",
      "Q values:  tensor([[-0.6642, -0.2416, -0.5426, -0.5089, -0.5279, -0.3596]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10370 211 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  237\n",
      "1 22 True\n",
      "x_t:  2 [0.740625   0.40416667 0.078125   0.25416667]\n",
      "Q values:  tensor([[-7.6298, -5.2214, -5.1582, -4.6017, -4.5903, -5.8293]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2291 313 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  884\n",
      "2 0 True\n",
      "x_t:  0 [0.88125    0.40416667 0.109375   0.35833333]\n",
      "Q values:  tensor([[-15.2050, -10.2141, -10.1408, -11.5586,  -7.0935, -12.8436]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10330 440 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 2: ep_len:440 episode reward: total was -351.400000. running mean: -511.139999\n",
      "startIDX:  628\n",
      "2 1 True\n",
      "x_t:  2 [0.8125     0.38333333 0.1125     0.30833333]\n",
      "Q values:  tensor([[-13.3808, -10.0567, -11.5307, -15.0188,  -9.0664,  -9.4581]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31459 366 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 2: ep_len:366 episode reward: total was -303.200000. running mean: -509.060599\n",
      "startIDX:  1764\n",
      "2 5 True\n",
      "x_t:  1 [0.88125    0.28333333 0.053125   0.30833333]\n",
      "Q values:  tensor([[-21.8228, -20.4305, -20.0200, -20.4086, -15.9279, -17.2507]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14924 569 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 2: ep_len:569 episode reward: total was -449.200000. running mean: -508.461993\n",
      "startIDX:  1087\n",
      "2 10 True\n",
      "x_t:  2 [0.778125 0.4      0.0875   0.2375  ]\n",
      "Q values:  tensor([[-15.3726, -11.0908, -13.6171, -11.2161,  -6.8251, -12.2184]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12066 368 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 2: ep_len:368 episode reward: total was -297.000000. running mean: -506.347373\n",
      "startIDX:  1819\n",
      "2 12 True\n",
      "x_t:  0 [0.909375   0.4        0.08125    0.36666667]\n",
      "Q values:  tensor([[-18.6376, -17.5240, -20.7740, -21.2825, -20.7998, -13.9071]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21090 564 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 2: ep_len:564 episode reward: total was -457.900000. running mean: -505.862900\n",
      "startIDX:  895\n",
      "2 15 True\n",
      "x_t:  3 [0.0625     0.23333333 0.034375   0.23333333]\n",
      "Q values:  tensor([[-72.8140, -46.9401, -70.2883, -74.1801, -37.3371, -41.0349]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8491 1220 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 2: ep_len:1220 episode reward: total was -1009.600000. running mean: -510.900271\n",
      "startIDX:  336\n",
      "2 22 True\n",
      "x_t:  3 [0.0625     0.24166667 0.053125   0.23333333]\n",
      "Q values:  tensor([[-68.7331, -44.6657, -79.0812, -58.0405, -61.6737, -45.4581]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4869 1255 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 2: ep_len:1255 episode reward: total was -1008.900000. running mean: -515.880268\n",
      "startIDX:  495\n",
      "3 0 True\n",
      "x_t:  3 [0.821875   0.38333333 0.140625   0.44583333]\n",
      "Q values:  tensor([[-54.3028, -40.0569, -42.9339, -43.6078, -38.1713, -50.2154]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 6995 1025 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  206\n",
      "3 1 True\n",
      "x_t:  2 [0.003125 0.375    0.15625  0.4375  ]\n",
      "Q values:  tensor([[-36.3155, -33.1805, -54.7247, -42.1019, -46.8535, -46.8584]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27435 864 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2886\n",
      "startIDX:  1535\n",
      "3 10 True\n",
      "x_t:  3 [0.803125   0.30416667 0.090625   0.40416667]\n",
      "Q values:  tensor([[ -9.6527,  -8.9088, -12.9114, -12.0449,  -7.9700,  -8.6399]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16411 328 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1095\n",
      "3 12 True\n",
      "x_t:  3 [0.06875 0.2625  0.06875 0.25   ]\n",
      "Q values:  tensor([[-61.3241, -52.2965, -54.3306, -39.9739, -70.5826, -57.9304]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16374 1383 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2470\n",
      "3 15 True\n",
      "x_t:  3 [0.9        0.34166667 0.096875   0.39583333]\n",
      "Q values:  tensor([[-5.6585, -4.2686, -4.3127, -7.0287, -5.7786, -5.2097]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19655 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  930\n",
      "3 22 True\n",
      "x_t:  1 [0.003125   0.35833333 0.1625     0.39583333]\n",
      "Q values:  tensor([[-6.6529, -8.2501, -6.8911, -6.8071, -7.3877, -6.5755]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9484 230 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2442\n",
      "ep 4: ep_len:70 episode reward: total was -42.900000. running mean: -507.825378\n",
      "startIDX:  478\n",
      "4 1 False\n",
      "x_t:  1 [0.853125   0.27083333 0.134375   0.45833333]\n",
      "Q values:  tensor([[-15.9637, -14.6016, -25.6700, -18.2992, -20.2820, -19.3967]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30682 768 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 4: ep_len:768 episode reward: total was -626.800000. running mean: -509.015124\n",
      "startIDX:  2761\n",
      "4 5 True\n",
      "x_t:  0 [0.94375 0.3875  0.04375 0.3125 ]\n",
      "Q values:  tensor([[-13.6482, -14.2746, -12.3801,  -7.6100, -15.4715,  -9.0942]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23147 504 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 4: ep_len:504 episode reward: total was -397.400000. running mean: -507.898973\n",
      "startIDX:  1977\n",
      "4 10 True\n",
      "x_t:  1 [0.071875   0.33333333 0.071875   0.39166667]\n",
      "Q values:  tensor([[-2.2561, -5.1950, -6.8803, -6.3517, -8.5597, -5.7759]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18817 336 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 4: ep_len:336 episode reward: total was -257.600000. running mean: -505.395983\n",
      "startIDX:  149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 12 False\n",
      "x_t:  2 [0.771875   0.40416667 0.04375    0.25      ]\n",
      "Q values:  tensor([[ -8.4929, -10.0742,  -5.6954,  -8.6432,  -7.4265,  -7.9977]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2816 281 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 4: ep_len:281 episode reward: total was -231.900000. running mean: -502.661023\n",
      "startIDX:  85\n",
      "4 15 False\n",
      "x_t:  3 [0.75       0.35       0.13125    0.41666667]\n",
      "Q values:  tensor([[-7.0835, -7.5822, -7.4430, -6.0022, -7.0229, -6.3053]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 532 213 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 4: ep_len:213 episode reward: total was -174.700000. running mean: -499.381413\n",
      "startIDX:  2643\n",
      "4 22 True\n",
      "x_t:  4 [0.00625    0.40833333 0.103125   0.30416667]\n",
      "Q values:  tensor([[ -9.1971, -16.5183, -12.6770, -15.2389, -15.9677, -11.7099]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27263 552 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 4: ep_len:552 episode reward: total was -428.000000. running mean: -498.667599\n",
      "startIDX:  1966\n",
      "5 0 True\n",
      "x_t:  1 [0.003125 0.3875   0.18125  0.4     ]\n",
      "Q values:  tensor([[-4.8897, -5.5738, -2.8727, -4.4966, -5.6853, -4.9414]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18926 215 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1042\n",
      "5 1 False\n",
      "x_t:  3 [0.83125    0.30416667 0.125      0.41666667]\n",
      "Q values:  tensor([[-4.4168, -5.0202, -5.4675, -3.7994, -5.2928, -5.4398]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35902 205 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  529\n",
      "5 5 True\n",
      "x_t:  2 [0.853125   0.37916667 0.05625    0.2375    ]\n",
      "Q values:  tensor([[-11.2642, -10.4446,  -9.0679, -10.2029, -11.1938, -10.9506]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6026 491 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1733\n",
      "5 10 False\n",
      "x_t:  3 [0.86875    0.32916667 0.125      0.4       ]\n",
      "Q values:  tensor([[-5.9917, -8.5253, -8.8434, -5.4535, -6.2938, -6.4305]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16401 220 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1811\n",
      "5 12 True\n",
      "x_t:  0 [0.896875   0.40833333 0.05625    0.35416667]\n",
      "Q values:  tensor([[-17.3258, -12.3616, -14.6405, -15.1579, -21.7439, -14.0687]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21097 612 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  441\n",
      "5 15 True\n",
      "x_t:  0 [0.934375   0.4        0.053125   0.34166667]\n",
      "Q values:  tensor([[-11.8673, -13.3174, -10.0931, -10.4571, -15.1287, -12.5754]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3652 420 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2122\n",
      "5 22 False\n",
      "x_t:  0 [0.940625   0.39583333 0.05625    0.34583333]\n",
      "Q values:  tensor([[-17.5272, -26.1230, -20.3903, -19.0201, -24.2106, -23.5954]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20684 849 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1311\n",
      "6 0 False\n",
      "x_t:  3 [0.075      0.24583333 0.084375   0.25833333]\n",
      "Q values:  tensor([[-40.8491, -36.9838, -49.3705, -26.8671, -40.0948, -41.3103]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15163 1204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 6: ep_len:1204 episode reward: total was -993.200000. running mean: -494.154315\n",
      "startIDX:  715\n",
      "6 1 True\n",
      "x_t:  3 [0.10625    0.22916667 0.08125    0.30833333]\n",
      "Q values:  tensor([[-44.9841, -45.1543, -27.5203, -42.6569, -49.9587, -46.9892]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34320 1409 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 6: ep_len:1409 episode reward: total was -1200.000000. running mean: -501.212772\n",
      "startIDX:  2711\n",
      "6 5 False\n",
      "x_t:  1 [0.06875    0.35833333 0.20625    0.50833333]\n",
      "Q values:  tensor([[-12.4729,  -6.7050,  -7.7997,  -7.0617,  -9.8730,  -9.1354]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22113 233 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 6: ep_len:233 episode reward: total was -198.400000. running mean: -498.184644\n",
      "startIDX:  1962\n",
      "6 10 True\n",
      "x_t:  1 [0.028125   0.34583333 0.109375   0.375     ]\n",
      "Q values:  tensor([[-13.1954, -15.3056, -14.3042, -12.1694, -14.3454, -11.7648]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18814 322 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 6: ep_len:322 episode reward: total was -252.600000. running mean: -495.728797\n",
      "startIDX:  1336\n",
      "6 12 True\n",
      "x_t:  3 [0.890625   0.37916667 0.10625    0.425     ]\n",
      "Q values:  tensor([[-7.0956, -9.8789, -6.4704, -7.3795, -7.1156, -7.4064]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17841 216 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 6: ep_len:216 episode reward: total was -158.700000. running mean: -492.358509\n",
      "startIDX:  2867\n",
      "6 15 False\n",
      "x_t:  1 [0.003125   0.39166667 0.13125    0.47916667]\n",
      "Q values:  tensor([[-11.9980,  -7.5995, -10.1675,  -8.4880, -13.5654,  -9.6000]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22036 230 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 6: ep_len:230 episode reward: total was -189.700000. running mean: -489.331924\n",
      "startIDX:  1658\n",
      "6 22 True\n",
      "x_t:  3 [0.83125    0.3375     0.090625   0.42083333]\n",
      "Q values:  tensor([[ -7.7479,  -9.5509,  -5.8786,  -9.4646, -10.4683,  -9.5691]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16851 232 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 6: ep_len:232 episode reward: total was -184.300000. running mean: -486.281605\n",
      "startIDX:  0\n",
      "7 0 False\n",
      "x_t:  1 [0.80625    0.3        0.096875   0.42083333]\n",
      "Q values:  tensor([[-30.3317, -22.4801, -31.1871, -36.6415, -32.2975, -24.1709]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1618 772 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  162\n",
      "7 1 True\n",
      "x_t:  2 [0.003125   0.375      0.096875   0.42916667]\n",
      "Q values:  tensor([[-27.3133, -27.2187, -27.9748, -32.7931, -36.1750, -31.3098]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27430 862 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1411\n",
      "7 5 False\n",
      "x_t:  1 [0.1125     0.3375     0.090625   0.38333333]\n",
      "Q values:  tensor([[ -8.3329,  -6.2387,  -7.9099,  -9.9556, -10.9160,  -7.4835]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12516 211 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  112\n",
      "7 10 True\n",
      "x_t:  3 [0.18125 0.25    0.08125 0.2875 ]\n",
      "Q values:  tensor([[-30.3134, -21.6236, -41.3139, -35.5251, -26.4314, -26.8651]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3615 1068 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  79\n",
      "7 12 False\n",
      "x_t:  1 [0.671875   0.31666667 0.075      0.45      ]\n",
      "Q values:  tensor([[-24.1838, -22.6563, -24.3192, -29.8077, -24.1888, -28.8893]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2235 625 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3107\n",
      "startIDX:  1703\n",
      "7 22 True\n",
      "x_t:  3 [0.8625     0.33333333 0.084375   0.425     ]\n",
      "Q values:  tensor([[-10.9375,  -8.3607, -11.1576, -13.9169, -10.0709,  -9.8747]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16848 206 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  689\n",
      "8 0 False\n",
      "x_t:  2 [0.01875    0.40416667 0.1125     0.275     ]\n",
      "Q values:  tensor([[-29.1668, -35.7436, -23.7926, -37.7999, -29.0840, -27.0130]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8874 892 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 8: ep_len:892 episode reward: total was -683.600000. running mean: -483.260363\n",
      "startIDX:  343\n",
      "8 1 True\n",
      "x_t:  1 [0.565625   0.30833333 0.2375     0.5625    ]\n",
      "Q values:  tensor([[-13.7486, -13.4948,  -8.0078, -14.7182, -10.8587, -11.7821]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28102 302 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 8: ep_len:302 episode reward: total was -232.900000. running mean: -480.756760\n",
      "startIDX:  2323\n",
      "8 5 True\n",
      "x_t:  3 [0.08125    0.25       0.115625   0.27916667]\n",
      "Q values:  tensor([[-11.7688, -12.9286, -13.5596, -13.9889, -11.1729, -12.6275]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 20004 216 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 8: ep_len:216 episode reward: total was -160.800000. running mean: -477.557192\n",
      "startIDX:  1968\n",
      "8 10 False\n",
      "x_t:  1 [0.01875    0.34166667 0.11875    0.4       ]\n",
      "Q values:  tensor([[-14.0184, -10.3671, -12.8913, -15.7002, -13.0520, -13.0763]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18813 308 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 8: ep_len:308 episode reward: total was -238.100000. running mean: -475.162620\n",
      "startIDX:  1544\n",
      "8 12 True\n",
      "x_t:  2 [0.140625   0.40833333 0.053125   0.2875    ]\n",
      "Q values:  tensor([[-31.1283, -37.4644, -34.4935, -28.1848, -32.1324, -30.1381]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19397 762 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 8: ep_len:762 episode reward: total was -566.800000. running mean: -476.078994\n",
      "startIDX:  1705\n",
      "8 15 False\n",
      "x_t:  1 [0.021875   0.36666667 0.146875   0.4       ]\n",
      "Q values:  tensor([[-14.3149, -11.0103, -13.7635, -13.4588, -14.7884, -13.1976]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12450 224 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 8: ep_len:224 episode reward: total was -166.500000. running mean: -472.983204\n",
      "startIDX:  1438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 22 False\n",
      "x_t:  4 [0.009375   0.39166667 0.084375   0.3       ]\n",
      "Q values:  tensor([[-24.8772, -24.6236, -24.4866, -29.9388, -17.4953, -29.5916]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16325 565 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 8: ep_len:565 episode reward: total was -433.700000. running mean: -472.590372\n",
      "startIDX:  1148\n",
      "9 0 False\n",
      "x_t:  2 [0.7875     0.4        0.103125   0.29166667]\n",
      "Q values:  tensor([[-17.9622, -18.9742, -16.4140, -20.4435, -20.9364, -17.9808]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12630 320 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  871\n",
      "9 1 True\n",
      "x_t:  4 [0.003125   0.39583333 0.11875    0.40833333]\n",
      "Q values:  tensor([[-28.8038, -31.6973, -30.1388, -26.9326, -29.3650, -27.8099]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35421 538 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2230\n",
      "9 5 False\n",
      "x_t:  3 [0.828125   0.33333333 0.11875    0.45      ]\n",
      "Q values:  tensor([[-12.4369, -13.4163,  -9.5156,  -8.3361, -13.9200, -16.2563]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19888 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1038\n",
      "9 10 False\n",
      "x_t:  1 [0.796875   0.27916667 0.090625   0.34166667]\n",
      "Q values:  tensor([[-84.4186, -76.1295, -94.7011, -90.8875, -96.6657, -91.5200]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11338 1538 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1872\n",
      "9 12 False\n",
      "x_t:  0 [0.2625     0.41666667 0.071875   0.30416667]\n",
      "Q values:  tensor([[-34.0990, -57.2289, -36.7827, -54.9745, -46.6689, -40.1186]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 22998 942 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1366\n",
      "9 15 True\n",
      "x_t:  3 [0.678125   0.32916667 0.11875    0.35833333]\n",
      "Q values:  tensor([[-14.5683, -14.3557, -11.6771, -17.6167, -15.3826, -15.8145]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10364 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2258\n",
      "9 22 False\n",
      "x_t:  1 [0.684375   0.31666667 0.084375   0.4375    ]\n",
      "Q values:  tensor([[-43.1000, -35.9306, -38.3957, -46.6655, -38.4585, -50.8123]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22952 1106 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  73.29876899719238\n",
      "startIDX:  2539\n",
      "ep 10: ep_len:25 episode reward: total was -17.000000. running mean: -472.618593\n",
      "startIDX:  244\n",
      "10 1 False\n",
      "x_t:  2 [0.003125   0.36666667 0.10625    0.45833333]\n",
      "Q values:  tensor([[-35.1901, -23.4789, -18.8284, -24.8239, -21.6788, -21.1426]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27432 815 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 10: ep_len:815 episode reward: total was -611.900000. running mean: -474.011407\n",
      "startIDX:  1804\n",
      "10 5 False\n",
      "x_t:  2 [0.84375    0.40416667 0.071875   0.25416667]\n",
      "Q values:  tensor([[-10.6919, -12.3971,  -9.1355, -12.7630, -14.3791, -12.4906]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15642 361 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 10: ep_len:361 episode reward: total was -277.100000. running mean: -472.042293\n",
      "startIDX:  376\n",
      "10 10 False\n",
      "x_t:  3 [0.671875   0.29583333 0.0875     0.36666667]\n",
      "Q values:  tensor([[ -9.9451,  -9.7421, -10.3658,  -8.6063,  -9.8530, -13.8893]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5058 205 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 10: ep_len:205 episode reward: total was -155.100000. running mean: -468.872870\n",
      "startIDX:  443\n",
      "10 12 False\n",
      "x_t:  3 [0.809375   0.375      0.1625     0.40416667]\n",
      "Q values:  tensor([[-11.1173,  -9.7118, -10.6714,  -8.3251, -13.3479, -10.3659]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7713 234 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 10: ep_len:234 episode reward: total was -187.700000. running mean: -466.061141\n",
      "startIDX:  3084\n",
      "ep 10: ep_len:41 episode reward: total was -35.000000. running mean: -461.750530\n",
      "startIDX:  2720\n",
      "10 22 False\n",
      "x_t:  4 [0.00625    0.4125     0.109375   0.29166667]\n",
      "Q values:  tensor([[-11.6255, -15.0679, -12.5794, -14.7319, -10.6477, -15.7610]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27264 504 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 10: ep_len:504 episode reward: total was -401.800000. running mean: -461.151025\n",
      "startIDX:  985\n",
      "11 0 False\n",
      "x_t:  1 [0.796875   0.29583333 0.090625   0.4375    ]\n",
      "Q values:  tensor([[-16.7903, -16.6895, -20.0109, -21.1337, -22.3479, -18.6634]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11957 807 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  359\n",
      "11 1 False\n",
      "x_t:  1 [0.496875 0.3      0.240625 0.575   ]\n",
      "Q values:  tensor([[-15.1839,  -9.8696, -11.3451, -11.7501, -12.5079, -11.7833]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28099 290 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2791\n",
      "11 5 True\n",
      "x_t:  0 [0.940625 0.3875   0.05     0.3125  ]\n",
      "Q values:  tensor([[-14.6612, -12.7346, -16.2527, -17.8503, -15.5540, -13.2321]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23148 488 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  437\n",
      "11 10 False\n",
      "x_t:  3 [0.30625    0.25       0.078125   0.30833333]\n",
      "Q values:  tensor([[-28.0825, -31.0822, -34.4646, -26.7875, -29.9915, -35.1416]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5119 207 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1306\n",
      "11 12 True\n",
      "x_t:  4 [0.08125    0.42916667 0.125      0.3625    ]\n",
      "Q values:  tensor([[-18.4200, -17.1988, -16.7237, -13.8582, -20.3496, -21.9237]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17400 447 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  854\n",
      "11 15 True\n",
      "x_t:  3 [0.0625     0.23333333 0.04375    0.225     ]\n",
      "Q values:  tensor([[-45.1620, -30.6305, -36.6513, -35.2665, -28.9056, -30.1757]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8492 1216 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1234\n",
      "11 22 True\n",
      "x_t:  2 [0.765625   0.4125     0.09375    0.24583333]\n",
      "Q values:  tensor([[-16.2696, -13.1957, -16.6539, -20.3224, -17.5757, -15.8796]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12593 329 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  573\n",
      "12 0 False\n",
      "x_t:  2 [0.303125   0.4125     0.08125    0.25833333]\n",
      "Q values:  tensor([[-45.1967, -37.4805, -30.8286, -47.1118, -36.7488, -34.3204]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8912 946 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 12: ep_len:946 episode reward: total was -797.800000. running mean: -463.988043\n",
      "startIDX:  280\n",
      "12 1 True\n",
      "x_t:  2 [0.203125   0.37083333 0.153125   0.42916667]\n",
      "Q values:  tensor([[-37.5633, -34.0493, -46.2201, -36.4405, -44.4145, -45.0494]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27466 836 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 12: ep_len:836 episode reward: total was -721.800000. running mean: -466.566162\n",
      "startIDX:  2699\n",
      "12 5 True\n",
      "x_t:  1 [0.00625    0.35416667 0.11875    0.51666667]\n",
      "Q values:  tensor([[-18.6570, -18.8782, -22.7868, -21.7854, -16.1181, -19.3586]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22106 222 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 12: ep_len:222 episode reward: total was -194.700000. running mean: -463.847501\n",
      "startIDX:  429\n",
      "12 10 True\n",
      "x_t:  3 [0.434375   0.275      0.121875   0.32916667]\n",
      "Q values:  tensor([[-36.5293, -27.5576, -38.3232, -27.5014, -46.1756, -33.2808]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5090 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 12: ep_len:200 episode reward: total was -149.500000. running mean: -460.704026\n",
      "startIDX:  805\n",
      "12 12 False\n",
      "x_t:  0 [0.75       0.40833333 0.084375   0.30416667]\n",
      "Q values:  tensor([[-25.0931, -35.4403, -42.1109, -35.8324, -25.1032, -29.8887]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11657 666 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 12: ep_len:666 episode reward: total was -550.400000. running mean: -461.600985\n",
      "startIDX:  627\n",
      "12 15 False\n",
      "x_t:  1 [0.85       0.2875     0.059375   0.27916667]\n",
      "Q values:  tensor([[-35.6969, -32.8216, -39.0186, -43.4513, -37.1505, -37.9159]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5173 668 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 12: ep_len:668 episode reward: total was -542.300000. running mean: -462.407976\n",
      "startIDX:  1268\n",
      "12 22 False\n",
      "x_t:  2 [0.890625   0.39583333 0.046875   0.17083333]\n",
      "Q values:  tensor([[-23.3749, -26.1175, -18.8317, -26.1409, -22.0937, -24.0167]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12576 301 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 12: ep_len:301 episode reward: total was -240.900000. running mean: -460.192896\n",
      "startIDX:  2040\n",
      "13 0 False\n",
      "x_t:  0 [0.74375    0.39583333 0.103125   0.33333333]\n",
      "Q values:  tensor([[-27.3032, -43.9782, -45.6270, -39.4022, -29.4052, -40.4495]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20656 848 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  108\n",
      "13 1 True\n",
      "x_t:  3 [0.125    0.225    0.071875 0.2875  ]\n",
      "Q values:  tensor([[-37.3711, -35.4707, -40.5066, -39.9244, -31.5943, -31.6819]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25774 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 5 True\n",
      "x_t:  2 [0.00625    0.40416667 0.096875   0.2625    ]\n",
      "Q values:  tensor([[-34.3780, -41.4149, -35.2906, -29.4161, -22.9169, -18.3328]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12006 720 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  813\n",
      "13 10 True\n",
      "x_t:  0 [0.81875    0.39166667 0.1125     0.32083333]\n",
      "Q values:  tensor([[-32.0692, -27.2392, -31.2464, -22.7547, -16.7356, -22.4479]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8115 506 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1620\n",
      "13 12 False\n",
      "x_t:  2 [0.15   0.4125 0.075  0.2875]\n",
      "Q values:  tensor([[-37.2329, -29.3199, -27.9556, -39.8047, -36.8074, -32.7187]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19399 711 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2312\n",
      "13 15 False\n",
      "x_t:  3 [0.096875   0.27083333 0.059375   0.30416667]\n",
      "Q values:  tensor([[-44.5941, -38.7510, -42.0681, -35.2030, -36.6500, -37.6978]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18179 1251 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2653\n",
      "13 22 False\n",
      "x_t:  4 [0.00625    0.40833333 0.115625   0.3       ]\n",
      "Q values:  tensor([[-31.0821, -30.4895, -27.2664, -22.0724, -20.5467, -25.5279]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27265 545 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  368\n",
      "14 0 True\n",
      "x_t:  3 [0.109375   0.2375     0.05625    0.24166667]\n",
      "Q values:  tensor([[-36.6328, -43.7003, -29.9810, -41.6085, -27.3428, -34.9988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4853 1213 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 14: ep_len:1213 episode reward: total was -929.400000. running mean: -469.835657\n",
      "startIDX:  1088\n",
      "14 1 False\n",
      "x_t:  3 [0.6375     0.29166667 0.1        0.375     ]\n",
      "Q values:  tensor([[-41.7435, -29.6292, -37.9962, -22.1563, -36.3527, -36.9778]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35934 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 14: ep_len:204 episode reward: total was -147.500000. running mean: -466.612300\n",
      "startIDX:  2929\n",
      "ep 14: ep_len:72 episode reward: total was -50.000000. running mean: -462.446177\n",
      "startIDX:  2284\n",
      "14 10 False\n",
      "x_t:  1 [0.884375   0.2875     0.1125     0.33333333]\n",
      "Q values:  tensor([[-33.4828, -24.0818, -31.7671, -30.4733, -28.4525, -29.9514]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22468 1254 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 14: ep_len:1254 episode reward: total was -984.700000. running mean: -467.668715\n",
      "startIDX:  478\n",
      "14 12 False\n",
      "x_t:  3 [0.70625    0.34166667 0.13125    0.40416667]\n",
      "Q values:  tensor([[-14.4049, -16.0260, -19.3289, -14.2014, -18.4043, -14.8020]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7728 221 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 14: ep_len:221 episode reward: total was -180.200000. running mean: -464.794028\n",
      "startIDX:  52\n",
      "14 15 False\n",
      "x_t:  3 [0.825      0.34166667 0.096875   0.42916667]\n",
      "Q values:  tensor([[-19.9069, -19.2950, -24.9041, -16.8978, -23.9949, -20.4836]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 525 228 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 14: ep_len:228 episode reward: total was -166.200000. running mean: -461.808088\n",
      "startIDX:  853\n",
      "14 22 False\n",
      "x_t:  1 [0.14375    0.35416667 0.153125   0.4125    ]\n",
      "Q values:  tensor([[-17.7289, -15.9477, -16.7137, -18.6347, -16.8302, -20.1395]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9497 270 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 14: ep_len:270 episode reward: total was -224.800000. running mean: -459.438007\n",
      "startIDX:  2201\n",
      "15 0 False\n",
      "x_t:  1 [0.85       0.30416667 0.146875   0.54166667]\n",
      "Q values:  tensor([[-24.8522, -18.5095, -33.6642, -30.2877, -24.8625, -29.2491]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22920 1110 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1122\n",
      "startIDX:  2667\n",
      "15 5 True\n",
      "x_t:  1 [0.046875   0.34583333 0.175      0.52083333]\n",
      "Q values:  tensor([[-16.3121, -19.6900, -18.4715, -16.8188, -22.1341, -20.8862]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22109 249 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  133\n",
      "15 10 True\n",
      "x_t:  3 [0.0625     0.24166667 0.059375   0.24583333]\n",
      "Q values:  tensor([[-32.9214, -31.2202, -24.6692, -32.0512, -25.8841, -23.3963]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3578 1052 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1113\n",
      "15 12 False\n",
      "x_t:  3 [0.165625   0.27083333 0.078125   0.32083333]\n",
      "Q values:  tensor([[-30.3624, -34.3024, -35.5895, -25.0958, -36.5591, -33.4241]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16400 1383 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1715\n",
      "15 15 False\n",
      "x_t:  1 [0.03125    0.36666667 0.1375     0.4       ]\n",
      "Q values:  tensor([[-23.2552, -20.2254, -22.3813, -21.9362, -23.0618, -26.5196]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12451 229 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1106\n",
      "15 22 True\n",
      "x_t:  1 [0.575      0.32916667 0.084375   0.49583333]\n",
      "Q values:  tensor([[-23.1502, -30.3333, -33.1960, -30.3256, -32.8491, -33.8945]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11942 740 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2272\n",
      "16 0 False\n",
      "x_t:  2 [0.903125   0.39166667 0.046875   0.19166667]\n",
      "Q values:  tensor([[-29.8434, -22.1492, -20.4362, -25.7335, -27.1215, -24.2843]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23573 304 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 16: ep_len:304 episode reward: total was -260.200000. running mean: -464.599707\n",
      "startIDX:  117\n",
      "16 1 True\n",
      "x_t:  2 [0.003125   0.37916667 0.171875   0.43333333]\n",
      "Q values:  tensor([[-29.3964, -30.9821, -33.1946, -39.7809, -37.6330, -30.4519]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27438 914 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 16: ep_len:914 episode reward: total was -753.200000. running mean: -467.485710\n",
      "startIDX:  428\n",
      "16 5 False\n",
      "x_t:  1 [0.86875    0.2875     0.125      0.37916667]\n",
      "Q values:  tensor([[-29.3584, -23.2376, -34.6600, -28.1602, -32.9915, -29.4935]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5027 679 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 16: ep_len:679 episode reward: total was -536.900000. running mean: -468.179853\n",
      "startIDX:  1545\n",
      "16 10 False\n",
      "x_t:  3 [0.73125 0.3125  0.14375 0.3875 ]\n",
      "Q values:  tensor([[-21.5770, -27.6589, -24.6764, -19.7064, -25.0824, -28.3780]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16418 329 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 16: ep_len:329 episode reward: total was -249.000000. running mean: -465.988055\n",
      "startIDX:  1418\n",
      "16 12 False\n",
      "x_t:  3 [0.44375    0.30833333 0.109375   0.35416667]\n",
      "Q values:  tensor([[-39.4874, -33.5721, -26.7690, -22.7203, -30.1960, -35.9970]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17899 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 16: ep_len:202 episode reward: total was -164.600000. running mean: -462.974174\n",
      "startIDX:  1377\n",
      "16 15 False\n",
      "x_t:  3 [0.609375   0.31666667 0.10625    0.34583333]\n",
      "Q values:  tensor([[-32.5449, -29.0716, -29.9557, -28.4654, -29.9365, -42.1283]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10374 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 16: ep_len:202 episode reward: total was -153.900000. running mean: -459.883432\n",
      "startIDX:  146\n",
      "16 22 False\n",
      "x_t:  1 [0.8375     0.30833333 0.11875    0.39583333]\n",
      "Q values:  tensor([[-25.2280, -25.0462, -28.3473, -31.7415, -28.0823, -34.2938]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1583 645 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 16: ep_len:645 episode reward: total was -495.800000. running mean: -460.242598\n",
      "startIDX:  186\n",
      "17 0 False\n",
      "x_t:  2 [0.796875   0.40833333 0.1        0.2875    ]\n",
      "Q values:  tensor([[-25.5458, -29.3131, -21.7035, -26.5434, -22.7157, -28.3318]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2320 347 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  638\n",
      "17 1 True\n",
      "x_t:  2 [0.809375   0.37916667 0.09375    0.31666667]\n",
      "Q values:  tensor([[-23.1387, -25.9340, -27.8705, -32.1737, -30.9061, -27.7104]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31462 361 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2695\n",
      "17 5 False\n",
      "x_t:  1 [0.24375    0.34166667 0.196875   0.5125    ]\n",
      "Q values:  tensor([[-27.9867, -22.9808, -28.4632, -25.3568, -23.4502, -27.4680]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22128 240 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  260\n",
      "17 10 True\n",
      "x_t:  4 [0.053125   0.36666667 0.103125   0.2375    ]\n",
      "Q values:  tensor([[-21.3260, -19.6042, -30.3728, -24.6949, -22.6458, -21.8917]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4554 436 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1194\n",
      "17 12 False\n",
      "x_t:  4 [0.384375   0.38333333 0.075      0.30833333]\n",
      "Q values:  tensor([[-25.5742, -22.9215, -27.1006, -29.5614, -22.4019, -27.1072]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17440 525 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  88\n",
      "17 15 False\n",
      "x_t:  3 [0.8375     0.35833333 0.1375     0.42916667]\n",
      "Q values:  tensor([[-23.3018, -23.1825, -24.0009, -21.2953, -24.9119, -21.8805]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 522 209 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2242\n",
      "17 22 True\n",
      "x_t:  1 [0.8625     0.30833333 0.134375   0.45416667]\n",
      "Q values:  tensor([[-23.2572, -30.2410, -28.3487, -30.0878, -30.0508, -28.1223]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22932 1096 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2386\n",
      "18 0 True\n",
      "x_t:  3 [0.2      0.25     0.071875 0.275   ]\n",
      "Q values:  tensor([[-32.5784, -30.7155, -35.6935, -31.8418, -27.6924, -31.4497]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26131 1238 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 18: ep_len:1238 episode reward: total was -990.000000. running mean: -458.303045\n",
      "startIDX:  301\n",
      "18 1 False\n",
      "x_t:  0 [0.759375   0.375      0.115625   0.39166667]\n",
      "Q values:  tensor([[-21.3094, -25.5735, -28.6594, -25.6731, -32.2924, -27.7651]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29110 821 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 18: ep_len:821 episode reward: total was -623.900000. running mean: -459.959015\n",
      "startIDX:  2079\n",
      "18 5 False\n",
      "x_t:  4 [0.01875    0.42916667 0.1125     0.4       ]\n",
      "Q values:  tensor([[-23.6384, -31.7645, -27.0992, -35.2886, -20.9758, -24.2008]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19467 641 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 18: ep_len:641 episode reward: total was -491.200000. running mean: -460.271425\n",
      "startIDX:  1306\n",
      "18 10 False\n",
      "x_t:  3 [0.11875    0.225      0.059375   0.27083333]\n",
      "Q values:  tensor([[-32.1229, -34.5286, -46.5149, -28.7553, -30.7108, -33.8564]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14594 1202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 18: ep_len:1202 episode reward: total was -871.300000. running mean: -464.381711\n",
      "startIDX:  41\n",
      "18 12 False\n",
      "x_t:  1 [0.684375   0.32916667 0.140625   0.4375    ]\n",
      "Q values:  tensor([[-27.5152, -19.8958, -21.5428, -25.6334, -21.5118, -24.8986]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2231 632 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 18: ep_len:632 episode reward: total was -466.300000. running mean: -464.400894\n",
      "startIDX:  187\n",
      "18 15 False\n",
      "x_t:  2 [0.00625    0.40416667 0.109375   0.33333333]\n",
      "Q values:  tensor([[-22.0653, -17.8299, -15.3469, -27.6088, -23.6453, -20.0138]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2194 804 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 18: ep_len:804 episode reward: total was -606.300000. running mean: -465.819885\n",
      "startIDX:  2354\n",
      "18 22 True\n",
      "x_t:  1 [0.721875   0.31666667 0.153125   0.45      ]\n",
      "Q values:  tensor([[-24.0398, -26.1680, -27.7584, -22.8584, -24.3255, -21.6715]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22946 1044 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 18: ep_len:1044 episode reward: total was -770.200000. running mean: -468.863686\n",
      "startIDX:  1187\n",
      "19 0 False\n",
      "x_t:  3 [0.13125    0.25416667 0.06875    0.27916667]\n",
      "Q values:  tensor([[-32.6018, -28.2884, -29.3770, -20.9563, -28.9740, -30.5289]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15179 1280 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  459\n",
      "19 1 False\n",
      "x_t:  1 [0.61875    0.2875     0.178125   0.45416667]\n",
      "Q values:  tensor([[-25.3182, -24.9323, -31.5486, -27.3385, -25.0067, -25.4219]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30704 801 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1145\n",
      "19 5 True\n",
      "x_t:  2 [0.13125    0.3875     0.0625     0.27916667]\n",
      "Q values:  tensor([[-18.2450, -26.3801, -24.9635, -27.4428, -21.6248, -23.7424]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12021 891 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1639\n",
      "19 10 False\n",
      "x_t:  3 [0.909375   0.32083333 0.0875     0.4125    ]\n",
      "Q values:  tensor([[-27.1413, -24.9053, -26.2115, -17.2433, -24.6053, -20.7167]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16399 260 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  842\n",
      "19 12 False\n",
      "x_t:  0 [0.915625   0.40833333 0.08125    0.30416667]\n",
      "Q values:  tensor([[-18.4271, -22.1111, -20.3336, -24.5590, -25.8976, -20.7952]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11631 638 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3025\n",
      "startIDX:  2287\n",
      "19 22 False\n",
      "x_t:  1 [0.234375   0.3625     0.134375   0.45416667]\n",
      "Q values:  tensor([[-27.5941, -17.5199, -29.7709, -19.8788, -25.9511, -21.5099]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22991 1108 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  154.9750509262085\n",
      "startIDX:  614\n",
      "20 0 True\n",
      "x_t:  2 [0.003125   0.40833333 0.059375   0.275     ]\n",
      "Q values:  tensor([[-24.7499, -20.7645, -19.4595, -21.2398, -25.3313, -23.1528]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8869 911 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 20: ep_len:911 episode reward: total was -717.400000. running mean: -476.600979\n",
      "startIDX:  626\n",
      "20 1 True\n",
      "x_t:  2 [0.725      0.37916667 0.096875   0.31666667]\n",
      "Q values:  tensor([[-23.5828, -24.4284, -25.7189, -25.9099, -26.5218, -25.8105]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31477 371 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 20: ep_len:371 episode reward: total was -293.900000. running mean: -474.773969\n",
      "startIDX:  1821\n",
      "20 5 False\n",
      "x_t:  2 [0.834375   0.39583333 0.046875   0.2375    ]\n",
      "Q values:  tensor([[-22.5058, -25.4983, -20.9745, -24.7772, -21.6387, -22.1245]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15647 349 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 20: ep_len:349 episode reward: total was -281.300000. running mean: -472.839229\n",
      "startIDX:  380\n",
      "20 10 True\n",
      "x_t:  3 [0.625      0.29583333 0.134375   0.36666667]\n",
      "Q values:  tensor([[-24.8721, -25.5276, -18.6861, -26.1953, -19.9951, -20.2677]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5061 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 20: ep_len:201 episode reward: total was -166.500000. running mean: -469.775837\n",
      "startIDX:  1018\n",
      "20 12 False\n",
      "x_t:  2 [0.865625   0.39166667 0.065625   0.23333333]\n",
      "Q values:  tensor([[-24.6673, -21.5282, -17.7532, -22.6881, -28.3491, -22.0565]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13567 300 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 20: ep_len:300 episode reward: total was -244.100000. running mean: -467.519079\n",
      "startIDX:  854\n",
      "20 15 True\n",
      "x_t:  3 [0.06875    0.22916667 0.0625     0.2375    ]\n",
      "Q values:  tensor([[-28.0780, -36.1106, -31.4320, -45.0512, -34.7505, -30.8969]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8499 1229 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 20: ep_len:1229 episode reward: total was -1002.700000. running mean: -472.870888\n",
      "startIDX:  1172\n",
      "20 22 False\n",
      "x_t:  1 [0.8875     0.30416667 0.109375   0.5       ]\n",
      "Q values:  tensor([[-32.1799, -25.2856, -26.1690, -26.0611, -31.3759, -31.6669]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11916 710 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 20: ep_len:710 episode reward: total was -560.000000. running mean: -473.742179\n",
      "startIDX:  2232\n",
      "21 0 True\n",
      "x_t:  2 [0.8625     0.38333333 0.05       0.22083333]\n",
      "Q values:  tensor([[-26.1976, -25.6150, -30.3920, -27.4485, -27.9547, -26.5428]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23579 330 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  897\n",
      "21 1 True\n",
      "x_t:  4 [0.00625    0.39583333 0.11875    0.4       ]\n",
      "Q values:  tensor([[-22.8318, -30.2835, -28.2663, -26.5371, -30.9441, -24.1172]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35424 520 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1270\n",
      "21 5 True\n",
      "x_t:  2 [0.15     0.4      0.078125 0.275   ]\n",
      "Q values:  tensor([[-30.4101, -29.1666, -28.5945, -28.0022, -34.4586, -26.5020]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12023 719 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1988\n",
      "21 10 False\n",
      "x_t:  1 [0.1        0.34166667 0.146875   0.375     ]\n",
      "Q values:  tensor([[-25.2324, -16.6051, -18.3053, -25.3503, -25.5073, -19.6744]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18823 319 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1193\n",
      "21 12 False\n",
      "x_t:  4 [0.196875   0.425      0.13125    0.34583333]\n",
      "Q values:  tensor([[-24.9457, -27.0081, -30.6010, -25.9529, -24.1041, -25.3042]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17412 513 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3090\n",
      "startIDX:  908\n",
      "21 22 True\n",
      "x_t:  1 [0.1375     0.35416667 0.1375     0.40416667]\n",
      "Q values:  tensor([[-29.2703, -25.4602, -27.5047, -24.8223, -34.7432, -30.1633]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9496 244 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1486\n",
      "22 0 False\n",
      "x_t:  3 [0.696875   0.34166667 0.1625     0.4       ]\n",
      "Q values:  tensor([[-24.7273, -28.8648, -29.5775, -24.6687, -36.1824, -34.4594]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16828 275 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 22: ep_len:275 episode reward: total was -208.600000. running mean: -459.361784\n",
      "startIDX:  494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 1 False\n",
      "x_t:  1 [0.85625    0.26666667 0.140625   0.45833333]\n",
      "Q values:  tensor([[-31.8076, -23.6590, -25.4914, -31.2738, -26.1834, -25.8281]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30680 749 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 22: ep_len:749 episode reward: total was -604.000000. running mean: -460.808167\n",
      "startIDX:  1581\n",
      "22 5 False\n",
      "x_t:  1 [0.8125     0.28333333 0.115625   0.31666667]\n",
      "Q values:  tensor([[-24.5998, -18.6156, -23.0535, -26.7284, -23.7748, -30.1036]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14929 688 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 22: ep_len:688 episode reward: total was -514.300000. running mean: -461.343085\n",
      "startIDX:  37\n",
      "22 10 False\n",
      "x_t:  3 [0.059375   0.24166667 0.05625    0.25      ]\n",
      "Q values:  tensor([[-26.4179, -24.0243, -30.3325, -21.8195, -24.2476, -32.8577]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3577 1088 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 22: ep_len:1088 episode reward: total was -806.700000. running mean: -464.796654\n",
      "startIDX:  927\n",
      "22 12 False\n",
      "x_t:  1 [0.821875   0.35416667 0.1375     0.5125    ]\n",
      "Q values:  tensor([[-25.5270, -20.9605, -27.4883, -23.5871, -29.2640, -28.4606]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12916 604 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 22: ep_len:604 episode reward: total was -479.900000. running mean: -464.947688\n",
      "startIDX:  698\n",
      "22 15 False\n",
      "x_t:  2 [0.7        0.40416667 0.109375   0.3       ]\n",
      "Q values:  tensor([[-29.4425, -31.4547, -23.9532, -28.8340, -26.2739, -24.9530]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5982 406 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 22: ep_len:406 episode reward: total was -307.700000. running mean: -463.375211\n",
      "startIDX:  1044\n",
      "22 22 False\n",
      "x_t:  0 [0.7625     0.4125     0.1125     0.32083333]\n",
      "Q values:  tensor([[-20.8732, -27.5378, -21.8268, -21.6049, -24.2644, -24.2660]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10418 414 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 22: ep_len:414 episode reward: total was -332.100000. running mean: -462.062459\n",
      "startIDX:  2405\n",
      "23 0 False\n",
      "x_t:  3 [0.115625   0.24166667 0.059375   0.25833333]\n",
      "Q values:  tensor([[-23.8630, -27.1937, -23.4377, -20.6595, -25.7064, -21.3176]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26108 1212 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  611\n",
      "23 1 False\n",
      "x_t:  2 [0.809375   0.38333333 0.10625    0.30833333]\n",
      "Q values:  tensor([[-23.8421, -23.5910, -20.9254, -24.2402, -23.9238, -22.2403]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31461 372 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  958\n",
      "23 5 True\n",
      "x_t:  3 [0.875      0.32916667 0.11875    0.41666667]\n",
      "Q values:  tensor([[-21.6331, -26.1781, -23.3610, -24.6249, -20.6087, -28.6253]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10483 210 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1711\n",
      "23 10 False\n",
      "x_t:  3 [0.909375   0.32083333 0.0875     0.4125    ]\n",
      "Q values:  tensor([[-29.9014, -25.5778, -30.1346, -25.1905, -30.1056, -33.4055]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16399 237 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1212\n",
      "23 12 True\n",
      "x_t:  4 [0.059375   0.44166667 0.146875   0.35833333]\n",
      "Q values:  tensor([[-29.5364, -29.7178, -28.9330, -27.9793, -27.6535, -32.4161]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17397 499 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  19\n",
      "23 15 False\n",
      "x_t:  3 [0.74375 0.3375  0.09375 0.4125 ]\n",
      "Q values:  tensor([[-27.4237, -24.6189, -28.8093, -23.1718, -32.4374, -26.5725]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 536 251 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  43\n",
      "23 22 True\n",
      "x_t:  1 [0.853125   0.30833333 0.140625   0.40833333]\n",
      "Q values:  tensor([[-26.7998, -27.0331, -28.5235, -24.0966, -26.8279, -26.7011]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1580 704 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  522\n",
      "24 0 False\n",
      "x_t:  3 [0.828125   0.39583333 0.165625   0.425     ]\n",
      "Q values:  tensor([[-27.6752, -34.7976, -37.6713, -25.1232, -34.9364, -28.6554]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 6990 1014 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 24: ep_len:1014 episode reward: total was -794.400000. running mean: -460.162275\n",
      "startIDX:  607\n",
      "24 1 False\n",
      "x_t:  2 [0.746875   0.37916667 0.1        0.31666667]\n",
      "Q values:  tensor([[-28.5127, -29.2950, -26.5678, -28.4333, -33.5393, -27.7564]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31471 368 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 24: ep_len:368 episode reward: total was -287.600000. running mean: -458.436652\n",
      "startIDX:  243\n",
      "24 5 True\n",
      "x_t:  1 [0.0375     0.37083333 0.209375   0.49583333]\n",
      "Q values:  tensor([[-32.0509, -26.8971, -33.9662, -25.4553, -33.3007, -33.8391]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2518 208 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 24: ep_len:208 episode reward: total was -167.900000. running mean: -455.531286\n",
      "startIDX:  1546\n",
      "24 10 True\n",
      "x_t:  3 [0.69375    0.29166667 0.08125    0.38333333]\n",
      "Q values:  tensor([[-27.7550, -28.9535, -31.9723, -25.6840, -26.1632, -23.1819]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16426 324 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 24: ep_len:324 episode reward: total was -225.800000. running mean: -453.233973\n",
      "startIDX:  991\n",
      "24 12 False\n",
      "x_t:  2 [0.8        0.4125     0.09375    0.24583333]\n",
      "Q values:  tensor([[-23.0986, -27.6544, -19.8489, -28.0362, -26.2644, -23.9133]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13573 311 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 24: ep_len:311 episode reward: total was -255.000000. running mean: -451.251633\n",
      "startIDX:  1290\n",
      "24 15 False\n",
      "x_t:  3 [0.915625   0.35       0.078125   0.38333333]\n",
      "Q values:  tensor([[-29.1951, -19.1058, -23.4423, -18.5822, -23.4473, -28.2573]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10334 227 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 24: ep_len:227 episode reward: total was -157.400000. running mean: -448.313117\n",
      "startIDX:  672\n",
      "24 22 False\n",
      "x_t:  2 [0.003125   0.41666667 0.078125   0.25416667]\n",
      "Q values:  tensor([[-24.6796, -23.1982, -17.3233, -24.3437, -21.9736, -24.2319]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8914 906 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 24: ep_len:906 episode reward: total was -685.500000. running mean: -450.684985\n",
      "startIDX:  2273\n",
      "25 0 False\n",
      "x_t:  2 [0.9125     0.37916667 0.046875   0.15833333]\n",
      "Q values:  tensor([[-26.2020, -24.5818, -23.0211, -29.0243, -26.6145, -23.1968]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23569 313 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  380\n",
      "25 1 False\n",
      "x_t:  1 [0.565625   0.30833333 0.2375     0.5625    ]\n",
      "Q values:  tensor([[-29.2624, -22.5585, -24.3516, -24.1494, -23.9943, -29.8392]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28102 287 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1904\n",
      "25 5 True\n",
      "x_t:  2 [0.640625 0.4      0.08125  0.25    ]\n",
      "Q values:  tensor([[-17.9908, -18.5034, -23.8268, -25.1316, -23.7815, -23.0628]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15674 329 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  64\n",
      "25 10 False\n",
      "x_t:  3 [0.09375    0.2375     0.065625   0.27083333]\n",
      "Q values:  tensor([[-25.6585, -22.0001, -25.1599, -20.0731, -23.3581, -22.6893]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3592 1068 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  781\n",
      "25 12 False\n",
      "x_t:  1 [0.74375    0.32083333 0.096875   0.5375    ]\n",
      "Q values:  tensor([[-21.0860, -17.6578, -20.6102, -20.0537, -20.7220, -24.0775]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10351 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2311\n",
      "25 15 False\n",
      "x_t:  3 [0.121875   0.27916667 0.09375    0.31666667]\n",
      "Q values:  tensor([[-35.9821, -28.5995, -29.4338, -26.5313, -30.4880, -27.9516]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18188 1237 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  374\n",
      "25 22 False\n",
      "x_t:  3 [0.059375   0.2375     0.059375   0.24166667]\n",
      "Q values:  tensor([[-29.5240, -33.7177, -31.7623, -26.9950, -31.4187, -28.7047]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4870 1238 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  130\n",
      "26 0 False\n",
      "x_t:  1 [0.853125   0.3        0.1        0.43333333]\n",
      "Q values:  tensor([[-35.4104, -23.1228, -36.0912, -30.8588, -30.4240, -29.0533]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1614 689 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 26: ep_len:689 episode reward: total was -548.600000. running mean: -457.065753\n",
      "startIDX:  30\n",
      "26 1 False\n",
      "x_t:  3 [0.403125   0.2625     0.109375   0.34166667]\n",
      "Q values:  tensor([[-32.0340, -28.9436, -28.5053, -27.3083, -31.7532, -29.5320]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25703 206 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 26: ep_len:206 episode reward: total was -150.000000. running mean: -453.995096\n",
      "startIDX:  2690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 5 False\n",
      "x_t:  1 [0.175      0.33333333 0.109375   0.50833333]\n",
      "Q values:  tensor([[-23.1162, -20.8202, -22.3685, -24.5961, -27.2303, -25.4094]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22120 239 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 26: ep_len:239 episode reward: total was -191.600000. running mean: -451.371145\n",
      "startIDX:  922\n",
      "26 10 True\n",
      "x_t:  1 [0.671875 0.2875   0.121875 0.3375  ]\n",
      "Q values:  tensor([[-31.0581, -30.8185, -28.7342, -34.5545, -29.4797, -29.7178]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11353 1603 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 26: ep_len:1603 episode reward: total was -1219.100000. running mean: -459.048433\n",
      "startIDX:  1395\n",
      "26 12 False\n",
      "x_t:  3 [0.684375   0.35       0.14375    0.42916667]\n",
      "Q values:  tensor([[-29.3655, -29.1411, -32.3988, -21.6644, -29.9588, -27.3720]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17861 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 26: ep_len:202 episode reward: total was -151.400000. running mean: -455.971949\n",
      "startIDX:  717\n",
      "26 15 True\n",
      "x_t:  2 [0.80625    0.40416667 0.075      0.29583333]\n",
      "Q values:  tensor([[-28.5218, -29.0073, -31.9759, -30.0194, -26.0689, -28.7069]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5966 385 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 26: ep_len:385 episode reward: total was -294.700000. running mean: -454.359229\n",
      "startIDX:  1110\n",
      "26 22 True\n",
      "x_t:  1 [0.75625    0.31666667 0.1875     0.49166667]\n",
      "Q values:  tensor([[-26.7751, -25.5379, -18.1142, -16.2243, -17.9551, -22.5831]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11924 731 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 26: ep_len:731 episode reward: total was -544.800000. running mean: -455.263637\n",
      "startIDX:  2340\n",
      "27 0 False\n",
      "x_t:  3 [0.15625    0.25       0.065625   0.25833333]\n",
      "Q values:  tensor([[-25.4517, -26.5398, -25.3724, -24.4095, -25.7751, -24.8403]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26119 1237 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  263\n",
      "27 1 True\n",
      "x_t:  2 [0.003125   0.375      0.096875   0.42916667]\n",
      "Q values:  tensor([[-20.5627, -27.2516, -20.6596, -22.9746, -19.7067, -18.9180]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27430 820 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1815\n",
      "27 5 False\n",
      "x_t:  2 [0.778125   0.4        0.084375   0.24583333]\n",
      "Q values:  tensor([[-22.8138, -24.2433, -20.2402, -26.4841, -20.8632, -22.7194]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15654 360 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1551\n",
      "27 10 False\n",
      "x_t:  3 [0.53125  0.2875   0.065625 0.35    ]\n",
      "Q values:  tensor([[-20.8360, -28.5992, -26.4344, -20.3485, -22.7549, -21.2326]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16452 338 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1260\n",
      "27 12 True\n",
      "x_t:  4 [0.1625     0.42083333 0.125      0.36666667]\n",
      "Q values:  tensor([[-24.4978, -31.9919, -24.6818, -29.2041, -28.7825, -26.1352]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17406 479 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1584\n",
      "27 15 False\n",
      "x_t:  2 [0.003125   0.4125     0.071875   0.25416667]\n",
      "Q values:  tensor([[-20.4954, -23.2032, -17.3498, -17.5424, -20.4890, -19.3367]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 11907 730 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2376\n",
      "27 22 False\n",
      "x_t:  1 [0.86875    0.3        0.128125   0.45833333]\n",
      "Q values:  tensor([[-25.3603, -19.2062, -26.9232, -25.0691, -27.9731, -24.1004]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22931 1067 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  983\n",
      "28 0 False\n",
      "x_t:  1 [0.85625    0.30416667 0.128125   0.42916667]\n",
      "Q values:  tensor([[-29.2270, -26.4668, -31.5449, -32.7846, -34.4489, -27.3264]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11948 804 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 28: ep_len:804 episode reward: total was -659.800000. running mean: -465.143266\n",
      "startIDX:  654\n",
      "28 1 False\n",
      "x_t:  2 [0.746875   0.37916667 0.1        0.31666667]\n",
      "Q values:  tensor([[-28.8413, -30.0246, -28.4507, -34.9790, -34.3781, -30.9559]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31471 362 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 28: ep_len:362 episode reward: total was -309.800000. running mean: -463.589833\n",
      "startIDX:  2423\n",
      "28 5 False\n",
      "x_t:  2 [0.003125   0.39583333 0.071875   0.27083333]\n",
      "Q values:  tensor([[-31.7237, -31.2482, -22.7526, -27.8463, -27.9021, -26.3032]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21546 941 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 28: ep_len:941 episode reward: total was -764.500000. running mean: -466.598935\n",
      "startIDX:  398\n",
      "28 10 True\n",
      "x_t:  3 [0.546875 0.2875   0.121875 0.35    ]\n",
      "Q values:  tensor([[-29.9636, -29.5927, -31.2186, -36.5371, -28.1932, -34.5536]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5072 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 28: ep_len:202 episode reward: total was -156.700000. running mean: -463.499946\n",
      "startIDX:  1460\n",
      "28 12 True\n",
      "x_t:  3 [0.2375   0.275    0.053125 0.275   ]\n",
      "Q values:  tensor([[-33.1055, -24.1600, -24.9104, -31.1911, -20.9114, -25.0774]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17949 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 28: ep_len:203 episode reward: total was -158.200000. running mean: -460.446946\n",
      "startIDX:  1046\n",
      "28 15 False\n",
      "x_t:  4 [0.0125     0.39166667 0.090625   0.29583333]\n",
      "Q values:  tensor([[-37.2742, -33.9796, -36.5253, -36.6782, -29.2854, -36.0897]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9814 596 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 28: ep_len:596 episode reward: total was -470.300000. running mean: -460.545477\n",
      "startIDX:  2859\n",
      "ep 28: ep_len:79 episode reward: total was -51.000000. running mean: -456.450022\n",
      "startIDX:  1590\n",
      "29 0 False\n",
      "x_t:  3 [0.43125    0.3125     0.1125     0.34583333]\n",
      "Q values:  tensor([[-34.7700, -24.5367, -28.9351, -23.2728, -28.3168, -34.3581]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16868 231 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1091\n",
      "29 1 False\n",
      "x_t:  3 [0.603125   0.29583333 0.115625   0.36666667]\n",
      "Q values:  tensor([[-33.0760, -32.5084, -32.2728, -30.8098, -32.0929, -32.8877]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35940 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1802\n",
      "29 5 False\n",
      "x_t:  2 [0.834375   0.39583333 0.059375   0.24583333]\n",
      "Q values:  tensor([[-27.3404, -29.5144, -24.1286, -28.4843, -30.0625, -28.3400]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15645 361 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1228\n",
      "29 10 False\n",
      "x_t:  3 [0.059375   0.22083333 0.05       0.2375    ]\n",
      "Q values:  tensor([[-23.5041, -22.0165, -24.0608, -21.2094, -22.2696, -22.2655]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14571 1236 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1274\n",
      "29 12 True\n",
      "x_t:  4 [0.1125     0.42083333 0.09375    0.36666667]\n",
      "Q values:  tensor([[-32.0656, -26.5763, -29.7390, -20.5236, -33.9301, -22.3851]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17401 462 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  433\n",
      "29 15 False\n",
      "x_t:  0 [0.7625   0.4      0.121875 0.35    ]\n",
      "Q values:  tensor([[-21.9160, -29.5443, -24.6803, -28.8696, -29.5829, -25.2438]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3676 442 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2001\n",
      "29 22 False\n",
      "x_t:  1 [0.096875   0.36666667 0.15       0.38333333]\n",
      "Q values:  tensor([[-24.4253, -23.2472, -27.4072, -24.4666, -28.5262, -27.8535]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19001 267 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  231.51407313346863\n",
      "startIDX:  1403\n",
      "30 0 False\n",
      "x_t:  4 [0.015625   0.38333333 0.08125    0.29166667]\n",
      "Q values:  tensor([[-34.4131, -28.8518, -35.7892, -29.2054, -27.5996, -32.9838]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16288 526 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 30: ep_len:526 episode reward: total was -391.400000. running mean: -447.779193\n",
      "startIDX:  465\n",
      "30 1 False\n",
      "x_t:  1 [0.859375   0.25833333 0.1375     0.47083333]\n",
      "Q values:  tensor([[-26.2223, -18.4697, -20.4280, -21.5341, -27.4735, -20.7950]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30678 771 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 30: ep_len:771 episode reward: total was -566.400000. running mean: -448.965401\n",
      "startIDX:  2052\n",
      "30 5 False\n",
      "x_t:  3 [0.0625     0.25       0.084375   0.27083333]\n",
      "Q values:  tensor([[-22.5813, -22.5619, -22.3420, -20.9985, -23.8467, -22.5170]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18204 1229 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 30: ep_len:1229 episode reward: total was -896.300000. running mean: -453.438747\n",
      "startIDX:  1593\n",
      "30 10 False\n",
      "x_t:  3 [0.821875   0.32083333 0.128125   0.39166667]\n",
      "Q values:  tensor([[-30.8070, -29.7229, -28.7581, -24.9297, -31.0810, -29.3657]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16408 299 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 30: ep_len:299 episode reward: total was -213.700000. running mean: -451.041360\n",
      "startIDX:  1505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 12 False\n",
      "x_t:  2 [0.00625    0.4125     0.10625    0.28333333]\n",
      "Q values:  tensor([[-31.2568, -24.0247, -20.0846, -22.5743, -28.2659, -26.1909]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19381 759 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 30: ep_len:759 episode reward: total was -552.500000. running mean: -452.055946\n",
      "startIDX:  389\n",
      "30 15 True\n",
      "x_t:  0 [0.765625   0.40416667 0.0625     0.34583333]\n",
      "Q values:  tensor([[-32.0460, -25.9196, -24.9648, -26.2177, -25.5247, -28.1956]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3682 457 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 30: ep_len:457 episode reward: total was -359.700000. running mean: -451.132387\n",
      "startIDX:  1602\n",
      "30 22 False\n",
      "x_t:  3 [0.878125   0.35416667 0.11875    0.40833333]\n",
      "Q values:  tensor([[-26.1041, -29.8621, -30.2975, -24.7697, -25.8311, -28.8265]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16842 259 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 30: ep_len:259 episode reward: total was -195.900000. running mean: -448.580063\n",
      "startIDX:  2145\n",
      "31 0 False\n",
      "x_t:  1 [0.853125   0.3125     0.14375    0.53333333]\n",
      "Q values:  tensor([[-25.2526, -24.6288, -28.8986, -31.8927, -32.6748, -29.2455]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22918 1104 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  727\n",
      "31 1 False\n",
      "x_t:  3 [0.065625   0.22916667 0.0625     0.28333333]\n",
      "Q values:  tensor([[-33.7040, -34.5629, -31.2999, -25.8368, -30.6391, -30.9130]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34303 1415 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2960\n",
      "startIDX:  277\n",
      "31 10 False\n",
      "x_t:  3 [0.61875    0.30416667 0.13125    0.35416667]\n",
      "Q values:  tensor([[-27.7352, -38.8905, -35.4540, -26.3136, -33.3472, -36.2784]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5063 259 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1649\n",
      "31 12 True\n",
      "x_t:  1 [0.05625    0.36666667 0.13125    0.35833333]\n",
      "Q values:  tensor([[-29.6121, -28.9312, -37.9165, -28.8278, -24.2613, -33.0930]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19878 254 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3140\n",
      "startIDX:  2081\n",
      "31 22 True\n",
      "x_t:  1 [0.0375     0.36666667 0.096875   0.39166667]\n",
      "Q values:  tensor([[-38.7710, -35.1271, -39.9939, -32.3225, -35.7501, -35.8469]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18992 215 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2062\n",
      "32 0 False\n",
      "x_t:  0 [0.846875   0.4        0.128125   0.35416667]\n",
      "Q values:  tensor([[-25.1462, -34.2165, -28.0542, -32.2604, -27.5495, -25.6995]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20633 830 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 32: ep_len:830 episode reward: total was -661.200000. running mean: -444.979397\n",
      "startIDX:  562\n",
      "32 1 True\n",
      "x_t:  1 [0.75       0.275      0.165625   0.45416667]\n",
      "Q values:  tensor([[-26.1998, -25.7669, -29.8458, -28.4940, -30.9807, -25.4809]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30692 729 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 32: ep_len:729 episode reward: total was -586.600000. running mean: -446.395603\n",
      "startIDX:  2483\n",
      "32 5 False\n",
      "x_t:  2 [0.103125   0.39583333 0.09375    0.26666667]\n",
      "Q values:  tensor([[-23.9051, -23.3229, -22.6415, -26.1318, -25.3428, -25.4118]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21564 829 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 32: ep_len:829 episode reward: total was -641.300000. running mean: -448.344647\n",
      "startIDX:  1440\n",
      "32 10 False\n",
      "x_t:  4 [0.003125   0.36666667 0.090625   0.27916667]\n",
      "Q values:  tensor([[-27.3835, -27.4415, -25.6659, -26.5555, -20.7347, -23.9624]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15703 506 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 32: ep_len:506 episode reward: total was -433.600000. running mean: -448.197201\n",
      "startIDX:  1406\n",
      "32 12 False\n",
      "x_t:  3 [0.33125    0.28333333 0.08125    0.31666667]\n",
      "Q values:  tensor([[-27.4696, -24.8740, -28.5341, -24.4493, -26.0239, -25.0011]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17926 232 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 32: ep_len:232 episode reward: total was -174.100000. running mean: -445.456229\n",
      "startIDX:  2899\n",
      "32 15 True\n",
      "x_t:  0 [0.85625    0.40416667 0.1125     0.34583333]\n",
      "Q values:  tensor([[-25.1735, -24.5995, -31.1901, -35.0419, -33.7923, -33.8354]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23075 509 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 32: ep_len:509 episode reward: total was -407.900000. running mean: -445.080667\n",
      "startIDX:  1707\n",
      "32 22 False\n",
      "x_t:  3 [0.6875   0.3375   0.134375 0.3875  ]\n",
      "Q values:  tensor([[-21.2175, -22.7511, -30.9564, -20.6512, -24.2558, -28.3443]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16867 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 32: ep_len:204 episode reward: total was -139.700000. running mean: -442.026860\n",
      "startIDX:  1078\n",
      "33 0 False\n",
      "x_t:  1 [0.796875   0.29583333 0.090625   0.4375    ]\n",
      "Q values:  tensor([[-25.2293, -22.8087, -23.6436, -28.2144, -25.0721, -24.1244]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11957 753 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  711\n",
      "33 1 False\n",
      "x_t:  3 [0.078125   0.23333333 0.08125    0.29166667]\n",
      "Q values:  tensor([[-25.7503, -25.6495, -24.2011, -21.3763, -25.9719, -22.8001]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34308 1405 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1201\n",
      "33 5 True\n",
      "x_t:  2 [0.25625    0.39583333 0.09375    0.28333333]\n",
      "Q values:  tensor([[-24.3361, -31.7690, -21.6252, -26.9087, -26.5513, -23.1563]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12038 772 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  646\n",
      "33 10 False\n",
      "x_t:  2 [0.003125   0.40833333 0.103125   0.25      ]\n",
      "Q values:  tensor([[-33.8199, -30.0510, -28.5884, -29.3998, -32.8040, -30.6455]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6586 718 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  997\n",
      "33 12 False\n",
      "x_t:  2 [0.7875     0.40833333 0.0625     0.25      ]\n",
      "Q values:  tensor([[-26.1946, -32.8222, -21.8188, -27.2407, -28.1728, -27.0397]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13579 317 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3073\n",
      "startIDX:  1241\n",
      "33 22 False\n",
      "x_t:  2 [0.846875   0.39583333 0.065625   0.23333333]\n",
      "Q values:  tensor([[-32.0560, -32.0354, -29.4157, -30.0740, -32.4665, -33.7062]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12582 314 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1278\n",
      "34 0 True\n",
      "x_t:  3 [0.1125     0.24583333 0.059375   0.27083333]\n",
      "Q values:  tensor([[-18.3602, -16.6951, -22.6801, -22.1584, -21.5826, -15.1485]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15173 1202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 34: ep_len:1202 episode reward: total was -895.400000. running mean: -448.680221\n",
      "startIDX:  1036\n",
      "34 1 False\n",
      "x_t:  3 [0.83125    0.30833333 0.10625    0.41666667]\n",
      "Q values:  tensor([[-23.6165, -24.7832, -27.1663, -16.2701, -26.1946, -24.1988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35903 211 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 34: ep_len:211 episode reward: total was -151.100000. running mean: -445.704418\n",
      "startIDX:  229\n",
      "34 5 True\n",
      "x_t:  1 [0.490625   0.32916667 0.196875   0.5375    ]\n",
      "Q values:  tensor([[-25.8778, -30.9942, -33.0906, -28.6216, -27.3126, -27.8754]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2547 227 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 34: ep_len:227 episode reward: total was -183.400000. running mean: -443.081374\n",
      "startIDX:  1509\n",
      "34 10 False\n",
      "x_t:  3 [0.834375   0.33333333 0.15       0.3875    ]\n",
      "Q values:  tensor([[-31.8233, -28.6439, -26.6081, -24.8592, -27.9078, -25.9851]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16405 337 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 34: ep_len:337 episode reward: total was -222.500000. running mean: -440.875560\n",
      "startIDX:  1483\n",
      "34 12 True\n",
      "x_t:  2 [0.003125   0.41666667 0.096875   0.27916667]\n",
      "Q values:  tensor([[-31.8094, -27.8214, -29.4535, -26.1074, -28.5526, -30.7085]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19377 757 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 34: ep_len:757 episode reward: total was -581.600000. running mean: -442.282805\n",
      "startIDX:  1050\n",
      "34 15 False\n",
      "x_t:  4 [0.003125   0.4        0.065625   0.29166667]\n",
      "Q values:  tensor([[-25.2637, -25.7031, -25.4566, -27.6147, -25.1721, -26.7420]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9808 590 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 34: ep_len:590 episode reward: total was -437.300000. running mean: -442.232977\n",
      "startIDX:  2638\n",
      "34 22 False\n",
      "x_t:  4 [0.11875    0.39166667 0.115625   0.31666667]\n",
      "Q values:  tensor([[-27.8780, -29.0490, -24.7396, -25.6955, -23.2592, -28.0749]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27282 542 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 34: ep_len:542 episode reward: total was -414.500000. running mean: -441.955647\n",
      "startIDX:  1695\n",
      "35 0 False\n",
      "x_t:  3 [0.259375   0.26666667 0.096875   0.30833333]\n",
      "Q values:  tensor([[-30.7170, -27.2535, -27.1979, -25.4604, -27.3751, -29.4927]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16906 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  108\n",
      "35 1 False\n",
      "x_t:  3 [0.065625   0.225      0.0625     0.26666667]\n",
      "Q values:  tensor([[-28.5535, -29.0789, -27.1373, -23.9050, -26.0305, -25.6332]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25796 207 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1837\n",
      "35 5 True\n",
      "x_t:  2 [0.8125     0.4        0.075      0.25833333]\n",
      "Q values:  tensor([[-33.0404, -26.3296, -31.8671, -27.5845, -21.6263, -30.3699]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15649 347 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  742\n",
      "35 10 False\n",
      "x_t:  1 [0.1      0.35     0.128125 0.375   ]\n",
      "Q values:  tensor([[-34.9788, -25.9926, -29.3073, -28.5588, -29.4537, -26.4209]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7115 224 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  9\n",
      "35 12 True\n",
      "x_t:  1 [0.790625 0.3125   0.078125 0.425   ]\n",
      "Q values:  tensor([[-25.6353, -24.4786, -25.6861, -25.2467, -23.9538, -24.8882]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2226 661 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3150\n",
      "startIDX:  38\n",
      "35 22 True\n",
      "x_t:  1 [0.934375   0.2875     0.0625     0.41666667]\n",
      "Q values:  tensor([[-28.8160, -27.8839, -29.5809, -27.9892, -28.5025, -25.3424]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1575 708 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2216\n",
      "36 0 False\n",
      "x_t:  1 [0.859375   0.3        0.134375   0.54166667]\n",
      "Q values:  tensor([[-25.6688, -20.4316, -22.7701, -26.7778, -21.4786, -20.4681]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22917 1084 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 36: ep_len:1084 episode reward: total was -895.200000. running mean: -434.835339\n",
      "startIDX:  1041\n",
      "36 1 False\n",
      "x_t:  3 [0.878125   0.30833333 0.115625   0.42916667]\n",
      "Q values:  tensor([[-28.0097, -26.1808, -24.9033, -18.2002, -20.6057, -28.9026]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35894 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 36: ep_len:204 episode reward: total was -140.300000. running mean: -431.889986\n",
      "startIDX:  662\n",
      "36 5 True\n",
      "x_t:  3 [0.075      0.25833333 0.08125    0.31666667]\n",
      "Q values:  tensor([[-27.4400, -26.5376, -33.6885, -29.9470, -29.5004, -32.0792]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8751 1319 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 36: ep_len:1319 episode reward: total was -1055.400000. running mean: -438.125086\n",
      "startIDX:  82\n",
      "36 10 True\n",
      "x_t:  3 [0.134375   0.24166667 0.075      0.28333333]\n",
      "Q values:  tensor([[-31.5228, -32.9727, -27.5252, -31.0600, -27.1163, -31.3422]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3605 1102 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 36: ep_len:1102 episode reward: total was -864.500000. running mean: -442.388835\n",
      "startIDX:  1993\n",
      "ep 36: ep_len:50 episode reward: total was -39.600000. running mean: -438.360947\n",
      "startIDX:  943\n",
      "36 15 False\n",
      "x_t:  4 [0.003125 0.4      0.078125 0.2875  ]\n",
      "Q values:  tensor([[-32.4779, -32.8695, -32.7665, -33.6904, -27.8637, -30.7043]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9809 644 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 36: ep_len:644 episode reward: total was -486.500000. running mean: -438.842337\n",
      "startIDX:  1778\n",
      "36 22 False\n",
      "x_t:  3 [0.30625 0.275   0.11875 0.3125 ]\n",
      "Q values:  tensor([[-26.0185, -26.0188, -29.7043, -25.3477, -28.0869, -28.2812]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16932 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 36: ep_len:204 episode reward: total was -152.900000. running mean: -435.982914\n",
      "startIDX:  2278\n",
      "37 0 False\n",
      "x_t:  2 [0.775      0.40416667 0.096875   0.2375    ]\n",
      "Q values:  tensor([[-37.1542, -38.3225, -34.4280, -41.5140, -37.7834, -42.0150]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23592 312 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  296\n",
      "37 1 True\n",
      "x_t:  1 [0.6375     0.2875     0.175      0.58333333]\n",
      "Q values:  tensor([[-32.9115, -32.5097, -29.1277, -35.6820, -27.6736, -34.1476]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28107 332 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  231\n",
      "37 5 False\n",
      "x_t:  1 [0.021875   0.3625     0.203125   0.50833333]\n",
      "Q values:  tensor([[-31.8754, -31.3842, -31.8578, -37.8449, -38.5857, -32.4550]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2517 211 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1892\n",
      "37 10 False\n",
      "x_t:  2 [0.134375   0.40416667 0.084375   0.24583333]\n",
      "Q values:  tensor([[-21.3226, -22.0112, -17.6075, -24.8939, -21.8467, -20.3062]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18168 821 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  668\n",
      "37 12 False\n",
      "x_t:  1 [0.20625 0.375   0.23125 0.5    ]\n",
      "Q values:  tensor([[-34.1784, -29.3630, -38.4735, -34.5532, -35.3757, -31.9723]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10319 243 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  33\n",
      "37 15 True\n",
      "x_t:  3 [0.81875    0.34166667 0.09375    0.42916667]\n",
      "Q values:  tensor([[-30.3704, -35.3749, -33.9914, -32.9272, -36.4564, -30.1480]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 526 242 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1182\n",
      "37 22 False\n",
      "x_t:  1 [0.615625   0.34166667 0.184375   0.47916667]\n",
      "Q values:  tensor([[-25.9793, -21.4688, -28.2229, -26.2587, -31.9628, -26.1130]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11936 705 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  303\n",
      "38 0 False\n",
      "x_t:  3 [0.078125   0.23333333 0.059375   0.2375    ]\n",
      "Q values:  tensor([[-21.0585, -23.7442, -23.3425, -19.8593, -30.0371, -21.0389]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4840 1236 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 38: ep_len:1236 episode reward: total was -820.500000. running mean: -430.948152\n",
      "startIDX:  938\n",
      "38 1 False\n",
      "x_t:  4 [0.00625    0.39583333 0.11875    0.4       ]\n",
      "Q values:  tensor([[-27.9963, -33.7889, -31.0616, -22.6209, -22.3915, -27.8430]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35424 498 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 38: ep_len:498 episode reward: total was -356.900000. running mean: -430.207670\n",
      "startIDX:  1570\n",
      "38 5 False\n",
      "x_t:  1 [0.81875    0.28333333 0.1        0.325     ]\n",
      "Q values:  tensor([[-24.1801, -22.5504, -23.3443, -24.5507, -25.9598, -25.8732]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14930 701 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 38: ep_len:701 episode reward: total was -495.800000. running mean: -430.863594\n",
      "startIDX:  1083\n",
      "38 10 True\n",
      "x_t:  2 [0.859375   0.38333333 0.075      0.26666667]\n",
      "Q values:  tensor([[-24.3318, -31.6407, -26.4556, -20.9255, -27.2560, -26.7734]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12054 352 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 38: ep_len:352 episode reward: total was -263.200000. running mean: -429.186958\n",
      "startIDX:  509\n",
      "38 12 False\n",
      "x_t:  3 [0.809375   0.375      0.1625     0.40416667]\n",
      "Q values:  tensor([[-22.2922, -25.4596, -29.5032, -20.5203, -27.5326, -28.5190]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7713 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 38: ep_len:202 episode reward: total was -151.600000. running mean: -426.411088\n",
      "startIDX:  1262\n",
      "38 15 False\n",
      "x_t:  3 [0.915625   0.35       0.078125   0.38333333]\n",
      "Q values:  tensor([[-30.5467, -33.8324, -33.2028, -27.3625, -31.3513, -29.1775]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10334 238 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 38: ep_len:238 episode reward: total was -182.300000. running mean: -423.969977\n",
      "startIDX:  1657\n",
      "38 22 False\n",
      "x_t:  3 [0.815625   0.3375     0.10625    0.41666667]\n",
      "Q values:  tensor([[-22.6522, -21.7693, -24.4327, -21.4993, -25.6455, -26.0642]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16852 225 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 38: ep_len:225 episode reward: total was -165.100000. running mean: -421.381278\n",
      "startIDX:  1342\n",
      "39 0 True\n",
      "x_t:  4 [0.046875   0.39166667 0.1375     0.28333333]\n",
      "Q values:  tensor([[-24.9907, -23.8125, -21.9000, -25.2654, -24.8969, -24.0038]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16296 567 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  552\n",
      "39 1 False\n",
      "x_t:  1 [0.859375   0.25833333 0.1375     0.47083333]\n",
      "Q values:  tensor([[-21.2320, -18.3585, -23.3572, -23.6471, -22.7570, -23.4667]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30678 738 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2105\n",
      "39 5 False\n",
      "x_t:  4 [0.225      0.40416667 0.096875   0.41666667]\n",
      "Q values:  tensor([[-21.6576, -25.3288, -23.1293, -27.1673, -20.9122, -24.6369]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19483 631 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  330\n",
      "39 10 False\n",
      "x_t:  3 [0.728125   0.3        0.1375     0.39583333]\n",
      "Q values:  tensor([[-28.4020, -23.8571, -25.0222, -23.1541, -32.2199, -27.6459]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5049 224 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  64\n",
      "39 12 False\n",
      "x_t:  1 [0.94375    0.3        0.05       0.43333333]\n",
      "Q values:  tensor([[-22.6173, -21.6648, -25.4860, -25.8721, -23.4801, -27.6466]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2214 619 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  41\n",
      "39 15 False\n",
      "x_t:  3 [0.75       0.34166667 0.1375     0.43333333]\n",
      "Q values:  tensor([[-25.5927, -30.1827, -27.6972, -22.9300, -26.6829, -29.8358]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 531 236 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  846\n",
      "39 22 True\n",
      "x_t:  1 [0.009375 0.3625   0.08125  0.4     ]\n",
      "Q values:  tensor([[-30.5907, -29.1046, -26.9536, -26.0119, -30.6378, -29.2722]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9481 265 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  305.25726103782654\n",
      "startIDX:  2494\n",
      "ep 40: ep_len:47 episode reward: total was -31.000000. running mean: -413.611865\n",
      "startIDX:  603\n",
      "40 1 True\n",
      "x_t:  2 [0.5625  0.3875  0.11875 0.3125 ]\n",
      "Q values:  tensor([[-30.9844, -30.2694, -30.4224, -27.8725, -26.2016, -24.9806]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31499 395 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 40: ep_len:395 episode reward: total was -309.500000. running mean: -412.570746\n",
      "startIDX:  0\n",
      "40 5 False\n",
      "x_t:  1 [0.0625     0.37083333 0.20625    0.49583333]\n",
      "Q values:  tensor([[-28.3965, -24.5934, -28.2168, -24.9242, -27.3641, -30.2954]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2519 1165 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 40: ep_len:1165 episode reward: total was -925.600000. running mean: -417.701039\n",
      "startIDX:  1331\n",
      "40 10 True\n",
      "x_t:  4 [0.05       0.37083333 0.078125   0.26666667]\n",
      "Q values:  tensor([[-23.5576, -30.2869, -31.6398, -29.1851, -33.3331, -27.1997]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15711 569 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 40: ep_len:569 episode reward: total was -419.200000. running mean: -417.716028\n",
      "startIDX:  224\n",
      "40 12 False\n",
      "x_t:  3 [0.1        0.26666667 0.090625   0.275     ]\n",
      "Q values:  tensor([[-27.9255, -28.4335, -31.4054, -27.2739, -29.7926, -29.2281]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5675 1389 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 40: ep_len:1389 episode reward: total was -1076.300000. running mean: -424.301868\n",
      "startIDX:  606\n",
      "40 15 False\n",
      "x_t:  1 [0.7375     0.30416667 0.0875     0.27083333]\n",
      "Q values:  tensor([[-30.8551, -19.1080, -27.1595, -27.1184, -28.6740, -21.4409]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5189 679 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 40: ep_len:679 episode reward: total was -527.100000. running mean: -425.329849\n",
      "startIDX:  1986\n",
      "40 22 True\n",
      "x_t:  1 [0.1        0.37083333 0.140625   0.36666667]\n",
      "Q values:  tensor([[-28.9863, -28.9004, -27.5834, -32.2106, -25.7163, -32.6989]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19002 260 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 40: ep_len:260 episode reward: total was -201.600000. running mean: -423.092551\n",
      "startIDX:  560\n",
      "41 0 True\n",
      "x_t:  3 [0.65625    0.375      0.184375   0.44583333]\n",
      "Q values:  tensor([[-26.9687, -30.6716, -31.2902, -30.7343, -30.1156, -26.5980]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7008 996 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  727\n",
      "41 1 True\n",
      "x_t:  3 [0.10625    0.23333333 0.071875   0.29583333]\n",
      "Q values:  tensor([[-28.5813, -32.9363, -28.4722, -26.7497, -30.2184, -27.2933]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34316 1401 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1094\n",
      "41 5 True\n",
      "x_t:  3 [0.121875   0.22916667 0.071875   0.27083333]\n",
      "Q values:  tensor([[-27.6187, -32.0180, -27.6134, -25.1273, -28.3952, -32.3720]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10600 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1800\n",
      "41 10 False\n",
      "x_t:  2 [0.5        0.39166667 0.046875   0.25833333]\n",
      "Q values:  tensor([[-29.5176, -27.8511, -23.4587, -25.1212, -28.3402, -27.5359]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18230 901 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1378\n",
      "41 12 False\n",
      "x_t:  3 [0.603125 0.3375   0.146875 0.4     ]\n",
      "Q values:  tensor([[-28.5054, -29.5784, -25.0085, -19.3731, -31.3570, -25.9588]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17871 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1355\n",
      "41 15 False\n",
      "x_t:  3 [0.634375   0.3125     0.09375    0.35416667]\n",
      "Q values:  tensor([[-30.6758, -37.9986, -33.7500, -29.3753, -33.0549, -30.4765]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10372 206 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1879\n",
      "41 22 False\n",
      "x_t:  2 [0.00625    0.40416667 0.071875   0.26666667]\n",
      "Q values:  tensor([[-27.3753, -30.5820, -24.1939, -29.7081, -24.2563, -26.9301]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18454 766 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1924\n",
      "42 0 False\n",
      "x_t:  1 [0.21875    0.34166667 0.096875   0.3875    ]\n",
      "Q values:  tensor([[-28.4463, -18.9147, -27.2200, -21.6514, -28.7029, -29.4857]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18944 252 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 42: ep_len:252 episode reward: total was -187.800000. running mean: -425.356306\n",
      "startIDX:  167\n",
      "42 1 False\n",
      "x_t:  2 [0.1875     0.35416667 0.125      0.45      ]\n",
      "Q values:  tensor([[-26.7299, -26.5894, -26.2090, -29.6955, -30.1376, -29.4860]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27464 891 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 42: ep_len:891 episode reward: total was -695.200000. running mean: -428.054743\n",
      "startIDX:  545\n",
      "42 5 False\n",
      "x_t:  2 [0.828125   0.35833333 0.096875   0.29166667]\n",
      "Q values:  tensor([[-26.4143, -24.9531, -24.3259, -26.3981, -29.8865, -26.5752]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6029 485 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 42: ep_len:485 episode reward: total was -377.700000. running mean: -427.551196\n",
      "startIDX:  2491\n",
      "42 10 False\n",
      "x_t:  1 [0.88125    0.28333333 0.078125   0.34583333]\n",
      "Q values:  tensor([[-26.2340, -22.0443, -24.9443, -25.3458, -26.1723, -24.7628]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22471 1132 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 42: ep_len:1132 episode reward: total was -875.400000. running mean: -432.029684\n",
      "startIDX:  362\n",
      "42 12 False\n",
      "x_t:  4 [0.271875   0.425      0.13125    0.37083333]\n",
      "Q values:  tensor([[-26.5389, -26.4776, -25.5869, -25.7412, -22.4212, -27.4143]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7209 715 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 42: ep_len:715 episode reward: total was -546.400000. running mean: -433.173387\n",
      "startIDX:  3138\n",
      "ep 42: ep_len:11 episode reward: total was -7.000000. running mean: -428.911653\n",
      "startIDX:  646\n",
      "42 22 False\n",
      "x_t:  2 [0.059375   0.40833333 0.09375    0.2625    ]\n",
      "Q values:  tensor([[-26.5787, -31.5073, -25.5240, -26.0578, -28.9941, -29.2024]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8925 907 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 42: ep_len:907 episode reward: total was -689.600000. running mean: -431.518537\n",
      "startIDX:  1557\n",
      "43 0 False\n",
      "x_t:  3 [0.878125   0.34166667 0.115625   0.43333333]\n",
      "Q values:  tensor([[-29.0290, -26.3880, -28.1920, -23.7002, -26.5739, -28.6929]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16811 224 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  655\n",
      "43 1 False\n",
      "x_t:  2 [0.65       0.3875     0.115625   0.30833333]\n",
      "Q values:  tensor([[-30.2434, -27.6155, -24.8570, -27.4350, -27.9760, -26.7811]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31487 363 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1537\n",
      "43 5 True\n",
      "x_t:  1 [0.903125   0.27916667 0.090625   0.325     ]\n",
      "Q values:  tensor([[-29.1789, -31.5492, -21.0616, -27.2838, -24.7759, -25.2740]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14919 707 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1560\n",
      "43 10 False\n",
      "x_t:  3 [0.909375   0.32083333 0.0875     0.4125    ]\n",
      "Q values:  tensor([[-28.8785, -32.2736, -29.0905, -25.8350, -28.1289, -26.3876]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16399 310 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  927\n",
      "43 12 True\n",
      "x_t:  1 [0.815625   0.35416667 0.165625   0.52083333]\n",
      "Q values:  tensor([[-32.8834, -32.3970, -30.6362, -29.6936, -36.4796, -30.3580]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12915 602 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2003\n",
      "43 15 False\n",
      "x_t:  1 [0.896875   0.29583333 0.08125    0.30833333]\n",
      "Q values:  tensor([[-24.4385, -24.2632, -24.3798, -26.5038, -26.8053, -26.8620]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14842 665 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  2216\n",
      "43 22 False\n",
      "x_t:  1 [0.85       0.3125     0.128125   0.45833333]\n",
      "Q values:  tensor([[-28.9816, -22.2628, -26.7284, -30.4291, -23.2174, -27.1933]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22935 1107 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1123\n",
      "44 0 False\n",
      "x_t:  2 [0.7375     0.40833333 0.071875   0.28333333]\n",
      "Q values:  tensor([[-27.0872, -27.1059, -19.3576, -29.4786, -23.9920, -24.7324]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12642 340 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 44: ep_len:340 episode reward: total was -257.000000. running mean: -430.020207\n",
      "startIDX:  965\n",
      "44 1 False\n",
      "x_t:  4 [0.01875    0.38333333 0.10625    0.41666667]\n",
      "Q values:  tensor([[-29.3218, -26.9380, -27.8614, -27.2795, -24.2565, -24.6031]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35426 484 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 44: ep_len:484 episode reward: total was -373.700000. running mean: -429.457005\n",
      "startIDX:  722\n",
      "44 5 False\n",
      "x_t:  3 [0.109375   0.27083333 0.075      0.30833333]\n",
      "Q values:  tensor([[-24.9979, -23.8006, -24.3149, -20.0456, -24.1659, -23.6760]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8761 1319 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 44: ep_len:1319 episode reward: total was -1026.300000. running mean: -435.425435\n",
      "startIDX:  2114\n",
      "44 10 False\n",
      "x_t:  0 [0.88125    0.3875     0.10625    0.37916667]\n",
      "Q values:  tensor([[-21.5117, -26.5299, -25.9324, -23.2089, -23.9791, -22.6093]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19934 565 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 44: ep_len:565 episode reward: total was -442.900000. running mean: -435.500181\n",
      "startIDX:  1642\n",
      "44 12 True\n",
      "x_t:  1 [0.00625    0.3625     0.071875   0.37916667]\n",
      "Q values:  tensor([[-25.5536, -32.3470, -26.2199, -30.1871, -33.1280, -29.6791]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19870 231 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 44: ep_len:231 episode reward: total was -183.100000. running mean: -432.976179\n",
      "startIDX:  1400\n",
      "44 15 False\n",
      "x_t:  3 [0.496875   0.29166667 0.103125   0.31666667]\n",
      "Q values:  tensor([[-30.1684, -29.1755, -24.9909, -22.2250, -29.9298, -30.4269]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10399 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 44: ep_len:200 episode reward: total was -137.000000. running mean: -430.016417\n",
      "startIDX:  1910\n",
      "44 22 False\n",
      "x_t:  2 [0.01875    0.4125     0.10625    0.26666667]\n",
      "Q values:  tensor([[-29.6373, -27.5664, -22.9612, -25.5633, -27.5632, -24.2304]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18460 756 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 44: ep_len:756 episode reward: total was -559.000000. running mean: -431.306253\n",
      "startIDX:  1597\n",
      "45 0 False\n",
      "x_t:  3 [0.803125   0.34166667 0.175      0.425     ]\n",
      "Q values:  tensor([[-32.0783, -28.1703, -29.0093, -27.9172, -28.1043, -35.5589]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16818 208 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  542\n",
      "45 1 True\n",
      "x_t:  1 [0.553125 0.2875   0.11875  0.4625  ]\n",
      "Q values:  tensor([[-31.3664, -30.6802, -33.1154, -30.1002, -31.9466, -28.3436]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30715 762 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1570\n",
      "45 5 False\n",
      "x_t:  1 [0.815625   0.28333333 0.071875   0.3125    ]\n",
      "Q values:  tensor([[-29.2799, -28.9587, -32.4626, -36.9869, -35.8356, -32.0305]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14933 693 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2257\n",
      "45 10 False\n",
      "x_t:  1 [0.884375   0.2875     0.1125     0.33333333]\n",
      "Q values:  tensor([[-26.9816, -21.5848, -23.9186, -22.9073, -27.8306, -21.8123]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22468 1260 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  413\n",
      "45 12 False\n",
      "x_t:  3 [0.878125   0.35833333 0.10625    0.42916667]\n",
      "Q values:  tensor([[-29.0551, -27.0308, -28.9248, -25.9734, -33.2286, -29.2747]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7711 243 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1592\n",
      "45 15 False\n",
      "x_t:  2 [0.3375     0.40833333 0.053125   0.2625    ]\n",
      "Q values:  tensor([[-30.1524, -30.5853, -27.3356, -30.6975, -32.3597, -30.4720]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 11961 739 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  978\n",
      "45 22 False\n",
      "x_t:  0 [0.903125 0.4      0.053125 0.3375  ]\n",
      "Q values:  tensor([[-26.7347, -33.6828, -37.6899, -31.6323, -33.4420, -29.4130]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10402 443 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1369\n",
      "46 0 True\n",
      "x_t:  4 [0.0375     0.3875     0.1375     0.29166667]\n",
      "Q values:  tensor([[-27.6744, -26.5806, -27.1481, -28.5877, -25.4313, -31.5933]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16295 550 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 46: ep_len:550 episode reward: total was -413.800000. running mean: -434.546519\n",
      "startIDX:  654\n",
      "46 1 False\n",
      "x_t:  2 [0.796875   0.37916667 0.075      0.30416667]\n",
      "Q values:  tensor([[-24.9181, -23.0896, -21.7939, -23.7390, -27.6281, -30.4570]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31467 345 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 46: ep_len:345 episode reward: total was -271.500000. running mean: -432.916054\n",
      "startIDX:  2843\n",
      "ep 46: ep_len:118 episode reward: total was -74.900000. running mean: -429.335893\n",
      "startIDX:  794\n",
      "46 10 True\n",
      "x_t:  1 [0.178125   0.33333333 0.06875    0.35833333]\n",
      "Q values:  tensor([[-21.3102, -21.7939, -26.9291, -19.0768, -23.1120, -21.3724]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7122 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 46: ep_len:200 episode reward: total was -162.100000. running mean: -426.663534\n",
      "startIDX:  939\n",
      "46 12 False\n",
      "x_t:  1 [0.821875   0.35416667 0.1375     0.5125    ]\n",
      "Q values:  tensor([[-27.7242, -23.1284, -26.6925, -29.8625, -28.7499, -26.1974]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12916 612 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 46: ep_len:612 episode reward: total was -459.000000. running mean: -426.986899\n",
      "startIDX:  2343\n",
      "46 15 False\n",
      "x_t:  4 [0.190625   0.39583333 0.08125    0.325     ]\n",
      "Q values:  tensor([[-32.0288, -34.1880, -30.5363, -37.0966, -30.4020, -31.6663]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19279 539 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 46: ep_len:539 episode reward: total was -391.000000. running mean: -426.627030\n",
      "startIDX:  2160\n",
      "46 22 False\n",
      "x_t:  0 [0.85       0.40416667 0.078125   0.32083333]\n",
      "Q values:  tensor([[-29.4144, -33.6537, -32.0901, -33.5433, -31.1030, -32.0793]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20705 827 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 46: ep_len:827 episode reward: total was -640.600000. running mean: -428.766760\n",
      "startIDX:  3\n",
      "47 0 True\n",
      "x_t:  1 [0.74375    0.30833333 0.15625    0.41666667]\n",
      "Q values:  tensor([[-30.3623, -24.8952, -23.4346, -25.3624, -24.3163, -21.9649]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1621 764 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1063\n",
      "47 1 True\n",
      "x_t:  3 [0.7        0.3        0.096875   0.39166667]\n",
      "Q values:  tensor([[-21.3064, -24.3619, -24.0658, -23.9587, -24.9954, -20.7718]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35922 211 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2010\n",
      "47 5 False\n",
      "x_t:  3 [0.15       0.2625     0.071875   0.32083333]\n",
      "Q values:  tensor([[-30.9594, -29.2325, -27.0526, -26.2362, -26.2667, -27.4175]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18226 1247 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1186\n",
      "47 10 False\n",
      "x_t:  3 [0.08125    0.22083333 0.059375   0.25416667]\n",
      "Q values:  tensor([[-27.3908, -25.7547, -24.3774, -23.0438, -24.0429, -24.3119]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14579 1260 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1529\n",
      "47 12 False\n",
      "x_t:  2 [0.003125   0.4125     0.10625    0.28333333]\n",
      "Q values:  tensor([[-29.7762, -28.0606, -23.2756, -28.8762, -32.8765, -26.7170]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19380 756 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2511\n",
      "47 15 True\n",
      "x_t:  3 [0.4625     0.2875     0.078125   0.29583333]\n",
      "Q values:  tensor([[-30.6597, -22.1733, -30.8284, -29.3703, -25.4851, -31.1255]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19728 210 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2272\n",
      "47 22 False\n",
      "x_t:  1 [0.6375     0.31666667 0.128125   0.44166667]\n",
      "Q values:  tensor([[-18.1882, -15.9934, -20.3147, -18.7156, -19.6344, -20.4709]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22954 1102 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  53\n",
      "48 0 False\n",
      "x_t:  1 [0.74375    0.30833333 0.15625    0.41666667]\n",
      "Q values:  tensor([[-26.3383, -22.2954, -26.9498, -23.2692, -28.9714, -23.9971]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1621 746 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 48: ep_len:746 episode reward: total was -563.000000. running mean: -441.051387\n",
      "startIDX:  1078\n",
      "48 1 False\n",
      "x_t:  3 [0.65625    0.3        0.121875   0.37083333]\n",
      "Q values:  tensor([[-25.8617, -28.5147, -28.4248, -25.8558, -27.4622, -27.4832]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35929 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 48: ep_len:202 episode reward: total was -149.400000. running mean: -438.134873\n",
      "startIDX:  1971\n",
      "48 5 False\n",
      "x_t:  3 [0.0625     0.25416667 0.08125    0.25833333]\n",
      "Q values:  tensor([[-24.0758, -25.1642, -26.5736, -23.4879, -25.0621, -30.0905]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18202 1273 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 48: ep_len:1273 episode reward: total was -963.500000. running mean: -443.388524\n",
      "startIDX:  5\n",
      "48 10 False\n",
      "x_t:  3 [0.059375   0.2375     0.05625    0.25416667]\n",
      "Q values:  tensor([[-28.0771, -26.4784, -25.3546, -23.8706, -27.6656, -28.9651]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3576 1114 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 48: ep_len:1114 episode reward: total was -868.300000. running mean: -447.637639\n",
      "startIDX:  1353\n",
      "48 12 False\n",
      "x_t:  3 [0.70625    0.3625     0.14375    0.42916667]\n",
      "Q values:  tensor([[-38.4900, -30.9058, -30.1343, -28.8460, -31.2365, -31.9847]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17858 217 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 48: ep_len:217 episode reward: total was -162.600000. running mean: -444.787263\n",
      "startIDX:  2729\n",
      "48 15 False\n",
      "x_t:  2 [0.078125   0.4        0.1125     0.34583333]\n",
      "Q values:  tensor([[-25.5500, -24.3541, -21.5757, -23.4900, -24.0078, -25.7796]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21484 831 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 48: ep_len:831 episode reward: total was -664.400000. running mean: -446.983390\n",
      "startIDX:  2662\n",
      "48 22 True\n",
      "x_t:  4 [0.003125   0.40833333 0.090625   0.29583333]\n",
      "Q values:  tensor([[-35.9440, -35.1873, -32.1081, -33.5504, -29.3008, -32.6245]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27262 515 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 48: ep_len:515 episode reward: total was -397.200000. running mean: -446.485556\n",
      "startIDX:  177\n",
      "49 0 False\n",
      "x_t:  2 [0.796875   0.40833333 0.1        0.2875    ]\n",
      "Q values:  tensor([[-34.0064, -34.7753, -28.5662, -30.0410, -31.3865, -34.6212]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2320 359 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  465\n",
      "49 1 True\n",
      "x_t:  1 [0.853125   0.26666667 0.14375    0.4625    ]\n",
      "Q values:  tensor([[-24.1979, -27.3036, -23.5613, -24.8111, -24.7120, -30.4439]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30681 774 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  724\n",
      "49 5 False\n",
      "x_t:  3 [0.0625     0.25833333 0.078125   0.31666667]\n",
      "Q values:  tensor([[-34.6497, -30.2939, -29.5949, -27.9230, -31.1086, -30.5820]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8745 1300 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  275\n",
      "49 10 True\n",
      "x_t:  3 [0.8125     0.32916667 0.165625   0.375     ]\n",
      "Q values:  tensor([[-33.5610, -32.2551, -33.6804, -34.7548, -29.3850, -31.3363]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5039 248 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1579\n",
      "49 12 True\n",
      "x_t:  2 [0.003125   0.41666667 0.1        0.27083333]\n",
      "Q values:  tensor([[-27.9762, -30.7174, -26.6282, -32.4374, -28.9095, -28.8481]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19378 718 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  898\n",
      "49 15 False\n",
      "x_t:  3 [0.0625     0.23333333 0.034375   0.23333333]\n",
      "Q values:  tensor([[-26.0691, -26.4728, -29.3262, -25.6327, -28.1284, -26.0221]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8491 1202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  149\n",
      "49 22 False\n",
      "x_t:  1 [0.85       0.30833333 0.14375    0.40833333]\n",
      "Q values:  tensor([[-28.7201, -20.7915, -29.9697, -22.9374, -23.4916, -26.9336]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1581 670 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  393.6249370574951\n",
      "startIDX:  75\n",
      "50 0 True\n",
      "x_t:  1 [0.71875    0.30833333 0.178125   0.41666667]\n",
      "Q values:  tensor([[-29.6055, -33.5747, -31.4508, -34.3551, -34.3086, -28.3502]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1623 721 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 50: ep_len:721 episode reward: total was -568.400000. running mean: -456.439471\n",
      "startIDX:  64\n",
      "50 1 False\n",
      "x_t:  3 [0.35625    0.25833333 0.090625   0.32083333]\n",
      "Q values:  tensor([[-20.9008, -23.8872, -28.9371, -20.6322, -25.8419, -22.9888]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25715 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 50: ep_len:202 episode reward: total was -155.600000. running mean: -453.431076\n",
      "startIDX:  2618\n",
      "50 5 True\n",
      "x_t:  1 [0.490625   0.30416667 0.08125    0.52083333]\n",
      "Q values:  tensor([[-36.9716, -37.0481, -40.9549, -33.8696, -40.4449, -34.0292]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22145 294 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 50: ep_len:294 episode reward: total was -242.900000. running mean: -451.325766\n",
      "startIDX:  2526\n",
      "50 10 True\n",
      "x_t:  1 [0.875      0.275      0.065625   0.34583333]\n",
      "Q values:  tensor([[-26.7219, -29.8485, -27.9853, -28.5182, -24.1458, -25.7557]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22472 1115 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 50: ep_len:1115 episode reward: total was -819.300000. running mean: -455.005508\n",
      "startIDX:  346\n",
      "50 12 False\n",
      "x_t:  4 [0.003125   0.44166667 0.103125   0.375     ]\n",
      "Q values:  tensor([[-26.8730, -25.4579, -23.6788, -26.1924, -19.8700, -26.3947]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7183 707 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 50: ep_len:707 episode reward: total was -500.500000. running mean: -455.460453\n",
      "startIDX:  774\n",
      "50 15 True\n",
      "x_t:  2 [0.784375   0.40833333 0.090625   0.29166667]\n",
      "Q values:  tensor([[-28.5242, -23.8660, -25.8206, -23.8029, -30.7737, -21.0887]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5968 337 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 50: ep_len:337 episode reward: total was -241.700000. running mean: -453.322848\n",
      "startIDX:  2777\n",
      "50 22 False\n",
      "x_t:  4 [0.0125     0.41666667 0.1125     0.29583333]\n",
      "Q values:  tensor([[-33.1579, -28.9844, -28.4993, -26.9670, -26.8200, -28.0173]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27267 468 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 50: ep_len:468 episode reward: total was -364.800000. running mean: -452.437620\n",
      "startIDX:  226\n",
      "51 0 False\n",
      "x_t:  2 [0.659375   0.40416667 0.084375   0.29583333]\n",
      "Q values:  tensor([[-30.1139, -25.8780, -22.9986, -25.0905, -29.0737, -24.5967]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2344 341 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  663\n",
      "51 1 True\n",
      "x_t:  2 [0.8125     0.37916667 0.08125    0.3125    ]\n",
      "Q values:  tensor([[-27.4391, -22.2546, -22.7509, -28.4952, -30.5976, -23.8375]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31463 349 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2617\n",
      "51 5 False\n",
      "x_t:  1 [0.025      0.35833333 0.159375   0.50833333]\n",
      "Q values:  tensor([[-33.8383, -26.4974, -30.0528, -27.4252, -28.1041, -27.0719]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22108 268 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  285\n",
      "51 10 False\n",
      "x_t:  3 [0.815625   0.32916667 0.140625   0.36666667]\n",
      "Q values:  tensor([[-30.4509, -28.9288, -30.3962, -26.7438, -28.5309, -27.8873]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5040 245 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1192\n",
      "51 12 False\n",
      "x_t:  4 [0.053125 0.4375   0.153125 0.3625  ]\n",
      "Q values:  tensor([[-27.0272, -28.2152, -26.6107, -28.5831, -19.9590, -26.3316]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17396 497 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  106\n",
      "51 15 False\n",
      "x_t:  3 [0.734375   0.33333333 0.090625   0.40833333]\n",
      "Q values:  tensor([[-29.6138, -23.6982, -24.8598, -23.0515, -26.2251, -25.0112]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 537 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1210\n",
      "51 22 False\n",
      "x_t:  1 [0.6        0.32916667 0.178125   0.50416667]\n",
      "Q values:  tensor([[-28.1031, -24.9246, -26.4915, -28.6793, -30.0265, -28.7347]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11938 695 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1632\n",
      "52 0 True\n",
      "x_t:  3 [0.69375    0.33333333 0.121875   0.4       ]\n",
      "Q values:  tensor([[-29.5331, -29.4438, -27.0442, -28.6778, -25.4209, -20.6395]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16833 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 52: ep_len:200 episode reward: total was -146.500000. running mean: -438.330873\n",
      "startIDX:  511\n",
      "52 1 False\n",
      "x_t:  1 [0.596875   0.28333333 0.09375    0.47083333]\n",
      "Q values:  tensor([[-25.8277, -22.5410, -31.0038, -24.2309, -27.1509, -24.6789]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30712 760 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 52: ep_len:760 episode reward: total was -614.700000. running mean: -440.094564\n",
      "startIDX:  80\n",
      "52 5 True\n",
      "x_t:  2 [0.190625   0.375      0.128125   0.43333333]\n",
      "Q values:  tensor([[-29.3471, -25.3028, -22.4741, -24.8577, -25.7598, -24.0155]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2070 902 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 52: ep_len:902 episode reward: total was -656.900000. running mean: -442.262619\n",
      "startIDX:  2239\n",
      "52 10 False\n",
      "x_t:  1 [0.76875    0.2875     0.125      0.33333333]\n",
      "Q values:  tensor([[-27.6111, -19.9974, -24.9935, -21.3765, -25.6295, -25.2666]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22481 1282 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 52: ep_len:1282 episode reward: total was -975.100000. running mean: -447.590992\n",
      "startIDX:  723\n",
      "52 12 False\n",
      "x_t:  1 [0.340625   0.35833333 0.121875   0.5125    ]\n",
      "Q values:  tensor([[-28.2383, -20.9656, -27.1237, -28.7032, -26.0360, -26.8083]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10326 209 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 52: ep_len:209 episode reward: total was -169.100000. running mean: -444.806083\n",
      "startIDX:  1139\n",
      "52 15 False\n",
      "x_t:  4 [0.0125     0.39583333 0.0875     0.29583333]\n",
      "Q values:  tensor([[-26.6250, -30.3082, -28.6283, -33.1653, -25.6828, -31.6703]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9813 553 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 52: ep_len:553 episode reward: total was -430.900000. running mean: -444.667022\n",
      "startIDX:  1926\n",
      "52 22 False\n",
      "x_t:  2 [0.00625    0.40416667 0.071875   0.26666667]\n",
      "Q values:  tensor([[-31.3788, -30.2060, -27.0542, -31.6448, -30.2105, -28.7713]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18454 735 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 52: ep_len:735 episode reward: total was -566.600000. running mean: -445.886351\n",
      "startIDX:  57\n",
      "53 0 False\n",
      "x_t:  1 [0.86875    0.3        0.128125   0.42916667]\n",
      "Q values:  tensor([[-30.1229, -25.9353, -30.8477, -26.6644, -27.2175, -29.5885]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1607 736 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  623\n",
      "53 1 False\n",
      "x_t:  2 [0.634375   0.37916667 0.096875   0.3125    ]\n",
      "Q values:  tensor([[-31.5627, -35.9794, -29.1076, -33.1705, -33.0917, -29.2303]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31491 383 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1933\n",
      "53 5 False\n",
      "x_t:  3 [0.0625     0.25       0.084375   0.27083333]\n",
      "Q values:  tensor([[-35.1002, -40.7438, -34.7467, -32.9393, -36.0931, -38.0899]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18204 1269 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1781\n",
      "53 10 False\n",
      "x_t:  2 [0.046875 0.4      0.10625  0.25    ]\n",
      "Q values:  tensor([[-22.4834, -24.3340, -22.3612, -29.5423, -29.2393, -31.7701]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18155 882 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  186\n",
      "53 12 False\n",
      "x_t:  3 [0.1125     0.26666667 0.090625   0.27916667]\n",
      "Q values:  tensor([[-36.1485, -39.3584, -38.6325, -35.0091, -38.4012, -35.0210]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5677 1418 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1564\n",
      "53 15 False\n",
      "x_t:  2 [0.003125 0.4125   0.059375 0.25    ]\n",
      "Q values:  tensor([[-29.4566, -29.3749, -25.8170, -28.6016, -29.8879, -28.8578]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 11906 724 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1197\n",
      "53 22 True\n",
      "x_t:  1 [0.8625     0.29583333 0.096875   0.5       ]\n",
      "Q values:  tensor([[-27.8052, -25.6242, -28.8002, -26.6445, -27.1762, -24.2226]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11918 690 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1231\n",
      "54 0 False\n",
      "x_t:  3 [0.1125     0.24583333 0.059375   0.27083333]\n",
      "Q values:  tensor([[-28.9239, -32.7765, -27.8218, -23.0768, -28.1502, -28.9709]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15173 1245 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 54: ep_len:1245 episode reward: total was -918.600000. running mean: -465.590588\n",
      "startIDX:  740\n",
      "54 1 False\n",
      "x_t:  3 [0.078125   0.23333333 0.08125    0.29166667]\n",
      "Q values:  tensor([[-37.1530, -38.1979, -35.5397, -28.7265, -32.5535, -33.8894]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34308 1379 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 54: ep_len:1379 episode reward: total was -1064.500000. running mean: -471.579682\n",
      "startIDX:  1057\n",
      "54 5 False\n",
      "x_t:  3 [0.25625    0.24166667 0.125      0.30833333]\n",
      "Q values:  tensor([[-34.4949, -29.8067, -29.5026, -24.2292, -28.7839, -26.9017]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10568 207 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 54: ep_len:207 episode reward: total was -144.600000. running mean: -468.309886\n",
      "startIDX:  2517\n",
      "54 10 False\n",
      "x_t:  1 [0.884375   0.2875     0.1125     0.34166667]\n",
      "Q values:  tensor([[-34.5910, -30.3999, -37.6814, -31.9433, -36.6256, -32.8565]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22467 1120 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 54: ep_len:1120 episode reward: total was -839.200000. running mean: -472.018787\n",
      "startIDX:  974\n",
      "54 12 False\n",
      "x_t:  2 [0.63125    0.40833333 0.06875    0.25      ]\n",
      "Q values:  tensor([[-23.8455, -28.5642, -19.7411, -23.2770, -23.2405, -23.8508]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13603 349 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 54: ep_len:349 episode reward: total was -285.600000. running mean: -470.154599\n",
      "startIDX:  985\n",
      "54 15 True\n",
      "x_t:  4 [0.003125   0.4        0.065625   0.29166667]\n",
      "Q values:  tensor([[-29.1768, -29.4361, -27.5040, -22.3998, -27.4729, -26.1263]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9808 632 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 54: ep_len:632 episode reward: total was -458.000000. running mean: -470.033053\n",
      "startIDX:  908\n",
      "54 22 False\n",
      "x_t:  1 [0.38125 0.325   0.125   0.4125 ]\n",
      "Q values:  tensor([[-21.6204, -19.1284, -23.3463, -21.4891, -21.4706, -23.6462]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9521 261 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 54: ep_len:261 episode reward: total was -213.000000. running mean: -467.462722\n",
      "startIDX:  1261\n",
      "55 0 False\n",
      "x_t:  3 [0.0625     0.25       0.059375   0.24583333]\n",
      "Q values:  tensor([[-27.2656, -24.1585, -28.1019, -23.1034, -23.5254, -27.5062]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15154 1204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  664\n",
      "55 1 False\n",
      "x_t:  2 [0.734375   0.37916667 0.1125     0.31666667]\n",
      "Q values:  tensor([[-27.5331, -26.5918, -24.3717, -25.0606, -28.6421, -25.0791]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31472 348 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1349\n",
      "55 5 False\n",
      "x_t:  1 [0.36875    0.30833333 0.06875    0.37916667]\n",
      "Q values:  tensor([[-31.4503, -26.0628, -30.9385, -28.2778, -32.2926, -30.2092]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12541 256 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  220\n",
      "55 10 False\n",
      "x_t:  4 [0.121875   0.35       0.05625    0.25416667]\n",
      "Q values:  tensor([[-29.0694, -27.6221, -31.1346, -33.1963, -24.8990, -30.9257]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4562 444 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1951\n",
      "startIDX:  1973\n",
      "55 15 True\n",
      "x_t:  1 [0.871875   0.29166667 0.04375    0.30833333]\n",
      "Q values:  tensor([[-31.4853, -26.5835, -25.0056, -24.6548, -29.9821, -28.9303]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14846 697 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1755\n",
      "55 22 False\n",
      "x_t:  3 [0.371875   0.29166667 0.090625   0.30833333]\n",
      "Q values:  tensor([[-28.9373, -26.0353, -28.1718, -24.1162, -25.2476, -26.4542]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16922 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  217\n",
      "56 0 False\n",
      "x_t:  2 [0.79375 0.4     0.0625  0.2875 ]\n",
      "Q values:  tensor([[-36.7992, -31.9932, -27.5744, -34.9936, -27.8213, -38.2006]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2326 339 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 56: ep_len:339 episode reward: total was -260.200000. running mean: -457.785959\n",
      "startIDX:  895\n",
      "56 1 False\n",
      "x_t:  4 [0.003125 0.4      0.121875 0.4     ]\n",
      "Q values:  tensor([[-27.3703, -29.7717, -26.8997, -27.0655, -24.7103, -28.3411]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35423 527 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 56: ep_len:527 episode reward: total was -400.900000. running mean: -457.217100\n",
      "startIDX:  2373\n",
      "56 5 True\n",
      "x_t:  2 [0.021875   0.39166667 0.078125   0.275     ]\n",
      "Q values:  tensor([[-39.3806, -34.4584, -33.6751, -31.2752, -36.5898, -32.3105]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21549 945 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 56: ep_len:945 episode reward: total was -675.800000. running mean: -459.402929\n",
      "startIDX:  166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 10 False\n",
      "x_t:  4 [0.003125   0.36666667 0.078125   0.25      ]\n",
      "Q values:  tensor([[-31.2962, -31.5353, -31.8500, -29.2031, -26.9043, -32.1053]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4542 456 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 56: ep_len:456 episode reward: total was -342.700000. running mean: -458.235899\n",
      "startIDX:  1305\n",
      "56 12 False\n",
      "x_t:  4 [0.059375   0.43333333 0.15       0.37083333]\n",
      "Q values:  tensor([[-24.6746, -29.8460, -26.8468, -32.5265, -23.2628, -29.1698]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17399 429 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 56: ep_len:429 episode reward: total was -310.600000. running mean: -456.759540\n",
      "startIDX:  371\n",
      "56 15 False\n",
      "x_t:  1 [0.671875   0.30416667 0.0875     0.52916667]\n",
      "Q values:  tensor([[-31.4488, -22.2874, -28.4874, -28.6059, -28.4801, -33.3885]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2802 257 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 56: ep_len:257 episode reward: total was -181.300000. running mean: -454.004945\n",
      "startIDX:  2596\n",
      "56 22 True\n",
      "x_t:  3 [0.0625     0.23333333 0.05       0.24166667]\n",
      "Q values:  tensor([[-18.1257, -22.8986, -22.9109, -19.0273, -19.2811, -22.1661]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26170 1203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 56: ep_len:1203 episode reward: total was -850.500000. running mean: -457.969895\n",
      "startIDX:  2197\n",
      "57 0 True\n",
      "x_t:  1 [0.6375     0.31666667 0.109375   0.5125    ]\n",
      "Q values:  tensor([[-25.0220, -20.6565, -24.1694, -22.9568, -26.5727, -23.3652]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22937 1115 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  185\n",
      "57 1 False\n",
      "x_t:  2 [0.003125   0.36666667 0.10625    0.45833333]\n",
      "Q values:  tensor([[-27.1483, -26.7587, -24.3898, -28.6116, -28.8593, -28.8226]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27432 842 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  321\n",
      "57 5 False\n",
      "x_t:  1 [0.65625    0.3        0.134375   0.35833333]\n",
      "Q values:  tensor([[-25.5264, -23.3566, -26.7762, -31.3638, -29.1657, -27.6532]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5053 740 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  356\n",
      "57 10 True\n",
      "x_t:  3 [0.815625   0.32916667 0.140625   0.36666667]\n",
      "Q values:  tensor([[-27.3789, -28.2107, -25.8956, -27.5432, -23.2936, -21.2125]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5040 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  529\n",
      "57 12 False\n",
      "x_t:  2 [0.003125   0.41666667 0.078125   0.24583333]\n",
      "Q values:  tensor([[-28.7010, -29.2857, -23.7481, -28.2492, -29.6165, -26.9960]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9825 1066 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1920\n",
      "57 15 False\n",
      "x_t:  1 [0.703125   0.3        0.115625   0.30416667]\n",
      "Q values:  tensor([[-27.7874, -25.7614, -29.1442, -27.9696, -27.6544, -29.1481]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14864 729 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  109\n",
      "57 22 False\n",
      "x_t:  1 [0.934375   0.2875     0.0625     0.41666667]\n",
      "Q values:  tensor([[-32.1246, -23.4223, -23.8188, -24.0244, -23.7824, -24.0417]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1575 669 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1531\n",
      "58 0 True\n",
      "x_t:  3 [0.815625   0.33333333 0.10625    0.41666667]\n",
      "Q values:  tensor([[-29.7779, -27.2087, -26.6612, -25.1064, -28.2550, -25.1862]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16821 246 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 58: ep_len:246 episode reward: total was -170.800000. running mean: -461.837849\n",
      "startIDX:  588\n",
      "58 1 False\n",
      "x_t:  2 [0.640625   0.37916667 0.1        0.32083333]\n",
      "Q values:  tensor([[-29.5019, -31.7805, -26.7288, -33.9218, -29.5246, -28.8520]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31490 401 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 58: ep_len:401 episode reward: total was -301.500000. running mean: -460.234470\n",
      "startIDX:  219\n",
      "58 5 False\n",
      "x_t:  1 [0.45625    0.33333333 0.228125   0.54166667]\n",
      "Q values:  tensor([[-26.6372, -24.0398, -27.9257, -25.4253, -29.0755, -25.8613]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2545 232 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 58: ep_len:232 episode reward: total was -193.000000. running mean: -457.562126\n",
      "startIDX:  2312\n",
      "58 10 False\n",
      "x_t:  1 [0.875      0.275      0.065625   0.34583333]\n",
      "Q values:  tensor([[-35.3413, -24.5624, -31.9967, -31.2138, -32.4492, -29.9870]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22472 1254 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 58: ep_len:1254 episode reward: total was -947.500000. running mean: -462.461504\n",
      "startIDX:  1509\n",
      "58 12 False\n",
      "x_t:  2 [0.084375   0.41666667 0.109375   0.28333333]\n",
      "Q values:  tensor([[-29.7957, -30.8448, -28.6238, -29.1912, -29.9908, -28.8244]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19393 761 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 58: ep_len:761 episode reward: total was -594.900000. running mean: -463.785889\n",
      "startIDX:  3032\n",
      "ep 58: ep_len:66 episode reward: total was -30.000000. running mean: -459.448030\n",
      "startIDX:  1602\n",
      "58 22 False\n",
      "x_t:  3 [0.753125   0.32916667 0.08125    0.39166667]\n",
      "Q values:  tensor([[-30.7457, -34.8803, -36.0051, -30.1658, -36.4122, -32.6919]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16862 250 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 58: ep_len:250 episode reward: total was -194.700000. running mean: -456.800550\n",
      "startIDX:  774\n",
      "59 0 False\n",
      "x_t:  1 [0.01875    0.36666667 0.13125    0.4       ]\n",
      "Q values:  tensor([[-28.2075, -27.1389, -31.0751, -31.3846, -31.3062, -31.8714]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9408 238 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  419\n",
      "59 1 False\n",
      "x_t:  0 [0.91875    0.37083333 0.06875    0.40416667]\n",
      "Q values:  tensor([[-22.5455, -28.6714, -27.0939, -27.2183, -27.7087, -25.9585]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29092 479 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1167\n",
      "59 5 False\n",
      "x_t:  2 [0.003125   0.40416667 0.090625   0.25416667]\n",
      "Q values:  tensor([[-27.1447, -27.7843, -24.6628, -25.2793, -28.5246, -29.5845]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12002 858 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  396\n",
      "59 10 False\n",
      "x_t:  3 [0.60625    0.29166667 0.090625   0.35      ]\n",
      "Q values:  tensor([[-26.9703, -27.6738, -29.1888, -24.3532, -26.5293, -28.1588]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5067 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1824\n",
      "59 12 False\n",
      "x_t:  0 [0.89375    0.40416667 0.05625    0.36666667]\n",
      "Q values:  tensor([[-24.6310, -30.8462, -26.6989, -26.9822, -26.0805, -25.8615]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21096 582 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  513\n",
      "59 15 False\n",
      "x_t:  1 [0.953125   0.29166667 0.040625   0.27916667]\n",
      "Q values:  tensor([[-33.4098, -33.1514, -33.4814, -35.2216, -34.9483, -37.4048]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5161 711 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2529\n",
      "59 22 False\n",
      "x_t:  3 [0.115625   0.24583333 0.05625    0.25416667]\n",
      "Q values:  tensor([[-34.1481, -34.0752, -32.4221, -30.8367, -34.9915, -33.5667]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26191 1249 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  478.73758149147034\n",
      "startIDX:  1331\n",
      "60 0 False\n",
      "x_t:  4 [0.003125   0.38333333 0.090625   0.29583333]\n",
      "Q values:  tensor([[-26.6303, -27.5143, -26.5057, -25.5778, -25.1649, -27.8353]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16287 566 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 60: ep_len:566 episode reward: total was -405.200000. running mean: -457.845908\n",
      "startIDX:  594\n",
      "60 1 False\n",
      "x_t:  2 [0.809375   0.37916667 0.09375    0.31666667]\n",
      "Q values:  tensor([[-25.9765, -27.8620, -24.9876, -28.9081, -27.8810, -29.4343]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31462 388 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 60: ep_len:388 episode reward: total was -282.900000. running mean: -456.096449\n",
      "startIDX:  943\n",
      "60 5 True\n",
      "x_t:  3 [0.896875   0.32916667 0.1        0.4125    ]\n",
      "Q values:  tensor([[-36.3617, -34.2466, -30.5261, -37.2779, -28.9948, -32.8858]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10482 217 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 60: ep_len:217 episode reward: total was -132.600000. running mean: -452.861484\n",
      "startIDX:  308\n",
      "60 10 False\n",
      "x_t:  3 [0.846875   0.325      0.14375    0.39166667]\n",
      "Q values:  tensor([[-27.6836, -30.7835, -26.1782, -24.3690, -32.7448, -25.2795]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5034 220 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 60: ep_len:220 episode reward: total was -157.900000. running mean: -449.911869\n",
      "startIDX:  1665\n",
      "60 12 False\n",
      "x_t:  1 [0.071875   0.35833333 0.115625   0.3625    ]\n",
      "Q values:  tensor([[-32.2844, -30.0097, -30.3527, -30.1140, -33.5718, -31.7098]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19879 230 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 60: ep_len:230 episode reward: total was -171.800000. running mean: -447.130751\n",
      "startIDX:  761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 15 False\n",
      "x_t:  2 [0.79375 0.4125  0.08125 0.2875 ]\n",
      "Q values:  tensor([[-25.6532, -31.4242, -24.1184, -26.6051, -27.1791, -24.1476]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5967 371 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 60: ep_len:371 episode reward: total was -280.500000. running mean: -445.464443\n",
      "startIDX:  1749\n",
      "60 22 False\n",
      "x_t:  3 [0.434375   0.30416667 0.109375   0.32916667]\n",
      "Q values:  tensor([[-26.7358, -22.4139, -26.5421, -21.8659, -23.9195, -26.5678]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16908 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 60: ep_len:204 episode reward: total was -143.000000. running mean: -442.439799\n",
      "startIDX:  287\n",
      "61 0 False\n",
      "x_t:  3 [0.059375   0.23333333 0.0625     0.225     ]\n",
      "Q values:  tensor([[-24.6933, -23.6260, -25.7625, -19.4629, -23.5067, -23.4964]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4828 1249 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  961\n",
      "61 1 False\n",
      "x_t:  4 [0.096875   0.37916667 0.134375   0.4125    ]\n",
      "Q values:  tensor([[-27.9459, -26.7710, -25.5452, -26.9928, -19.8019, -28.6989]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35439 490 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  759\n",
      "61 5 True\n",
      "x_t:  4 [0.153125   0.40416667 0.128125   0.3875    ]\n",
      "Q values:  tensor([[-25.4884, -27.6789, -27.9559, -27.1493, -26.7391, -25.2960]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10032 648 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1885\n",
      "61 10 False\n",
      "x_t:  2 [0.003125   0.40416667 0.065625   0.24583333]\n",
      "Q values:  tensor([[-24.2170, -24.6980, -21.7145, -24.8936, -23.2075, -24.7910]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18140 799 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1365\n",
      "61 12 False\n",
      "x_t:  3 [0.78125    0.35416667 0.078125   0.44166667]\n",
      "Q values:  tensor([[-30.9996, -27.9697, -32.6884, -26.3868, -28.1300, -29.4996]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17854 208 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  826\n",
      "61 15 False\n",
      "x_t:  3 [0.0625     0.22916667 0.065625   0.2375    ]\n",
      "Q values:  tensor([[-26.1971, -27.5013, -27.8323, -22.5560, -28.3333, -23.4973]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8497 1262 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  591\n",
      "61 22 True\n",
      "x_t:  3 [0.765625   0.32916667 0.09375    0.37916667]\n",
      "Q values:  tensor([[-24.5666, -25.9115, -26.3694, -22.9164, -19.7189, -27.6973]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7066 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  921\n",
      "62 0 False\n",
      "x_t:  0 [0.859375   0.40416667 0.065625   0.34166667]\n",
      "Q values:  tensor([[-27.8796, -28.4279, -30.2836, -30.6271, -29.0211, -29.1741]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10339 436 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 62: ep_len:436 episode reward: total was -339.100000. running mean: -444.641008\n",
      "startIDX:  170\n",
      "62 1 False\n",
      "x_t:  2 [0.003125   0.375      0.096875   0.42916667]\n",
      "Q values:  tensor([[-26.3528, -27.0150, -22.1421, -30.1173, -26.2447, -24.2243]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27430 863 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 62: ep_len:863 episode reward: total was -643.400000. running mean: -446.628598\n",
      "startIDX:  62\n",
      "62 5 False\n",
      "x_t:  2 [0.003125   0.3875     0.1        0.42083333]\n",
      "Q values:  tensor([[-28.3231, -29.1855, -22.7667, -26.1932, -23.7674, -25.9690]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2052 898 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 62: ep_len:898 episode reward: total was -695.200000. running mean: -449.114312\n",
      "startIDX:  2315\n",
      "62 10 True\n",
      "x_t:  1 [0.875      0.275      0.065625   0.34583333]\n",
      "Q values:  tensor([[-33.5552, -25.9318, -30.7834, -31.9899, -28.0688, -26.2468]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22472 1237 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 62: ep_len:1237 episode reward: total was -951.200000. running mean: -454.135169\n",
      "startIDX:  924\n",
      "62 12 False\n",
      "x_t:  1 [0.71875    0.36666667 0.1625     0.50416667]\n",
      "Q values:  tensor([[-28.2365, -25.9514, -28.5866, -26.7685, -31.0913, -26.4325]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12922 604 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 62: ep_len:604 episode reward: total was -489.100000. running mean: -454.484817\n",
      "startIDX:  782\n",
      "62 15 False\n",
      "x_t:  2 [0.778125   0.40833333 0.08125    0.2875    ]\n",
      "Q values:  tensor([[-29.3021, -26.5732, -24.5958, -27.0554, -25.6373, -28.6761]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5970 341 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 62: ep_len:341 episode reward: total was -260.900000. running mean: -452.548969\n",
      "startIDX:  1104\n",
      "62 22 False\n",
      "x_t:  1 [0.796875   0.30416667 0.15625    0.49166667]\n",
      "Q values:  tensor([[-30.8545, -24.8185, -30.5714, -26.9659, -27.7531, -31.1186]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11920 731 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 62: ep_len:731 episode reward: total was -574.800000. running mean: -453.771479\n",
      "startIDX:  2279\n",
      "63 0 True\n",
      "x_t:  2 [0.90625    0.39583333 0.053125   0.1625    ]\n",
      "Q values:  tensor([[-28.8122, -30.0584, -30.0066, -29.1264, -27.7480, -24.9761]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23570 297 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  458\n",
      "63 1 False\n",
      "x_t:  1 [0.8625  0.2625  0.10625 0.4625 ]\n",
      "Q values:  tensor([[-25.3919, -23.6382, -26.0249, -27.3337, -29.5872, -27.3885]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30683 785 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1599\n",
      "63 5 False\n",
      "x_t:  1 [0.684375   0.2875     0.065625   0.30416667]\n",
      "Q values:  tensor([[-33.0058, -31.1484, -33.6797, -32.9309, -33.8280, -32.1897]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14951 688 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  578\n",
      "63 10 True\n",
      "x_t:  2 [0.025      0.40833333 0.09375    0.24583333]\n",
      "Q values:  tensor([[-26.5205, -26.2461, -29.6887, -28.0292, -27.7801, -27.6169]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6591 753 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  471\n",
      "63 12 False\n",
      "x_t:  3 [0.846875   0.3625     0.13125    0.42083333]\n",
      "Q values:  tensor([[-26.9582, -30.6660, -27.2369, -26.8570, -28.9794, -26.9022]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7712 229 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  877\n",
      "63 15 False\n",
      "x_t:  3 [0.065625   0.23333333 0.059375   0.2375    ]\n",
      "Q values:  tensor([[-31.8339, -28.8494, -29.0942, -26.5407, -27.4594, -27.5640]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8498 1229 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1875\n",
      "63 22 True\n",
      "x_t:  2 [0.0625     0.40833333 0.0625     0.27083333]\n",
      "Q values:  tensor([[-30.1809, -32.1000, -32.4081, -25.4803, -31.5405, -33.2763]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18463 789 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  55\n",
      "64 0 True\n",
      "x_t:  1 [0.8875     0.29166667 0.109375   0.43333333]\n",
      "Q values:  tensor([[-24.7002, -27.7285, -29.0296, -31.1278, -25.3511, -29.5831]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1606 720 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 64: ep_len:720 episode reward: total was -553.900000. running mean: -460.538693\n",
      "startIDX:  655\n",
      "64 1 True\n",
      "x_t:  2 [0.6        0.38333333 0.078125   0.31666667]\n",
      "Q values:  tensor([[-29.5919, -28.2934, -26.4983, -23.8599, -27.7587, -28.9874]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31496 363 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 64: ep_len:363 episode reward: total was -286.200000. running mean: -458.795306\n",
      "startIDX:  2281\n",
      "64 5 False\n",
      "x_t:  3 [0.35       0.26666667 0.115625   0.35416667]\n",
      "Q values:  tensor([[-29.7919, -29.2329, -30.1249, -23.5572, -27.7143, -29.4708]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19949 207 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 64: ep_len:207 episode reward: total was -146.500000. running mean: -455.672353\n",
      "startIDX:  388\n",
      "64 10 True\n",
      "x_t:  3 [0.696875   0.29583333 0.065625   0.36666667]\n",
      "Q values:  tensor([[-31.5691, -28.0446, -28.2541, -34.7586, -27.6127, -27.8387]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5057 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 64: ep_len:202 episode reward: total was -147.000000. running mean: -452.585630\n",
      "startIDX:  176\n",
      "64 12 False\n",
      "x_t:  3 [0.1        0.26666667 0.090625   0.275     ]\n",
      "Q values:  tensor([[-42.2453, -39.6002, -42.5261, -39.4196, -40.6586, -39.6010]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5675 1422 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 64: ep_len:1422 episode reward: total was -1026.500000. running mean: -458.324773\n",
      "startIDX:  301\n",
      "64 15 True\n",
      "x_t:  1 [0.203125   0.37083333 0.1375     0.49583333]\n",
      "Q values:  tensor([[-35.8397, -36.2223, -34.8788, -38.0878, -38.6702, -34.7488]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2766 279 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 64: ep_len:279 episode reward: total was -213.100000. running mean: -455.872526\n",
      "startIDX:  1094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 22 False\n",
      "x_t:  1 [0.8625     0.29583333 0.096875   0.5       ]\n",
      "Q values:  tensor([[-33.5103, -27.7126, -31.4991, -31.0447, -31.3915, -30.3738]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11918 746 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 64: ep_len:746 episode reward: total was -552.900000. running mean: -456.842800\n",
      "startIDX:  688\n",
      "65 0 False\n",
      "x_t:  2 [0.109375   0.40833333 0.0875     0.275     ]\n",
      "Q values:  tensor([[-23.4609, -25.3417, -19.8414, -20.3253, -20.5142, -20.9695]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8885 874 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1020\n",
      "65 1 False\n",
      "x_t:  3 [0.790625   0.29583333 0.1125     0.42916667]\n",
      "Q values:  tensor([[-23.7641, -22.8328, -23.7521, -22.1848, -23.5750, -23.2838]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35908 219 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1802\n",
      "65 5 True\n",
      "x_t:  2 [0.834375   0.39583333 0.046875   0.25416667]\n",
      "Q values:  tensor([[-25.0234, -26.6213, -26.6227, -28.4261, -21.1042, -24.1735]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15648 359 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2536\n",
      "startIDX:  326\n",
      "65 12 True\n",
      "x_t:  4 [0.003125   0.44166667 0.103125   0.375     ]\n",
      "Q values:  tensor([[-25.0946, -21.9414, -24.4809, -24.7154, -26.1943, -23.9135]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7183 722 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2786\n",
      "65 15 True\n",
      "x_t:  1 [0.33125    0.35833333 0.171875   0.5125    ]\n",
      "Q values:  tensor([[-30.0293, -29.5119, -31.1225, -31.4327, -30.1061, -25.7098]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22065 280 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1416\n",
      "65 22 False\n",
      "x_t:  3 [0.2        0.27083333 0.08125    0.30833333]\n",
      "Q values:  tensor([[-30.8380, -27.6880, -30.6387, -25.4748, -26.3345, -27.1124]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15240 1260 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  588\n",
      "66 0 False\n",
      "x_t:  2 [0.10625    0.40416667 0.075      0.275     ]\n",
      "Q values:  tensor([[-28.4397, -29.2352, -24.2077, -31.5159, -28.2615, -24.7835]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8884 918 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 66: ep_len:918 episode reward: total was -728.300000. running mean: -456.357993\n",
      "startIDX:  45\n",
      "66 1 False\n",
      "x_t:  3 [0.346875   0.25833333 0.08125    0.31666667]\n",
      "Q values:  tensor([[-22.8670, -27.6360, -25.9772, -22.1153, -23.4254, -23.6916]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25717 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 66: ep_len:202 episode reward: total was -154.100000. running mean: -453.335413\n",
      "startIDX:  994\n",
      "66 5 False\n",
      "x_t:  3 [0.690625   0.29166667 0.09375    0.38333333]\n",
      "Q values:  tensor([[-23.3700, -26.8521, -27.7689, -21.5290, -26.7714, -27.3926]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10504 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 66: ep_len:201 episode reward: total was -132.000000. running mean: -450.122059\n",
      "startIDX:  1549\n",
      "66 10 True\n",
      "x_t:  3 [0.728125   0.30416667 0.134375   0.39166667]\n",
      "Q values:  tensor([[-30.6650, -37.7909, -32.6093, -32.6338, -34.4574, -34.5240]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16419 329 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 66: ep_len:329 episode reward: total was -211.100000. running mean: -447.731838\n",
      "startIDX:  437\n",
      "66 12 False\n",
      "x_t:  3 [0.68125    0.32916667 0.075      0.37916667]\n",
      "Q values:  tensor([[-32.2098, -31.6562, -31.5989, -28.5927, -29.2411, -30.7141]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7735 257 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 66: ep_len:257 episode reward: total was -195.100000. running mean: -445.205520\n",
      "startIDX:  2816\n",
      "66 15 False\n",
      "x_t:  1 [0.284375 0.35     0.109375 0.525   ]\n",
      "Q values:  tensor([[-26.2766, -24.5809, -31.5459, -30.5454, -31.0190, -34.6444]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22059 258 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 66: ep_len:258 episode reward: total was -229.300000. running mean: -443.046465\n",
      "startIDX:  1265\n",
      "66 22 False\n",
      "x_t:  2 [0.765625   0.4125     0.09375    0.24583333]\n",
      "Q values:  tensor([[-30.2711, -27.0060, -26.4206, -26.8034, -28.4684, -27.6986]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12593 322 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 66: ep_len:322 episode reward: total was -273.800000. running mean: -441.354000\n",
      "startIDX:  1528\n",
      "67 0 False\n",
      "x_t:  3 [0.678125   0.33333333 0.0875     0.38333333]\n",
      "Q values:  tensor([[-35.1661, -33.0918, -33.8583, -31.3645, -32.8052, -32.4584]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16836 253 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  357\n",
      "67 1 False\n",
      "x_t:  1 [0.53125    0.30833333 0.246875   0.56666667]\n",
      "Q values:  tensor([[-36.3401, -30.0613, -34.0788, -36.3361, -31.6825, -32.0901]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28101 292 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1542\n",
      "67 5 True\n",
      "x_t:  1 [0.909375   0.27083333 0.084375   0.3375    ]\n",
      "Q values:  tensor([[-27.3205, -27.7987, -31.3402, -28.0336, -25.3327, -28.6109]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14916 695 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  835\n",
      "67 10 False\n",
      "x_t:  0 [0.725      0.39583333 0.078125   0.30416667]\n",
      "Q values:  tensor([[-20.3924, -24.5492, -22.9289, -26.9803, -28.3906, -30.2030]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8134 490 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1481\n",
      "67 12 False\n",
      "x_t:  3 [0.190625   0.2625     0.075      0.29166667]\n",
      "Q values:  tensor([[-28.4522, -26.4629, -26.1768, -24.1207, -27.0351, -28.2277]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17960 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1733\n",
      "67 15 False\n",
      "x_t:  1 [0.009375   0.37083333 0.14375    0.40416667]\n",
      "Q values:  tensor([[-34.1961, -29.0250, -35.2729, -33.8420, -34.9851, -34.5406]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12448 212 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2626\n",
      "67 22 False\n",
      "x_t:  4 [0.165625   0.39166667 0.078125   0.3125    ]\n",
      "Q values:  tensor([[-26.4276, -24.5201, -24.2471, -24.8820, -23.4293, -28.9437]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27286 561 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1644\n",
      "68 0 True\n",
      "x_t:  3 [0.41875    0.29583333 0.0875     0.34166667]\n",
      "Q values:  tensor([[-27.0462, -26.8068, -22.5108, -25.3424, -25.7911, -22.5827]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16875 205 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 68: ep_len:205 episode reward: total was -138.400000. running mean: -428.371938\n",
      "startIDX:  300\n",
      "68 1 False\n",
      "x_t:  1 [0.60625    0.3        0.20625    0.57083333]\n",
      "Q values:  tensor([[-33.2127, -31.3400, -36.3382, -33.3450, -36.1958, -34.7841]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28104 329 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 68: ep_len:329 episode reward: total was -252.300000. running mean: -426.611219\n",
      "startIDX:  2298\n",
      "68 5 False\n",
      "x_t:  3 [0.378125   0.28333333 0.121875   0.35      ]\n",
      "Q values:  tensor([[-27.4937, -22.9193, -23.4318, -19.9203, -25.4258, -26.8618]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19944 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 68: ep_len:200 episode reward: total was -115.500000. running mean: -423.500106\n",
      "startIDX:  2131\n",
      "68 10 False\n",
      "x_t:  0 [0.884375   0.39583333 0.103125   0.34166667]\n",
      "Q values:  tensor([[-25.4118, -25.9395, -31.0224, -27.1204, -28.3840, -26.1237]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19931 548 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 68: ep_len:548 episode reward: total was -407.700000. running mean: -423.342105\n",
      "startIDX:  784\n",
      "68 12 False\n",
      "x_t:  0 [0.9125     0.40833333 0.08125    0.30833333]\n",
      "Q values:  tensor([[-23.1962, -28.7002, -28.5940, -26.4871, -27.6058, -23.9170]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11632 841 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 68: ep_len:841 episode reward: total was -620.500000. running mean: -425.313684\n",
      "startIDX:  891\n",
      "68 15 False\n",
      "x_t:  3 [0.084375   0.23333333 0.046875   0.2375    ]\n",
      "Q values:  tensor([[-20.8936, -22.6128, -22.9623, -18.1692, -21.0668, -18.3190]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8505 1210 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 68: ep_len:1210 episode reward: total was -847.400000. running mean: -429.534547\n",
      "startIDX:  2280\n",
      "68 22 False\n",
      "x_t:  1 [0.4625     0.34583333 0.165625   0.425     ]\n",
      "Q values:  tensor([[-23.7308, -18.8172, -22.4608, -21.2861, -19.8932, -19.7589]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22970 1103 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 68: ep_len:1103 episode reward: total was -775.600000. running mean: -432.995202\n",
      "startIDX:  1034\n",
      "69 0 True\n",
      "x_t:  1 [0.90625    0.29166667 0.090625   0.44166667]\n",
      "Q values:  tensor([[-24.6187, -24.2723, -20.9368, -25.9228, -27.1965, -21.8931]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11945 753 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  587\n",
      "69 1 False\n",
      "x_t:  2 [0.8125     0.38333333 0.1125     0.30833333]\n",
      "Q values:  tensor([[-31.5950, -31.3248, -25.4730, -28.5097, -30.1519, -30.4475]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31459 384 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2292\n",
      "69 5 True\n",
      "x_t:  3 [0.34375    0.27916667 0.11875    0.3375    ]\n",
      "Q values:  tensor([[-20.9258, -22.5073, -22.8998, -22.1240, -21.4409, -20.4432]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19950 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1778\n",
      "69 10 False\n",
      "x_t:  2 [0.025      0.39583333 0.053125   0.25416667]\n",
      "Q values:  tensor([[-22.7464, -21.4739, -21.2199, -24.2112, -29.6648, -21.3759]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18146 868 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1847\n",
      "69 12 False\n",
      "x_t:  0 [0.209375   0.425      0.08125    0.35833333]\n",
      "Q values:  tensor([[-28.9052, -31.4500, -29.0121, -32.2751, -32.7180, -29.1168]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 22990 961 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3046\n",
      "startIDX:  1626\n",
      "69 22 False\n",
      "x_t:  3 [0.778125   0.33333333 0.096875   0.40416667]\n",
      "Q values:  tensor([[-26.3439, -24.5815, -26.0580, -23.2234, -30.2111, -28.6903]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16859 249 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  556.0192906856537\n",
      "startIDX:  496\n",
      "70 0 False\n",
      "x_t:  3 [0.809375 0.375    0.109375 0.45    ]\n",
      "Q values:  tensor([[-26.9705, -24.6257, -22.9988, -22.7853, -30.7875, -23.9346]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 6997 1017 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 70: ep_len:1017 episode reward: total was -763.100000. running mean: -430.368661\n",
      "startIDX:  837\n",
      "70 1 False\n",
      "x_t:  4 [0.003125 0.4      0.121875 0.4     ]\n",
      "Q values:  tensor([[-22.8570, -23.6169, -24.2580, -25.1086, -21.9523, -25.0729]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35423 541 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 70: ep_len:541 episode reward: total was -411.100000. running mean: -430.175974\n",
      "startIDX:  322\n",
      "70 5 True\n",
      "x_t:  1 [0.665625   0.29166667 0.115625   0.35833333]\n",
      "Q values:  tensor([[-26.4507, -25.4465, -26.5001, -23.0987, -23.6194, -25.8297]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5054 746 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 70: ep_len:746 episode reward: total was -535.300000. running mean: -431.227215\n",
      "startIDX:  2240\n",
      "70 10 True\n",
      "x_t:  1 [0.671875   0.29583333 0.134375   0.325     ]\n",
      "Q values:  tensor([[-27.3318, -24.7229, -28.1462, -25.4227, -27.8951, -25.9357]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22491 1269 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 70: ep_len:1269 episode reward: total was -937.100000. running mean: -436.285942\n",
      "startIDX:  837\n",
      "70 12 False\n",
      "x_t:  0 [0.621875 0.4125   0.09375  0.3     ]\n",
      "Q values:  tensor([[-24.8079, -30.3639, -28.3784, -26.8454, -31.5741, -27.9503]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11677 656 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 70: ep_len:656 episode reward: total was -497.100000. running mean: -436.894083\n",
      "startIDX:  885\n",
      "70 15 False\n",
      "x_t:  3 [0.0625     0.23333333 0.05625    0.22916667]\n",
      "Q values:  tensor([[-27.4979, -27.5242, -31.1833, -21.9989, -28.4404, -26.7518]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8494 1227 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 70: ep_len:1227 episode reward: total was -930.400000. running mean: -441.829142\n",
      "startIDX:  1223\n",
      "70 22 True\n",
      "x_t:  2 [0.775      0.40416667 0.040625   0.2625    ]\n",
      "Q values:  tensor([[-32.7480, -36.9036, -35.8011, -39.0196, -30.7102, -33.6499]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12596 336 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 70: ep_len:336 episode reward: total was -255.400000. running mean: -439.964851\n",
      "startIDX:  488\n",
      "71 0 True\n",
      "x_t:  3 [0.828125   0.37916667 0.1125     0.44166667]\n",
      "Q values:  tensor([[-32.8454, -26.1232, -29.6359, -28.1691, -30.1548, -29.1046]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 6996 1022 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  887\n",
      "71 1 False\n",
      "x_t:  4 [0.040625   0.39166667 0.090625   0.40833333]\n",
      "Q values:  tensor([[-32.9549, -30.6205, -31.0359, -34.1494, -29.6509, -31.2480]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35428 519 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  647\n",
      "71 5 False\n",
      "x_t:  3 [0.115625   0.27083333 0.06875    0.3125    ]\n",
      "Q values:  tensor([[-37.7351, -32.4207, -31.7692, -30.8027, -35.7652, -31.9772]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8764 1367 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1008\n",
      "71 10 True\n",
      "x_t:  1 [0.725   0.2875  0.06875 0.3375 ]\n",
      "Q values:  tensor([[-31.3253, -33.2766, -29.9428, -26.9808, -35.0341, -32.0070]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11350 1531 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1353\n",
      "71 12 False\n",
      "x_t:  3 [0.696875   0.35833333 0.15       0.425     ]\n",
      "Q values:  tensor([[-28.6767, -28.6505, -26.2999, -25.8473, -29.3930, -30.3052]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17859 213 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1521\n",
      "71 15 True\n",
      "x_t:  2 [0.003125   0.4125     0.075      0.25416667]\n",
      "Q values:  tensor([[-24.6430, -31.9891, -25.5927, -32.5037, -29.5535, -30.4914]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 11908 740 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1573\n",
      "71 22 False\n",
      "x_t:  4 [0.028125   0.39166667 0.078125   0.30833333]\n",
      "Q values:  tensor([[-26.2764, -24.6749, -27.3353, -25.7208, -22.7974, -23.9959]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16327 476 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2475\n",
      "ep 72: ep_len:55 episode reward: total was -31.000000. running mean: -449.100249\n",
      "startIDX:  124\n",
      "72 1 False\n",
      "x_t:  2 [0.19375    0.35833333 0.103125   0.4375    ]\n",
      "Q values:  tensor([[-32.7652, -30.9658, -30.3501, -30.4519, -36.7519, -30.6827]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27462 913 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 72: ep_len:913 episode reward: total was -691.900000. running mean: -451.528246\n",
      "startIDX:  1592\n",
      "72 5 False\n",
      "x_t:  1 [0.8125     0.28333333 0.115625   0.31666667]\n",
      "Q values:  tensor([[-33.2520, -29.4672, -33.0271, -33.2078, -31.1699, -30.3535]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14929 675 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 72: ep_len:675 episode reward: total was -527.400000. running mean: -452.286964\n",
      "startIDX:  94\n",
      "72 10 False\n",
      "x_t:  3 [0.059375   0.2375     0.05625    0.25416667]\n",
      "Q values:  tensor([[-38.6349, -42.1642, -36.7290, -34.8746, -37.3312, -36.7643]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3576 1043 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 72: ep_len:1043 episode reward: total was -798.300000. running mean: -455.747094\n",
      "startIDX:  1018\n",
      "72 12 False\n",
      "x_t:  2 [0.8875     0.39166667 0.0625     0.22083333]\n",
      "Q values:  tensor([[-31.2776, -33.0204, -26.0689, -30.1145, -30.5152, -28.1342]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13565 297 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 72: ep_len:297 episode reward: total was -230.500000. running mean: -453.494623\n",
      "startIDX:  725\n",
      "72 15 False\n",
      "x_t:  2 [0.70625    0.41666667 0.109375   0.29166667]\n",
      "Q values:  tensor([[-28.4847, -30.5547, -26.8494, -26.9133, -31.4392, -28.8776]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5981 381 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 72: ep_len:381 episode reward: total was -293.100000. running mean: -451.890677\n",
      "startIDX:  1004\n",
      "72 22 False\n",
      "x_t:  0 [0.7625     0.4125     0.1125     0.32083333]\n",
      "Q values:  tensor([[-28.2079, -33.7725, -32.2088, -30.1127, -28.8677, -31.8058]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10418 450 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 72: ep_len:450 episode reward: total was -336.200000. running mean: -450.733770\n",
      "startIDX:  1598\n",
      "73 0 False\n",
      "x_t:  3 [0.846875   0.34583333 0.15       0.425     ]\n",
      "Q values:  tensor([[-28.3326, -30.3558, -28.8654, -27.5138, -30.5914, -28.9919]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16812 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  659\n",
      "73 1 True\n",
      "x_t:  2 [0.78125    0.37083333 0.084375   0.33333333]\n",
      "Q values:  tensor([[-33.3694, -29.0622, -25.7841, -27.6307, -25.1832, -24.8388]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31468 352 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  682\n",
      "73 5 False\n",
      "x_t:  3 [0.103125   0.26666667 0.08125    0.31666667]\n",
      "Q values:  tensor([[-27.7187, -28.8689, -28.9926, -24.0021, -26.8713, -25.1785]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8760 1325 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  371\n",
      "73 10 False\n",
      "x_t:  3 [0.815625   0.30416667 0.103125   0.39166667]\n",
      "Q values:  tensor([[-29.7879, -26.2774, -27.9059, -25.4520, -27.5186, -28.5457]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5042 206 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 12 False\n",
      "x_t:  1 [0.61875    0.37916667 0.125      0.48333333]\n",
      "Q values:  tensor([[-25.5286, -24.5267, -24.8530, -24.9675, -27.3461, -24.5913]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12928 619 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2251\n",
      "73 15 False\n",
      "x_t:  3 [0.175      0.28333333 0.1        0.32083333]\n",
      "Q values:  tensor([[-24.2178, -22.6619, -19.5831, -19.3317, -21.5405, -19.3909]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18196 1296 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  445\n",
      "73 22 False\n",
      "x_t:  4 [0.009375   0.41666667 0.09375    0.37083333]\n",
      "Q values:  tensor([[-30.2312, -29.9702, -27.7325, -29.1254, -25.2476, -27.4324]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 6625 838 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1115\n",
      "74 0 False\n",
      "x_t:  2 [0.575      0.40833333 0.096875   0.29583333]\n",
      "Q values:  tensor([[-25.5991, -31.1531, -23.8865, -28.8320, -26.7898, -28.4535]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12664 356 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 74: ep_len:356 episode reward: total was -256.700000. running mean: -453.426874\n",
      "startIDX:  419\n",
      "74 1 False\n",
      "x_t:  0 [0.84375    0.37083333 0.128125   0.4       ]\n",
      "Q values:  tensor([[-23.5728, -26.0773, -25.4985, -24.2677, -25.9801, -27.0117]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29097 488 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 74: ep_len:488 episode reward: total was -388.300000. running mean: -452.775605\n",
      "startIDX:  2792\n",
      "74 5 True\n",
      "x_t:  0 [0.940625 0.3875   0.05     0.3125  ]\n",
      "Q values:  tensor([[-30.9607, -36.3614, -34.5629, -34.7522, -32.7022, -33.2248]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23148 490 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 74: ep_len:490 episode reward: total was -359.500000. running mean: -451.842849\n",
      "startIDX:  2225\n",
      "74 10 False\n",
      "x_t:  0 [0.9    0.3875 0.0875 0.3625]\n",
      "Q values:  tensor([[-31.5816, -35.0043, -34.3902, -32.0097, -34.3091, -32.3136]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19929 491 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 74: ep_len:491 episode reward: total was -341.600000. running mean: -450.740421\n",
      "startIDX:  1328\n",
      "74 12 False\n",
      "x_t:  3 [0.81875    0.37083333 0.171875   0.43333333]\n",
      "Q values:  tensor([[-29.5943, -30.7000, -32.6583, -26.3593, -30.4100, -31.3716]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17844 219 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 74: ep_len:219 episode reward: total was -122.000000. running mean: -447.453017\n",
      "startIDX:  636\n",
      "74 15 False\n",
      "x_t:  1 [0.93125    0.29583333 0.05625    0.27916667]\n",
      "Q values:  tensor([[-33.9542, -27.9143, -28.2723, -30.6829, -29.7121, -28.9712]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5163 659 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 74: ep_len:659 episode reward: total was -487.300000. running mean: -447.851486\n",
      "startIDX:  28\n",
      "74 22 True\n",
      "x_t:  1 [0.853125   0.30833333 0.140625   0.40833333]\n",
      "Q values:  tensor([[-26.6029, -28.4238, -27.1626, -28.3694, -29.9158, -26.0483]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1580 719 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 74: ep_len:719 episode reward: total was -511.800000. running mean: -448.490971\n",
      "startIDX:  3\n",
      "75 0 False\n",
      "x_t:  1 [0.715625   0.30833333 0.109375   0.425     ]\n",
      "Q values:  tensor([[-26.5482, -20.5246, -24.0173, -21.4057, -26.0297, -21.9730]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1628 762 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  325\n",
      "75 1 True\n",
      "x_t:  0 [0.865625   0.37083333 0.1125     0.4125    ]\n",
      "Q values:  tensor([[-27.4439, -28.3862, -28.4994, -28.8025, -25.6470, -28.2769]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29095 804 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  689\n",
      "75 5 True\n",
      "x_t:  3 [0.0625     0.25833333 0.078125   0.31666667]\n",
      "Q values:  tensor([[-22.7684, -25.2095, -26.3473, -25.1298, -24.8517, -24.8542]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8745 1334 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2422\n",
      "75 10 False\n",
      "x_t:  1 [0.846875   0.275      0.078125   0.34583333]\n",
      "Q values:  tensor([[-20.5987, -16.8591, -18.6160, -19.6653, -21.9113, -20.3721]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22474 1173 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  471\n",
      "75 12 True\n",
      "x_t:  3 [0.846875   0.3625     0.13125    0.42083333]\n",
      "Q values:  tensor([[-27.7025, -31.8653, -31.0964, -24.8128, -29.7982, -27.6471]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7712 225 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1337\n",
      "75 15 False\n",
      "x_t:  3 [0.86875    0.35416667 0.125      0.37916667]\n",
      "Q values:  tensor([[-20.1788, -22.5498, -25.9175, -18.9154, -23.8172, -24.0914]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10337 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  137\n",
      "75 22 False\n",
      "x_t:  1 [0.8625     0.30416667 0.134375   0.40833333]\n",
      "Q values:  tensor([[-32.2944, -31.2845, -32.2604, -33.9817, -31.4541, -31.3829]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1578 650 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  560\n",
      "76 0 False\n",
      "x_t:  3 [0.821875   0.38333333 0.140625   0.44583333]\n",
      "Q values:  tensor([[-29.9830, -29.8089, -30.4066, -27.1765, -32.3659, -30.9723]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 6995 991 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 76: ep_len:991 episode reward: total was -714.000000. running mean: -456.198352\n",
      "startIDX:  1190\n",
      "ep 76: ep_len:9 episode reward: total was -9.000000. running mean: -451.726369\n",
      "startIDX:  1098\n",
      "76 5 False\n",
      "x_t:  3 [0.10625    0.23333333 0.071875   0.2625    ]\n",
      "Q values:  tensor([[-23.5712, -22.8080, -26.8783, -22.4728, -25.4027, -24.7679]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10605 206 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 76: ep_len:206 episode reward: total was -136.000000. running mean: -448.569105\n",
      "startIDX:  1947\n",
      "76 10 True\n",
      "x_t:  1 [0.1        0.3375     0.125      0.37916667]\n",
      "Q values:  tensor([[-24.0508, -26.0994, -22.7279, -25.8074, -27.4905, -24.5930]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18821 333 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 76: ep_len:333 episode reward: total was -237.800000. running mean: -446.461414\n",
      "startIDX:  1003\n",
      "76 12 True\n",
      "x_t:  2 [0.178125   0.40833333 0.059375   0.25      ]\n",
      "Q values:  tensor([[-30.3308, -29.5437, -26.8831, -30.2491, -32.0272, -25.4327]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13670 361 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 76: ep_len:361 episode reward: total was -241.800000. running mean: -444.414800\n",
      "startIDX:  2967\n",
      "ep 76: ep_len:98 episode reward: total was -44.900000. running mean: -440.419652\n",
      "startIDX:  2269\n",
      "76 22 False\n",
      "x_t:  1 [0.721875   0.30833333 0.178125   0.45416667]\n",
      "Q values:  tensor([[-23.7387, -20.3552, -21.0802, -22.9889, -25.3494, -22.9088]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22943 1096 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 76: ep_len:1096 episode reward: total was -761.100000. running mean: -443.626455\n",
      "startIDX:  505\n",
      "77 0 False\n",
      "x_t:  3 [0.584375   0.35416667 0.159375   0.45833333]\n",
      "Q values:  tensor([[-19.9871, -19.9065, -20.6028, -18.8222, -19.6577, -23.5833]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7018 1039 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  133\n",
      "77 1 True\n",
      "x_t:  2 [0.103125   0.36666667 0.109375   0.44583333]\n",
      "Q values:  tensor([[-24.9470, -25.5368, -25.5589, -22.9532, -22.8413, -22.3874]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27446 909 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  358\n",
      "77 5 False\n",
      "x_t:  1 [0.865625   0.27916667 0.128125   0.3875    ]\n",
      "Q values:  tensor([[-25.5394, -23.1704, -26.8812, -26.1346, -27.4986, -23.9931]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5028 706 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  955\n",
      "77 10 False\n",
      "x_t:  1 [0.746875   0.28333333 0.090625   0.3375    ]\n",
      "Q values:  tensor([[-32.3289, -28.7012, -30.0955, -31.0016, -31.3825, -29.9192]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11346 1574 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1210\n",
      "77 12 True\n",
      "x_t:  4 [0.128125   0.42083333 0.084375   0.37083333]\n",
      "Q values:  tensor([[-25.9042, -30.8822, -23.7421, -29.0243, -26.3971, -28.0542]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17402 493 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  462\n",
      "77 15 False\n",
      "x_t:  1 [0.95625    0.29166667 0.040625   0.2875    ]\n",
      "Q values:  tensor([[-32.8737, -29.1687, -33.7528, -30.6830, -29.1751, -29.8976]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5160 759 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1987\n",
      "77 22 False\n",
      "x_t:  1 [0.090625   0.36666667 0.146875   0.38333333]\n",
      "Q values:  tensor([[-29.5444, -27.5876, -32.2657, -34.5209, -29.1912, -29.4566]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19000 261 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 0 False\n",
      "x_t:  3 [0.559375 0.3125   0.08125  0.375   ]\n",
      "Q values:  tensor([[-26.5666, -25.8474, -25.7692, -24.3109, -28.6044, -28.0088]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16852 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 78: ep_len:200 episode reward: total was -106.800000. running mean: -449.397286\n",
      "startIDX:  517\n",
      "78 1 False\n",
      "x_t:  1 [0.6875     0.27083333 0.109375   0.4625    ]\n",
      "Q values:  tensor([[-30.2931, -26.0733, -27.4394, -29.5940, -29.6921, -28.4347]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30700 770 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 78: ep_len:770 episode reward: total was -571.400000. running mean: -450.617313\n",
      "startIDX:  2719\n",
      "78 5 False\n",
      "x_t:  1 [0.146875   0.3375     0.13125    0.50416667]\n",
      "Q values:  tensor([[-26.9494, -22.8763, -26.4924, -26.6292, -28.0559, -24.9987]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22118 233 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 78: ep_len:233 episode reward: total was -190.500000. running mean: -448.016140\n",
      "startIDX:  1310\n",
      "78 10 False\n",
      "x_t:  3 [0.071875 0.225    0.065625 0.25    ]\n",
      "Q values:  tensor([[-32.3637, -30.2822, -30.3040, -27.8204, -28.9595, -28.8592]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14576 1209 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 78: ep_len:1209 episode reward: total was -891.300000. running mean: -452.448979\n",
      "startIDX:  1567\n",
      "78 12 False\n",
      "x_t:  2 [0.00625    0.4125     0.10625    0.28333333]\n",
      "Q values:  tensor([[-24.8716, -27.7805, -24.6827, -27.0929, -29.9659, -27.1317]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19381 740 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 78: ep_len:740 episode reward: total was -511.100000. running mean: -453.035489\n",
      "startIDX:  1036\n",
      "78 15 True\n",
      "x_t:  4 [0.071875   0.39166667 0.103125   0.3       ]\n",
      "Q values:  tensor([[-29.5625, -30.5120, -28.5151, -28.6287, -24.9611, -32.2694]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9824 600 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 78: ep_len:600 episode reward: total was -443.600000. running mean: -452.941134\n",
      "startIDX:  796\n",
      "78 22 False\n",
      "x_t:  2 [0.09375    0.41666667 0.08125    0.25      ]\n",
      "Q values:  tensor([[-25.9252, -25.9543, -23.1135, -25.9584, -24.5595, -25.8436]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8932 836 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 78: ep_len:836 episode reward: total was -582.700000. running mean: -454.238723\n",
      "startIDX:  918\n",
      "79 0 False\n",
      "x_t:  0 [0.8625     0.40416667 0.125      0.35833333]\n",
      "Q values:  tensor([[-26.7132, -30.1101, -33.7855, -35.4138, -28.5611, -31.4374]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10333 432 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  648\n",
      "79 1 True\n",
      "x_t:  2 [0.725      0.37916667 0.0875     0.31666667]\n",
      "Q values:  tensor([[-24.3912, -23.0090, -21.9408, -26.5392, -26.6463, -22.2061]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31478 367 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  365\n",
      "79 5 False\n",
      "x_t:  1 [0.559375   0.30416667 0.134375   0.35833333]\n",
      "Q values:  tensor([[-35.1849, -29.9979, -31.8820, -33.6340, -31.4033, -31.2278]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5065 723 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  227\n",
      "79 10 False\n",
      "x_t:  4 [0.003125 0.3625   0.078125 0.25    ]\n",
      "Q values:  tensor([[-24.4867, -31.6252, -28.5384, -27.6739, -24.2734, -26.1751]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4545 446 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1035\n",
      "79 12 False\n",
      "x_t:  2 [0.69375    0.40833333 0.053125   0.24583333]\n",
      "Q values:  tensor([[-29.7691, -27.9002, -26.9635, -28.5263, -29.7985, -27.4279]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13594 312 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1198\n",
      "79 15 False\n",
      "x_t:  4 [0.11875    0.39166667 0.06875    0.29166667]\n",
      "Q values:  tensor([[-25.4151, -24.1518, -23.6550, -22.6307, -22.4809, -25.4701]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9832 532 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1026\n",
      "79 22 True\n",
      "x_t:  0 [0.83125    0.40833333 0.08125    0.32916667]\n",
      "Q values:  tensor([[-29.3490, -31.4929, -24.3782, -21.8105, -26.2648, -26.1756]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10413 432 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  647.9970459938049\n",
      "startIDX:  1959\n",
      "80 0 False\n",
      "x_t:  1 [0.003125 0.375    0.159375 0.4125  ]\n",
      "Q values:  tensor([[-31.5148, -24.6205, -27.4815, -30.9772, -29.2197, -28.1977]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18924 222 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 80: ep_len:222 episode reward: total was -162.300000. running mean: -443.005110\n",
      "startIDX:  391\n",
      "80 1 False\n",
      "x_t:  1 [0.496875 0.3      0.240625 0.575   ]\n",
      "Q values:  tensor([[-24.1627, -23.4156, -27.1534, -28.7684, -25.4782, -24.4494]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28099 281 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 80: ep_len:281 episode reward: total was -189.900000. running mean: -440.474059\n",
      "startIDX:  2405\n",
      "80 5 False\n",
      "x_t:  2 [0.06875 0.4     0.09375 0.2625 ]\n",
      "Q values:  tensor([[-25.2133, -26.6106, -23.7414, -29.8773, -26.3220, -27.3089]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21559 960 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 80: ep_len:960 episode reward: total was -689.300000. running mean: -442.962319\n",
      "startIDX:  2365\n",
      "80 10 False\n",
      "x_t:  1 [0.78125  0.2875   0.140625 0.3375  ]\n",
      "Q values:  tensor([[-29.1127, -28.5425, -29.5634, -29.2837, -28.8545, -30.0227]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22478 1233 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 80: ep_len:1233 episode reward: total was -867.800000. running mean: -447.210696\n",
      "startIDX:  156\n",
      "80 12 False\n",
      "x_t:  2 [0.23125    0.4125     0.09375    0.24583333]\n",
      "Q values:  tensor([[-25.8678, -24.2457, -17.9720, -21.9732, -24.5640, -27.1848]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2894 323 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 80: ep_len:323 episode reward: total was -247.300000. running mean: -445.211589\n",
      "startIDX:  391\n",
      "80 15 True\n",
      "x_t:  0 [0.903125   0.40416667 0.0625     0.33333333]\n",
      "Q values:  tensor([[-25.6373, -26.1904, -25.0994, -23.8883, -24.5709, -24.9130]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3656 443 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 80: ep_len:443 episode reward: total was -342.800000. running mean: -444.187473\n",
      "startIDX:  841\n",
      "80 22 False\n",
      "x_t:  1 [0.009375   0.36666667 0.10625    0.40416667]\n",
      "Q values:  tensor([[-28.1512, -21.6570, -26.4932, -27.0686, -24.4420, -27.1282]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9482 276 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 80: ep_len:276 episode reward: total was -202.900000. running mean: -441.774598\n",
      "startIDX:  2443\n",
      "startIDX:  708\n",
      "81 1 False\n",
      "x_t:  3 [0.0625     0.23333333 0.059375   0.275     ]\n",
      "Q values:  tensor([[-27.5863, -24.4878, -31.3183, -22.6862, -26.8976, -25.6213]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34301 1424 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  503\n",
      "81 5 False\n",
      "x_t:  2 [0.75625    0.4        0.096875   0.29166667]\n",
      "Q values:  tensor([[-31.6819, -31.9175, -26.3070, -29.5168, -29.0832, -26.5453]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6045 515 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  959\n",
      "81 10 True\n",
      "x_t:  1 [0.85       0.2875     0.128125   0.33333333]\n",
      "Q values:  tensor([[-29.1250, -29.7612, -29.3105, -27.7826, -30.7811, -32.3406]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11331 1585 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1759\n",
      "81 12 True\n",
      "x_t:  0 [0.74375    0.41666667 0.1125     0.3375    ]\n",
      "Q values:  tensor([[-28.1448, -21.9556, -27.4567, -21.7009, -24.7917, -28.0241]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21111 619 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1245\n",
      "81 15 False\n",
      "x_t:  3 [0.825      0.33333333 0.09375    0.38333333]\n",
      "Q values:  tensor([[-33.0758, -33.3178, -35.3947, -28.1357, -32.4622, -30.6018]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10345 253 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1000\n",
      "81 22 False\n",
      "x_t:  0 [0.921875   0.4        0.071875   0.34166667]\n",
      "Q values:  tensor([[-22.8599, -31.1121, -27.5009, -29.1215, -29.0209, -25.3468]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10399 439 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2152\n",
      "82 0 True\n",
      "x_t:  1 [0.8125     0.3        0.11875    0.52916667]\n",
      "Q values:  tensor([[-39.8166, -40.9383, -43.5200, -37.1375, -32.4186, -38.6379]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22924 1134 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 82: ep_len:1134 episode reward: total was -885.400000. running mean: -453.101558\n",
      "startIDX:  495\n",
      "82 1 False\n",
      "x_t:  1 [0.8625  0.2625  0.10625 0.4625 ]\n",
      "Q values:  tensor([[-33.6884, -29.7399, -31.7555, -32.2966, -32.0636, -30.1635]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30683 753 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 82: ep_len:753 episode reward: total was -583.600000. running mean: -454.406543\n",
      "startIDX:  2793\n",
      "82 5 False\n",
      "x_t:  0 [0.94375    0.38333333 0.046875   0.3125    ]\n",
      "Q values:  tensor([[-27.5398, -33.6757, -30.6283, -29.5889, -29.0844, -31.3065]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23146 482 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 82: ep_len:482 episode reward: total was -386.400000. running mean: -453.726477\n",
      "startIDX:  739\n",
      "82 10 False\n",
      "x_t:  1 [0.0875     0.34583333 0.084375   0.37916667]\n",
      "Q values:  tensor([[-35.9895, -29.3600, -32.9103, -32.2972, -32.9768, -30.8866]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7113 230 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 82: ep_len:230 episode reward: total was -177.900000. running mean: -450.968212\n",
      "startIDX:  1081\n",
      "82 12 False\n",
      "x_t:  3 [0.065625   0.2625     0.0625     0.24583333]\n",
      "Q values:  tensor([[-32.7390, -32.6162, -34.6461, -28.5257, -29.1285, -31.5660]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16373 1399 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 82: ep_len:1399 episode reward: total was -1076.800000. running mean: -457.226530\n",
      "startIDX:  1627\n",
      "82 15 True\n",
      "x_t:  1 [0.11875    0.35833333 0.109375   0.37916667]\n",
      "Q values:  tensor([[-30.1917, -30.4961, -35.6055, -33.1352, -32.5884, -32.4882]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12458 269 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 82: ep_len:269 episode reward: total was -209.200000. running mean: -454.746265\n",
      "startIDX:  2989\n",
      "ep 82: ep_len:15 episode reward: total was 5.000000. running mean: -450.148802\n",
      "startIDX:  1890\n",
      "83 0 False\n",
      "x_t:  1 [0.003125 0.3875   0.18125  0.4     ]\n",
      "Q values:  tensor([[-29.0748, -26.9934, -35.0390, -35.8249, -33.9392, -36.0589]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18926 254 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  545\n",
      "83 1 False\n",
      "x_t:  1 [0.8625     0.25833333 0.0875     0.47083333]\n",
      "Q values:  tensor([[-27.7171, -21.2734, -22.5302, -25.7168, -26.4453, -27.9244]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30684 745 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2735\n",
      "83 5 True\n",
      "x_t:  1 [0.003125   0.34583333 0.121875   0.51666667]\n",
      "Q values:  tensor([[-33.4455, -32.4305, -31.0742, -32.3319, -31.4607, -31.4677]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22105 206 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1954\n",
      "83 10 False\n",
      "x_t:  1 [0.01875    0.34166667 0.11875    0.4       ]\n",
      "Q values:  tensor([[-30.3332, -28.3973, -32.5592, -29.2419, -30.4427, -31.0031]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18813 321 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1990\n",
      "startIDX:  1730\n",
      "83 15 False\n",
      "x_t:  1 [0.04375    0.3625     0.121875   0.40833333]\n",
      "Q values:  tensor([[-34.3348, -28.0567, -32.4698, -29.0890, -32.9939, -28.1690]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12452 219 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1076\n",
      "83 22 True\n",
      "x_t:  1 [0.8625     0.29583333 0.096875   0.5       ]\n",
      "Q values:  tensor([[-26.8516, -24.9682, -23.6140, -25.5134, -24.1691, -21.0178]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11918 746 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1581\n",
      "84 0 False\n",
      "x_t:  3 [0.878125   0.34166667 0.115625   0.43333333]\n",
      "Q values:  tensor([[-30.2237, -28.6430, -29.8504, -27.5769, -28.4022, -29.2191]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16811 218 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 84: ep_len:218 episode reward: total was -143.700000. running mean: -434.652451\n",
      "startIDX:  599\n",
      "84 1 True\n",
      "x_t:  2 [0.75625    0.37916667 0.09375    0.32916667]\n",
      "Q values:  tensor([[-28.1748, -26.5849, -29.7618, -30.7410, -28.8688, -27.9501]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31470 397 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 84: ep_len:397 episode reward: total was -279.800000. running mean: -433.103927\n",
      "startIDX:  1835\n",
      "84 5 False\n",
      "x_t:  2 [0.84375    0.40416667 0.08125    0.2375    ]\n",
      "Q values:  tensor([[-26.0973, -27.1504, -24.5541, -30.5355, -26.0905, -26.1299]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15641 348 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 84: ep_len:348 episode reward: total was -260.100000. running mean: -431.373887\n",
      "startIDX:  1321\n",
      "84 10 True\n",
      "x_t:  4 [0.00625    0.36666667 0.103125   0.27916667]\n",
      "Q values:  tensor([[-32.6805, -29.3030, -30.5444, -31.1974, -25.2605, -27.3361]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15704 567 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 84: ep_len:567 episode reward: total was -390.500000. running mean: -430.965149\n",
      "startIDX:  396\n",
      "84 12 False\n",
      "x_t:  3 [0.58125    0.32916667 0.1625     0.37083333]\n",
      "Q values:  tensor([[-28.6208, -28.3989, -28.2718, -27.2851, -28.9581, -28.5390]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7740 273 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 84: ep_len:273 episode reward: total was -170.900000. running mean: -428.364497\n",
      "startIDX:  964\n",
      "84 15 False\n",
      "x_t:  4 [0.0125     0.39166667 0.090625   0.29583333]\n",
      "Q values:  tensor([[-28.4947, -28.8822, -30.5241, -29.8798, -27.6734, -30.9709]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9814 640 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 84: ep_len:640 episode reward: total was -455.500000. running mean: -428.635852\n",
      "startIDX:  2901\n",
      "ep 84: ep_len:59 episode reward: total was -23.000000. running mean: -424.579494\n",
      "startIDX:  1172\n",
      "85 0 False\n",
      "x_t:  2 [0.76875    0.40833333 0.096875   0.2875    ]\n",
      "Q values:  tensor([[-26.8816, -26.2820, -24.9337, -27.6565, -27.3560, -25.4293]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12635 310 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  42\n",
      "85 1 False\n",
      "x_t:  3 [0.284375   0.24583333 0.10625    0.32083333]\n",
      "Q values:  tensor([[-22.4650, -22.4047, -26.5694, -20.5381, -23.5643, -25.1581]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25727 205 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  736\n",
      "85 5 False\n",
      "x_t:  3 [0.09375    0.26666667 0.084375   0.31666667]\n",
      "Q values:  tensor([[-20.8477, -20.7967, -22.5805, -18.5393, -20.4437, -21.1427]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8758 1295 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2237\n",
      "85 10 False\n",
      "x_t:  0 [0.871875   0.3875     0.078125   0.35416667]\n",
      "Q values:  tensor([[-21.1375, -21.2498, -26.5600, -21.1881, -26.2239, -22.9334]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19939 508 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1899\n",
      "85 12 False\n",
      "x_t:  0 [0.24375    0.425      0.065625   0.29583333]\n",
      "Q values:  tensor([[-23.0380, -24.9509, -25.5639, -27.0157, -27.2592, -24.9945]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 22994 917 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2288\n",
      "85 15 True\n",
      "x_t:  3 [0.071875   0.27083333 0.078125   0.3       ]\n",
      "Q values:  tensor([[-23.2092, -26.5592, -28.5429, -26.9950, -26.4403, -21.7637]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18176 1251 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  260\n",
      "85 22 False\n",
      "x_t:  3 [0.071875   0.24166667 0.059375   0.2375    ]\n",
      "Q values:  tensor([[-35.8149, -32.4366, -30.9943, -28.5202, -29.7110, -28.9480]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4874 1293 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  510\n",
      "86 0 True\n",
      "x_t:  3 [0.68125    0.37083333 0.178125   0.45      ]\n",
      "Q values:  tensor([[-30.6993, -34.9835, -31.8046, -32.2550, -31.8398, -33.4189]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7003 1036 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 86: ep_len:1036 episode reward: total was -746.900000. running mean: -439.971637\n",
      "startIDX:  463\n",
      "86 1 False\n",
      "x_t:  1 [0.73125    0.27916667 0.121875   0.44583333]\n",
      "Q values:  tensor([[-41.7041, -32.2174, -39.5455, -34.7505, -34.9214, -32.7656]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30697 793 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 86: ep_len:793 episode reward: total was -579.200000. running mean: -441.363921\n",
      "startIDX:  468\n",
      "86 5 False\n",
      "x_t:  1 [0.8375     0.27916667 0.08125    0.38333333]\n",
      "Q values:  tensor([[-28.7281, -27.1014, -29.9581, -28.2757, -31.3729, -32.1992]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5034 665 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 86: ep_len:665 episode reward: total was -459.900000. running mean: -441.549282\n",
      "startIDX:  870\n",
      "86 10 False\n",
      "x_t:  0 [0.896875   0.39583333 0.096875   0.32083333]\n",
      "Q values:  tensor([[-20.2662, -23.6444, -23.0806, -23.7501, -24.4271, -25.8234]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8106 453 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 86: ep_len:453 episode reward: total was -333.500000. running mean: -440.468789\n",
      "startIDX:  719\n",
      "86 12 True\n",
      "x_t:  1 [0.003125   0.39583333 0.153125   0.47083333]\n",
      "Q values:  tensor([[-30.9525, -30.6188, -30.4729, -28.6016, -27.6951, -30.3551]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10304 206 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 86: ep_len:206 episode reward: total was -153.600000. running mean: -437.600101\n",
      "startIDX:  2192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 15 False\n",
      "x_t:  3 [0.065625   0.275      0.084375   0.29583333]\n",
      "Q values:  tensor([[-24.3985, -20.8502, -21.7387, -18.8567, -21.5845, -22.0752]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18172 1296 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 86: ep_len:1296 episode reward: total was -942.500000. running mean: -442.649100\n",
      "startIDX:  598\n",
      "86 22 False\n",
      "x_t:  3 [0.60625    0.32083333 0.115625   0.35      ]\n",
      "Q values:  tensor([[-26.7232, -28.4554, -31.1409, -24.3042, -27.3753, -25.7129]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7088 208 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 86: ep_len:208 episode reward: total was -171.900000. running mean: -439.941609\n",
      "startIDX:  2236\n",
      "87 0 True\n",
      "x_t:  2 [0.890625   0.4        0.053125   0.16666667]\n",
      "Q values:  tensor([[-22.5858, -25.3655, -21.5131, -22.5887, -22.8897, -20.5986]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23574 313 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  441\n",
      "87 1 False\n",
      "x_t:  1 [0.859375   0.25833333 0.1375     0.47083333]\n",
      "Q values:  tensor([[-27.0968, -22.0974, -23.9033, -23.2687, -24.6123, -22.9852]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30678 778 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  957\n",
      "87 5 False\n",
      "x_t:  3 [0.828125   0.3375     0.1625     0.40416667]\n",
      "Q values:  tensor([[-33.1896, -34.4615, -29.2672, -28.7154, -33.2234, -34.1272]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10486 208 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  126\n",
      "87 10 False\n",
      "x_t:  3 [0.059375 0.2375   0.065625 0.25    ]\n",
      "Q values:  tensor([[-21.7648, -29.0503, -27.5907, -21.5960, -23.9958, -25.0717]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3580 1055 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1377\n",
      "87 12 False\n",
      "x_t:  3 [0.68125    0.3375     0.078125   0.40833333]\n",
      "Q values:  tensor([[-24.2685, -22.0178, -26.8213, -21.8639, -22.8181, -25.8026]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17865 207 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2960\n",
      "startIDX:  1275\n",
      "87 22 False\n",
      "x_t:  2 [0.878125   0.37916667 0.05625    0.2375    ]\n",
      "Q values:  tensor([[-32.4052, -29.1118, -27.1921, -28.1104, -29.7896, -27.2927]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12578 302 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1407\n",
      "88 0 False\n",
      "x_t:  4 [0.109375 0.3875   0.0875   0.2875  ]\n",
      "Q values:  tensor([[-26.7338, -27.2775, -28.4163, -28.4095, -23.7287, -30.3512]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16302 534 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 88: ep_len:534 episode reward: total was -378.500000. running mean: -429.269922\n",
      "startIDX:  258\n",
      "88 1 False\n",
      "x_t:  2 [0.03125    0.37083333 0.15       0.44166667]\n",
      "Q values:  tensor([[-28.1880, -30.4485, -23.3177, -32.0176, -25.9353, -27.1264]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27440 817 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 88: ep_len:817 episode reward: total was -582.200000. running mean: -430.799222\n",
      "startIDX:  26\n",
      "88 5 False\n",
      "x_t:  2 [0.003125   0.37916667 0.103125   0.43333333]\n",
      "Q values:  tensor([[-21.0326, -24.0463, -19.9466, -22.4365, -22.0219, -25.0980]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2053 913 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 88: ep_len:913 episode reward: total was -619.100000. running mean: -432.682230\n",
      "startIDX:  993\n",
      "88 10 True\n",
      "x_t:  1 [0.73125    0.28333333 0.065625   0.34166667]\n",
      "Q values:  tensor([[-32.5165, -32.8942, -33.8673, -31.5116, -31.8869, -31.6056]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11349 1560 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 88: ep_len:1560 episode reward: total was -1107.300000. running mean: -439.428408\n",
      "startIDX:  1346\n",
      "88 12 False\n",
      "x_t:  3 [0.7625     0.35416667 0.103125   0.4375    ]\n",
      "Q values:  tensor([[-27.1157, -27.8426, -27.7750, -25.0166, -30.0153, -28.8465]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17855 212 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 88: ep_len:212 episode reward: total was -120.500000. running mean: -436.239124\n",
      "startIDX:  2179\n",
      "88 15 False\n",
      "x_t:  2 [0.6        0.40833333 0.05       0.25833333]\n",
      "Q values:  tensor([[-31.7025, -31.4099, -28.2535, -29.2830, -29.5833, -29.0352]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15599 326 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 88: ep_len:326 episode reward: total was -234.000000. running mean: -434.216733\n",
      "startIDX:  1416\n",
      "88 22 False\n",
      "x_t:  3 [0.059375 0.25     0.0625   0.2625  ]\n",
      "Q values:  tensor([[-28.0289, -30.3006, -30.2348, -25.5791, -27.7788, -31.4898]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15195 1239 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 88: ep_len:1239 episode reward: total was -851.700000. running mean: -438.391565\n",
      "startIDX:  410\n",
      "89 0 False\n",
      "x_t:  3 [0.821875   0.40416667 0.175      0.41666667]\n",
      "Q values:  tensor([[-29.2243, -28.7860, -31.5712, -27.4701, -29.2933, -28.1958]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 6992 1052 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  756\n",
      "89 1 False\n",
      "x_t:  3 [0.19375    0.24166667 0.08125    0.325     ]\n",
      "Q values:  tensor([[-29.4352, -28.2428, -29.1098, -28.1952, -29.6642, -28.4391]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34343 1411 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1912\n",
      "89 5 True\n",
      "x_t:  2 [0.8375     0.4        0.071875   0.24583333]\n",
      "Q values:  tensor([[-26.2526, -24.0397, -23.0408, -25.5413, -27.1300, -21.4679]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15643 299 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1683\n",
      "89 10 False\n",
      "x_t:  3 [0.86875    0.32916667 0.125      0.4       ]\n",
      "Q values:  tensor([[-24.2859, -25.5639, -24.6777, -21.4218, -27.2264, -24.0844]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16401 263 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1373\n",
      "89 12 False\n",
      "x_t:  3 [0.684375   0.35       0.14375    0.42916667]\n",
      "Q values:  tensor([[-26.7257, -23.7316, -23.1168, -21.7647, -23.4097, -23.6207]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17861 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2556\n",
      "89 15 True\n",
      "x_t:  3 [0.396875   0.27083333 0.08125    0.29583333]\n",
      "Q values:  tensor([[-23.3948, -22.7573, -24.0804, -19.6893, -24.1390, -23.0991]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19742 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1551\n",
      "89 22 False\n",
      "x_t:  4 [0.04375    0.3875     0.1        0.30416667]\n",
      "Q values:  tensor([[-28.7414, -26.4005, -26.9813, -29.5899, -24.4157, -24.5902]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16330 516 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  732.1887407302856\n",
      "startIDX:  1757\n",
      "90 0 False\n",
      "x_t:  2 [0.00625    0.40833333 0.1125     0.24166667]\n",
      "Q values:  tensor([[-29.2024, -26.3299, -21.3779, -29.3288, -28.1172, -24.9236]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18394 758 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 90: ep_len:758 episode reward: total was -548.800000. running mean: -435.496452\n",
      "startIDX:  1116\n",
      "90 1 False\n",
      "x_t:  3 [0.509375   0.28333333 0.109375   0.34166667]\n",
      "Q values:  tensor([[-23.7361, -20.9264, -23.0077, -20.1938, -22.0341, -23.8871]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35955 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 90: ep_len:200 episode reward: total was -132.700000. running mean: -432.468488\n",
      "startIDX:  1655\n",
      "90 5 False\n",
      "x_t:  1 [0.903125   0.27916667 0.0875     0.325     ]\n",
      "Q values:  tensor([[-26.0095, -24.0866, -30.5326, -24.1978, -27.1969, -25.8163]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14920 650 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 90: ep_len:650 episode reward: total was -466.000000. running mean: -432.803803\n",
      "startIDX:  2246\n",
      "90 10 True\n",
      "x_t:  1 [0.884375   0.2875     0.1125     0.33333333]\n",
      "Q values:  tensor([[-27.3425, -27.5557, -26.2341, -23.8243, -25.6460, -23.0182]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22468 1269 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 90: ep_len:1269 episode reward: total was -935.800000. running mean: -437.833765\n",
      "startIDX:  1730\n",
      "90 12 False\n",
      "x_t:  1 [0.003125   0.37083333 0.06875    0.3625    ]\n",
      "Q values:  tensor([[-34.6168, -31.6791, -33.4916, -33.2971, -33.5929, -35.4448]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19869 206 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 90: ep_len:206 episode reward: total was -153.600000. running mean: -434.991427\n",
      "startIDX:  2875\n",
      "90 15 True\n",
      "x_t:  0 [0.921875   0.39583333 0.06875    0.35833333]\n",
      "Q values:  tensor([[-32.0685, -26.9568, -30.5519, -27.1400, -25.0864, -28.3621]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23066 516 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 90: ep_len:516 episode reward: total was -387.800000. running mean: -434.519513\n",
      "startIDX:  2174\n",
      "90 22 True\n",
      "x_t:  0 [0.859375   0.4        0.075      0.32916667]\n",
      "Q values:  tensor([[-26.2064, -26.2363, -23.3753, -26.3782, -25.0519, -22.4942]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20703 795 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 90: ep_len:795 episode reward: total was -603.300000. running mean: -436.207318\n",
      "startIDX:  2127\n",
      "91 0 False\n",
      "x_t:  1 [0.665625 0.3125   0.115625 0.5125  ]\n",
      "Q values:  tensor([[-30.0687, -25.8772, -31.1352, -26.7723, -30.4579, -26.9527]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22935 1140 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  831\n",
      "91 1 True\n",
      "x_t:  4 [0.309375   0.37916667 0.10625    0.37916667]\n",
      "Q values:  tensor([[-28.1143, -30.7947, -31.2651, -30.1680, -32.1094, -29.5556]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35507 595 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1083\n",
      "91 5 False\n",
      "x_t:  3 [0.225      0.24583333 0.071875   0.29583333]\n",
      "Q values:  tensor([[-24.0160, -25.7503, -25.1460, -23.0324, -25.4208, -24.2956]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10579 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2158\n",
      "91 10 False\n",
      "x_t:  0 [0.878125   0.3875     0.10625    0.35833333]\n",
      "Q values:  tensor([[-27.4654, -27.5134, -30.4009, -29.5900, -32.6645, -28.5484]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19933 534 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  119\n",
      "91 12 True\n",
      "x_t:  1 [0.846875   0.30833333 0.146875   0.425     ]\n",
      "Q values:  tensor([[-33.1006, -33.2840, -32.7015, -34.5299, -30.9573, -29.1111]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2217 593 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  956\n",
      "91 15 True\n",
      "x_t:  4 [0.0375     0.39166667 0.065625   0.29583333]\n",
      "Q values:  tensor([[-28.9949, -27.9879, -32.8161, -28.6666, -27.9275, -24.5441]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9817 647 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  322\n",
      "91 22 True\n",
      "x_t:  3 [0.059375   0.2375     0.059375   0.24166667]\n",
      "Q values:  tensor([[-20.9527, -23.8719, -22.1328, -20.1619, -22.4266, -23.8034]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4870 1272 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1104\n",
      "92 0 False\n",
      "x_t:  2 [0.7875     0.4        0.103125   0.29166667]\n",
      "Q values:  tensor([[-32.1855, -32.4878, -27.1816, -29.0759, -27.8576, -27.8276]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12630 343 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 92: ep_len:343 episode reward: total was -244.500000. running mean: -438.591967\n",
      "startIDX:  459\n",
      "92 1 False\n",
      "x_t:  1 [0.859375   0.25833333 0.1375     0.47083333]\n",
      "Q values:  tensor([[-29.8026, -25.0323, -30.6883, -27.0304, -28.4638, -25.7986]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30678 769 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 92: ep_len:769 episode reward: total was -535.500000. running mean: -439.561047\n",
      "startIDX:  81\n",
      "92 5 False\n",
      "x_t:  2 [0.18125 0.375   0.15625 0.4375 ]\n",
      "Q values:  tensor([[-22.2868, -22.6748, -17.5879, -24.8091, -24.4799, -21.1467]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2071 887 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 92: ep_len:887 episode reward: total was -643.400000. running mean: -441.599436\n",
      "startIDX:  997\n",
      "92 10 True\n",
      "x_t:  1 [0.74375    0.28333333 0.059375   0.33333333]\n",
      "Q values:  tensor([[-21.8226, -21.4427, -24.5492, -22.7807, -21.5871, -21.4911]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11348 1564 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 92: ep_len:1564 episode reward: total was -1130.800000. running mean: -448.491442\n",
      "startIDX:  1597\n",
      "92 12 False\n",
      "x_t:  2 [0.06875 0.4125  0.09375 0.2875 ]\n",
      "Q values:  tensor([[-32.0728, -29.8674, -28.5945, -31.0409, -31.9319, -29.6167]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19389 705 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 92: ep_len:705 episode reward: total was -516.500000. running mean: -449.171528\n",
      "startIDX:  2952\n",
      "ep 92: ep_len:104 episode reward: total was -68.000000. running mean: -445.359812\n",
      "startIDX:  2733\n",
      "92 22 False\n",
      "x_t:  4 [0.128125   0.39583333 0.1        0.30833333]\n",
      "Q values:  tensor([[-33.1516, -32.9111, -34.8508, -33.1413, -31.3678, -33.2382]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27283 512 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 92: ep_len:512 episode reward: total was -370.000000. running mean: -444.606214\n",
      "startIDX:  2126\n",
      "93 0 False\n",
      "x_t:  1 [0.68125    0.325      0.21875    0.50833333]\n",
      "Q values:  tensor([[-33.5040, -28.9951, -31.6440, -35.7281, -34.9001, -30.4599]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22931 1142 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  406\n",
      "93 1 False\n",
      "x_t:  0 [0.8375     0.37083333 0.13125    0.40416667]\n",
      "Q values:  tensor([[-29.8836, -31.8788, -30.6335, -33.0762, -30.1319, -30.0523]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29096 491 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1986\n",
      "93 5 False\n",
      "x_t:  3 [0.09375    0.2625     0.103125   0.29583333]\n",
      "Q values:  tensor([[-30.1477, -30.8757, -30.1863, -27.8402, -33.6466, -28.2998]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18212 1268 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  278\n",
      "93 10 True\n",
      "x_t:  3 [0.734375   0.30416667 0.13125    0.3875    ]\n",
      "Q values:  tensor([[-26.4971, -26.5897, -27.0203, -28.8449, -25.8616, -27.8946]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5048 263 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1769\n",
      "93 12 False\n",
      "x_t:  0 [0.909375   0.4        0.08125    0.36666667]\n",
      "Q values:  tensor([[-21.3151, -24.6838, -25.3347, -23.6268, -30.8204, -24.1271]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21090 602 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1229\n",
      "93 15 True\n",
      "x_t:  3 [0.54375    0.29583333 0.11875    0.33333333]\n",
      "Q values:  tensor([[-27.1174, -28.0887, -30.8190, -25.8226, -23.1740, -28.2310]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10388 276 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  191\n",
      "93 22 False\n",
      "x_t:  2 [0.6875     0.40833333 0.0875     0.24583333]\n",
      "Q values:  tensor([[-28.1134, -31.2124, -26.7302, -31.6309, -30.8479, -29.0359]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2299 337 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1435\n",
      "94 0 False\n",
      "x_t:  4 [0.228125   0.37916667 0.125      0.28333333]\n",
      "Q values:  tensor([[-29.8047, -31.5392, -30.9781, -29.8650, -29.0596, -30.2455]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16322 534 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 94: ep_len:534 episode reward: total was -386.300000. running mean: -442.885525\n",
      "startIDX:  425\n",
      "94 1 False\n",
      "x_t:  0 [0.934375   0.37083333 0.059375   0.40416667]\n",
      "Q values:  tensor([[-30.1478, -34.6536, -36.1967, -34.2103, -33.9827, -33.8934]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29087 477 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 94: ep_len:477 episode reward: total was -334.200000. running mean: -441.798669\n",
      "startIDX:  1017\n",
      "94 5 False\n",
      "x_t:  3 [0.53125    0.3        0.115625   0.34583333]\n",
      "Q values:  tensor([[-20.3845, -19.8306, -20.7105, -18.5660, -19.9283, -18.9847]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10525 207 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 94: ep_len:207 episode reward: total was -54.800000. running mean: -437.928683\n",
      "startIDX:  1231\n",
      "94 10 True\n",
      "x_t:  3 [0.13125 0.225   0.05625 0.2625 ]\n",
      "Q values:  tensor([[-29.0635, -28.3279, -28.5969, -29.5998, -25.9739, -28.8953]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14596 1248 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 94: ep_len:1248 episode reward: total was -886.200000. running mean: -442.411396\n",
      "startIDX:  725\n",
      "94 12 False\n",
      "x_t:  1 [0.234375   0.38333333 0.203125   0.49166667]\n",
      "Q values:  tensor([[-22.9659, -21.4666, -28.2192, -27.4416, -27.1234, -27.4877]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10322 207 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 94: ep_len:207 episode reward: total was -147.900000. running mean: -439.466282\n",
      "startIDX:  2273\n",
      "94 15 False\n",
      "x_t:  3 [0.103125   0.27916667 0.09375    0.30416667]\n",
      "Q values:  tensor([[-27.4000, -25.2473, -26.5789, -23.7960, -26.2193, -27.6831]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18184 1273 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 94: ep_len:1273 episode reward: total was -900.200000. running mean: -444.073619\n",
      "startIDX:  882\n",
      "94 22 False\n",
      "x_t:  1 [0.0125     0.37083333 0.175      0.39583333]\n",
      "Q values:  tensor([[-33.9638, -29.8941, -32.6502, -31.4430, -29.8987, -32.0068]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9486 246 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 94: ep_len:246 episode reward: total was -183.600000. running mean: -441.468883\n",
      "startIDX:  515\n",
      "95 0 False\n",
      "x_t:  3 [0.809375 0.375    0.109375 0.45    ]\n",
      "Q values:  tensor([[-24.8107, -21.8901, -22.2135, -20.9286, -22.1760, -22.3103]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 6997 1027 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  422\n",
      "95 1 True\n",
      "x_t:  0 [0.934375   0.37083333 0.059375   0.40833333]\n",
      "Q values:  tensor([[-22.7589, -25.0267, -25.5349, -21.9970, -25.9819, -21.7510]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29088 490 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  924\n",
      "95 5 True\n",
      "x_t:  3 [0.825      0.3375     0.165625   0.40416667]\n",
      "Q values:  tensor([[-31.9961, -30.0618, -30.7892, -33.7262, -28.7847, -30.9495]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10485 224 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2473\n",
      "95 10 False\n",
      "x_t:  1 [0.696875   0.2875     0.115625   0.32916667]\n",
      "Q values:  tensor([[-24.3022, -22.3093, -22.3517, -27.6126, -27.2631, -25.3910]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22488 1144 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  980\n",
      "95 12 False\n",
      "x_t:  2 [0.734375   0.4125     0.0875     0.24583333]\n",
      "Q values:  tensor([[-26.9650, -26.7899, -24.4488, -26.9532, -27.8530, -28.2105]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13584 329 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1740\n",
      "95 15 False\n",
      "x_t:  1 [0.44375    0.31666667 0.075      0.38333333]\n",
      "Q values:  tensor([[-27.6701, -25.9403, -26.1734, -28.3719, -30.4430, -29.7419]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12493 233 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2091\n",
      "95 22 False\n",
      "x_t:  1 [0.0375     0.36666667 0.096875   0.39166667]\n",
      "Q values:  tensor([[-27.7297, -26.7611, -28.5439, -29.3414, -26.7790, -27.3400]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18992 209 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  212\n",
      "96 0 False\n",
      "x_t:  2 [0.79375    0.40416667 0.075      0.28333333]\n",
      "Q values:  tensor([[-33.0253, -32.1578, -29.1330, -32.8105, -29.4068, -30.3540]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2324 347 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 96: ep_len:347 episode reward: total was -245.000000. running mean: -433.259111\n",
      "startIDX:  419\n",
      "96 1 False\n",
      "x_t:  0 [0.746875 0.375    0.115625 0.4     ]\n",
      "Q values:  tensor([[-24.5530, -27.6425, -26.5505, -28.6506, -27.7599, -26.3760]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29117 515 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 96: ep_len:515 episode reward: total was -399.900000. running mean: -432.925519\n",
      "startIDX:  2584\n",
      "96 5 True\n",
      "x_t:  2 [0.109375   0.39583333 0.109375   0.27083333]\n",
      "Q values:  tensor([[-22.9959, -22.7681, -20.7455, -22.3910, -22.9629, -20.5577]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21567 769 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 96: ep_len:769 episode reward: total was -564.100000. running mean: -434.237264\n",
      "startIDX:  1174\n",
      "96 10 True\n",
      "x_t:  3 [0.0625     0.22083333 0.059375   0.24166667]\n",
      "Q values:  tensor([[-24.2250, -22.2699, -21.5032, -21.4204, -20.2343, -21.4748]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14573 1242 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 96: ep_len:1242 episode reward: total was -878.300000. running mean: -438.677892\n",
      "startIDX:  1161\n",
      "96 12 False\n",
      "x_t:  3 [0.0625     0.26666667 0.065625   0.23333333]\n",
      "Q values:  tensor([[-23.5372, -23.1003, -20.5402, -20.3995, -23.3185, -21.4584]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16371 1359 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 96: ep_len:1359 episode reward: total was -922.900000. running mean: -443.520113\n",
      "startIDX:  1023\n",
      "96 15 False\n",
      "x_t:  4 [0.0875     0.3875     0.09375    0.29166667]\n",
      "Q values:  tensor([[-25.1500, -23.0031, -22.8803, -24.7226, -22.0551, -22.9716]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9828 606 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 96: ep_len:606 episode reward: total was -419.100000. running mean: -443.275912\n",
      "startIDX:  1805\n",
      "96 22 True\n",
      "x_t:  2 [0.00625    0.40416667 0.071875   0.26666667]\n",
      "Q values:  tensor([[-31.8526, -32.4420, -34.9334, -32.0927, -28.6886, -31.5681]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18454 788 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 96: ep_len:788 episode reward: total was -540.000000. running mean: -444.243152\n",
      "startIDX:  113\n",
      "97 0 False\n",
      "x_t:  1 [0.85625    0.3        0.121875   0.42916667]\n",
      "Q values:  tensor([[-31.5323, -28.6971, -30.3376, -31.4935, -29.3192, -30.6133]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1613 710 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  329\n",
      "97 1 False\n",
      "x_t:  1 [0.63125    0.29166667 0.18125    0.57916667]\n",
      "Q values:  tensor([[-34.2536, -29.4021, -34.0200, -29.9268, -36.0615, -31.3636]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28106 308 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  407\n",
      "97 5 False\n",
      "x_t:  1 [0.659375 0.3      0.1125   0.3625  ]\n",
      "Q values:  tensor([[-30.1726, -28.1838, -30.4197, -31.5582, -31.0955, -31.1572]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5055 684 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1701\n",
      "97 10 False\n",
      "x_t:  3 [0.909375   0.32083333 0.0875     0.4125    ]\n",
      "Q values:  tensor([[-31.2906, -30.5090, -31.9271, -29.0468, -29.1582, -30.8788]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16399 241 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1964\n",
      "startIDX:  2618\n",
      "97 15 True\n",
      "x_t:  2 [0.04375    0.40416667 0.084375   0.33333333]\n",
      "Q values:  tensor([[-26.2568, -21.2023, -26.4288, -22.5963, -24.3840, -23.7514]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21479 884 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1608\n",
      "97 22 False\n",
      "x_t:  3 [0.8625     0.34166667 0.071875   0.41666667]\n",
      "Q values:  tensor([[-25.1370, -26.4379, -28.7164, -24.3101, -27.2971, -24.3522]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16849 244 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2114\n",
      "98 0 True\n",
      "x_t:  1 [0.85       0.30416667 0.146875   0.54166667]\n",
      "Q values:  tensor([[-17.7397, -15.8317, -21.2472, -17.6033, -17.0418, -18.2403]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22920 1122 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 98: ep_len:1122 episode reward: total was -884.000000. running mean: -439.754460\n",
      "startIDX:  495\n",
      "98 1 False\n",
      "x_t:  1 [0.61875    0.2875     0.178125   0.45416667]\n",
      "Q values:  tensor([[-27.5947, -22.4179, -27.9859, -25.9583, -25.9689, -28.1340]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30704 768 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 98: ep_len:768 episode reward: total was -590.300000. running mean: -441.259916\n",
      "startIDX:  947\n",
      "98 5 False\n",
      "x_t:  3 [0.8125     0.325      0.1375     0.39583333]\n",
      "Q values:  tensor([[-29.5489, -31.0141, -30.7291, -25.9723, -30.1826, -32.6629]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10490 213 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 98: ep_len:213 episode reward: total was -10.400000. running mean: -436.951317\n",
      "startIDX:  188\n",
      "98 10 True\n",
      "x_t:  4 [0.121875   0.35       0.05625    0.25416667]\n",
      "Q values:  tensor([[-37.3141, -31.7880, -32.3827, -31.2513, -34.9510, -31.4302]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4562 467 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 98: ep_len:467 episode reward: total was -349.800000. running mean: -436.079803\n",
      "startIDX:  1361\n",
      "98 12 False\n",
      "x_t:  3 [0.86875    0.375      0.128125   0.43333333]\n",
      "Q values:  tensor([[-30.3050, -28.6374, -35.2209, -28.6227, -29.6277, -32.1486]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17842 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 98: ep_len:204 episode reward: total was -98.900000. running mean: -432.708005\n",
      "startIDX:  1821\n",
      "98 15 False\n",
      "x_t:  0 [0.828125   0.4        0.096875   0.32916667]\n",
      "Q values:  tensor([[-21.2988, -25.5848, -27.9314, -25.2840, -25.0301, -26.9140]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13376 420 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 98: ep_len:420 episode reward: total was -314.300000. running mean: -431.523925\n",
      "startIDX:  994\n",
      "98 22 False\n",
      "x_t:  0 [0.921875   0.4        0.071875   0.34166667]\n",
      "Q values:  tensor([[-31.4699, -35.9024, -32.2707, -34.0233, -35.0100, -35.8033]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10399 448 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 98: ep_len:448 episode reward: total was -333.900000. running mean: -430.547686\n",
      "startIDX:  2128\n",
      "99 0 True\n",
      "x_t:  1 [0.8375 0.3125 0.1375 0.525 ]\n",
      "Q values:  tensor([[-31.2062, -32.0544, -32.3229, -34.0695, -33.7435, -29.4291]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22921 1147 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  424\n",
      "99 1 False\n",
      "x_t:  0 [0.91875    0.37083333 0.06875    0.40416667]\n",
      "Q values:  tensor([[-24.2550, -29.0493, -25.4428, -28.6285, -26.2857, -25.9882]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29092 484 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  650\n",
      "99 5 False\n",
      "x_t:  3 [0.08125    0.2625     0.090625   0.31666667]\n",
      "Q values:  tensor([[-30.1218, -32.6492, -34.2350, -28.7215, -29.8715, -30.1517]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8754 1374 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  963\n",
      "99 10 False\n",
      "x_t:  1 [0.940625   0.27916667 0.05625    0.34166667]\n",
      "Q values:  tensor([[-26.1039, -25.4098, -27.3204, -26.1322, -29.4292, -27.9343]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11322 1571 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  245\n",
      "99 12 True\n",
      "x_t:  3 [0.15       0.2625     0.0625     0.28333333]\n",
      "Q values:  tensor([[-23.6357, -26.8758, -22.7045, -26.4383, -26.8509, -23.1514]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5682 1386 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  522\n",
      "99 15 False\n",
      "x_t:  1 [0.7375     0.30416667 0.0875     0.27083333]\n",
      "Q values:  tensor([[-24.1233, -21.4706, -26.6893, -22.5713, -22.0230, -27.0581]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5189 735 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2759\n",
      "99 22 True\n",
      "x_t:  4 [0.00625    0.40833333 0.125      0.3125    ]\n",
      "Q values:  tensor([[-27.4730, -32.9295, -35.1192, -29.9414, -31.1032, -24.7112]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27266 490 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  825.0670878887177\n",
      "startIDX:  1863\n",
      "100 0 False\n",
      "x_t:  1 [0.003125 0.375    0.146875 0.4125  ]\n",
      "Q values:  tensor([[-31.1567, -28.4018, -29.0782, -29.3933, -30.2396, -29.7154]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18923 270 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 100: ep_len:270 episode reward: total was -200.100000. running mean: -449.894931\n",
      "startIDX:  714\n",
      "100 1 False\n",
      "x_t:  3 [0.18125    0.25       0.090625   0.30833333]\n",
      "Q values:  tensor([[-33.1818, -31.3185, -33.8436, -30.7129, -35.5889, -31.9460]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34339 1408 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 100: ep_len:1408 episode reward: total was -996.500000. running mean: -455.360982\n",
      "startIDX:  2149\n",
      "100 5 False\n",
      "x_t:  4 [0.0875     0.42916667 0.171875   0.40416667]\n",
      "Q values:  tensor([[-28.4506, -29.3219, -31.7564, -29.6387, -26.3974, -29.6694]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19475 600 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 100: ep_len:600 episode reward: total was -404.300000. running mean: -454.850372\n",
      "startIDX:  1138\n",
      "100 10 True\n",
      "x_t:  2 [0.85       0.37083333 0.071875   0.2375    ]\n",
      "Q values:  tensor([[-28.4370, -33.4543, -26.9930, -27.8332, -28.0210, -27.0881]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12055 328 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 100: ep_len:328 episode reward: total was -225.400000. running mean: -452.555869\n",
      "startIDX:  225\n",
      "100 12 False\n",
      "x_t:  3 [0.321875   0.29166667 0.10625    0.3125    ]\n",
      "Q values:  tensor([[-26.3412, -24.9450, -26.3585, -23.1009, -25.6289, -25.3541]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5716 1439 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 100: ep_len:1439 episode reward: total was -931.600000. running mean: -457.346310\n",
      "startIDX:  565\n",
      "100 15 False\n",
      "x_t:  1 [0.95625    0.29166667 0.040625   0.2875    ]\n",
      "Q values:  tensor([[-28.4305, -27.3525, -31.2615, -31.6630, -31.7973, -29.6097]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5160 694 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 100: ep_len:694 episode reward: total was -492.000000. running mean: -457.692847\n",
      "startIDX:  2176\n",
      "100 22 False\n",
      "x_t:  0 [0.771875   0.40833333 0.05625    0.31666667]\n",
      "Q values:  tensor([[-19.4805, -24.4423, -23.1057, -21.5752, -21.9577, -21.5904]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20729 824 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 100: ep_len:824 episode reward: total was -569.600000. running mean: -458.811918\n",
      "startIDX:  962\n",
      "101 0 False\n",
      "x_t:  1 [0.878125   0.3        0.109375   0.42916667]\n",
      "Q values:  tensor([[-23.0476, -22.7968, -24.9904, -24.8347, -23.1562, -25.0788]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11946 808 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1003\n",
      "101 1 True\n",
      "x_t:  3 [0.640625   0.2875     0.096875   0.37916667]\n",
      "Q values:  tensor([[-32.1474, -26.0387, -24.3318, -27.8666, -29.5555, -25.1179]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35933 244 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1490\n",
      "101 5 False\n",
      "x_t:  0 [0.678125   0.40416667 0.090625   0.325     ]\n",
      "Q values:  tensor([[-24.7849, -27.4884, -27.7371, -27.0941, -27.2120, -27.7056]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13539 486 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1188\n",
      "101 10 False\n",
      "x_t:  3 [0.146875   0.23333333 0.075      0.26666667]\n",
      "Q values:  tensor([[-28.7818, -28.7427, -28.7070, -26.2266, -28.3875, -27.0758]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14602 1274 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  219\n",
      "101 12 False\n",
      "x_t:  3 [0.0875     0.25833333 0.071875   0.275     ]\n",
      "Q values:  tensor([[-26.4910, -25.1319, -25.2633, -23.7155, -23.9270, -25.4254]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5671 1395 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1879\n",
      "101 15 False\n",
      "x_t:  1 [0.8625     0.29583333 0.05625    0.30833333]\n",
      "Q values:  tensor([[-29.9128, -25.7966, -30.3236, -30.0284, -30.6736, -27.3438]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14847 723 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  149\n",
      "101 22 False\n",
      "x_t:  1 [0.7125     0.30833333 0.115625   0.40416667]\n",
      "Q values:  tensor([[-26.7834, -23.0992, -24.6343, -25.8681, -27.1671, -25.7910]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1596 642 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2284\n",
      "102 0 False\n",
      "x_t:  2 [0.884375   0.39166667 0.0625     0.17916667]\n",
      "Q values:  tensor([[-26.0784, -27.0193, -25.9610, -28.6216, -28.3937, -27.6541]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23572 294 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 102: ep_len:294 episode reward: total was -228.600000. running mean: -462.032002\n",
      "startIDX:  626\n",
      "102 1 False\n",
      "x_t:  2 [0.728125   0.37916667 0.0625     0.31666667]\n",
      "Q values:  tensor([[-24.6983, -23.5307, -19.2808, -27.0161, -26.0584, -27.1484]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31479 373 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 102: ep_len:373 episode reward: total was -281.400000. running mean: -460.225682\n",
      "startIDX:  2572\n",
      "102 5 True\n",
      "x_t:  2 [0.096875   0.39166667 0.06875    0.27083333]\n",
      "Q values:  tensor([[-26.2709, -28.2749, -29.1914, -26.5652, -30.1061, -26.3387]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21562 785 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 102: ep_len:785 episode reward: total was -599.700000. running mean: -461.620425\n",
      "startIDX:  2010\n",
      "102 10 False\n",
      "x_t:  1 [0.028125   0.34583333 0.109375   0.375     ]\n",
      "Q values:  tensor([[-27.9488, -26.3454, -29.7384, -27.4042, -30.4635, -29.5038]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18814 289 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 102: ep_len:289 episode reward: total was -217.000000. running mean: -459.174221\n",
      "startIDX:  1651\n",
      "102 12 False\n",
      "x_t:  1 [0.003125 0.375    0.071875 0.3625  ]\n",
      "Q values:  tensor([[-33.8100, -30.7413, -34.3171, -36.4568, -32.3553, -34.5310]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19868 237 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 102: ep_len:237 episode reward: total was -175.600000. running mean: -456.338479\n",
      "startIDX:  2035\n",
      "102 15 False\n",
      "x_t:  1 [0.8875     0.29583333 0.078125   0.3125    ]\n",
      "Q values:  tensor([[-23.3921, -20.4148, -24.2057, -22.9958, -21.6026, -27.5893]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14843 644 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 102: ep_len:644 episode reward: total was -510.100000. running mean: -456.876094\n",
      "startIDX:  1831\n",
      "102 22 False\n",
      "x_t:  2 [0.0625     0.40833333 0.0625     0.27083333]\n",
      "Q values:  tensor([[-30.4036, -29.4064, -25.6309, -30.3212, -29.1881, -26.0916]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18463 802 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 102: ep_len:802 episode reward: total was -625.300000. running mean: -458.560333\n",
      "startIDX:  2222\n",
      "103 0 False\n",
      "x_t:  1 [0.853125   0.3125     0.14375    0.53333333]\n",
      "Q values:  tensor([[-25.4427, -25.1093, -29.5307, -27.2851, -27.9164, -25.6875]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22918 1081 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  593\n",
      "103 1 False\n",
      "x_t:  2 [0.7375     0.38333333 0.103125   0.31666667]\n",
      "Q values:  tensor([[-27.5400, -30.7517, -25.8343, -29.6861, -27.5290, -33.3020]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31473 384 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  922\n",
      "103 5 False\n",
      "x_t:  3 [0.8125     0.325      0.1375     0.39583333]\n",
      "Q values:  tensor([[-32.1203, -32.1765, -33.8150, -29.2490, -32.3740, -34.0439]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10490 235 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1535\n",
      "103 10 False\n",
      "x_t:  3 [0.909375   0.32083333 0.0875     0.4125    ]\n",
      "Q values:  tensor([[-32.5000, -31.9419, -30.0449, -29.0827, -29.7786, -30.2197]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16399 330 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  588\n",
      "103 12 True\n",
      "x_t:  2 [0.05   0.4125 0.0625 0.25  ]\n",
      "Q values:  tensor([[-30.1240, -32.0583, -30.6726, -28.4470, -32.2882, -26.7799]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9834 1030 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  753\n",
      "103 15 False\n",
      "x_t:  2 [0.7625     0.4125     0.084375   0.29166667]\n",
      "Q values:  tensor([[-33.0652, -29.6519, -28.5435, -33.8217, -29.5666, -30.1521]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5973 354 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2250\n",
      "103 22 False\n",
      "x_t:  1 [0.725      0.325      0.078125   0.43333333]\n",
      "Q values:  tensor([[-28.7979, -25.7437, -32.1873, -26.7670, -28.6535, -28.1089]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22949 1090 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1058\n",
      "104 0 False\n",
      "x_t:  1 [0.915625   0.29166667 0.08125    0.4375    ]\n",
      "Q values:  tensor([[-36.5148, -31.8831, -35.0853, -33.9114, -34.9765, -33.2269]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11944 753 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 104: ep_len:753 episode reward: total was -518.300000. running mean: -458.519591\n",
      "startIDX:  1068\n",
      "104 1 False\n",
      "x_t:  3 [0.684375 0.3      0.109375 0.3875  ]\n",
      "Q values:  tensor([[-32.2291, -34.6347, -32.3774, -31.1802, -35.6981, -33.1528]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35923 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 104: ep_len:204 episode reward: total was -122.600000. running mean: -455.160395\n",
      "startIDX:  2714\n",
      "104 5 False\n",
      "x_t:  1 [0.225      0.34166667 0.165625   0.50416667]\n",
      "Q values:  tensor([[-30.0112, -28.4478, -28.9684, -29.1254, -30.6742, -30.1155]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22124 238 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 104: ep_len:238 episode reward: total was -170.400000. running mean: -452.312791\n",
      "startIDX:  1383\n",
      "104 10 False\n",
      "x_t:  4 [0.00625    0.36666667 0.1125     0.275     ]\n",
      "Q values:  tensor([[-33.0611, -30.3591, -29.7256, -33.3266, -28.6639, -29.3340]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15705 522 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 104: ep_len:522 episode reward: total was -349.700000. running mean: -451.286663\n",
      "startIDX:  1903\n",
      "104 12 False\n",
      "x_t:  0 [0.265625   0.42083333 0.065625   0.28333333]\n",
      "Q values:  tensor([[-22.6712, -23.6750, -23.3499, -24.0122, -22.7592, -22.8440]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 22999 950 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 104: ep_len:950 episode reward: total was -657.900000. running mean: -453.352797\n",
      "startIDX:  1719\n",
      "104 15 False\n",
      "x_t:  1 [0.015625   0.37083333 0.14375    0.4       ]\n",
      "Q values:  tensor([[-29.7439, -26.1600, -33.1641, -29.3931, -27.0768, -32.6789]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12449 219 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 104: ep_len:219 episode reward: total was -149.400000. running mean: -450.313269\n",
      "startIDX:  912\n",
      "104 22 True\n",
      "x_t:  1 [0.515625   0.32916667 0.15625    0.40416667]\n",
      "Q values:  tensor([[-23.5805, -21.6255, -26.1567, -23.3037, -24.4439, -23.5716]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9538 267 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 104: ep_len:267 episode reward: total was -193.700000. running mean: -447.747136\n",
      "startIDX:  269\n",
      "105 0 True\n",
      "x_t:  3 [0.15       0.24583333 0.053125   0.25      ]\n",
      "Q values:  tensor([[-24.9206, -24.3589, -21.6456, -22.2083, -23.6957, -24.7360]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4865 1267 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  300\n",
      "105 1 False\n",
      "x_t:  1 [0.740625   0.28333333 0.16875    0.59166667]\n",
      "Q values:  tensor([[-30.5377, -26.2139, -27.8330, -29.1981, -30.0492, -29.6363]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28116 335 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  650\n",
      "105 5 False\n",
      "x_t:  3 [0.09375    0.2625     0.084375   0.31666667]\n",
      "Q values:  tensor([[-29.6307, -28.5930, -27.1371, -24.6292, -29.8899, -26.5614]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8757 1358 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2333\n",
      "105 10 False\n",
      "x_t:  1 [0.678125   0.29583333 0.13125    0.32083333]\n",
      "Q values:  tensor([[-23.9411, -22.6220, -23.5631, -23.9424, -25.8493, -26.0492]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22490 1228 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  401\n",
      "105 12 False\n",
      "x_t:  3 [0.68125    0.34166667 0.13125    0.39166667]\n",
      "Q values:  tensor([[-31.5563, -30.6666, -31.2763, -27.3630, -28.8534, -27.9570]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7731 259 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  712\n",
      "105 15 False\n",
      "x_t:  2 [0.75       0.40416667 0.065625   0.29583333]\n",
      "Q values:  tensor([[-28.2628, -26.2671, -25.9759, -27.2097, -27.4452, -26.7169]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5977 381 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1776\n",
      "105 22 False\n",
      "x_t:  3 [0.253125   0.2625     0.0625     0.29583333]\n",
      "Q values:  tensor([[-33.0215, -29.4747, -33.2059, -26.5844, -33.2515, -31.9645]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16949 212 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2515\n",
      "ep 106: ep_len:36 episode reward: total was -14.900000. running mean: -446.307123\n",
      "startIDX:  1121\n",
      "ep 106: ep_len:43 episode reward: total was -27.000000. running mean: -442.114052\n",
      "startIDX:  1881\n",
      "106 5 False\n",
      "x_t:  2 [0.684375   0.39166667 0.046875   0.25      ]\n",
      "Q values:  tensor([[-28.3942, -27.1251, -23.9273, -29.8282, -28.0208, -24.2291]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15671 330 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 106: ep_len:330 episode reward: total was -238.600000. running mean: -440.078912\n",
      "startIDX:  1908\n",
      "106 10 False\n",
      "x_t:  2 [0.2375     0.39583333 0.065625   0.24166667]\n",
      "Q values:  tensor([[-22.9542, -23.6902, -20.7194, -22.2369, -24.3976, -23.4606]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18186 818 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 106: ep_len:818 episode reward: total was -614.800000. running mean: -441.826123\n",
      "startIDX:  281\n",
      "106 12 True\n",
      "x_t:  4 [0.221875   0.425      0.1        0.37083333]\n",
      "Q values:  tensor([[-29.6857, -23.9341, -26.4677, -27.1788, -29.3265, -25.7254]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7204 770 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 106: ep_len:770 episode reward: total was -540.500000. running mean: -442.812861\n",
      "startIDX:  2900\n",
      "106 15 False\n",
      "x_t:  0 [0.840625   0.40416667 0.05625    0.35416667]\n",
      "Q values:  tensor([[-22.6898, -26.0094, -23.2900, -25.7800, -29.0415, -28.8894]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23083 509 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 106: ep_len:509 episode reward: total was -370.500000. running mean: -442.089733\n",
      "startIDX:  2165\n",
      "106 22 False\n",
      "x_t:  0 [0.909375 0.4      0.0875   0.35    ]\n",
      "Q values:  tensor([[-24.8115, -24.9612, -27.2680, -27.0933, -25.3862, -25.4514]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20685 796 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 106: ep_len:796 episode reward: total was -603.000000. running mean: -443.698835\n",
      "startIDX:  1626\n",
      "107 0 False\n",
      "x_t:  3 [0.51875  0.3125   0.121875 0.375   ]\n",
      "Q values:  tensor([[-28.4756, -30.8113, -29.9078, -26.8675, -28.6433, -28.3599]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16855 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  765\n",
      "107 1 False\n",
      "x_t:  3 [0.078125   0.23333333 0.08125    0.29166667]\n",
      "Q values:  tensor([[-31.2034, -29.3635, -31.9501, -27.3322, -33.1511, -32.4133]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34308 1384 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2556\n",
      "107 5 False\n",
      "x_t:  2 [0.221875 0.4      0.090625 0.2625  ]\n",
      "Q values:  tensor([[-30.1594, -30.2667, -27.9369, -29.9241, -33.2602, -33.2604]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21583 801 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2552\n",
      "startIDX:  476\n",
      "107 12 True\n",
      "x_t:  3 [0.878125   0.35833333 0.10625    0.42916667]\n",
      "Q values:  tensor([[-30.2465, -30.0906, -35.7606, -31.1514, -35.7321, -29.9592]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7711 219 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  68\n",
      "107 15 False\n",
      "x_t:  3 [0.81875    0.34166667 0.09375    0.42916667]\n",
      "Q values:  tensor([[-28.1414, -29.5988, -29.6226, -26.4062, -27.9071, -29.3852]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 526 225 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2127\n",
      "107 22 False\n",
      "x_t:  0 [0.9        0.39583333 0.084375   0.3375    ]\n",
      "Q values:  tensor([[-24.1535, -27.1584, -27.0877, -26.6225, -26.9560, -25.3505]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20691 831 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1985\n",
      "108 0 False\n",
      "x_t:  1 [0.003125 0.375    0.146875 0.4125  ]\n",
      "Q values:  tensor([[-36.1368, -33.4451, -35.5226, -35.1584, -35.9358, -33.5419]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18923 205 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 108: ep_len:205 episode reward: total was -143.600000. running mean: -437.688033\n",
      "startIDX:  187\n",
      "108 1 False\n",
      "x_t:  2 [0.103125   0.36666667 0.109375   0.44583333]\n",
      "Q values:  tensor([[-28.9155, -25.9840, -24.7562, -25.0431, -29.2667, -25.5374]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27446 866 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 108: ep_len:866 episode reward: total was -587.800000. running mean: -439.189153\n",
      "startIDX:  3027\n",
      "ep 108: ep_len:23 episode reward: total was -13.000000. running mean: -434.927261\n",
      "startIDX:  1560\n",
      "108 10 False\n",
      "x_t:  3 [0.884375   0.325      0.1125     0.40416667]\n",
      "Q values:  tensor([[-27.1131, -26.6992, -25.5045, -22.7928, -29.2906, -23.8162]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16400 308 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 108: ep_len:308 episode reward: total was -223.900000. running mean: -432.816989\n",
      "startIDX:  1985\n",
      "ep 108: ep_len:58 episode reward: total was -32.900000. running mean: -428.817819\n",
      "startIDX:  2349\n",
      "108 15 False\n",
      "x_t:  4 [0.1625     0.4        0.09375    0.33333333]\n",
      "Q values:  tensor([[-26.9602, -27.3959, -27.1283, -29.1067, -23.1073, -27.9349]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19273 528 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 108: ep_len:528 episode reward: total was -345.300000. running mean: -427.982641\n",
      "startIDX:  566\n",
      "108 22 False\n",
      "x_t:  3 [0.89375    0.34166667 0.103125   0.41666667]\n",
      "Q values:  tensor([[-32.4809, -29.3792, -27.1205, -26.2051, -31.0335, -30.2807]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7050 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 108: ep_len:203 episode reward: total was -129.000000. running mean: -424.992814\n",
      "startIDX:  542\n",
      "109 0 False\n",
      "x_t:  3 [0.83125    0.39166667 0.1625     0.4375    ]\n",
      "Q values:  tensor([[-32.2831, -30.0861, -33.8482, -23.2174, -26.1430, -25.4999]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 6991 995 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  439\n",
      "109 1 False\n",
      "x_t:  1 [0.821875   0.2625     0.1        0.45833333]\n",
      "Q values:  tensor([[-27.7795, -27.0128, -27.3149, -29.0196, -29.7934, -29.9201]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30687 788 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2075\n",
      "109 5 False\n",
      "x_t:  4 [0.01875    0.42916667 0.1125     0.4       ]\n",
      "Q values:  tensor([[-25.2145, -29.2269, -28.3402, -25.0701, -24.4981, -24.8733]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19467 640 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  853\n",
      "109 10 False\n",
      "x_t:  0 [0.81875    0.39166667 0.1125     0.32083333]\n",
      "Q values:  tensor([[-23.4550, -28.2767, -24.2430, -25.7073, -24.0955, -23.9552]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8115 472 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  788\n",
      "109 12 False\n",
      "x_t:  0 [0.915625   0.40833333 0.08125    0.30416667]\n",
      "Q values:  tensor([[-29.3042, -29.4038, -30.7359, -30.3681, -30.9675, -30.4432]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11631 848 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2791\n",
      "109 15 False\n",
      "x_t:  1 [0.0375     0.39166667 0.1625     0.47916667]\n",
      "Q values:  tensor([[-22.4451, -18.6812, -20.9046, -21.7959, -19.1170, -21.4902]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22040 268 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1136\n",
      "109 22 False\n",
      "x_t:  1 [0.334375   0.34583333 0.171875   0.5       ]\n",
      "Q values:  tensor([[-20.1516, -19.0782, -20.3114, -20.0551, -21.3205, -21.0698]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11958 741 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  908.524087190628\n",
      "startIDX:  172\n",
      "110 0 True\n",
      "x_t:  2 [0.74375    0.40416667 0.09375    0.28333333]\n",
      "Q values:  tensor([[-24.9357, -21.5398, -26.6795, -25.8966, -25.4612, -23.7370]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2331 358 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 110: ep_len:358 episode reward: total was -261.500000. running mean: -425.903179\n",
      "startIDX:  679\n",
      "110 1 False\n",
      "x_t:  3 [0.071875   0.22916667 0.065625   0.29166667]\n",
      "Q values:  tensor([[-32.2998, -34.6627, -35.8775, -30.9646, -32.6856, -34.3777]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34306 1429 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 110: ep_len:1429 episode reward: total was -1078.800000. running mean: -432.432147\n",
      "startIDX:  1331\n",
      "110 5 False\n",
      "x_t:  1 [0.28125    0.325      0.146875   0.39166667]\n",
      "Q values:  tensor([[-28.5954, -23.8025, -25.5589, -26.1433, -28.4846, -25.1385]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12536 266 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 110: ep_len:266 episode reward: total was -214.100000. running mean: -430.248826\n",
      "startIDX:  1926\n",
      "110 10 False\n",
      "x_t:  2 [0.41875    0.39583333 0.04375    0.24583333]\n",
      "Q values:  tensor([[-32.0236, -29.9071, -29.8221, -30.3009, -31.3078, -32.9678]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18216 825 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 110: ep_len:825 episode reward: total was -628.700000. running mean: -432.233338\n",
      "startIDX:  990\n",
      "110 12 True\n",
      "x_t:  2 [0.79375    0.4125     0.096875   0.24583333]\n",
      "Q values:  tensor([[-30.4701, -27.9933, -25.0240, -28.4129, -28.6153, -29.8101]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13574 319 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 110: ep_len:319 episode reward: total was -243.200000. running mean: -430.343004\n",
      "startIDX:  1027\n",
      "110 15 False\n",
      "x_t:  4 [0.0875   0.3875   0.096875 0.3     ]\n",
      "Q values:  tensor([[-32.1625, -31.7894, -34.7208, -34.0916, -30.3839, -31.3101]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9829 621 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 110: ep_len:621 episode reward: total was -431.700000. running mean: -430.356574\n",
      "startIDX:  2940\n",
      "ep 110: ep_len:41 episode reward: total was -27.000000. running mean: -426.323008\n",
      "startIDX:  967\n",
      "111 0 False\n",
      "x_t:  1 [0.6875     0.3125     0.1625     0.44583333]\n",
      "Q values:  tensor([[-30.8059, -23.6346, -27.8337, -26.1024, -30.8391, -27.9504]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11963 813 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  597\n",
      "111 1 False\n",
      "x_t:  2 [0.78125    0.37083333 0.084375   0.33333333]\n",
      "Q values:  tensor([[-27.1200, -27.2575, -25.9305, -26.9624, -32.1138, -30.2598]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31468 380 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1834\n",
      "111 5 False\n",
      "x_t:  2 [0.778125   0.39583333 0.0875     0.2625    ]\n",
      "Q values:  tensor([[-25.6145, -29.9015, -24.6066, -27.6779, -26.8170, -26.3708]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15653 358 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2143\n",
      "111 10 False\n",
      "x_t:  0 [0.94375    0.37916667 0.046875   0.35833333]\n",
      "Q values:  tensor([[-24.7570, -25.6608, -25.3470, -27.0145, -29.9432, -25.5189]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19927 548 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  762\n",
      "111 12 False\n",
      "x_t:  1 [0.303125   0.37083333 0.153125   0.49583333]\n",
      "Q values:  tensor([[-34.5933, -25.2287, -30.6629, -28.6758, -32.7515, -29.8565]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10325 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1798\n",
      "111 15 False\n",
      "x_t:  0 [0.9375     0.40416667 0.053125   0.325     ]\n",
      "Q values:  tensor([[-28.4263, -33.7700, -30.0193, -33.0470, -29.8715, -30.7791]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13362 423 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1706\n",
      "111 22 False\n",
      "x_t:  3 [0.778125   0.325      0.075      0.40416667]\n",
      "Q values:  tensor([[-34.7629, -32.9514, -31.2429, -28.7127, -32.8532, -30.1470]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16860 205 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  585\n",
      "112 0 False\n",
      "x_t:  2 [0.00625    0.40833333 0.06875    0.27083333]\n",
      "Q values:  tensor([[-34.2345, -31.0570, -30.2783, -31.3725, -32.7215, -31.5117]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8870 937 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 112: ep_len:937 episode reward: total was -748.500000. running mean: -422.959643\n",
      "startIDX:  309\n",
      "112 1 False\n",
      "x_t:  1 [0.74375    0.2875     0.16875    0.58333333]\n",
      "Q values:  tensor([[-35.8812, -30.5932, -31.6899, -31.0515, -34.2886, -32.2463]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28117 326 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 112: ep_len:326 episode reward: total was -259.500000. running mean: -421.325046\n",
      "startIDX:  24\n",
      "112 5 False\n",
      "x_t:  2 [0.15625    0.35833333 0.084375   0.4625    ]\n",
      "Q values:  tensor([[-30.4890, -31.4887, -30.1067, -33.9176, -30.2839, -32.0392]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2067 932 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 112: ep_len:932 episode reward: total was -763.900000. running mean: -424.750796\n",
      "startIDX:  231\n",
      "112 10 False\n",
      "x_t:  4 [0.028125   0.35416667 0.05625    0.2625    ]\n",
      "Q values:  tensor([[-35.3361, -30.7983, -32.1715, -36.3369, -29.3607, -33.0666]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4547 444 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 112: ep_len:444 episode reward: total was -343.000000. running mean: -423.933288\n",
      "startIDX:  1441\n",
      "112 12 False\n",
      "x_t:  3 [0.315625   0.27916667 0.078125   0.3125    ]\n",
      "Q values:  tensor([[-32.5464, -29.1463, -30.7134, -28.5194, -29.8806, -32.7523]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17928 205 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 112: ep_len:205 episode reward: total was -177.600000. running mean: -421.469955\n",
      "startIDX:  1279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 15 False\n",
      "x_t:  3 [0.88125    0.34583333 0.115625   0.39166667]\n",
      "Q values:  tensor([[-26.8110, -26.1053, -29.5939, -25.2960, -29.9159, -28.1758]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10336 232 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 112: ep_len:232 episode reward: total was -162.400000. running mean: -418.879256\n",
      "startIDX:  2300\n",
      "112 22 False\n",
      "x_t:  1 [0.86875    0.3        0.128125   0.44583333]\n",
      "Q values:  tensor([[-31.2287, -29.2190, -32.0227, -32.7850, -33.8223, -31.6740]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22930 1065 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 112: ep_len:1065 episode reward: total was -838.400000. running mean: -423.074463\n",
      "startIDX:  2206\n",
      "113 0 False\n",
      "x_t:  1 [0.321875   0.35       0.240625   0.50416667]\n",
      "Q values:  tensor([[-33.3835, -30.1083, -30.3064, -34.5517, -30.9988, -30.5951]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22957 1112 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  956\n",
      "113 1 False\n",
      "x_t:  4 [0.046875   0.3875     0.09375    0.41666667]\n",
      "Q values:  tensor([[-35.8239, -34.8299, -34.1508, -31.5579, -31.4941, -32.7100]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35429 487 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  73\n",
      "113 5 False\n",
      "x_t:  2 [0.184375   0.36666667 0.115625   0.45416667]\n",
      "Q values:  tensor([[-24.3279, -28.6188, -24.2701, -27.9491, -27.4192, -24.8081]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2069 902 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1275\n",
      "113 10 False\n",
      "x_t:  3 [0.08125    0.22083333 0.059375   0.25416667]\n",
      "Q values:  tensor([[-34.7629, -33.3569, -32.4113, -31.1237, -33.2178, -32.2494]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14579 1208 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  901\n",
      "113 12 True\n",
      "x_t:  1 [0.821875   0.35416667 0.1375     0.5125    ]\n",
      "Q values:  tensor([[-32.7620, -30.1376, -32.7610, -30.5151, -35.1299, -31.3255]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12916 616 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2420\n",
      "113 15 False\n",
      "x_t:  4 [0.021875   0.42916667 0.09375    0.37083333]\n",
      "Q values:  tensor([[-29.8203, -30.3712, -33.4935, -30.3083, -28.1970, -33.7585]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19250 481 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1093\n",
      "113 22 True\n",
      "x_t:  1 [0.8875     0.30416667 0.109375   0.5       ]\n",
      "Q values:  tensor([[-29.5751, -29.1519, -31.3518, -32.3265, -32.2175, -30.7904]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11916 731 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1586\n",
      "114 0 False\n",
      "x_t:  3 [0.80625    0.34583333 0.190625   0.42083333]\n",
      "Q values:  tensor([[-25.6376, -27.6011, -24.1537, -23.1771, -26.6599, -25.6924]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16816 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 114: ep_len:202 episode reward: total was -153.700000. running mean: -431.894179\n",
      "startIDX:  63\n",
      "114 1 False\n",
      "x_t:  3 [0.24375    0.2375     0.0875     0.32083333]\n",
      "Q values:  tensor([[-25.3796, -28.3350, -23.5127, -23.1353, -25.5674, -23.1393]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25739 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 114: ep_len:200 episode reward: total was -120.200000. running mean: -428.777238\n",
      "startIDX:  988\n",
      "114 5 False\n",
      "x_t:  3 [0.734375   0.3125     0.178125   0.40416667]\n",
      "Q values:  tensor([[-25.6671, -24.7639, -24.8202, -22.6140, -22.6443, -22.8060]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10496 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 114: ep_len:201 episode reward: total was -162.800000. running mean: -426.117465\n",
      "startIDX:  1008\n",
      "114 10 False\n",
      "x_t:  1 [0.796875   0.27916667 0.090625   0.34166667]\n",
      "Q values:  tensor([[-27.1346, -25.4328, -25.4550, -29.1490, -28.5309, -26.2204]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11338 1566 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 114: ep_len:1566 episode reward: total was -988.200000. running mean: -431.738291\n",
      "startIDX:  36\n",
      "114 12 False\n",
      "x_t:  1 [0.94375    0.3        0.05       0.43333333]\n",
      "Q values:  tensor([[-31.7057, -28.3038, -32.1361, -31.4656, -31.8287, -28.6107]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2214 631 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 114: ep_len:631 episode reward: total was -399.900000. running mean: -431.419908\n",
      "startIDX:  1306\n",
      "114 15 True\n",
      "x_t:  3 [0.846875 0.3375   0.096875 0.3875  ]\n",
      "Q values:  tensor([[-31.4141, -29.7837, -31.1399, -30.4404, -29.5214, -30.7475]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10343 224 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 114: ep_len:224 episode reward: total was -170.400000. running mean: -428.809709\n",
      "startIDX:  2659\n",
      "114 22 False\n",
      "x_t:  4 [0.075      0.39166667 0.10625    0.31666667]\n",
      "Q values:  tensor([[-25.7489, -25.4056, -25.1173, -27.4223, -24.3077, -24.6771]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27275 529 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 114: ep_len:529 episode reward: total was -288.200000. running mean: -427.403612\n",
      "startIDX:  126\n",
      "115 0 False\n",
      "x_t:  1 [0.371875   0.33333333 0.13125    0.42916667]\n",
      "Q values:  tensor([[-21.5277, -20.5718, -22.3033, -20.8562, -22.7807, -22.7503]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1661 706 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  645\n",
      "115 1 False\n",
      "x_t:  2 [0.634375   0.37916667 0.084375   0.32083333]\n",
      "Q values:  tensor([[-28.3492, -29.4183, -24.1642, -28.1948, -25.1171, -24.6595]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31492 370 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1938\n",
      "115 5 False\n",
      "x_t:  3 [0.146875   0.2625     0.11875    0.31666667]\n",
      "Q values:  tensor([[-22.2409, -21.9031, -20.7725, -20.2494, -20.6537, -20.9289]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18224 1252 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2633\n",
      "startIDX:  1595\n",
      "115 12 True\n",
      "x_t:  2 [0.140625   0.40833333 0.053125   0.2875    ]\n",
      "Q values:  tensor([[-23.6275, -26.4020, -26.4319, -22.8614, -20.7401, -21.6084]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19397 730 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  417\n",
      "115 15 False\n",
      "x_t:  0 [0.765625   0.40416667 0.103125   0.34166667]\n",
      "Q values:  tensor([[-20.8202, -23.8084, -25.4925, -23.4358, -23.8662, -22.4348]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3677 446 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1225\n",
      "115 22 True\n",
      "x_t:  2 [0.778125   0.40833333 0.090625   0.25      ]\n",
      "Q values:  tensor([[-26.6885, -26.2160, -25.5521, -22.4535, -29.0152, -23.0238]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12591 340 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1496\n",
      "116 0 False\n",
      "x_t:  3 [0.80625    0.34583333 0.190625   0.42083333]\n",
      "Q values:  tensor([[-25.6725, -24.7693, -27.1383, -23.0242, -27.8964, -25.5123]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16816 256 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 116: ep_len:256 episode reward: total was -198.500000. running mean: -419.393043\n",
      "startIDX:  64\n",
      "116 1 False\n",
      "x_t:  3 [0.228125   0.23333333 0.075      0.30416667]\n",
      "Q values:  tensor([[-24.5238, -24.4205, -25.4695, -23.1139, -23.8533, -23.5190]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25745 208 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 116: ep_len:208 episode reward: total was -159.200000. running mean: -416.791112\n",
      "startIDX:  822\n",
      "116 5 True\n",
      "x_t:  4 [0.046875   0.41666667 0.13125    0.36666667]\n",
      "Q values:  tensor([[-23.1161, -24.9855, -25.2905, -25.5781, -22.0422, -23.2179]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10018 602 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 116: ep_len:602 episode reward: total was -382.300000. running mean: -416.446201\n",
      "startIDX:  548\n",
      "116 10 False\n",
      "x_t:  2 [0.003125   0.40833333 0.103125   0.25      ]\n",
      "Q values:  tensor([[-24.6901, -22.9976, -20.8911, -22.6806, -21.0259, -22.9145]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6586 746 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 116: ep_len:746 episode reward: total was -517.900000. running mean: -417.460739\n",
      "startIDX:  1277\n",
      "116 12 False\n",
      "x_t:  4 [0.128125   0.42083333 0.084375   0.37083333]\n",
      "Q values:  tensor([[-25.8899, -25.4973, -24.0178, -24.4174, -22.8989, -24.2532]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17402 461 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 116: ep_len:461 episode reward: total was -343.900000. running mean: -416.725132\n",
      "startIDX:  2560\n",
      "116 15 False\n",
      "x_t:  3 [0.246875   0.2625     0.0625     0.26666667]\n",
      "Q values:  tensor([[-25.5714, -22.7426, -22.6238, -22.2305, -23.1302, -22.5605]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19778 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 116: ep_len:201 episode reward: total was -156.600000. running mean: -414.123880\n",
      "startIDX:  44\n",
      "116 22 False\n",
      "x_t:  1 [0.934375   0.2875     0.0625     0.41666667]\n",
      "Q values:  tensor([[-24.6838, -22.0617, -22.3713, -22.9931, -22.3202, -22.7566]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1575 699 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 116: ep_len:699 episode reward: total was -538.200000. running mean: -415.364642\n",
      "startIDX:  205\n",
      "117 0 False\n",
      "x_t:  2 [0.609375   0.40416667 0.053125   0.29166667]\n",
      "Q values:  tensor([[-26.0516, -26.5349, -23.4786, -27.7426, -26.0622, -23.8809]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2355 355 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  596\n",
      "117 1 False\n",
      "x_t:  2 [0.815625   0.38333333 0.103125   0.31666667]\n",
      "Q values:  tensor([[-27.6658, -27.0748, -23.7312, -27.2964, -26.5816, -27.3794]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31460 380 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  668\n",
      "117 5 False\n",
      "x_t:  3 [0.10625  0.2625   0.078125 0.3125  ]\n",
      "Q values:  tensor([[-33.8255, -29.9014, -31.1926, -29.0171, -29.5102, -30.2303]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8762 1345 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1492\n",
      "117 10 False\n",
      "x_t:  3 [0.81875 0.3125  0.1125  0.4    ]\n",
      "Q values:  tensor([[-31.3982, -27.2583, -29.2116, -26.6473, -28.0418, -31.2498]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16409 343 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1499\n",
      "117 12 True\n",
      "x_t:  2 [0.003125   0.41666667 0.096875   0.27916667]\n",
      "Q values:  tensor([[-34.7004, -29.6237, -31.2878, -31.5123, -31.5216, -31.9275]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19377 761 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2949\n",
      "117 15 True\n",
      "x_t:  0 [0.584375   0.4125     0.128125   0.35833333]\n",
      "Q values:  tensor([[-33.7494, -33.1245, -35.7779, -33.9297, -32.6959, -34.6790]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23114 493 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  801\n",
      "117 22 False\n",
      "x_t:  2 [0.140625   0.40416667 0.071875   0.2625    ]\n",
      "Q values:  tensor([[-30.6558, -35.0274, -29.5113, -31.4625, -31.3743, -30.1601]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8937 837 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1500\n",
      "118 0 False\n",
      "x_t:  3 [0.83125    0.35       0.165625   0.41666667]\n",
      "Q values:  tensor([[-35.6741, -30.7663, -29.9808, -28.8916, -30.4963, -31.0956]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16813 246 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 118: ep_len:246 episode reward: total was -168.600000. running mean: -418.204462\n",
      "startIDX:  361\n",
      "118 1 False\n",
      "x_t:  1 [0.60625    0.3        0.20625    0.57083333]\n",
      "Q values:  tensor([[-30.4992, -29.9574, -31.2756, -31.9861, -33.2039, -30.6377]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28104 298 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 118: ep_len:298 episode reward: total was -227.500000. running mean: -416.297417\n",
      "startIDX:  2273\n",
      "118 5 False\n",
      "x_t:  3 [0.4375     0.28333333 0.11875    0.37916667]\n",
      "Q values:  tensor([[-34.5250, -33.0641, -35.0873, -32.6869, -34.6128, -36.3964]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19933 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 118: ep_len:200 episode reward: total was -140.800000. running mean: -413.542443\n",
      "startIDX:  309\n",
      "118 10 True\n",
      "x_t:  3 [0.546875 0.2875   0.121875 0.35    ]\n",
      "Q values:  tensor([[-29.2044, -24.4348, -25.1633, -26.4705, -27.4587, -25.5157]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5072 240 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 118: ep_len:240 episode reward: total was -169.500000. running mean: -411.102019\n",
      "startIDX:  1061\n",
      "118 12 True\n",
      "x_t:  3 [0.165625   0.27083333 0.078125   0.32083333]\n",
      "Q values:  tensor([[-31.2018, -27.7460, -28.8235, -28.6644, -30.3990, -24.2691]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16400 1402 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 118: ep_len:1402 episode reward: total was -1052.400000. running mean: -417.514998\n",
      "startIDX:  846\n",
      "118 15 False\n",
      "x_t:  3 [0.109375 0.2375   0.05625  0.2375  ]\n",
      "Q values:  tensor([[-27.1861, -27.6196, -27.7145, -25.7710, -29.9765, -28.3335]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8518 1257 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 118: ep_len:1257 episode reward: total was -904.600000. running mean: -422.385848\n",
      "startIDX:  2617\n",
      "118 22 False\n",
      "x_t:  3 [0.175      0.25       0.05625    0.26666667]\n",
      "Q values:  tensor([[-32.6764, -31.3363, -30.6781, -28.8742, -32.4280, -29.5783]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26206 1239 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 118: ep_len:1239 episode reward: total was -921.300000. running mean: -427.374990\n",
      "startIDX:  1283\n",
      "119 0 True\n",
      "x_t:  3 [0.0625     0.24583333 0.05625    0.25416667]\n",
      "Q values:  tensor([[-33.5518, -30.8601, -30.8513, -34.2912, -30.0814, -29.8030]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15155 1227 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  849\n",
      "119 1 False\n",
      "x_t:  4 [0.146875   0.37916667 0.090625   0.4125    ]\n",
      "Q values:  tensor([[-38.2075, -36.0917, -39.0068, -36.5122, -33.4463, -38.1740]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35442 549 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  997\n",
      "119 5 True\n",
      "x_t:  3 [0.490625   0.2875     0.096875   0.32916667]\n",
      "Q values:  tensor([[-27.1066, -27.4024, -26.8304, -24.3889, -25.8179, -31.0675]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10531 208 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  534\n",
      "119 10 False\n",
      "x_t:  2 [0.115625   0.4        0.0875     0.26666667]\n",
      "Q values:  tensor([[-31.7704, -29.1326, -28.0377, -31.2618, -32.2882, -32.0793]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6604 779 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1680\n",
      "119 12 False\n",
      "x_t:  1 [0.03125    0.37083333 0.125      0.3625    ]\n",
      "Q values:  tensor([[-31.4077, -29.7788, -31.7777, -29.9342, -30.3701, -30.1841]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19873 228 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1833\n",
      "119 15 True\n",
      "x_t:  0 [0.865625   0.4        0.096875   0.33333333]\n",
      "Q values:  tensor([[-26.4009, -24.4516, -25.1428, -23.0101, -24.9909, -24.4621]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13369 403 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3006\n",
      "Time elapsed:  989.6875839233398\n",
      "startIDX:  1738\n",
      "120 0 False\n",
      "x_t:  2 [0.184375 0.4      0.059375 0.2625  ]\n",
      "Q values:  tensor([[-28.2342, -31.3291, -27.2816, -31.1690, -29.0705, -30.0802]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18416 785 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 120: ep_len:785 episode reward: total was -504.300000. running mean: -422.195709\n",
      "startIDX:  661\n",
      "120 1 True\n",
      "x_t:  2 [0.75625    0.37916667 0.09375    0.32916667]\n",
      "Q values:  tensor([[-29.7215, -30.7264, -30.7034, -30.1486, -26.6711, -27.9219]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31470 351 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 120: ep_len:351 episode reward: total was -263.200000. running mean: -420.605752\n",
      "startIDX:  85\n",
      "120 5 True\n",
      "x_t:  2 [0.04375    0.3875     0.19375    0.42083333]\n",
      "Q values:  tensor([[-32.5116, -30.9574, -29.6658, -32.6744, -29.1597, -27.3484]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2060 889 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 120: ep_len:889 episode reward: total was -596.900000. running mean: -422.368695\n",
      "startIDX:  2172\n",
      "120 10 False\n",
      "x_t:  0 [0.94375    0.37916667 0.05       0.36666667]\n",
      "Q values:  tensor([[-31.3206, -33.7785, -32.6611, -32.1805, -33.3802, -33.4559]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19926 520 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 120: ep_len:520 episode reward: total was -385.300000. running mean: -421.998008\n",
      "startIDX:  1776\n",
      "120 12 True\n",
      "x_t:  0 [0.690625   0.41666667 0.10625    0.34166667]\n",
      "Q values:  tensor([[-26.8876, -30.4986, -28.8695, -25.8102, -27.6330, -26.3475]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21117 610 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 120: ep_len:610 episode reward: total was -470.200000. running mean: -422.480028\n",
      "startIDX:  361\n",
      "120 15 False\n",
      "x_t:  1 [0.003125   0.38333333 0.128125   0.48333333]\n",
      "Q values:  tensor([[-33.7442, -32.6791, -34.1786, -33.5143, -33.7545, -32.9749]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2752 241 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 120: ep_len:241 episode reward: total was -168.800000. running mean: -419.943227\n",
      "startIDX:  1707\n",
      "120 22 False\n",
      "x_t:  3 [0.790625   0.34166667 0.125      0.4125    ]\n",
      "Q values:  tensor([[-25.6354, -27.1124, -26.3781, -24.8600, -25.1438, -27.2204]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16855 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 120: ep_len:201 episode reward: total was -140.900000. running mean: -417.152795\n",
      "startIDX:  1305\n",
      "121 0 False\n",
      "x_t:  3 [0.0625     0.24583333 0.05625    0.25416667]\n",
      "Q values:  tensor([[-26.0639, -28.6307, -31.6504, -26.0629, -28.2547, -29.9651]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15155 1208 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  435\n",
      "121 1 False\n",
      "x_t:  1 [0.8625     0.25833333 0.0875     0.47083333]\n",
      "Q values:  tensor([[-28.6135, -25.0125, -30.8363, -26.9257, -30.0764, -27.2983]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30684 792 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  2611\n",
      "121 5 False\n",
      "x_t:  1 [0.796875   0.27916667 0.09375    0.51666667]\n",
      "Q values:  tensor([[-34.7547, -26.8262, -29.8086, -32.9777, -34.2944, -31.0915]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22174 300 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  324\n",
      "121 10 False\n",
      "x_t:  3 [0.83125  0.3375   0.153125 0.375   ]\n",
      "Q values:  tensor([[-28.5043, -29.8816, -31.1535, -27.0530, -30.5074, -27.6765]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5036 224 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  676\n",
      "121 12 True\n",
      "x_t:  1 [0.025      0.40416667 0.228125   0.46666667]\n",
      "Q values:  tensor([[-26.5858, -25.0900, -27.0596, -28.9599, -29.7916, -28.4920]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10307 230 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  51\n",
      "121 15 False\n",
      "x_t:  3 [0.825      0.34166667 0.096875   0.42916667]\n",
      "Q values:  tensor([[-28.8723, -28.4228, -28.3959, -26.2760, -30.5973, -26.4070]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 525 228 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2738\n",
      "121 22 False\n",
      "x_t:  4 [0.165625   0.39166667 0.078125   0.3125    ]\n",
      "Q values:  tensor([[-27.4724, -25.8013, -24.8633, -26.3137, -21.3439, -26.9204]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27286 509 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  308\n",
      "122 0 False\n",
      "x_t:  3 [0.059375   0.23333333 0.0625     0.22916667]\n",
      "Q values:  tensor([[-24.6347, -25.0491, -23.5560, -23.4220, -25.1952, -23.9670]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4830 1246 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 122: ep_len:1246 episode reward: total was -869.200000. running mean: -417.000792\n",
      "startIDX:  706\n",
      "122 1 False\n",
      "x_t:  3 [0.0625     0.22916667 0.059375   0.28333333]\n",
      "Q values:  tensor([[-28.3243, -26.6971, -26.9895, -26.5673, -29.6097, -27.6645]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34302 1410 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 122: ep_len:1410 episode reward: total was -962.100000. running mean: -422.451784\n",
      "startIDX:  1581\n",
      "122 5 False\n",
      "x_t:  1 [0.828125   0.28333333 0.109375   0.32083333]\n",
      "Q values:  tensor([[-25.9052, -23.8538, -25.4406, -24.7964, -27.8730, -24.8166]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14927 697 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 122: ep_len:697 episode reward: total was -476.600000. running mean: -422.993266\n",
      "startIDX:  2202\n",
      "122 10 False\n",
      "x_t:  0 [0.875      0.39166667 0.09375    0.3625    ]\n",
      "Q values:  tensor([[-24.6121, -24.6244, -25.3297, -24.7334, -28.4294, -27.6985]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19935 518 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 122: ep_len:518 episode reward: total was -366.500000. running mean: -422.428334\n",
      "startIDX:  741\n",
      "122 12 False\n",
      "x_t:  1 [0.63125    0.34166667 0.190625   0.52083333]\n",
      "Q values:  tensor([[-33.3695, -28.5083, -30.9045, -31.4451, -32.2260, -31.1961]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10347 213 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 122: ep_len:213 episode reward: total was -165.300000. running mean: -419.857050\n",
      "startIDX:  2230\n",
      "122 15 False\n",
      "x_t:  3 [0.121875   0.27916667 0.09375    0.31666667]\n",
      "Q values:  tensor([[-32.2587, -31.9424, -28.9441, -27.2551, -30.9379, -30.5454]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18188 1262 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 122: ep_len:1262 episode reward: total was -935.700000. running mean: -425.015480\n",
      "startIDX:  1088\n",
      "122 22 False\n",
      "x_t:  1 [0.703125 0.3125   0.1125   0.5     ]\n",
      "Q values:  tensor([[-25.6385, -22.6788, -24.9923, -24.9244, -24.2670, -27.0233]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11932 745 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 122: ep_len:745 episode reward: total was -565.700000. running mean: -426.422325\n",
      "startIDX:  568\n",
      "123 0 False\n",
      "x_t:  2 [0.021875   0.4125     0.115625   0.26666667]\n",
      "Q values:  tensor([[-29.1940, -33.4935, -29.0353, -30.0177, -34.8893, -29.0618]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8876 943 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  597\n",
      "123 1 True\n",
      "x_t:  2 [0.8125     0.38333333 0.1125     0.30833333]\n",
      "Q values:  tensor([[-27.2713, -23.6004, -26.5552, -23.5949, -25.5713, -24.9230]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31459 367 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1716\n",
      "123 5 False\n",
      "x_t:  1 [0.796875   0.27916667 0.059375   0.3125    ]\n",
      "Q values:  tensor([[-29.7453, -28.7391, -29.3586, -31.5483, -34.2117, -31.5133]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14935 614 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1687\n",
      "123 10 True\n",
      "x_t:  3 [0.928125   0.3125     0.06875    0.41666667]\n",
      "Q values:  tensor([[-28.4153, -27.3575, -29.5004, -27.3670, -23.6701, -27.2473]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16398 243 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  381\n",
      "123 12 True\n",
      "x_t:  4 [0.025      0.44583333 0.153125   0.35833333]\n",
      "Q values:  tensor([[-30.2404, -35.4149, -29.6234, -36.1610, -29.7983, -29.7745]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7186 690 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1031\n",
      "123 15 False\n",
      "x_t:  4 [0.0625     0.39166667 0.096875   0.29583333]\n",
      "Q values:  tensor([[-31.2570, -33.3522, -32.2987, -31.7475, -29.3703, -31.9537]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9822 599 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1367\n",
      "123 22 True\n",
      "x_t:  3 [0.190625   0.27083333 0.084375   0.3       ]\n",
      "Q values:  tensor([[-32.2145, -31.8246, -29.5557, -32.0534, -29.6300, -32.5208]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15234 1301 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1304\n",
      "124 0 False\n",
      "x_t:  3 [0.18125    0.2625     0.084375   0.29166667]\n",
      "Q values:  tensor([[-23.9156, -23.8371, -24.9989, -23.7823, -25.8718, -24.3299]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15195 1219 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 124: ep_len:1219 episode reward: total was -901.000000. running mean: -435.674367\n",
      "startIDX:  933\n",
      "124 1 True\n",
      "x_t:  4 [0.003125   0.39583333 0.11875    0.4       ]\n",
      "Q values:  tensor([[-28.9953, -30.9623, -28.8903, -37.6582, -33.0878, -31.3430]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35422 496 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 124: ep_len:496 episode reward: total was -354.700000. running mean: -434.864623\n",
      "startIDX:  1918\n",
      "124 5 True\n",
      "x_t:  2 [0.846875   0.40416667 0.084375   0.2375    ]\n",
      "Q values:  tensor([[-28.9763, -28.5321, -27.9367, -27.3434, -29.8442, -28.1724]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15640 310 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 124: ep_len:310 episode reward: total was -244.200000. running mean: -432.957977\n",
      "startIDX:  2015\n",
      "124 10 True\n",
      "x_t:  1 [0.046875   0.34166667 0.090625   0.37916667]\n",
      "Q values:  tensor([[-27.0784, -32.0298, -35.3790, -33.3006, -28.2753, -27.3953]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18815 307 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 124: ep_len:307 episode reward: total was -218.100000. running mean: -430.809397\n",
      "startIDX:  1400\n",
      "124 12 False\n",
      "x_t:  3 [0.496875   0.3125     0.103125   0.36666667]\n",
      "Q values:  tensor([[-31.2332, -30.3964, -34.1830, -29.4290, -31.7328, -29.9553]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17888 207 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 124: ep_len:207 episode reward: total was -156.700000. running mean: -428.068303\n",
      "startIDX:  2220\n",
      "124 15 False\n",
      "x_t:  3 [0.06875    0.275      0.084375   0.29583333]\n",
      "Q values:  tensor([[-35.9392, -35.1224, -37.6017, -31.1982, -37.0069, -34.1405]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18174 1287 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 124: ep_len:1287 episode reward: total was -927.400000. running mean: -433.061620\n",
      "startIDX:  2239\n",
      "124 22 False\n",
      "x_t:  1 [0.86875    0.3        0.128125   0.44583333]\n",
      "Q values:  tensor([[-30.4746, -28.1605, -36.0099, -30.0406, -33.5550, -30.3258]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22930 1116 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 124: ep_len:1116 episode reward: total was -808.000000. running mean: -436.811004\n",
      "startIDX:  859\n",
      "125 0 False\n",
      "x_t:  0 [0.775      0.40416667 0.128125   0.34583333]\n",
      "Q values:  tensor([[-27.1990, -29.2728, -33.0940, -28.6540, -29.7703, -28.9813]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10345 481 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  380\n",
      "125 1 False\n",
      "x_t:  1 [0.4875     0.29583333 0.21875    0.575     ]\n",
      "Q values:  tensor([[-32.7105, -31.1613, -33.1537, -32.9731, -33.6262, -33.7759]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28098 289 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2306\n",
      "125 5 False\n",
      "x_t:  3 [0.296875   0.26666667 0.1        0.3375    ]\n",
      "Q values:  tensor([[-25.2099, -26.5599, -27.9730, -24.4869, -25.3192, -26.2221]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19958 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 10 False\n",
      "x_t:  2 [0.05       0.39583333 0.0875     0.25416667]\n",
      "Q values:  tensor([[-28.9663, -27.2383, -23.9757, -27.9822, -29.2304, -26.7324]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18151 827 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1449\n",
      "125 12 False\n",
      "x_t:  3 [0.14375    0.25833333 0.075      0.275     ]\n",
      "Q values:  tensor([[-39.9618, -38.2444, -32.6646, -32.5589, -35.3244, -34.8181]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17971 217 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  761\n",
      "125 15 False\n",
      "x_t:  2 [0.784375   0.40833333 0.090625   0.29166667]\n",
      "Q values:  tensor([[-29.8852, -26.7870, -26.6226, -30.2552, -31.1601, -27.8872]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5968 354 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2924\n",
      "startIDX:  1441\n",
      "126 0 False\n",
      "x_t:  4 [0.153125   0.3875     0.10625    0.27916667]\n",
      "Q values:  tensor([[-25.3719, -31.1685, -26.4965, -28.9314, -24.3745, -27.7299]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16308 515 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 126: ep_len:515 episode reward: total was -355.700000. running mean: -422.269337\n",
      "startIDX:  652\n",
      "126 1 True\n",
      "x_t:  2 [0.725      0.37916667 0.0875     0.31666667]\n",
      "Q values:  tensor([[-31.7530, -27.6960, -31.0735, -32.3428, -30.2507, -29.6985]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31478 358 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 126: ep_len:358 episode reward: total was -277.900000. running mean: -420.825644\n",
      "startIDX:  2860\n",
      "ep 126: ep_len:107 episode reward: total was -63.900000. running mean: -417.256388\n",
      "startIDX:  549\n",
      "126 10 True\n",
      "x_t:  2 [0.15       0.39583333 0.05625    0.26666667]\n",
      "Q values:  tensor([[-24.2175, -25.7705, -25.7464, -23.2811, -26.0575, -23.7146]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6607 775 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 126: ep_len:775 episode reward: total was -524.600000. running mean: -418.329824\n",
      "startIDX:  1424\n",
      "126 12 False\n",
      "x_t:  3 [0.3375     0.29166667 0.1        0.31666667]\n",
      "Q values:  tensor([[-29.7424, -30.0039, -27.5498, -26.1634, -28.2415, -29.3924]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17920 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 126: ep_len:203 episode reward: total was -151.000000. running mean: -415.656526\n",
      "startIDX:  1361\n",
      "126 15 False\n",
      "x_t:  3 [0.74375    0.32916667 0.09375    0.37083333]\n",
      "Q values:  tensor([[-25.9557, -27.3050, -26.0861, -22.6305, -24.0835, -27.1403]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10356 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 126: ep_len:202 episode reward: total was -117.700000. running mean: -412.676960\n",
      "startIDX:  1792\n",
      "126 22 True\n",
      "x_t:  3 [0.296875   0.275      0.096875   0.30833333]\n",
      "Q values:  tensor([[-23.0632, -24.2676, -22.3032, -21.1983, -18.8670, -20.3401]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16935 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 126: ep_len:202 episode reward: total was -155.300000. running mean: -410.103191\n",
      "startIDX:  557\n",
      "127 0 True\n",
      "x_t:  3 [0.821875   0.40416667 0.175      0.41666667]\n",
      "Q values:  tensor([[-29.9596, -30.6115, -30.1392, -31.6513, -31.3113, -31.1824]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 6992 988 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  625\n",
      "127 1 False\n",
      "x_t:  2 [0.725      0.37916667 0.1125     0.3125    ]\n",
      "Q values:  tensor([[-27.8448, -29.0114, -25.9366, -28.5077, -30.2590, -27.0683]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31476 360 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2360\n",
      "127 5 False\n",
      "x_t:  3 [0.0625     0.24166667 0.078125   0.27083333]\n",
      "Q values:  tensor([[-23.0668, -20.9026, -20.6606, -20.3729, -20.9362, -23.8389]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 20015 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  60\n",
      "127 10 False\n",
      "x_t:  3 [0.059375   0.24166667 0.05625    0.25      ]\n",
      "Q values:  tensor([[-40.0405, -39.1385, -38.6975, -34.2377, -39.8842, -38.9625]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3577 1081 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  469\n",
      "127 12 False\n",
      "x_t:  3 [0.68125    0.32916667 0.075      0.37916667]\n",
      "Q values:  tensor([[-32.6834, -29.6939, -34.7755, -28.5728, -31.7625, -30.1997]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7735 229 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  580\n",
      "127 15 False\n",
      "x_t:  1 [0.884375   0.29583333 0.096875   0.27916667]\n",
      "Q values:  tensor([[-37.7736, -30.0743, -35.4994, -34.5043, -33.8351, -31.9411]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5166 682 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2012\n",
      "127 22 False\n",
      "x_t:  1 [0.003125   0.375      0.134375   0.41666667]\n",
      "Q values:  tensor([[-33.2339, -29.8284, -31.5994, -30.1795, -32.5188, -31.0739]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18989 245 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1155\n",
      "128 0 False\n",
      "x_t:  2 [0.6875     0.40416667 0.115625   0.28333333]\n",
      "Q values:  tensor([[-37.1641, -36.9702, -35.8049, -36.2764, -40.8119, -38.8854]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12646 324 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 128: ep_len:324 episode reward: total was -251.800000. running mean: -410.512738\n",
      "startIDX:  578\n",
      "128 1 True\n",
      "x_t:  2 [0.7125     0.37916667 0.065625   0.3125    ]\n",
      "Q values:  tensor([[-36.0966, -35.0103, -31.4325, -33.7055, -30.6243, -34.2513]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31481 391 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 128: ep_len:391 episode reward: total was -325.100000. running mean: -409.658610\n",
      "startIDX:  2239\n",
      "128 5 False\n",
      "x_t:  3 [0.75       0.3375     0.175      0.43333333]\n",
      "Q values:  tensor([[-25.0036, -26.0355, -29.7910, -24.3778, -26.5050, -24.6166]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19893 206 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 128: ep_len:206 episode reward: total was -140.400000. running mean: -406.966024\n",
      "startIDX:  2321\n",
      "128 10 False\n",
      "x_t:  1 [0.875      0.275      0.065625   0.34583333]\n",
      "Q values:  tensor([[-29.8477, -28.0822, -29.2153, -33.1559, -30.9898, -28.8739]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22472 1255 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 128: ep_len:1255 episode reward: total was -971.400000. running mean: -412.610364\n",
      "startIDX:  1370\n",
      "128 12 False\n",
      "x_t:  3 [0.684375   0.35       0.14375    0.42916667]\n",
      "Q values:  tensor([[-23.4062, -24.2916, -25.1422, -22.8840, -24.3521, -25.2254]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17861 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 128: ep_len:202 episode reward: total was -122.400000. running mean: -409.708260\n",
      "startIDX:  1992\n",
      "128 15 False\n",
      "x_t:  1 [0.896875   0.29583333 0.08125    0.30833333]\n",
      "Q values:  tensor([[-32.4474, -28.7842, -32.0713, -32.7083, -31.0546, -29.9449]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14842 656 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 128: ep_len:656 episode reward: total was -488.600000. running mean: -410.497178\n",
      "startIDX:  1592\n",
      "128 22 False\n",
      "x_t:  3 [0.70625    0.34166667 0.115625   0.37916667]\n",
      "Q values:  tensor([[-32.4413, -33.2135, -30.6104, -26.9249, -27.0489, -28.9604]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16865 268 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 128: ep_len:268 episode reward: total was -193.000000. running mean: -408.322206\n",
      "startIDX:  2439\n",
      "startIDX:  212\n",
      "129 1 False\n",
      "x_t:  2 [0.0625  0.3625  0.11875 0.4625 ]\n",
      "Q values:  tensor([[-23.5114, -22.7486, -22.1959, -27.9954, -22.9488, -23.4285]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27441 850 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2919\n",
      "startIDX:  824\n",
      "129 10 False\n",
      "x_t:  0 [0.9        0.39583333 0.09375    0.325     ]\n",
      "Q values:  tensor([[-25.5594, -26.7074, -29.2810, -28.4591, -26.0200, -25.7884]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8105 489 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1521\n",
      "129 12 False\n",
      "x_t:  2 [0.08125    0.40833333 0.10625    0.29166667]\n",
      "Q values:  tensor([[-29.4821, -32.9959, -27.6896, -32.3146, -29.6130, -28.2366]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19392 758 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2240\n",
      "129 15 True\n",
      "x_t:  3 [0.121875   0.27916667 0.09375    0.31666667]\n",
      "Q values:  tensor([[-26.4576, -24.8462, -24.6298, -24.7586, -27.0417, -24.8084]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18188 1272 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  113\n",
      "129 22 False\n",
      "x_t:  1 [0.90625  0.2875   0.090625 0.4125  ]\n",
      "Q values:  tensor([[-27.1221, -23.0475, -24.8048, -28.7256, -27.2668, -26.3223]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1576 673 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  1069.569700717926\n",
      "startIDX:  1613\n",
      "130 0 True\n",
      "x_t:  3 [0.703125   0.35       0.153125   0.39166667]\n",
      "Q values:  tensor([[-27.2138, -27.9648, -28.8635, -28.3408, -25.6418, -26.4866]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16829 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 130: ep_len:202 episode reward: total was -119.200000. running mean: -406.949284\n",
      "startIDX:  1196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 130: ep_len:6 episode reward: total was -4.000000. running mean: -402.919792\n",
      "startIDX:  2650\n",
      "130 5 False\n",
      "x_t:  1 [0.09375    0.3625     0.1875     0.50416667]\n",
      "Q values:  tensor([[-27.2769, -26.2932, -27.8635, -28.0426, -29.5159, -26.3239]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22115 264 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 130: ep_len:264 episode reward: total was -191.400000. running mean: -400.804594\n",
      "startIDX:  804\n",
      "130 10 False\n",
      "x_t:  0 [0.896875   0.39166667 0.059375   0.32916667]\n",
      "Q values:  tensor([[-25.5786, -27.3102, -27.2770, -26.3966, -25.7540, -26.7465]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8110 501 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 130: ep_len:501 episode reward: total was -372.200000. running mean: -400.518548\n",
      "startIDX:  680\n",
      "130 12 False\n",
      "x_t:  1 [0.4125     0.36666667 0.23125    0.50416667]\n",
      "Q values:  tensor([[-30.6255, -29.5634, -31.5462, -34.5834, -29.8934, -30.6683]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10333 235 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 130: ep_len:235 episode reward: total was -193.100000. running mean: -398.444362\n",
      "startIDX:  1755\n",
      "130 15 False\n",
      "x_t:  0 [0.865625   0.4125     0.096875   0.31666667]\n",
      "Q values:  tensor([[-25.5979, -28.3753, -27.4446, -26.7378, -29.6481, -25.6398]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13370 459 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 130: ep_len:459 episode reward: total was -334.100000. running mean: -397.800919\n",
      "startIDX:  2049\n",
      "130 22 False\n",
      "x_t:  1 [0.003125   0.375      0.134375   0.41666667]\n",
      "Q values:  tensor([[-27.2092, -21.6405, -27.1904, -29.7561, -26.8596, -30.2647]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18989 230 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 130: ep_len:230 episode reward: total was -163.900000. running mean: -395.461909\n",
      "startIDX:  38\n",
      "131 0 False\n",
      "x_t:  1 [0.85625    0.3        0.121875   0.42916667]\n",
      "Q values:  tensor([[-26.3752, -24.7974, -27.1749, -28.2895, -30.1838, -28.7314]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1613 737 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  540\n",
      "131 1 False\n",
      "x_t:  1 [0.85625    0.26666667 0.140625   0.4625    ]\n",
      "Q values:  tensor([[-29.8391, -26.6729, -27.2258, -28.2491, -29.1189, -27.4960]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30679 733 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2902\n",
      "startIDX:  475\n",
      "131 10 False\n",
      "x_t:  3 [0.090625   0.23333333 0.075      0.25416667]\n",
      "Q values:  tensor([[-30.5393, -35.8354, -31.0519, -30.4066, -30.5277, -31.4508]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5178 211 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1000\n",
      "131 12 False\n",
      "x_t:  2 [0.846875   0.38333333 0.08125    0.25      ]\n",
      "Q values:  tensor([[-23.1225, -23.9840, -22.8492, -27.5318, -25.5715, -23.1548]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13568 312 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  448\n",
      "131 15 False\n",
      "x_t:  0 [0.934375   0.4        0.05625    0.34166667]\n",
      "Q values:  tensor([[-19.9758, -27.0264, -24.4535, -25.2764, -24.9479, -24.2523]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3651 411 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  828\n",
      "131 22 False\n",
      "x_t:  1 [0.2625     0.34166667 0.16875    0.39583333]\n",
      "Q values:  tensor([[-29.3771, -26.0444, -26.8918, -27.3774, -30.7518, -27.8005]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9513 290 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1478\n",
      "132 0 False\n",
      "x_t:  3 [0.8        0.34583333 0.1875     0.41666667]\n",
      "Q values:  tensor([[-24.3240, -25.4799, -26.2298, -21.9819, -23.7693, -25.3734]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16817 262 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 132: ep_len:262 episode reward: total was -169.500000. running mean: -384.703419\n",
      "startIDX:  442\n",
      "132 1 True\n",
      "x_t:  1 [0.75       0.275      0.16875    0.45416667]\n",
      "Q values:  tensor([[-22.8861, -25.2162, -24.2006, -24.1820, -27.0651, -25.3988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30691 780 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 132: ep_len:780 episode reward: total was -550.800000. running mean: -386.364384\n",
      "startIDX:  1196\n",
      "132 5 False\n",
      "x_t:  2 [0.003125   0.39583333 0.1        0.26666667]\n",
      "Q values:  tensor([[-26.3889, -24.6213, -23.7186, -25.7552, -26.2656, -24.7257]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12005 773 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 132: ep_len:773 episode reward: total was -513.200000. running mean: -387.632741\n",
      "startIDX:  2351\n",
      "132 10 True\n",
      "x_t:  1 [0.66875    0.30416667 0.1        0.31666667]\n",
      "Q values:  tensor([[-24.1269, -28.7537, -23.6101, -27.3904, -26.9758, -23.2803]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22494 1237 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 132: ep_len:1237 episode reward: total was -871.800000. running mean: -392.474413\n",
      "startIDX:  594\n",
      "132 12 False\n",
      "x_t:  2 [0.003125   0.4125     0.06875    0.25416667]\n",
      "Q values:  tensor([[-24.5802, -24.6051, -24.0122, -25.4495, -29.7685, -27.5736]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9824 1010 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 132: ep_len:1010 episode reward: total was -757.000000. running mean: -396.119669\n",
      "startIDX:  468\n",
      "132 15 False\n",
      "x_t:  1 [0.95625    0.29166667 0.040625   0.2875    ]\n",
      "Q values:  tensor([[-32.9743, -26.1078, -28.9103, -30.8166, -27.8734, -30.2275]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5160 757 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 132: ep_len:757 episode reward: total was -569.000000. running mean: -397.848472\n",
      "startIDX:  2511\n",
      "132 22 False\n",
      "x_t:  3 [0.128125   0.24166667 0.05       0.25833333]\n",
      "Q values:  tensor([[-33.6563, -35.8096, -36.1223, -33.5530, -35.3309, -35.7922]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26193 1262 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 132: ep_len:1262 episode reward: total was -995.800000. running mean: -403.827988\n",
      "startIDX:  2126\n",
      "133 0 False\n",
      "x_t:  1 [0.846875   0.30416667 0.146875   0.5375    ]\n",
      "Q values:  tensor([[-33.1588, -29.7183, -30.5052, -32.6128, -34.0912, -35.3072]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22919 1144 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1071\n",
      "133 1 False\n",
      "x_t:  3 [0.684375 0.3      0.109375 0.3875  ]\n",
      "Q values:  tensor([[-27.5432, -27.6451, -29.1912, -25.6871, -27.8903, -30.6629]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35923 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  28\n",
      "133 5 False\n",
      "x_t:  2 [0.003125   0.3875     0.1        0.42083333]\n",
      "Q values:  tensor([[-35.0298, -32.1726, -32.0757, -36.2331, -36.6184, -33.5796]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2052 922 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2199\n",
      "133 10 False\n",
      "x_t:  0 [0.909375   0.39166667 0.08125    0.35416667]\n",
      "Q values:  tensor([[-31.1297, -33.5737, -33.3458, -31.2349, -31.7866, -32.3328]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19928 517 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  393\n",
      "133 12 False\n",
      "x_t:  3 [0.9125     0.36666667 0.084375   0.425     ]\n",
      "Q values:  tensor([[-28.7184, -29.5286, -30.5787, -28.6922, -30.9252, -30.5614]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7709 261 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  345\n",
      "133 15 False\n",
      "x_t:  1 [0.003125   0.39166667 0.109375   0.47916667]\n",
      "Q values:  tensor([[-32.0490, -27.2403, -30.7434, -30.4067, -32.6938, -29.6473]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2751 244 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2201\n",
      "133 22 False\n",
      "x_t:  0 [0.903125   0.40833333 0.090625   0.3375    ]\n",
      "Q values:  tensor([[-25.5301, -30.4984, -30.3236, -27.9649, -29.2391, -28.2942]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20688 795 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1749\n",
      "134 0 False\n",
      "x_t:  2 [0.003125 0.4125   0.115625 0.2375  ]\n",
      "Q values:  tensor([[-29.2022, -31.0440, -27.8344, -29.0679, -33.2629, -29.3887]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18393 772 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 134: ep_len:772 episode reward: total was -564.700000. running mean: -407.806182\n",
      "startIDX:  97\n",
      "134 1 False\n",
      "x_t:  3 [0.146875   0.23333333 0.071875   0.28333333]\n",
      "Q values:  tensor([[-21.8544, -21.4617, -22.0467, -21.2989, -21.8660, -21.8093]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25770 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 134: ep_len:201 episode reward: total was -120.800000. running mean: -404.936120\n",
      "startIDX:  1226\n",
      "134 5 False\n",
      "x_t:  2 [0.059375   0.40416667 0.103125   0.26666667]\n",
      "Q values:  tensor([[-31.2677, -34.5776, -31.1260, -32.6382, -34.3813, -32.3648]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12013 741 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 134: ep_len:741 episode reward: total was -529.100000. running mean: -406.177759\n",
      "startIDX:  395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 10 False\n",
      "x_t:  3 [0.509375   0.2875     0.1125     0.34166667]\n",
      "Q values:  tensor([[-27.4374, -27.6123, -30.0525, -26.5272, -30.8976, -31.4441]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5078 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 134: ep_len:201 episode reward: total was -130.300000. running mean: -403.418981\n",
      "startIDX:  1997\n",
      "ep 134: ep_len:45 episode reward: total was -21.900000. running mean: -399.603791\n",
      "startIDX:  2648\n",
      "134 15 False\n",
      "x_t:  2 [0.025      0.40833333 0.10625    0.3375    ]\n",
      "Q values:  tensor([[-32.8023, -31.6134, -30.1933, -31.3578, -34.7436, -30.3799]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21478 879 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 134: ep_len:879 episode reward: total was -605.800000. running mean: -401.665753\n",
      "startIDX:  236\n",
      "134 22 False\n",
      "x_t:  2 [0.66875    0.4125     0.090625   0.24583333]\n",
      "Q values:  tensor([[-30.2322, -32.3168, -26.8987, -28.5352, -29.0571, -31.0165]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2303 318 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 134: ep_len:318 episode reward: total was -233.500000. running mean: -399.984096\n",
      "startIDX:  1162\n",
      "135 0 False\n",
      "x_t:  2 [0.7625     0.40416667 0.053125   0.2875    ]\n",
      "Q values:  tensor([[-28.0537, -27.6242, -27.0981, -29.8382, -28.3504, -28.8106]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12640 311 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  553\n",
      "135 1 False\n",
      "x_t:  1 [0.75       0.275      0.16875    0.45416667]\n",
      "Q values:  tensor([[-26.3314, -25.1670, -25.6317, -25.3296, -26.5124, -25.2629]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30691 740 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  99\n",
      "135 5 False\n",
      "x_t:  2 [0.003125   0.39583333 0.1        0.40416667]\n",
      "Q values:  tensor([[-23.3657, -26.0748, -20.8605, -24.0736, -23.8780, -24.9012]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2051 883 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  901\n",
      "135 10 False\n",
      "x_t:  1 [0.875      0.2875     0.11875    0.34166667]\n",
      "Q values:  tensor([[-25.0357, -22.3740, -24.3492, -25.1897, -28.3632, -24.2640]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11327 1592 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  886\n",
      "135 12 False\n",
      "x_t:  1 [0.525      0.35833333 0.146875   0.5125    ]\n",
      "Q values:  tensor([[-26.2506, -23.5708, -30.6375, -24.7375, -27.5356, -25.8702]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12932 649 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  438\n",
      "135 15 True\n",
      "x_t:  0 [0.678125   0.41666667 0.115625   0.33333333]\n",
      "Q values:  tensor([[-26.3382, -29.4740, -25.7428, -26.1466, -28.5087, -28.1038]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3692 444 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1693\n",
      "135 22 True\n",
      "x_t:  3 [0.60625    0.32083333 0.128125   0.36666667]\n",
      "Q values:  tensor([[-24.4588, -28.9439, -25.1883, -27.4241, -27.2503, -24.0480]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16882 222 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  48\n",
      "136 0 False\n",
      "x_t:  1 [0.715625   0.30833333 0.109375   0.425     ]\n",
      "Q values:  tensor([[-25.4027, -22.5687, -22.6199, -23.8882, -24.0797, -24.2153]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1628 747 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 136: ep_len:747 episode reward: total was -425.200000. running mean: -404.931258\n",
      "startIDX:  433\n",
      "136 1 False\n",
      "x_t:  1 [0.859375   0.25833333 0.1375     0.46666667]\n",
      "Q values:  tensor([[-25.9661, -24.6802, -25.4542, -25.1608, -25.0403, -24.9984]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30677 795 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 136: ep_len:795 episode reward: total was -509.300000. running mean: -405.974945\n",
      "startIDX:  1\n",
      "136 5 False\n",
      "x_t:  2 [0.18125    0.3875     0.1875     0.42083333]\n",
      "Q values:  tensor([[-23.4434, -22.2676, -20.3240, -23.6491, -21.2703, -22.1989]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2073 920 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 136: ep_len:920 episode reward: total was -476.700000. running mean: -406.682196\n",
      "startIDX:  1694\n",
      "136 10 False\n",
      "x_t:  3 [0.86875    0.32916667 0.125      0.4       ]\n",
      "Q values:  tensor([[-25.1229, -25.4815, -26.5052, -24.6414, -24.6918, -25.9385]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16401 235 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 136: ep_len:235 episode reward: total was -107.700000. running mean: -403.692374\n",
      "startIDX:  1789\n",
      "136 12 False\n",
      "x_t:  0 [0.8125   0.4125   0.121875 0.35    ]\n",
      "Q values:  tensor([[-20.3885, -21.9557, -21.2716, -22.6706, -22.1834, -21.8239]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21102 599 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 136: ep_len:599 episode reward: total was -335.800000. running mean: -403.013450\n",
      "startIDX:  2576\n",
      "136 15 True\n",
      "x_t:  2 [0.090625 0.4125   0.125    0.325   ]\n",
      "Q values:  tensor([[-18.4749, -20.8178, -18.9599, -21.1149, -18.1353, -17.9538]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21487 921 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 136: ep_len:921 episode reward: total was -386.200000. running mean: -402.845315\n",
      "startIDX:  1120\n",
      "136 22 False\n",
      "x_t:  1 [0.740625   0.30833333 0.13125    0.49166667]\n",
      "Q values:  tensor([[-19.9699, -19.6667, -21.2371, -20.5112, -20.6020, -19.8273]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11928 731 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 136: ep_len:731 episode reward: total was -381.800000. running mean: -402.634862\n",
      "startIDX:  1006\n",
      "137 0 False\n",
      "x_t:  1 [0.915625   0.29166667 0.08125    0.4375    ]\n",
      "Q values:  tensor([[-18.7082, -15.7375, -16.2900, -17.8571, -16.5530, -15.8041]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11944 786 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1011\n",
      "137 1 False\n",
      "x_t:  3 [0.5625     0.27916667 0.08125    0.35833333]\n",
      "Q values:  tensor([[-21.9531, -20.1425, -20.1393, -20.0596, -20.6458, -20.3094]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35949 246 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1288\n",
      "137 5 True\n",
      "x_t:  2 [0.071875 0.4      0.125    0.275   ]\n",
      "Q values:  tensor([[-19.2971, -19.1543, -17.3247, -17.2577, -16.9578, -16.1094]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12016 700 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1887\n",
      "137 10 False\n",
      "x_t:  2 [0.003125   0.40416667 0.065625   0.24583333]\n",
      "Q values:  tensor([[-17.4262, -16.8806, -16.4067, -17.5772, -18.0995, -16.8717]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18141 801 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2019\n",
      "startIDX:  477\n",
      "137 15 False\n",
      "x_t:  1 [0.625      0.30416667 0.05625    0.275     ]\n",
      "Q values:  tensor([[-17.8174, -17.2809, -20.2901, -18.9376, -20.6571, -18.2822]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5207 751 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  611\n",
      "137 22 False\n",
      "x_t:  2 [0.253125   0.40833333 0.078125   0.25416667]\n",
      "Q values:  tensor([[-22.8315, -25.1765, -21.3761, -24.5271, -23.7236, -21.6073]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8958 951 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2108\n",
      "138 0 True\n",
      "x_t:  1 [0.85       0.30416667 0.146875   0.54166667]\n",
      "Q values:  tensor([[-30.3671, -28.4869, -29.1070, -28.8273, -26.5801, -27.6634]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22920 1147 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 138: ep_len:1147 episode reward: total was -712.100000. running mean: -399.583525\n",
      "startIDX:  72\n",
      "138 1 False\n",
      "x_t:  3 [0.08125    0.22083333 0.071875   0.275     ]\n",
      "Q values:  tensor([[-27.6642, -27.9472, -27.7630, -27.3246, -27.7455, -30.2715]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25788 227 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 138: ep_len:227 episode reward: total was -133.000000. running mean: -396.917690\n",
      "startIDX:  2504\n",
      "138 5 False\n",
      "x_t:  2 [0.015625   0.39583333 0.0625     0.2625    ]\n",
      "Q values:  tensor([[-30.7415, -28.4615, -27.7031, -28.3314, -28.8954, -29.9984]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21548 813 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 138: ep_len:813 episode reward: total was -543.200000. running mean: -398.380513\n",
      "startIDX:  1522\n",
      "138 10 False\n",
      "x_t:  3 [0.821875   0.32083333 0.128125   0.39166667]\n",
      "Q values:  tensor([[-24.8213, -26.0422, -26.2350, -24.8006, -26.8030, -25.4050]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16408 342 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 138: ep_len:342 episode reward: total was -210.700000. running mean: -396.503707\n",
      "startIDX:  128\n",
      "138 12 False\n",
      "x_t:  1 [0.825      0.30833333 0.16875    0.43333333]\n",
      "Q values:  tensor([[-25.4163, -22.0208, -24.4887, -25.4529, -24.5823, -24.8357]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2219 595 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 138: ep_len:595 episode reward: total was -446.900000. running mean: -397.007670\n",
      "startIDX:  238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 15 True\n",
      "x_t:  2 [0.13125    0.4125     0.09375    0.33333333]\n",
      "Q values:  tensor([[-31.8625, -35.6645, -31.8223, -34.9215, -34.8016, -33.1405]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2210 768 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 138: ep_len:768 episode reward: total was -561.300000. running mean: -398.650594\n",
      "startIDX:  837\n",
      "138 22 False\n",
      "x_t:  1 [0.003125   0.37083333 0.084375   0.39583333]\n",
      "Q values:  tensor([[-26.6793, -24.0789, -24.5385, -25.6513, -25.1859, -24.3343]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9480 270 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 138: ep_len:270 episode reward: total was -208.300000. running mean: -396.747088\n",
      "startIDX:  84\n",
      "139 0 False\n",
      "x_t:  1 [0.84375    0.3        0.090625   0.42916667]\n",
      "Q values:  tensor([[-32.0097, -26.9743, -29.8694, -29.0798, -31.7418, -28.9257]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1615 698 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  30\n",
      "139 1 False\n",
      "x_t:  3 [0.459375   0.25833333 0.090625   0.35833333]\n",
      "Q values:  tensor([[-21.7911, -23.2901, -20.9015, -20.4709, -23.7139, -23.2028]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25694 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1442\n",
      "139 5 False\n",
      "x_t:  0 [0.846875   0.39166667 0.103125   0.325     ]\n",
      "Q values:  tensor([[-30.3108, -33.3974, -36.4920, -31.9117, -32.7514, -31.8501]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13509 497 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2453\n",
      "139 10 False\n",
      "x_t:  1 [0.884375   0.2875     0.1125     0.33333333]\n",
      "Q values:  tensor([[-35.7542, -31.7400, -34.2705, -33.5871, -32.5976, -32.5131]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22468 1139 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1124\n",
      "139 12 False\n",
      "x_t:  3 [0.11875    0.27083333 0.0625     0.29583333]\n",
      "Q values:  tensor([[-39.4054, -43.0135, -41.9936, -38.9415, -45.3125, -41.1871]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16385 1380 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2486\n",
      "139 15 True\n",
      "x_t:  3 [0.4625     0.29166667 0.10625    0.3125    ]\n",
      "Q values:  tensor([[-31.9646, -30.4578, -31.6498, -27.5308, -35.2200, -35.1378]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19724 226 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2603\n",
      "139 22 False\n",
      "x_t:  3 [0.078125 0.2375   0.0625   0.25    ]\n",
      "Q values:  tensor([[-29.0728, -31.4878, -28.9845, -26.4863, -33.4686, -28.9218]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26180 1195 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  1153.7435092926025\n",
      "startIDX:  1682\n",
      "140 0 True\n",
      "x_t:  3 [0.253125   0.27083333 0.1        0.30416667]\n",
      "Q values:  tensor([[-32.8784, -29.3198, -32.7930, -33.1513, -32.9029, -31.2671]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16907 206 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 140: ep_len:206 episode reward: total was -145.400000. running mean: -406.381307\n",
      "startIDX:  440\n",
      "140 1 False\n",
      "x_t:  1 [0.859375   0.25833333 0.1375     0.47083333]\n",
      "Q values:  tensor([[-27.0316, -21.4043, -23.5412, -26.2959, -23.0531, -25.0553]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30678 787 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 140: ep_len:787 episode reward: total was -543.000000. running mean: -407.747494\n",
      "startIDX:  2519\n",
      "140 5 False\n",
      "x_t:  2 [0.121875   0.4        0.103125   0.26666667]\n",
      "Q values:  tensor([[-30.7748, -31.4928, -29.5295, -34.4365, -32.9317, -32.9917]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21568 824 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 140: ep_len:824 episode reward: total was -575.100000. running mean: -409.421019\n",
      "startIDX:  1827\n",
      "140 10 False\n",
      "x_t:  2 [0.01875    0.39583333 0.05625    0.25      ]\n",
      "Q values:  tensor([[-23.2681, -26.2372, -23.0003, -26.8477, -24.8186, -23.4457]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18145 845 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 140: ep_len:845 episode reward: total was -614.000000. running mean: -411.466808\n",
      "startIDX:  1755\n",
      "140 12 True\n",
      "x_t:  0 [0.696875   0.41666667 0.140625   0.34166667]\n",
      "Q values:  tensor([[-32.5238, -31.9553, -32.4429, -29.9374, -31.2840, -28.4106]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21114 631 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 140: ep_len:631 episode reward: total was -449.700000. running mean: -411.849140\n",
      "startIDX:  1431\n",
      "140 15 False\n",
      "x_t:  3 [0.215625   0.25       0.096875   0.27083333]\n",
      "Q values:  tensor([[-38.7397, -36.7747, -35.1264, -33.9661, -37.3219, -35.6843]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10460 216 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 140: ep_len:216 episode reward: total was -152.600000. running mean: -409.256649\n",
      "startIDX:  1077\n",
      "140 22 False\n",
      "x_t:  1 [0.753125   0.32083333 0.140625   0.475     ]\n",
      "Q values:  tensor([[-27.0293, -24.5979, -26.7383, -26.4813, -29.9357, -26.4603]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11926 743 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 140: ep_len:743 episode reward: total was -510.300000. running mean: -410.267082\n",
      "startIDX:  2367\n",
      "141 0 True\n",
      "x_t:  3 [0.084375   0.24166667 0.071875   0.25      ]\n",
      "Q values:  tensor([[-27.2340, -27.1228, -24.7111, -27.6173, -30.8689, -23.9279]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26099 1227 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  33\n",
      "141 1 False\n",
      "x_t:  3 [0.415625   0.2625     0.1125     0.35416667]\n",
      "Q values:  tensor([[-29.6150, -28.9925, -28.9956, -25.5596, -30.6165, -28.4045]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25701 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  718\n",
      "141 5 False\n",
      "x_t:  3 [0.14375    0.2625     0.1        0.33333333]\n",
      "Q values:  tensor([[-26.2757, -26.5811, -27.5993, -24.9661, -26.2405, -26.8547]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8771 1329 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2315\n",
      "141 10 True\n",
      "x_t:  1 [0.846875   0.275      0.078125   0.34583333]\n",
      "Q values:  tensor([[-32.2333, -32.1389, -28.2677, -30.1796, -32.0592, -27.5597]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22474 1244 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  379\n",
      "141 12 False\n",
      "x_t:  4 [0.05625    0.4375     0.13125    0.36666667]\n",
      "Q values:  tensor([[-28.7927, -31.7108, -30.0780, -29.2370, -28.0215, -31.0647]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7190 704 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1517\n",
      "141 15 False\n",
      "x_t:  2 [0.003125   0.4125     0.078125   0.25416667]\n",
      "Q values:  tensor([[-27.1199, -29.8918, -25.8716, -28.5122, -26.1756, -28.5285]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 11909 750 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  116\n",
      "141 22 False\n",
      "x_t:  1 [0.853125   0.30833333 0.140625   0.40833333]\n",
      "Q values:  tensor([[-33.3227, -27.3469, -30.2931, -32.7133, -35.5442, -29.4032]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1580 669 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1622\n",
      "142 0 False\n",
      "x_t:  3 [0.428125   0.29166667 0.0875     0.35416667]\n",
      "Q values:  tensor([[-27.9982, -27.1383, -30.7910, -26.7265, -27.1870, -29.1091]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16874 208 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 142: ep_len:208 episode reward: total was -108.700000. running mean: -420.744507\n",
      "startIDX:  136\n",
      "142 1 False\n",
      "x_t:  2 [0.003125 0.3625   0.1      0.45    ]\n",
      "Q values:  tensor([[-28.6496, -30.2607, -24.5877, -30.5102, -28.6638, -27.5291]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27431 893 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 142: ep_len:893 episode reward: total was -545.200000. running mean: -421.989061\n",
      "startIDX:  1918\n",
      "142 5 True\n",
      "x_t:  2 [0.84375    0.40416667 0.071875   0.25416667]\n",
      "Q values:  tensor([[-19.8115, -21.7027, -24.3155, -21.5720, -24.3771, -22.5285]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15642 299 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 142: ep_len:299 episode reward: total was -203.500000. running mean: -419.804171\n",
      "startIDX:  2555\n",
      "ep 142: ep_len:40 episode reward: total was -32.900000. running mean: -415.935129\n",
      "startIDX:  547\n",
      "142 12 True\n",
      "x_t:  2 [0.159375   0.42083333 0.096875   0.25416667]\n",
      "Q values:  tensor([[-27.6816, -27.1882, -27.9187, -29.0600, -31.3767, -25.5874]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9852 1043 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 142: ep_len:1043 episode reward: total was -670.100000. running mean: -418.476778\n",
      "startIDX:  1803\n",
      "142 15 True\n",
      "x_t:  0 [0.765625 0.4      0.109375 0.3375  ]\n",
      "Q values:  tensor([[-23.3800, -24.6275, -26.9009, -26.2923, -23.7426, -23.6474]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13384 448 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 142: ep_len:448 episode reward: total was -297.800000. running mean: -417.270010\n",
      "startIDX:  1305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142 22 False\n",
      "x_t:  3 [0.190625   0.26666667 0.078125   0.29166667]\n",
      "Q values:  tensor([[-30.2876, -30.0591, -32.0202, -28.4108, -30.3246, -28.9064]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15233 1330 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 142: ep_len:1330 episode reward: total was -927.200000. running mean: -422.369310\n",
      "startIDX:  1158\n",
      "143 0 False\n",
      "x_t:  2 [0.7625     0.40416667 0.078125   0.2875    ]\n",
      "Q values:  tensor([[-22.2392, -25.5285, -20.7957, -21.6811, -23.5645, -22.8006]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12638 315 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1149\n",
      "startIDX:  726\n",
      "143 5 False\n",
      "x_t:  3 [0.121875   0.26666667 0.071875   0.30833333]\n",
      "Q values:  tensor([[-41.2398, -40.6768, -37.5647, -35.8630, -37.6443, -37.2309]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8766 1318 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  803\n",
      "143 10 True\n",
      "x_t:  1 [0.584375   0.3        0.09375    0.33333333]\n",
      "Q values:  tensor([[-29.7442, -29.9804, -26.5457, -31.8898, -30.4586, -28.7061]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7172 220 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1967\n",
      "startIDX:  818\n",
      "143 15 False\n",
      "x_t:  3 [0.1      0.2375   0.053125 0.2375  ]\n",
      "Q values:  tensor([[-25.2213, -25.9744, -23.6321, -23.0175, -25.8870, -24.3595]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8511 1278 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2998\n",
      "startIDX:  676\n",
      "144 0 False\n",
      "x_t:  2 [0.0625     0.40833333 0.078125   0.27083333]\n",
      "Q values:  tensor([[-30.0215, -31.0614, -26.4721, -30.0557, -27.2314, -27.3877]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8880 907 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 144: ep_len:907 episode reward: total was -612.600000. running mean: -416.674435\n",
      "startIDX:  1059\n",
      "144 1 False\n",
      "x_t:  3 [0.840625   0.3        0.153125   0.42916667]\n",
      "Q values:  tensor([[-25.3798, -26.2046, -25.6085, -22.7403, -26.3929, -25.0270]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35896 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 144: ep_len:200 episode reward: total was -104.000000. running mean: -413.547690\n",
      "startIDX:  456\n",
      "144 5 False\n",
      "x_t:  1 [0.884375   0.26666667 0.109375   0.4       ]\n",
      "Q values:  tensor([[-32.7958, -28.6897, -32.2165, -30.7101, -31.5155, -32.1183]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5024 657 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 144: ep_len:657 episode reward: total was -476.100000. running mean: -414.173213\n",
      "startIDX:  771\n",
      "144 10 False\n",
      "x_t:  1 [0.025      0.35       0.115625   0.37083333]\n",
      "Q values:  tensor([[-34.6308, -31.3009, -31.8999, -33.8822, -32.8476, -32.6929]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7109 212 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 144: ep_len:212 episode reward: total was -142.200000. running mean: -411.453481\n",
      "startIDX:  2059\n",
      "ep 144: ep_len:5 episode reward: total was -3.000000. running mean: -407.368946\n",
      "startIDX:  1269\n",
      "144 15 False\n",
      "x_t:  3 [0.896875   0.34583333 0.1        0.39166667]\n",
      "Q values:  tensor([[-27.7216, -30.4169, -29.2728, -26.2847, -30.4809, -28.2018]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10335 234 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 144: ep_len:234 episode reward: total was -103.100000. running mean: -404.326257\n",
      "startIDX:  1515\n",
      "144 22 False\n",
      "x_t:  4 [0.053125   0.39583333 0.1125     0.2875    ]\n",
      "Q values:  tensor([[-27.7048, -25.9643, -26.1216, -26.2494, -24.2571, -24.8277]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16332 526 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 144: ep_len:526 episode reward: total was -324.400000. running mean: -403.526994\n",
      "startIDX:  8\n",
      "145 0 True\n",
      "x_t:  1 [0.721875   0.3125     0.16875    0.41666667]\n",
      "Q values:  tensor([[-25.8790, -28.5982, -25.0892, -28.7292, -29.4680, -26.1700]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1624 739 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  533\n",
      "145 1 False\n",
      "x_t:  1 [0.596875   0.28333333 0.09375    0.47083333]\n",
      "Q values:  tensor([[-25.1522, -22.7202, -24.2219, -24.9944, -25.0777, -22.9223]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30712 761 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  635\n",
      "145 5 True\n",
      "x_t:  3 [0.09375    0.26666667 0.084375   0.31666667]\n",
      "Q values:  tensor([[-24.2739, -25.0115, -25.6613, -25.4273, -25.5513, -24.1433]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8758 1348 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2504\n",
      "145 10 False\n",
      "x_t:  1 [0.671875   0.3        0.125      0.32083333]\n",
      "Q values:  tensor([[-26.0466, -23.2116, -24.0270, -24.3932, -27.4876, -24.9652]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22492 1153 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  853\n",
      "145 12 False\n",
      "x_t:  1 [0.765625   0.35       0.15       0.52083333]\n",
      "Q values:  tensor([[-29.3237, -25.2394, -28.5380, -26.7861, -25.3520, -27.1576]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12920 640 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  907\n",
      "145 15 False\n",
      "x_t:  3 [0.103125   0.23333333 0.059375   0.24166667]\n",
      "Q values:  tensor([[-30.9652, -34.4607, -36.3702, -30.8492, -32.7293, -31.8020]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8514 1191 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  74\n",
      "145 22 True\n",
      "x_t:  1 [0.7125   0.3125   0.134375 0.4     ]\n",
      "Q values:  tensor([[-27.9756, -28.6900, -29.3309, -29.9987, -27.2140, -26.5059]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1595 688 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1790\n",
      "146 0 False\n",
      "x_t:  2 [0.003125   0.40833333 0.103125   0.25      ]\n",
      "Q values:  tensor([[-33.2022, -36.2644, -32.0024, -35.6142, -32.1675, -33.3396]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18392 743 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 146: ep_len:743 episode reward: total was -473.200000. running mean: -420.167118\n",
      "startIDX:  659\n",
      "146 1 False\n",
      "x_t:  2 [0.815625   0.38333333 0.103125   0.31666667]\n",
      "Q values:  tensor([[-30.6339, -31.5906, -28.1794, -29.1288, -30.0877, -29.4742]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31460 357 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 146: ep_len:357 episode reward: total was -237.300000. running mean: -418.338447\n",
      "startIDX:  129\n",
      "146 5 True\n",
      "x_t:  2 [0.096875   0.37916667 0.15       0.42916667]\n",
      "Q values:  tensor([[-26.9480, -28.1615, -26.0702, -27.1032, -25.4646, -24.4211]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2063 866 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 146: ep_len:866 episode reward: total was -553.200000. running mean: -419.687062\n",
      "startIDX:  1039\n",
      "146 10 False\n",
      "x_t:  1 [0.8625     0.28333333 0.128125   0.3375    ]\n",
      "Q values:  tensor([[-23.4267, -20.6502, -21.8609, -20.7151, -21.8667, -23.8698]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11328 1515 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 146: ep_len:1515 episode reward: total was -1018.800000. running mean: -425.678192\n",
      "startIDX:  1024\n",
      "146 12 False\n",
      "x_t:  2 [0.884375   0.39166667 0.078125   0.19583333]\n",
      "Q values:  tensor([[-25.6293, -25.6960, -24.2377, -24.3942, -26.5257, -25.3619]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13564 306 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 146: ep_len:306 episode reward: total was -204.700000. running mean: -423.468410\n",
      "startIDX:  2698\n",
      "146 15 False\n",
      "x_t:  2 [0.003125   0.4125     0.1125     0.32916667]\n",
      "Q values:  tensor([[-25.8162, -25.6212, -23.2471, -26.5636, -26.2637, -24.1229]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21473 844 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 146: ep_len:844 episode reward: total was -488.700000. running mean: -424.120726\n",
      "startIDX:  588\n",
      "146 22 False\n",
      "x_t:  3 [0.771875   0.34583333 0.153125   0.38333333]\n",
      "Q values:  tensor([[-25.2826, -27.3735, -27.9816, -24.7992, -25.3503, -25.2934]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7061 210 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 146: ep_len:210 episode reward: total was -143.200000. running mean: -421.311519\n",
      "startIDX:  2214\n",
      "147 0 True\n",
      "x_t:  1 [0.8375 0.3125 0.1375 0.525 ]\n",
      "Q values:  tensor([[-31.6242, -32.0583, -30.7224, -29.0853, -32.1217, -28.4988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22921 1096 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  659\n",
      "147 1 False\n",
      "x_t:  2 [0.796875   0.37916667 0.075      0.30416667]\n",
      "Q values:  tensor([[-29.8754, -28.4769, -24.5687, -27.7970, -26.5697, -25.2646]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31467 345 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2244\n",
      "147 5 False\n",
      "x_t:  3 [0.45625    0.29583333 0.153125   0.37916667]\n",
      "Q values:  tensor([[-27.0023, -29.7317, -30.1567, -25.0335, -27.9192, -28.9219]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19929 213 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  505\n",
      "147 10 True\n",
      "x_t:  2 [0.1625     0.39583333 0.059375   0.27083333]\n",
      "Q values:  tensor([[-23.2494, -20.4256, -25.2924, -25.4061, -25.7167, -21.6732]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6609 785 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  441\n",
      "147 12 False\n",
      "x_t:  3 [0.796875   0.35833333 0.16875    0.4125    ]\n",
      "Q values:  tensor([[-23.6380, -25.0031, -23.8415, -23.2212, -26.6062, -25.5316]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7717 237 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  123\n",
      "147 15 False\n",
      "x_t:  2 [0.00625    0.40416667 0.109375   0.33333333]\n",
      "Q values:  tensor([[-21.2120, -23.2796, -20.2806, -23.8690, -21.1604, -21.5940]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2194 851 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1332\n",
      "147 22 True\n",
      "x_t:  3 [0.1        0.25416667 0.05625    0.275     ]\n",
      "Q values:  tensor([[-20.0548, -19.9036, -21.9983, -18.5029, -22.3629, -20.4355]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15206 1302 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  475\n",
      "148 0 False\n",
      "x_t:  3 [0.81875    0.39166667 0.171875   0.42916667]\n",
      "Q values:  tensor([[-25.6995, -28.5943, -25.4454, -22.5147, -26.2453, -23.9033]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 6993 1038 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 148: ep_len:1038 episode reward: total was -618.800000. running mean: -421.915578\n",
      "startIDX:  533\n",
      "148 1 False\n",
      "x_t:  1 [0.60625    0.27916667 0.10625    0.475     ]\n",
      "Q values:  tensor([[-22.8476, -21.7834, -23.1833, -22.6198, -22.0921, -23.3405]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30711 751 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 148: ep_len:751 episode reward: total was -495.400000. running mean: -422.650422\n",
      "startIDX:  1031\n",
      "148 5 False\n",
      "x_t:  3 [0.453125   0.29583333 0.125      0.31666667]\n",
      "Q values:  tensor([[-24.2190, -25.8353, -25.6125, -22.1836, -28.1725, -24.5242]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10535 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 148: ep_len:201 episode reward: total was -57.200000. running mean: -418.995918\n",
      "startIDX:  499\n",
      "148 10 True\n",
      "x_t:  3 [0.071875   0.22083333 0.0625     0.25      ]\n",
      "Q values:  tensor([[-13.5752, -15.5775, -16.6737, -16.7162, -14.3889, -17.0751]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5185 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 148: ep_len:200 episode reward: total was -114.700000. running mean: -415.952959\n",
      "startIDX:  544\n",
      "148 12 False\n",
      "x_t:  2 [0.065625   0.4125     0.05625    0.25416667]\n",
      "Q values:  tensor([[-35.6935, -36.1631, -31.8510, -37.6869, -36.2174, -34.1317]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9836 1063 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 148: ep_len:1063 episode reward: total was -699.100000. running mean: -418.784429\n",
      "startIDX:  1906\n",
      "148 15 False\n",
      "x_t:  1 [0.728125   0.3        0.09375    0.30833333]\n",
      "Q values:  tensor([[-29.3100, -24.4533, -25.4540, -29.5754, -30.9192, -27.5814]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14861 718 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 148: ep_len:718 episode reward: total was -515.400000. running mean: -419.750585\n",
      "startIDX:  208\n",
      "148 22 False\n",
      "x_t:  2 [0.83125    0.40833333 0.075      0.24166667]\n",
      "Q values:  tensor([[-31.0417, -31.3858, -25.6842, -26.6953, -31.4469, -26.2196]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2274 323 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 148: ep_len:323 episode reward: total was -246.100000. running mean: -418.014079\n",
      "startIDX:  996\n",
      "149 0 True\n",
      "x_t:  1 [0.85       0.30416667 0.13125    0.42916667]\n",
      "Q values:  tensor([[-38.3888, -34.9503, -34.2265, -34.5974, -34.8328, -32.1942]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11947 781 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  911\n",
      "149 1 True\n",
      "x_t:  4 [0.078125   0.3875     0.153125   0.41666667]\n",
      "Q values:  tensor([[-35.6946, -32.7484, -33.4718, -33.5727, -34.0804, -32.9311]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35435 512 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2347\n",
      "149 5 False\n",
      "x_t:  3 [0.1375     0.25       0.084375   0.29166667]\n",
      "Q values:  tensor([[-19.8134, -22.1731, -22.6809, -17.8867, -24.4192, -20.9270]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19995 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  109\n",
      "149 10 False\n",
      "x_t:  3 [0.0625     0.24166667 0.059375   0.24583333]\n",
      "Q values:  tensor([[-32.9363, -29.6686, -32.6218, -29.3012, -31.0811, -32.0879]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3578 1066 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  606\n",
      "149 12 True\n",
      "x_t:  2 [0.003125   0.41666667 0.078125   0.24583333]\n",
      "Q values:  tensor([[-33.6370, -29.4878, -30.1717, -31.2590, -32.9133, -33.4204]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9825 1007 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2950\n",
      "149 15 False\n",
      "x_t:  0 [0.925   0.4     0.06875 0.35   ]\n",
      "Q values:  tensor([[-25.8778, -27.7529, -29.7737, -26.8866, -29.3181, -28.7356]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23069 482 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  911\n",
      "149 22 True\n",
      "x_t:  1 [0.153125   0.35416667 0.15625    0.40416667]\n",
      "Q values:  tensor([[-31.6643, -31.4360, -28.2099, -28.2148, -30.5478, -31.1150]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9499 240 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  1247.8662118911743\n",
      "startIDX:  1854\n",
      "150 0 False\n",
      "x_t:  2 [0.003125   0.4125     0.04375    0.24583333]\n",
      "Q values:  tensor([[-28.9309, -31.1933, -28.0760, -31.1126, -29.7451, -30.3240]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18389 719 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 150: ep_len:719 episode reward: total was -528.000000. running mean: -419.850478\n",
      "startIDX:  734\n",
      "150 1 False\n",
      "x_t:  3 [0.10625    0.22916667 0.075      0.30416667]\n",
      "Q values:  tensor([[-34.6916, -36.5714, -34.1237, -33.5573, -36.6777, -35.8239]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34317 1395 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 150: ep_len:1395 episode reward: total was -1025.900000. running mean: -425.910973\n",
      "startIDX:  494\n",
      "150 5 True\n",
      "x_t:  1 [0.884375   0.26666667 0.109375   0.4       ]\n",
      "Q values:  tensor([[-24.7454, -28.5415, -30.2059, -30.8251, -28.2148, -26.5111]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5024 636 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 150: ep_len:636 episode reward: total was -471.400000. running mean: -426.365864\n",
      "startIDX:  2507\n",
      "150 10 False\n",
      "x_t:  1 [0.896875   0.28333333 0.1        0.3375    ]\n",
      "Q values:  tensor([[-30.7407, -29.9461, -30.6897, -32.5244, -34.9782, -31.4486]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22465 1134 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 150: ep_len:1134 episode reward: total was -781.200000. running mean: -429.914205\n",
      "startIDX:  1986\n",
      "ep 150: ep_len:57 episode reward: total was -21.900000. running mean: -425.834063\n",
      "startIDX:  1724\n",
      "150 15 False\n",
      "x_t:  1 [0.246875   0.35       0.134375   0.37916667]\n",
      "Q values:  tensor([[-32.9086, -26.0073, -31.1342, -32.2925, -33.5811, -28.9559]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12472 232 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 150: ep_len:232 episode reward: total was -168.600000. running mean: -423.261722\n",
      "startIDX:  1883\n",
      "150 22 False\n",
      "x_t:  2 [0.075      0.40416667 0.05       0.27083333]\n",
      "Q values:  tensor([[-26.6011, -24.4226, -23.6529, -27.2644, -25.7076, -25.4125]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18465 759 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 150: ep_len:759 episode reward: total was -453.500000. running mean: -423.564105\n",
      "startIDX:  1307\n",
      "151 0 False\n",
      "x_t:  3 [0.103125   0.25       0.0625     0.26666667]\n",
      "Q values:  tensor([[-28.2955, -30.1042, -29.3141, -28.1059, -28.5148, -28.2610]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15171 1213 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  884\n",
      "151 1 False\n",
      "x_t:  4 [0.0125     0.39583333 0.109375   0.4       ]\n",
      "Q values:  tensor([[-28.0924, -27.0509, -26.4648, -27.6749, -25.5168, -26.8420]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35425 534 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  579\n",
      "151 5 False\n",
      "x_t:  2 [0.7625     0.40416667 0.103125   0.2875    ]\n",
      "Q values:  tensor([[-23.1291, -24.5091, -20.3390, -22.1983, -22.6865, -21.0521]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6042 463 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  8\n",
      "151 10 True\n",
      "x_t:  3 [0.0625     0.23333333 0.0625     0.25416667]\n",
      "Q values:  tensor([[-23.3705, -21.6278, -21.6937, -21.7000, -24.1678, -20.4854]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3581 1103 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  58\n",
      "151 12 False\n",
      "x_t:  1 [0.7     0.325   0.14375 0.425  ]\n",
      "Q values:  tensor([[-22.5864, -21.4314, -24.2293, -24.1626, -22.1314, -23.7306]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2230 632 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1266\n",
      "151 15 True\n",
      "x_t:  3 [0.75       0.33333333 0.13125    0.375     ]\n",
      "Q values:  tensor([[-27.5342, -24.5231, -24.3664, -25.0938, -27.9460, -24.3935]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10352 247 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151 22 False\n",
      "x_t:  4 [0.075      0.3875     0.08125    0.33333333]\n",
      "Q values:  tensor([[-27.0720, -27.6710, -25.5894, -28.5513, -24.6467, -26.3563]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27273 493 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2417\n",
      "152 0 True\n",
      "x_t:  3 [0.0625     0.23333333 0.05625    0.2375    ]\n",
      "Q values:  tensor([[-28.3106, -25.5238, -23.9181, -26.1387, -27.9293, -24.1672]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26091 1199 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 152: ep_len:1199 episode reward: total was -733.000000. running mean: -425.035353\n",
      "startIDX:  420\n",
      "152 1 True\n",
      "x_t:  0 [0.934375   0.37083333 0.059375   0.40833333]\n",
      "Q values:  tensor([[-24.5936, -27.2412, -23.7959, -23.5444, -25.8225, -24.6254]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29088 473 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 152: ep_len:473 episode reward: total was -331.300000. running mean: -424.098000\n",
      "startIDX:  1809\n",
      "152 5 True\n",
      "x_t:  2 [0.8125     0.4        0.075      0.25833333]\n",
      "Q values:  tensor([[-30.7441, -27.9968, -32.2911, -28.9296, -30.0083, -30.2728]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15649 354 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 152: ep_len:354 episode reward: total was -234.700000. running mean: -422.204020\n",
      "startIDX:  1623\n",
      "152 10 False\n",
      "x_t:  3 [0.640625   0.3        0.13125    0.36666667]\n",
      "Q values:  tensor([[-24.0991, -24.4838, -24.5700, -21.3847, -27.0316, -24.1384]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16430 298 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 152: ep_len:298 episode reward: total was -115.300000. running mean: -419.134979\n",
      "startIDX:  91\n",
      "152 12 False\n",
      "x_t:  1 [0.825      0.30833333 0.146875   0.42916667]\n",
      "Q values:  tensor([[-23.4909, -22.7915, -23.6447, -25.4107, -25.4190, -24.6397]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2220 621 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 152: ep_len:621 episode reward: total was -443.300000. running mean: -419.376630\n",
      "startIDX:  1374\n",
      "152 15 False\n",
      "x_t:  3 [0.6625     0.3125     0.075      0.35416667]\n",
      "Q values:  tensor([[-19.8220, -20.4643, -23.9545, -18.5140, -19.7969, -23.0753]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10370 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 152: ep_len:203 episode reward: total was -110.600000. running mean: -416.288863\n",
      "startIDX:  112\n",
      "152 22 False\n",
      "x_t:  1 [0.934375   0.2875     0.0625     0.41666667]\n",
      "Q values:  tensor([[-29.2219, -25.9235, -29.0598, -26.3344, -30.5636, -28.9093]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1575 661 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 152: ep_len:661 episode reward: total was -434.100000. running mean: -416.466975\n",
      "startIDX:  258\n",
      "153 0 True\n",
      "x_t:  3 [0.078125   0.23333333 0.059375   0.2375    ]\n",
      "Q values:  tensor([[-27.8042, -26.5038, -25.7135, -27.9858, -24.5728, -27.6757]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4840 1266 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  861\n",
      "153 1 False\n",
      "x_t:  4 [0.153125   0.375      0.090625   0.41666667]\n",
      "Q values:  tensor([[-28.7122, -27.8851, -27.0293, -26.5390, -26.1830, -26.4344]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35444 560 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  267\n",
      "153 5 False\n",
      "x_t:  0 [0.7125     0.39583333 0.1375     0.375     ]\n",
      "Q values:  tensor([[-26.7107, -26.8221, -27.0310, -28.1997, -27.6843, -27.4454]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3575 532 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1694\n",
      "153 10 False\n",
      "x_t:  3 [0.81875 0.3125  0.1125  0.4    ]\n",
      "Q values:  tensor([[-27.7416, -24.1937, -27.7698, -23.4833, -26.9881, -27.1429]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16409 252 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  426\n",
      "153 12 False\n",
      "x_t:  3 [0.68125    0.32916667 0.075      0.37916667]\n",
      "Q values:  tensor([[-24.9007, -23.8073, -23.5148, -23.2866, -26.2195, -23.4812]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7735 262 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  737\n",
      "153 15 False\n",
      "x_t:  2 [0.728125   0.40416667 0.0875     0.29583333]\n",
      "Q values:  tensor([[-27.5162, -28.7711, -25.8300, -31.5943, -30.1690, -26.1957]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5980 370 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1608\n",
      "153 22 False\n",
      "x_t:  3 [0.790625   0.34166667 0.125      0.4125    ]\n",
      "Q values:  tensor([[-32.9952, -28.5316, -31.2680, -28.1731, -28.8687, -28.6226]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16855 251 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  150\n",
      "154 0 False\n",
      "x_t:  1 [0.86875    0.3        0.128125   0.42916667]\n",
      "Q values:  tensor([[-30.0956, -27.2582, -30.4567, -30.0177, -31.6958, -31.8221]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1607 680 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 154: ep_len:680 episode reward: total was -538.700000. running mean: -412.160769\n",
      "startIDX:  684\n",
      "154 1 False\n",
      "x_t:  3 [0.18125    0.24583333 0.09375    0.31666667]\n",
      "Q values:  tensor([[-32.6819, -35.3006, -31.9740, -30.9659, -33.8305, -33.0306]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34342 1447 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 154: ep_len:1447 episode reward: total was -1152.000000. running mean: -419.559161\n",
      "startIDX:  719\n",
      "154 5 False\n",
      "x_t:  3 [0.08125    0.2625     0.090625   0.31666667]\n",
      "Q values:  tensor([[-32.6524, -30.4176, -29.7643, -27.8671, -31.2161, -28.7525]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8754 1319 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 154: ep_len:1319 episode reward: total was -1031.600000. running mean: -425.679569\n",
      "startIDX:  608\n",
      "154 10 False\n",
      "x_t:  2 [0.003125   0.40833333 0.115625   0.2625    ]\n",
      "Q values:  tensor([[-30.3402, -28.4596, -28.2810, -30.1839, -32.3025, -28.5396]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6589 729 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 154: ep_len:729 episode reward: total was -553.500000. running mean: -426.957774\n",
      "startIDX:  454\n",
      "154 12 False\n",
      "x_t:  3 [0.9125     0.36666667 0.084375   0.425     ]\n",
      "Q values:  tensor([[-29.2807, -27.3399, -29.3804, -23.3659, -28.0939, -26.1447]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7709 231 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 154: ep_len:231 episode reward: total was -127.100000. running mean: -423.959196\n",
      "startIDX:  2690\n",
      "154 15 True\n",
      "x_t:  2 [0.196875   0.40833333 0.125      0.32916667]\n",
      "Q values:  tensor([[-31.2204, -31.1296, -30.9668, -30.8269, -32.6269, -29.5132]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21502 877 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 154: ep_len:877 episode reward: total was -680.400000. running mean: -426.523604\n",
      "startIDX:  943\n",
      "154 22 False\n",
      "x_t:  1 [0.25625    0.3375     0.109375   0.40416667]\n",
      "Q values:  tensor([[-35.0807, -31.6069, -33.6583, -33.7433, -35.4520, -34.6127]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9509 239 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 154: ep_len:239 episode reward: total was -185.900000. running mean: -424.117368\n",
      "startIDX:  1536\n",
      "155 0 False\n",
      "x_t:  3 [0.715625   0.33333333 0.14375    0.4125    ]\n",
      "Q values:  tensor([[-34.1459, -37.4078, -37.7668, -33.6025, -36.8181, -36.8929]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16827 239 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  914\n",
      "155 1 False\n",
      "x_t:  4 [0.003125   0.39583333 0.11875    0.4       ]\n",
      "Q values:  tensor([[-38.2447, -38.9232, -39.4434, -36.2054, -36.1692, -37.4573]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35422 508 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2241\n",
      "155 5 False\n",
      "x_t:  3 [0.625      0.31666667 0.15625    0.42083333]\n",
      "Q values:  tensor([[-27.3333, -27.5181, -27.3820, -24.5935, -27.8521, -28.3092]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19906 207 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2405\n",
      "155 10 False\n",
      "x_t:  1 [0.89375    0.27916667 0.103125   0.34166667]\n",
      "Q values:  tensor([[-29.3299, -24.1883, -28.0618, -24.6459, -28.2224, -28.5076]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22466 1219 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1902\n",
      "155 12 False\n",
      "x_t:  0 [0.421875   0.41666667 0.109375   0.37083333]\n",
      "Q values:  tensor([[-26.5052, -31.5817, -28.6094, -32.0451, -27.3117, -26.7387]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23020 941 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2493\n",
      "155 15 False\n",
      "x_t:  3 [0.571875 0.3      0.08125  0.3375  ]\n",
      "Q values:  tensor([[-24.0609, -24.2148, -23.8743, -22.1031, -24.0307, -23.0773]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19705 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2762\n",
      "155 22 False\n",
      "x_t:  4 [0.015625   0.40833333 0.109375   0.30416667]\n",
      "Q values:  tensor([[-27.4793, -27.1599, -26.0434, -28.5793, -24.6570, -24.9538]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27268 479 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156 0 False\n",
      "x_t:  3 [0.0625     0.23333333 0.065625   0.22916667]\n",
      "Q values:  tensor([[-18.8251, -19.9348, -18.4555, -17.6586, -18.2789, -17.9621]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4834 1261 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 156: ep_len:1261 episode reward: total was -677.200000. running mean: -419.104302\n",
      "startIDX:  540\n",
      "156 1 True\n",
      "x_t:  1 [0.853125   0.26666667 0.14375    0.4625    ]\n",
      "Q values:  tensor([[-21.8482, -20.4394, -21.2775, -21.3212, -20.2304, -20.0731]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30681 740 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 156: ep_len:740 episode reward: total was -370.000000. running mean: -418.613259\n",
      "startIDX:  1015\n",
      "156 5 False\n",
      "x_t:  3 [0.521875   0.28333333 0.078125   0.3375    ]\n",
      "Q values:  tensor([[-34.3867, -32.9664, -32.2883, -31.5644, -33.9489, -33.2131]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10528 210 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 156: ep_len:210 episode reward: total was -27.900000. running mean: -414.706126\n",
      "startIDX:  1372\n",
      "156 10 False\n",
      "x_t:  4 [0.003125   0.36666667 0.075      0.2875    ]\n",
      "Q values:  tensor([[-23.7636, -23.4543, -23.7020, -23.2140, -19.9887, -21.4908]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15702 547 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 156: ep_len:547 episode reward: total was -282.800000. running mean: -413.387065\n",
      "startIDX:  845\n",
      "156 12 False\n",
      "x_t:  0 [0.88125    0.40833333 0.053125   0.3       ]\n",
      "Q values:  tensor([[-18.9747, -20.4879, -21.2204, -20.4444, -19.7395, -19.6395]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11641 633 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 156: ep_len:633 episode reward: total was -337.300000. running mean: -412.626195\n",
      "startIDX:  2254\n",
      "156 15 False\n",
      "x_t:  3 [0.090625   0.27083333 0.0625     0.30416667]\n",
      "Q values:  tensor([[-18.2160, -18.6907, -19.5371, -17.3285, -18.5144, -17.6525]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18178 1290 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 156: ep_len:1290 episode reward: total was -689.500000. running mean: -415.394933\n",
      "startIDX:  1538\n",
      "156 22 False\n",
      "x_t:  4 [0.0375     0.39166667 0.090625   0.30416667]\n",
      "Q values:  tensor([[-21.8845, -23.6237, -24.0238, -22.4730, -21.7093, -22.0796]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16329 507 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 156: ep_len:507 episode reward: total was -291.900000. running mean: -414.159983\n",
      "startIDX:  1534\n",
      "157 0 False\n",
      "x_t:  3 [0.68125    0.33333333 0.11875    0.375     ]\n",
      "Q values:  tensor([[-24.0478, -23.9411, -22.2281, -20.2997, -22.0677, -22.1051]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16834 240 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  531\n",
      "157 1 False\n",
      "x_t:  1 [0.003125   0.32916667 0.11875    0.54166667]\n",
      "Q values:  tensor([[-21.2826, -19.9540, -22.1625, -20.7042, -22.4375, -21.0076]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30768 772 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  891\n",
      "157 5 True\n",
      "x_t:  4 [0.009375 0.4125   0.140625 0.375   ]\n",
      "Q values:  tensor([[-22.8985, -26.2927, -24.0346, -25.5377, -23.3979, -23.3673]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10013 570 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1239\n",
      "157 10 False\n",
      "x_t:  3 [0.09375    0.225      0.059375   0.24583333]\n",
      "Q values:  tensor([[-24.1111, -24.4136, -24.3671, -20.9006, -24.7561, -21.0426]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14584 1253 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1393\n",
      "157 12 False\n",
      "x_t:  3 [0.546875   0.3125     0.10625    0.39166667]\n",
      "Q values:  tensor([[-26.1557, -26.1532, -26.8376, -25.1320, -27.9163, -26.8933]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17880 207 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2584\n",
      "157 15 True\n",
      "x_t:  2 [0.38125    0.40833333 0.115625   0.32916667]\n",
      "Q values:  tensor([[-25.5944, -26.1780, -25.0660, -23.6900, -23.6469, -23.2895]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21524 909 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2172\n",
      "157 22 False\n",
      "x_t:  0 [0.903125   0.4        0.08125    0.33333333]\n",
      "Q values:  tensor([[-22.8225, -24.0223, -24.0317, -27.5512, -27.0801, -24.1602]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20692 820 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1556\n",
      "158 0 False\n",
      "x_t:  3 [0.734375   0.32916667 0.125      0.4125    ]\n",
      "Q values:  tensor([[-23.4215, -22.4878, -22.2982, -19.7440, -22.9751, -20.0574]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16826 229 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 158: ep_len:229 episode reward: total was -56.600000. running mean: -408.153439\n",
      "startIDX:  939\n",
      "158 1 False\n",
      "x_t:  4 [0.01875    0.38333333 0.10625    0.41666667]\n",
      "Q values:  tensor([[-21.4282, -22.4592, -20.9641, -21.0795, -19.1513, -19.9311]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35426 497 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 158: ep_len:497 episode reward: total was -300.900000. running mean: -407.080905\n",
      "startIDX:  1587\n",
      "158 5 False\n",
      "x_t:  1 [0.828125   0.28333333 0.109375   0.32083333]\n",
      "Q values:  tensor([[-25.6228, -25.3372, -26.1399, -26.4451, -27.5935, -26.0382]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14927 685 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 158: ep_len:685 episode reward: total was -446.600000. running mean: -407.476096\n",
      "startIDX:  2158\n",
      "158 10 False\n",
      "x_t:  0 [0.875      0.39166667 0.09375    0.3625    ]\n",
      "Q values:  tensor([[-18.8867, -19.7385, -20.8788, -19.8893, -22.2114, -19.8004]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19935 541 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 158: ep_len:541 episode reward: total was -369.500000. running mean: -407.096335\n",
      "startIDX:  1266\n",
      "158 12 False\n",
      "x_t:  4 [0.33125    0.39583333 0.08125    0.32916667]\n",
      "Q values:  tensor([[-26.1735, -24.8082, -24.8028, -27.3497, -24.3636, -24.7607]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17430 491 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 158: ep_len:491 episode reward: total was -320.100000. running mean: -406.226371\n",
      "startIDX:  2151\n",
      "158 15 False\n",
      "x_t:  2 [0.840625   0.39166667 0.090625   0.25416667]\n",
      "Q values:  tensor([[-29.1040, -30.0134, -26.5781, -29.7992, -30.2488, -27.0150]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15560 327 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 158: ep_len:327 episode reward: total was -235.400000. running mean: -404.518108\n",
      "startIDX:  240\n",
      "158 22 False\n",
      "x_t:  2 [0.671875   0.40416667 0.103125   0.25      ]\n",
      "Q values:  tensor([[-26.7181, -26.8155, -25.2747, -28.3965, -27.3628, -27.0250]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2300 313 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 158: ep_len:313 episode reward: total was -247.200000. running mean: -402.944927\n",
      "startIDX:  1670\n",
      "159 0 False\n",
      "x_t:  3 [0.29375    0.2875     0.10625    0.30833333]\n",
      "Q values:  tensor([[-24.7028, -21.8545, -22.6413, -21.0597, -25.3441, -22.8628]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16897 205 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  522\n",
      "159 1 False\n",
      "x_t:  1 [0.85625    0.26666667 0.140625   0.4625    ]\n",
      "Q values:  tensor([[-33.5600, -29.6912, -32.5522, -32.2274, -35.8771, -30.5750]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30679 744 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1804\n",
      "159 5 False\n",
      "x_t:  2 [0.68125    0.39166667 0.075      0.25416667]\n",
      "Q values:  tensor([[-35.2317, -33.5827, -32.9979, -34.8893, -35.6390, -34.9334]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15669 376 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1929\n",
      "159 10 True\n",
      "x_t:  2 [0.2        0.40416667 0.103125   0.24583333]\n",
      "Q values:  tensor([[-23.7993, -25.7488, -24.8768, -26.8037, -26.4096, -27.5528]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18181 794 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1618\n",
      "159 12 False\n",
      "x_t:  2 [0.003125   0.4125     0.10625    0.27916667]\n",
      "Q values:  tensor([[-28.3195, -27.5976, -27.5770, -27.6677, -29.2721, -29.9057]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19379 696 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2071\n",
      "159 15 False\n",
      "x_t:  2 [0.821875   0.40833333 0.084375   0.27083333]\n",
      "Q values:  tensor([[-28.6919, -26.8442, -22.5033, -28.2859, -25.0235, -23.2243]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15562 365 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  841\n",
      "159 22 False\n",
      "x_t:  1 [0.009375 0.3625   0.08125  0.4     ]\n",
      "Q values:  tensor([[-31.8740, -29.6048, -31.1774, -33.7394, -31.4269, -32.1179]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9481 270 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  1336.0399453639984\n",
      "startIDX:  1044\n",
      "160 0 False\n",
      "x_t:  1 [0.840625   0.30416667 0.14375    0.42916667]\n",
      "Q values:  tensor([[-31.5961, -27.7664, -29.7177, -30.1650, -31.0345, -29.4498]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11949 763 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 160: ep_len:763 episode reward: total was -533.300000. running mean: -401.061459\n",
      "startIDX:  472\n",
      "160 1 False\n",
      "x_t:  1 [0.73125    0.27916667 0.121875   0.44583333]\n",
      "Q values:  tensor([[-33.3082, -32.4185, -32.9444, -34.8456, -36.8871, -34.4563]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30697 800 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 160: ep_len:800 episode reward: total was -558.100000. running mean: -402.631845\n",
      "startIDX:  2682\n",
      "160 5 False\n",
      "x_t:  1 [0.046875   0.34583333 0.175      0.52083333]\n",
      "Q values:  tensor([[-30.6353, -28.7229, -32.2743, -34.3706, -31.1514, -32.9452]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22109 248 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 160: ep_len:248 episode reward: total was -161.400000. running mean: -400.219526\n",
      "startIDX:  990\n",
      "160 10 False\n",
      "x_t:  1 [0.934375   0.27083333 0.059375   0.35416667]\n",
      "Q values:  tensor([[-30.6051, -28.1462, -33.6033, -32.8444, -31.8606, -28.5235]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11323 1543 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 160: ep_len:1543 episode reward: total was -1057.000000. running mean: -406.787331\n",
      "startIDX:  929\n",
      "160 12 False\n",
      "x_t:  1 [0.80625 0.35    0.1375  0.525  ]\n",
      "Q values:  tensor([[-26.4442, -25.7580, -30.0753, -28.6320, -27.6139, -29.3651]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12918 601 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 160: ep_len:601 episode reward: total was -393.600000. running mean: -406.655458\n",
      "startIDX:  677\n",
      "160 15 False\n",
      "x_t:  2 [0.634375   0.40416667 0.09375    0.29583333]\n",
      "Q values:  tensor([[-27.8519, -25.6050, -24.4189, -27.7197, -25.4440, -25.0222]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5992 409 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 160: ep_len:409 episode reward: total was -260.600000. running mean: -405.194903\n",
      "startIDX:  864\n",
      "160 22 False\n",
      "x_t:  1 [0.003125   0.375      0.078125   0.38333333]\n",
      "Q values:  tensor([[-25.5273, -23.1084, -23.7727, -24.7228, -23.7519, -23.3196]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9479 247 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 160: ep_len:247 episode reward: total was -145.800000. running mean: -402.600954\n",
      "startIDX:  1519\n",
      "161 0 False\n",
      "x_t:  3 [0.7875     0.32916667 0.0875     0.4125    ]\n",
      "Q values:  tensor([[-27.2975, -26.4881, -30.7600, -24.8606, -29.4037, -25.4743]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16824 252 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  709\n",
      "161 1 False\n",
      "x_t:  3 [0.19375    0.24166667 0.08125    0.325     ]\n",
      "Q values:  tensor([[-25.7748, -26.0504, -27.1317, -25.2443, -29.8642, -26.8670]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34343 1397 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1080\n",
      "161 5 True\n",
      "x_t:  3 [0.225      0.24583333 0.071875   0.29583333]\n",
      "Q values:  tensor([[-25.4998, -25.6582, -28.8076, -26.3429, -28.4672, -27.5971]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10579 205 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  739\n",
      "161 10 False\n",
      "x_t:  1 [0.003125   0.35416667 0.134375   0.37916667]\n",
      "Q values:  tensor([[-30.1716, -26.4923, -30.8781, -31.5976, -28.5296, -27.6152]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7107 228 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1395\n",
      "161 12 False\n",
      "x_t:  3 [0.453125 0.3125   0.115625 0.3625  ]\n",
      "Q values:  tensor([[-26.8616, -26.9311, -28.7568, -24.2775, -25.0660, -24.4402]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17894 210 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  789\n",
      "161 15 False\n",
      "x_t:  2 [0.771875   0.40833333 0.078125   0.29583333]\n",
      "Q values:  tensor([[-27.3522, -27.6830, -24.1630, -29.0917, -26.3832, -25.7569]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5971 342 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2549\n",
      "161 22 False\n",
      "x_t:  3 [0.078125 0.2375   0.0625   0.25    ]\n",
      "Q values:  tensor([[-30.0928, -28.7171, -28.1402, -26.0865, -30.8496, -28.3857]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26180 1235 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1176\n",
      "162 0 False\n",
      "x_t:  2 [0.6875     0.40416667 0.115625   0.28333333]\n",
      "Q values:  tensor([[-25.6445, -26.6886, -25.1449, -28.6911, -25.7102, -26.3903]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12646 309 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 162: ep_len:309 episode reward: total was -211.500000. running mean: -396.683613\n",
      "startIDX:  356\n",
      "162 1 False\n",
      "x_t:  1 [0.515625   0.3        0.24375    0.57916667]\n",
      "Q values:  tensor([[-28.7456, -26.4837, -27.7659, -31.3540, -30.1398, -26.5626]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28100 303 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 162: ep_len:303 episode reward: total was -208.300000. running mean: -394.799776\n",
      "startIDX:  1407\n",
      "162 5 False\n",
      "x_t:  1 [0.003125   0.34583333 0.084375   0.41666667]\n",
      "Q values:  tensor([[-21.9536, -19.8076, -24.3224, -23.3923, -23.1067, -23.1677]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12505 205 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 162: ep_len:205 episode reward: total was -151.200000. running mean: -392.363779\n",
      "startIDX:  1742\n",
      "162 10 False\n",
      "x_t:  3 [0.728125   0.30416667 0.134375   0.39166667]\n",
      "Q values:  tensor([[-23.5809, -23.2776, -24.1398, -21.4039, -23.7987, -21.9495]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16419 233 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 162: ep_len:233 episode reward: total was -161.300000. running mean: -390.053141\n",
      "startIDX:  319\n",
      "162 12 False\n",
      "x_t:  4 [0.259375   0.41666667 0.096875   0.38333333]\n",
      "Q values:  tensor([[-23.2105, -23.2941, -20.6416, -24.4312, -19.2536, -20.8260]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7207 742 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 162: ep_len:742 episode reward: total was -505.400000. running mean: -391.206609\n",
      "startIDX:  1650\n",
      "162 15 False\n",
      "x_t:  1 [0.4125     0.32083333 0.096875   0.37916667]\n",
      "Q values:  tensor([[-28.5847, -25.8099, -29.3304, -27.5607, -26.9807, -25.9434]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12491 279 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 162: ep_len:279 episode reward: total was -206.600000. running mean: -389.360543\n",
      "startIDX:  710\n",
      "162 22 False\n",
      "x_t:  2 [0.128125   0.40833333 0.053125   0.2625    ]\n",
      "Q values:  tensor([[-30.1344, -31.7022, -28.0339, -32.9010, -32.1531, -32.3785]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8934 892 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 162: ep_len:892 episode reward: total was -646.300000. running mean: -391.929938\n",
      "startIDX:  1064\n",
      "163 0 False\n",
      "x_t:  1 [0.840625   0.30416667 0.14375    0.42916667]\n",
      "Q values:  tensor([[-32.6422, -29.3380, -32.3295, -31.6547, -32.7379, -31.5926]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11949 762 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  633\n",
      "163 1 False\n",
      "x_t:  2 [0.809375   0.38333333 0.10625    0.30833333]\n",
      "Q values:  tensor([[-30.4983, -28.3919, -26.6798, -27.9141, -31.7733, -30.2794]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31461 353 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1456\n",
      "163 5 True\n",
      "x_t:  0 [0.775      0.39166667 0.1125     0.3375    ]\n",
      "Q values:  tensor([[-26.8916, -28.1236, -26.4769, -26.5295, -27.3577, -28.8187]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13520 504 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1356\n",
      "163 10 False\n",
      "x_t:  4 [0.165625   0.35416667 0.05       0.28333333]\n",
      "Q values:  tensor([[-34.7425, -31.4958, -31.9464, -31.4594, -30.1029, -30.8728]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15727 564 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  143\n",
      "163 12 False\n",
      "x_t:  2 [0.825      0.40833333 0.084375   0.24583333]\n",
      "Q values:  tensor([[-31.0715, -31.0738, -29.5337, -30.7831, -30.1419, -29.8216]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2804 293 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  606\n",
      "163 15 False\n",
      "x_t:  1 [0.80625    0.3        0.096875   0.27916667]\n",
      "Q values:  tensor([[-30.6056, -28.8494, -30.0442, -30.5491, -31.2134, -30.2973]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5176 680 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1978\n",
      "163 22 True\n",
      "x_t:  1 [0.003125   0.375      0.13125    0.40833333]\n",
      "Q values:  tensor([[-36.0044, -34.0719, -34.4658, -32.6919, -35.8321, -33.2405]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18988 253 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  766\n",
      "164 0 False\n",
      "x_t:  1 [0.075      0.35833333 0.0875     0.40416667]\n",
      "Q values:  tensor([[-39.2871, -36.9300, -38.3202, -37.9237, -41.2455, -37.1151]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9414 242 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 164: ep_len:242 episode reward: total was -185.900000. running mean: -387.677559\n",
      "startIDX:  652\n",
      "164 1 False\n",
      "x_t:  2 [0.75625    0.37916667 0.09375    0.32916667]\n",
      "Q values:  tensor([[-33.8186, -27.8865, -26.5387, -29.0953, -28.2180, -27.8187]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31470 361 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 164: ep_len:361 episode reward: total was -270.100000. running mean: -386.501783\n",
      "startIDX:  1145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164 5 False\n",
      "x_t:  2 [0.33125    0.39166667 0.084375   0.29166667]\n",
      "Q values:  tensor([[-29.2848, -26.8121, -25.7898, -28.0175, -26.6290, -28.3201]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12048 901 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 164: ep_len:901 episode reward: total was -645.000000. running mean: -389.086765\n",
      "startIDX:  1878\n",
      "164 10 False\n",
      "x_t:  2 [0.0875     0.4        0.06875    0.25416667]\n",
      "Q values:  tensor([[-24.9313, -26.9889, -24.9049, -27.0102, -31.8110, -26.3062]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18159 812 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 164: ep_len:812 episode reward: total was -601.800000. running mean: -391.213898\n",
      "startIDX:  1801\n",
      "164 12 False\n",
      "x_t:  0 [0.90625    0.40833333 0.090625   0.37083333]\n",
      "Q values:  tensor([[-26.6357, -29.2248, -30.7387, -29.4547, -31.7593, -31.6539]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21094 579 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 164: ep_len:579 episode reward: total was -456.800000. running mean: -391.869759\n",
      "startIDX:  5\n",
      "164 15 True\n",
      "x_t:  3 [0.840625   0.35833333 0.15625    0.425     ]\n",
      "Q values:  tensor([[-31.6117, -31.3410, -26.4616, -29.1046, -33.5596, -29.2005]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 518 247 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 164: ep_len:247 episode reward: total was -161.700000. running mean: -389.568061\n",
      "startIDX:  2184\n",
      "164 22 False\n",
      "x_t:  0 [0.909375   0.4        0.084375   0.34583333]\n",
      "Q values:  tensor([[-24.6934, -27.0188, -27.1098, -24.7956, -26.5662, -26.5192]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20686 800 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 164: ep_len:800 episode reward: total was -594.000000. running mean: -391.612381\n",
      "startIDX:  536\n",
      "165 0 True\n",
      "x_t:  3 [0.68125    0.37083333 0.178125   0.45      ]\n",
      "Q values:  tensor([[-28.7110, -27.5966, -29.1898, -30.7593, -30.0656, -30.6601]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7003 1007 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  487\n",
      "165 1 True\n",
      "x_t:  1 [0.85625    0.26666667 0.140625   0.45833333]\n",
      "Q values:  tensor([[-29.9054, -31.5192, -32.1879, -31.2733, -28.9304, -28.3665]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30680 755 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2579\n",
      "165 5 False\n",
      "x_t:  2 [0.225      0.39583333 0.090625   0.27083333]\n",
      "Q values:  tensor([[-28.3363, -29.4143, -26.3902, -30.3072, -31.5051, -28.2126]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21584 775 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  568\n",
      "165 10 False\n",
      "x_t:  2 [0.003125   0.40416667 0.109375   0.25      ]\n",
      "Q values:  tensor([[-24.9877, -25.9563, -22.3994, -26.7730, -27.9522, -24.1982]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6587 749 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1324\n",
      "165 12 False\n",
      "x_t:  3 [0.890625   0.37916667 0.10625    0.425     ]\n",
      "Q values:  tensor([[-31.4884, -31.1984, -36.5751, -28.2879, -34.2031, -32.7092]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17841 227 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2373\n",
      "165 15 True\n",
      "x_t:  4 [0.003125   0.4375     0.10625    0.36666667]\n",
      "Q values:  tensor([[-28.1036, -29.3462, -29.3161, -31.9190, -27.4536, -29.1279]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19246 508 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  212\n",
      "165 22 False\n",
      "x_t:  2 [0.821875   0.40416667 0.065625   0.25416667]\n",
      "Q values:  tensor([[-30.1077, -27.8203, -26.5613, -33.5645, -27.5904, -27.5780]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2277 316 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1726\n",
      "166 0 False\n",
      "x_t:  2 [0.028125   0.40833333 0.1        0.25      ]\n",
      "Q values:  tensor([[-20.5180, -19.7163, -18.0835, -19.5537, -21.0903, -20.8062]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18397 799 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 166: ep_len:799 episode reward: total was -380.600000. running mean: -391.953863\n",
      "startIDX:  1052\n",
      "166 1 False\n",
      "x_t:  3 [0.628125   0.29583333 0.103125   0.3625    ]\n",
      "Q values:  tensor([[-23.8930, -22.1176, -23.0820, -21.3695, -22.7029, -23.1886]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35936 215 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 166: ep_len:215 episode reward: total was -119.700000. running mean: -389.231324\n",
      "startIDX:  2920\n",
      "ep 166: ep_len:74 episode reward: total was -28.900000. running mean: -385.628011\n",
      "startIDX:  2132\n",
      "166 10 True\n",
      "x_t:  0 [0.88125    0.3875     0.10625    0.37916667]\n",
      "Q values:  tensor([[-23.7003, -22.8794, -22.8751, -23.4939, -22.4270, -20.4617]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19934 542 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 166: ep_len:542 episode reward: total was -298.100000. running mean: -384.752731\n",
      "startIDX:  59\n",
      "166 12 False\n",
      "x_t:  1 [0.81875  0.3125   0.109375 0.425   ]\n",
      "Q values:  tensor([[-21.1795, -20.9780, -22.1119, -22.3434, -23.1740, -20.9918]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2223 627 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 166: ep_len:627 episode reward: total was -324.300000. running mean: -384.148204\n",
      "startIDX:  611\n",
      "166 15 False\n",
      "x_t:  1 [0.8   0.3   0.1   0.275]\n",
      "Q values:  tensor([[-19.4042, -18.8138, -19.6495, -20.7877, -20.4630, -19.5502]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5178 678 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 166: ep_len:678 episode reward: total was -350.500000. running mean: -383.811722\n",
      "startIDX:  1589\n",
      "166 22 True\n",
      "x_t:  3 [0.490625   0.3        0.090625   0.34166667]\n",
      "Q values:  tensor([[-27.1674, -27.4278, -23.7311, -27.6081, -24.6084, -23.5337]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16901 283 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 166: ep_len:283 episode reward: total was -72.000000. running mean: -380.693604\n",
      "startIDX:  1833\n",
      "167 0 False\n",
      "x_t:  2 [0.003125   0.40833333 0.103125   0.25      ]\n",
      "Q values:  tensor([[-21.4999, -22.7339, -18.7017, -21.2574, -19.6856, -19.4191]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18392 742 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  204\n",
      "167 1 False\n",
      "x_t:  2 [0.003125   0.375      0.09375    0.42916667]\n",
      "Q values:  tensor([[-21.8872, -20.8488, -20.4781, -22.3431, -21.3647, -21.5660]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27429 841 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1908\n",
      "167 5 True\n",
      "x_t:  2 [0.796875   0.4        0.0875     0.25416667]\n",
      "Q values:  tensor([[-20.2546, -19.2329, -19.2937, -20.5903, -18.2444, -17.6025]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15650 322 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1258\n",
      "167 10 True\n",
      "x_t:  3 [0.271875   0.25833333 0.0875     0.29166667]\n",
      "Q values:  tensor([[-20.8187, -19.3741, -19.0670, -22.6110, -20.1784, -19.1317]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14642 1253 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  33\n",
      "167 12 False\n",
      "x_t:  1 [0.8375  0.3125  0.15625 0.425  ]\n",
      "Q values:  tensor([[-21.7961, -19.5214, -21.9677, -25.4123, -21.1411, -20.1365]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2218 639 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1273\n",
      "167 15 False\n",
      "x_t:  2 [0.0625     0.4125     0.103125   0.25833333]\n",
      "Q values:  tensor([[-20.6402, -20.9692, -20.0252, -22.2857, -20.4156, -22.2212]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 11921 1018 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  645\n",
      "167 22 False\n",
      "x_t:  2 [0.059375   0.40833333 0.084375   0.25833333]\n",
      "Q values:  tensor([[-27.1327, -26.0358, -25.1383, -27.7692, -27.4593, -25.2098]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8924 916 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2192\n",
      "168 0 True\n",
      "x_t:  1 [0.28125 0.35    0.1     0.5125 ]\n",
      "Q values:  tensor([[-31.6354, -31.1467, -33.6827, -35.7579, -30.7479, -30.7678]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22964 1129 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 168: ep_len:1129 episode reward: total was -752.700000. running mean: -390.950027\n",
      "startIDX:  401\n",
      "168 1 True\n",
      "x_t:  0 [0.91875    0.37083333 0.06875    0.40416667]\n",
      "Q values:  tensor([[-25.3230, -24.1467, -26.9561, -26.2947, -23.7183, -25.4338]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29092 495 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 168: ep_len:495 episode reward: total was -346.000000. running mean: -390.500527\n",
      "startIDX:  932\n",
      "168 5 False\n",
      "x_t:  3 [0.684375   0.3        0.1375     0.39583333]\n",
      "Q values:  tensor([[-20.9488, -21.8227, -23.2945, -20.6615, -20.7148, -22.5042]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10502 234 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 168: ep_len:234 episode reward: total was 2.400000. running mean: -386.571522\n",
      "startIDX:  2357\n",
      "168 10 False\n",
      "x_t:  1 [0.775      0.29166667 0.1375     0.325     ]\n",
      "Q values:  tensor([[-34.6035, -31.4442, -38.4715, -32.2933, -31.7588, -33.4002]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22480 1184 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 168: ep_len:1184 episode reward: total was -839.800000. running mean: -391.103807\n",
      "startIDX:  1004\n",
      "168 12 False\n",
      "x_t:  2 [0.7125     0.4125     0.09375    0.24166667]\n",
      "Q values:  tensor([[-28.3223, -31.0081, -24.7895, -27.8225, -27.9396, -25.9150]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13588 308 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 168: ep_len:308 episode reward: total was -204.100000. running mean: -389.233769\n",
      "startIDX:  786\n",
      "168 15 False\n",
      "x_t:  2 [0.76875    0.4        0.071875   0.30416667]\n",
      "Q values:  tensor([[-27.4937, -27.8666, -27.1205, -28.3028, -27.5302, -27.2570]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5974 337 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 168: ep_len:337 episode reward: total was -224.100000. running mean: -387.582431\n",
      "startIDX:  233\n",
      "168 22 False\n",
      "x_t:  2 [0.640625   0.40416667 0.059375   0.25833333]\n",
      "Q values:  tensor([[-24.1503, -23.1330, -22.4721, -24.2817, -24.8674, -22.9247]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2309 330 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 168: ep_len:330 episode reward: total was -228.300000. running mean: -385.989607\n",
      "startIDX:  898\n",
      "169 0 False\n",
      "x_t:  0 [0.7625  0.4     0.13125 0.35   ]\n",
      "Q values:  tensor([[-26.5929, -27.8565, -28.9237, -31.2559, -29.9756, -27.7499]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10351 456 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  453\n",
      "169 1 True\n",
      "x_t:  1 [0.859375   0.25833333 0.1375     0.47083333]\n",
      "Q values:  tensor([[-25.0018, -28.0072, -26.8690, -29.3358, -28.0191, -25.0592]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30678 782 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  979\n",
      "169 5 False\n",
      "x_t:  3 [0.36875    0.2625     0.134375   0.32916667]\n",
      "Q values:  tensor([[-25.9645, -24.8904, -24.9866, -23.8366, -26.4062, -24.1906]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10548 238 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2339\n",
      "169 10 False\n",
      "x_t:  1 [0.759375   0.2875     0.096875   0.32916667]\n",
      "Q values:  tensor([[-29.0759, -27.5548, -28.8517, -28.5065, -29.7041, -28.5849]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22483 1213 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1563\n",
      "169 12 False\n",
      "x_t:  2 [0.00625    0.4125     0.10625    0.28333333]\n",
      "Q values:  tensor([[-31.5753, -30.5367, -28.7888, -30.4757, -30.7257, -30.9278]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19381 732 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2208\n",
      "169 15 False\n",
      "x_t:  3 [0.071875   0.27083333 0.078125   0.3       ]\n",
      "Q values:  tensor([[-27.4581, -26.6261, -29.1573, -25.7994, -28.8379, -26.6077]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18176 1292 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1005\n",
      "169 22 False\n",
      "x_t:  0 [0.903125 0.4      0.053125 0.3375  ]\n",
      "Q values:  tensor([[-23.5323, -27.8868, -26.2956, -26.3206, -26.5216, -24.7413]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10402 436 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  1421.4197232723236\n",
      "startIDX:  174\n",
      "170 0 False\n",
      "x_t:  2 [0.79375    0.40416667 0.084375   0.28333333]\n",
      "Q values:  tensor([[-29.4458, -29.5085, -28.1345, -31.2857, -31.6177, -30.4673]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2323 358 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 170: ep_len:358 episode reward: total was -245.600000. running mean: -390.314654\n",
      "startIDX:  526\n",
      "170 1 True\n",
      "x_t:  1 [0.753125 0.275    0.165625 0.45    ]\n",
      "Q values:  tensor([[-26.0021, -26.3541, -28.3631, -30.1585, -27.5829, -25.4463]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30690 739 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 170: ep_len:739 episode reward: total was -477.200000. running mean: -391.183507\n",
      "startIDX:  1035\n",
      "170 5 False\n",
      "x_t:  3 [0.2375     0.2375     0.05625    0.29166667]\n",
      "Q values:  tensor([[-26.9223, -26.4180, -28.5238, -26.1761, -28.3991, -26.7829]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10578 214 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 170: ep_len:214 episode reward: total was -68.000000. running mean: -387.951672\n",
      "startIDX:  2032\n",
      "170 10 True\n",
      "x_t:  1 [0.01875    0.34166667 0.11875    0.4       ]\n",
      "Q values:  tensor([[-31.6332, -32.0194, -33.6999, -31.9199, -36.4387, -31.3208]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18813 290 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 170: ep_len:290 episode reward: total was -194.400000. running mean: -386.016156\n",
      "startIDX:  1014\n",
      "170 12 False\n",
      "x_t:  2 [0.8875     0.39166667 0.0625     0.22083333]\n",
      "Q values:  tensor([[-27.7408, -25.3406, -23.5972, -26.8336, -24.5822, -26.9826]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13565 303 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 170: ep_len:303 episode reward: total was -210.300000. running mean: -384.258994\n",
      "startIDX:  2125\n",
      "170 15 False\n",
      "x_t:  2 [0.828125   0.37916667 0.071875   0.25416667]\n",
      "Q values:  tensor([[-29.0608, -30.3846, -28.4126, -29.6960, -31.4013, -28.5324]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15561 336 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 170: ep_len:336 episode reward: total was -234.200000. running mean: -382.758404\n",
      "startIDX:  1593\n",
      "170 22 False\n",
      "x_t:  3 [0.459375   0.29583333 0.11875    0.34583333]\n",
      "Q values:  tensor([[-30.6919, -31.3484, -33.3178, -29.8525, -33.0634, -30.9071]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16904 282 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 170: ep_len:282 episode reward: total was -57.800000. running mean: -379.508820\n",
      "startIDX:  912\n",
      "171 0 False\n",
      "x_t:  0 [0.8625     0.40416667 0.125      0.35416667]\n",
      "Q values:  tensor([[-21.5190, -23.0867, -24.2756, -24.8151, -26.2884, -23.9272]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10334 430 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  225\n",
      "171 1 True\n",
      "x_t:  2 [0.059375   0.36666667 0.125      0.44166667]\n",
      "Q values:  tensor([[-22.6283, -24.1262, -28.7809, -27.2071, -24.2477, -25.5117]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27442 869 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1984\n",
      "171 5 False\n",
      "x_t:  3 [0.08125    0.25416667 0.103125   0.29583333]\n",
      "Q values:  tensor([[-23.7043, -22.2141, -23.8083, -21.9853, -24.2563, -23.0630]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18210 1243 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1693\n",
      "171 10 True\n",
      "x_t:  3 [0.884375   0.325      0.1125     0.40416667]\n",
      "Q values:  tensor([[-23.4577, -23.0407, -23.3699, -22.7808, -23.2460, -21.6503]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16400 247 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  357\n",
      "171 12 False\n",
      "x_t:  4 [0.35625    0.40416667 0.084375   0.36666667]\n",
      "Q values:  tensor([[-25.4120, -24.9116, -25.0128, -25.0070, -22.2622, -23.6097]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7218 738 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1382\n",
      "171 15 False\n",
      "x_t:  3 [0.54375    0.29583333 0.11875    0.33333333]\n",
      "Q values:  tensor([[-22.9286, -24.0466, -24.0712, -22.4085, -24.4704, -24.0595]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10388 206 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2426\n",
      "171 22 True\n",
      "x_t:  2 [0.75625    0.40416667 0.071875   0.25      ]\n",
      "Q values:  tensor([[-25.2235, -28.8515, -28.7124, -27.2591, -29.2340, -27.0722]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23648 341 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1647\n",
      "172 0 False\n",
      "x_t:  3 [0.340625   0.27916667 0.06875    0.31666667]\n",
      "Q values:  tensor([[-29.5031, -29.6726, -29.7848, -25.4632, -29.8474, -26.1704]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16890 211 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 172: ep_len:211 episode reward: total was -109.200000. running mean: -375.082980\n",
      "startIDX:  1123\n",
      "ep 172: ep_len:42 episode reward: total was 22.000000. running mean: -371.112150\n",
      "startIDX:  2746\n",
      "172 5 False\n",
      "x_t:  0 [0.903125   0.4        0.078125   0.29583333]\n",
      "Q values:  tensor([[-24.6254, -25.7287, -26.2211, -26.3830, -27.6826, -26.6312]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23152 517 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 172: ep_len:517 episode reward: total was -330.500000. running mean: -370.706029\n",
      "startIDX:  942\n",
      "172 10 False\n",
      "x_t:  1 [0.65625    0.29166667 0.128125   0.33333333]\n",
      "Q values:  tensor([[-27.0917, -23.5848, -26.9748, -25.3736, -25.1428, -23.9717]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11356 1608 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 172: ep_len:1608 episode reward: total was -1070.300000. running mean: -377.701968\n",
      "startIDX:  410\n",
      "172 12 False\n",
      "x_t:  3 [0.4125     0.29583333 0.06875    0.325     ]\n",
      "Q values:  tensor([[-27.1410, -24.4347, -23.5779, -22.5285, -25.5780, -24.5147]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7772 275 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 172: ep_len:275 episode reward: total was -142.700000. running mean: -375.351949\n",
      "startIDX:  72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172 15 False\n",
      "x_t:  3 [0.840625   0.35833333 0.15625    0.425     ]\n",
      "Q values:  tensor([[-24.8028, -25.2630, -26.3981, -23.1254, -24.3656, -23.1684]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 518 224 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 172: ep_len:224 episode reward: total was -126.900000. running mean: -372.867429\n",
      "startIDX:  1213\n",
      "172 22 False\n",
      "x_t:  2 [0.8375     0.39583333 0.059375   0.25      ]\n",
      "Q values:  tensor([[-25.5620, -24.9598, -23.9239, -26.4006, -24.8583, -24.4536]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12583 340 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 172: ep_len:340 episode reward: total was -214.700000. running mean: -371.285755\n",
      "startIDX:  1088\n",
      "173 0 False\n",
      "x_t:  1 [0.85625    0.30416667 0.128125   0.42916667]\n",
      "Q values:  tensor([[-24.4416, -24.0613, -26.8545, -24.4387, -29.3670, -26.6983]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11948 743 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1041\n",
      "173 1 True\n",
      "x_t:  3 [0.825      0.29583333 0.0875     0.42083333]\n",
      "Q values:  tensor([[-23.2280, -27.1772, -25.7946, -24.0379, -25.4063, -24.2275]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35905 207 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  612\n",
      "173 5 True\n",
      "x_t:  2 [0.6625     0.39166667 0.09375    0.3125    ]\n",
      "Q values:  tensor([[-25.4432, -27.8372, -23.3426, -25.4212, -24.3911, -23.5397]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6059 459 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2379\n",
      "173 10 True\n",
      "x_t:  1 [0.33125    0.32083333 0.128125   0.34583333]\n",
      "Q values:  tensor([[-31.9315, -34.1658, -36.3868, -35.1004, -34.6940, -32.7412]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22529 1219 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1362\n",
      "173 12 False\n",
      "x_t:  3 [0.86875    0.375      0.128125   0.43333333]\n",
      "Q values:  tensor([[-21.4168, -20.3575, -21.7461, -18.8853, -23.4178, -21.6564]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17842 209 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2504\n",
      "173 15 False\n",
      "x_t:  3 [0.54375    0.3        0.09375    0.33333333]\n",
      "Q values:  tensor([[-25.1727, -29.1730, -26.0474, -24.5310, -26.3426, -27.5135]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19708 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1924\n",
      "173 22 False\n",
      "x_t:  2 [0.259375   0.4        0.0625     0.26666667]\n",
      "Q values:  tensor([[-27.9946, -29.5078, -25.6948, -26.5510, -26.2071, -26.9198]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18491 753 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2567\n",
      "ep 174: ep_len:8 episode reward: total was -2.000000. running mean: -366.743723\n",
      "startIDX:  744\n",
      "174 1 False\n",
      "x_t:  3 [0.10625    0.2375     0.090625   0.30833333]\n",
      "Q values:  tensor([[-31.4272, -31.9878, -35.7859, -29.5058, -33.0811, -33.1339]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34322 1417 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 174: ep_len:1417 episode reward: total was -1072.400000. running mean: -373.800286\n",
      "startIDX:  724\n",
      "174 5 True\n",
      "x_t:  3 [0.09375    0.2625     0.084375   0.31666667]\n",
      "Q values:  tensor([[-31.2244, -31.2431, -31.7225, -31.3442, -29.2729, -29.9436]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8757 1316 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 174: ep_len:1316 episode reward: total was -990.300000. running mean: -379.965283\n",
      "startIDX:  2166\n",
      "174 10 False\n",
      "x_t:  0 [0.94375    0.37916667 0.046875   0.35833333]\n",
      "Q values:  tensor([[-29.1829, -31.7571, -31.4485, -31.7766, -29.6192, -29.6301]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19927 521 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 174: ep_len:521 episode reward: total was -412.400000. running mean: -380.289630\n",
      "startIDX:  1123\n",
      "174 12 False\n",
      "x_t:  3 [0.159375   0.275      0.078125   0.30833333]\n",
      "Q values:  tensor([[-35.3378, -35.2957, -36.7032, -34.1546, -34.7781, -36.2862]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16397 1374 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 174: ep_len:1374 episode reward: total was -1027.100000. running mean: -386.757734\n",
      "startIDX:  874\n",
      "174 15 False\n",
      "x_t:  3 [0.09375    0.23333333 0.05       0.24583333]\n",
      "Q values:  tensor([[-36.2975, -34.8387, -39.6674, -33.7018, -37.5132, -35.9993]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8507 1231 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 174: ep_len:1231 episode reward: total was -863.400000. running mean: -391.524157\n",
      "startIDX:  1656\n",
      "174 22 False\n",
      "x_t:  3 [0.86875    0.3625     0.125      0.40416667]\n",
      "Q values:  tensor([[-26.2404, -27.9901, -28.7982, -26.1678, -31.2115, -26.7483]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16843 217 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 174: ep_len:217 episode reward: total was -61.600000. running mean: -388.224915\n",
      "startIDX:  2211\n",
      "175 0 False\n",
      "x_t:  1 [0.859375   0.3        0.134375   0.54166667]\n",
      "Q values:  tensor([[-28.9466, -27.4932, -28.0330, -29.3831, -28.8198, -28.5442]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22917 1086 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  73\n",
      "175 1 False\n",
      "x_t:  3 [0.25       0.2375     0.090625   0.32083333]\n",
      "Q values:  tensor([[-24.3937, -24.2311, -26.3986, -23.6017, -24.7113, -23.8047]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25736 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2447\n",
      "175 5 False\n",
      "x_t:  2 [0.003125   0.4        0.075      0.25833333]\n",
      "Q values:  tensor([[-30.5071, -28.4939, -25.5610, -27.7504, -27.4058, -26.5164]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21545 942 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  876\n",
      "175 10 False\n",
      "x_t:  0 [0.81875    0.39166667 0.1125     0.32083333]\n",
      "Q values:  tensor([[-26.3358, -28.2851, -27.4557, -26.8146, -27.7306, -27.0605]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8115 450 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1997\n",
      "startIDX:  1222\n",
      "175 15 False\n",
      "x_t:  3 [0.753125   0.3375     0.140625   0.37916667]\n",
      "Q values:  tensor([[-24.6955, -24.5198, -24.4328, -20.8150, -27.5209, -23.6169]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10350 273 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2367\n",
      "175 22 False\n",
      "x_t:  1 [0.85625 0.3125  0.1375  0.45   ]\n",
      "Q values:  tensor([[-27.1277, -24.3065, -28.7101, -26.4065, -29.0458, -27.6167]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22933 1042 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1705\n",
      "176 0 False\n",
      "x_t:  3 [0.1875     0.2625     0.075      0.28333333]\n",
      "Q values:  tensor([[-28.4156, -29.6307, -28.7792, -26.2881, -28.9050, -27.8958]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16923 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 176: ep_len:200 episode reward: total was -120.300000. running mean: -383.925234\n",
      "startIDX:  765\n",
      "176 1 False\n",
      "x_t:  3 [0.171875   0.24166667 0.0875     0.31666667]\n",
      "Q values:  tensor([[-22.7514, -20.3607, -22.9978, -20.1712, -22.0462, -22.2181]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34336 1377 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 176: ep_len:1377 episode reward: total was -781.300000. running mean: -387.898982\n",
      "startIDX:  2107\n",
      "176 5 False\n",
      "x_t:  4 [0.0125     0.42083333 0.11875    0.40833333]\n",
      "Q values:  tensor([[-25.4834, -24.7429, -26.6685, -26.3964, -22.0554, -22.7843]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19466 618 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 176: ep_len:618 episode reward: total was -334.900000. running mean: -387.368992\n",
      "startIDX:  2009\n",
      "176 10 False\n",
      "x_t:  1 [0.084375   0.33333333 0.071875   0.39166667]\n",
      "Q values:  tensor([[-24.9324, -22.7736, -25.9820, -24.4956, -25.2484, -24.2059]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18818 293 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 176: ep_len:293 episode reward: total was -146.200000. running mean: -384.957302\n",
      "startIDX:  1442\n",
      "176 12 True\n",
      "x_t:  3 [0.378125   0.2875     0.08125    0.32916667]\n",
      "Q values:  tensor([[-23.9401, -22.6763, -21.4586, -21.8606, -22.3904, -19.5113]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17914 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 176: ep_len:203 episode reward: total was -89.200000. running mean: -381.999729\n",
      "startIDX:  2533\n",
      "176 15 True\n",
      "x_t:  3 [0.31875    0.2625     0.078125   0.28333333]\n",
      "Q values:  tensor([[-25.0247, -26.1298, -21.0499, -23.5270, -28.1073, -23.4374]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19761 220 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 176: ep_len:220 episode reward: total was -120.400000. running mean: -379.383732\n",
      "startIDX:  2369\n",
      "176 22 True\n",
      "x_t:  1 [0.8375     0.30833333 0.1        0.45      ]\n",
      "Q values:  tensor([[-19.4842, -19.9092, -19.8824, -19.8540, -21.1051, -19.1456]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22937 1047 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 176: ep_len:1047 episode reward: total was -526.100000. running mean: -380.850895\n",
      "startIDX:  105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177 0 False\n",
      "x_t:  1 [0.04375    0.36666667 0.178125   0.48333333]\n",
      "Q values:  tensor([[-21.9082, -21.1898, -21.9197, -22.6902, -23.0062, -22.1648]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1689 732 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  595\n",
      "177 1 False\n",
      "x_t:  2 [0.725      0.37916667 0.1125     0.3125    ]\n",
      "Q values:  tensor([[-26.7487, -27.7160, -21.4776, -26.1720, -26.6206, -23.8106]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31476 382 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1817\n",
      "177 5 False\n",
      "x_t:  2 [0.846875   0.40416667 0.084375   0.2375    ]\n",
      "Q values:  tensor([[-20.0364, -18.6892, -18.1085, -19.6124, -20.2045, -18.9331]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15640 348 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  447\n",
      "177 10 False\n",
      "x_t:  3 [0.284375   0.24583333 0.084375   0.30416667]\n",
      "Q values:  tensor([[-18.2134, -16.1958, -17.7520, -15.6788, -17.5683, -17.1408]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5124 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  259\n",
      "177 12 False\n",
      "x_t:  3 [0.1        0.26666667 0.090625   0.275     ]\n",
      "Q values:  tensor([[-27.2394, -26.3685, -24.5236, -23.4433, -24.7442, -23.7664]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5675 1367 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2243\n",
      "177 15 False\n",
      "x_t:  3 [0.096875   0.27083333 0.075      0.30833333]\n",
      "Q values:  tensor([[-23.8838, -23.7771, -22.3866, -22.0254, -23.5023, -22.7130]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18181 1275 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2796\n",
      "startIDX:  2271\n",
      "178 0 False\n",
      "x_t:  2 [0.90625    0.39583333 0.053125   0.1625    ]\n",
      "Q values:  tensor([[-19.9142, -19.0696, -16.7191, -18.4257, -19.1075, -16.7697]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23570 298 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 178: ep_len:298 episode reward: total was -171.900000. running mean: -373.244460\n",
      "startIDX:  178\n",
      "178 1 False\n",
      "x_t:  2 [0.003125 0.3625   0.1      0.45    ]\n",
      "Q values:  tensor([[-15.4007, -15.4822, -14.5852, -15.8376, -16.0447, -14.9790]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27431 852 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 178: ep_len:852 episode reward: total was -416.100000. running mean: -373.673016\n",
      "startIDX:  1491\n",
      "178 5 True\n",
      "x_t:  0 [0.90625    0.39166667 0.06875    0.325     ]\n",
      "Q values:  tensor([[-21.5344, -20.4980, -20.4215, -18.9876, -21.8386, -19.2598]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13501 461 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 178: ep_len:461 episode reward: total was -260.100000. running mean: -372.537285\n",
      "startIDX:  1697\n",
      "178 10 False\n",
      "x_t:  3 [0.721875   0.30416667 0.128125   0.3875    ]\n",
      "Q values:  tensor([[-19.3459, -19.5568, -19.2945, -17.4455, -20.7448, -18.1863]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16420 245 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 178: ep_len:245 episode reward: total was -97.900000. running mean: -369.790913\n",
      "startIDX:  807\n",
      "178 12 False\n",
      "x_t:  0 [0.7875     0.40416667 0.05625    0.30833333]\n",
      "Q values:  tensor([[-21.6715, -22.4032, -24.0891, -23.6495, -24.1823, -23.1862]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11655 676 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 178: ep_len:676 episode reward: total was -407.800000. running mean: -370.171003\n",
      "startIDX:  2344\n",
      "178 15 False\n",
      "x_t:  4 [0.134375   0.40833333 0.10625    0.34166667]\n",
      "Q values:  tensor([[-23.6400, -23.3128, -22.9232, -24.7681, -21.9957, -22.8031]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19266 534 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 178: ep_len:534 episode reward: total was -302.600000. running mean: -369.495293\n",
      "startIDX:  2879\n",
      "ep 178: ep_len:71 episode reward: total was 51.000000. running mean: -365.290340\n",
      "startIDX:  1783\n",
      "179 0 False\n",
      "x_t:  2 [0.00625    0.40833333 0.0875     0.24583333]\n",
      "Q values:  tensor([[-25.6877, -23.7816, -21.9303, -24.5733, -27.7331, -24.9862]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18391 752 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  644\n",
      "179 1 False\n",
      "x_t:  2 [0.796875   0.37916667 0.075      0.30416667]\n",
      "Q values:  tensor([[-22.4930, -21.7766, -21.3935, -23.8438, -23.0727, -22.2620]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31467 358 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  343\n",
      "179 5 False\n",
      "x_t:  1 [0.871875   0.28333333 0.125      0.39166667]\n",
      "Q values:  tensor([[-24.6134, -24.0983, -25.2517, -24.7075, -27.0430, -24.9860]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5026 716 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  870\n",
      "179 10 False\n",
      "x_t:  0 [0.784375   0.3875     0.065625   0.32083333]\n",
      "Q values:  tensor([[-21.3300, -23.1218, -22.4721, -24.7852, -25.0868, -22.1571]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8124 453 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1640\n",
      "179 12 False\n",
      "x_t:  1 [0.05625    0.36666667 0.13125    0.35833333]\n",
      "Q values:  tensor([[-27.8932, -26.1898, -26.3629, -27.4680, -29.9436, -28.9760]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19878 245 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1786\n",
      "179 15 False\n",
      "x_t:  0 [0.9375     0.40416667 0.053125   0.325     ]\n",
      "Q values:  tensor([[-24.9731, -25.8736, -26.8550, -26.3781, -26.3379, -25.1445]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13362 433 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1418\n",
      "179 22 True\n",
      "x_t:  3 [0.15       0.25833333 0.084375   0.28333333]\n",
      "Q values:  tensor([[-37.3002, -38.7910, -33.1527, -38.1431, -35.3968, -35.2136]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15221 1261 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  1504.460040807724\n",
      "startIDX:  1239\n",
      "180 0 False\n",
      "x_t:  3 [0.08125 0.25    0.08125 0.2625 ]\n",
      "Q values:  tensor([[-38.1132, -35.2786, -37.5519, -34.0181, -41.7039, -36.0033]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15164 1220 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 180: ep_len:1220 episode reward: total was -1007.600000. running mean: -376.955740\n",
      "startIDX:  311\n",
      "180 1 False\n",
      "x_t:  1 [0.678125   0.27083333 0.153125   0.60416667]\n",
      "Q values:  tensor([[-25.5635, -22.2086, -23.6884, -26.1252, -28.0151, -25.8061]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28110 322 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 180: ep_len:322 episode reward: total was -254.400000. running mean: -375.730182\n",
      "startIDX:  1639\n",
      "180 5 False\n",
      "x_t:  1 [0.903125 0.275    0.065625 0.325   ]\n",
      "Q values:  tensor([[-33.5683, -30.6519, -34.9595, -35.3383, -33.5841, -33.8583]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14921 652 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 180: ep_len:652 episode reward: total was -490.500000. running mean: -376.877881\n",
      "startIDX:  376\n",
      "180 10 False\n",
      "x_t:  3 [0.69375    0.29583333 0.090625   0.37083333]\n",
      "Q values:  tensor([[-25.6986, -25.3285, -26.1619, -22.5988, -23.8572, -26.3331]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5055 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 180: ep_len:203 episode reward: total was -86.900000. running mean: -373.978102\n",
      "startIDX:  1850\n",
      "180 12 True\n",
      "x_t:  0 [0.215625   0.43333333 0.08125    0.34583333]\n",
      "Q values:  tensor([[-32.7504, -37.7318, -33.2674, -31.8065, -36.9833, -33.7780]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 22992 949 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 180: ep_len:949 episode reward: total was -770.600000. running mean: -377.944321\n",
      "startIDX:  736\n",
      "180 15 False\n",
      "x_t:  2 [0.7625     0.40833333 0.059375   0.28333333]\n",
      "Q values:  tensor([[-32.0684, -30.6516, -28.7509, -32.2482, -33.5714, -31.4826]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5976 379 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 180: ep_len:379 episode reward: total was -321.100000. running mean: -377.375878\n",
      "startIDX:  76\n",
      "180 22 False\n",
      "x_t:  1 [0.734375   0.30833333 0.146875   0.39583333]\n",
      "Q values:  tensor([[-35.0919, -29.7504, -31.0059, -31.0397, -30.9980, -32.4249]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1592 702 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 180: ep_len:702 episode reward: total was -584.300000. running mean: -379.445119\n",
      "startIDX:  2205\n",
      "181 0 True\n",
      "x_t:  1 [0.846875   0.30416667 0.146875   0.5375    ]\n",
      "Q values:  tensor([[-30.2418, -30.3422, -34.6106, -29.9961, -31.0035, -32.0690]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22919 1104 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  108\n",
      "181 1 True\n",
      "x_t:  3 [0.178125   0.23333333 0.0875     0.29166667]\n",
      "Q values:  tensor([[-26.0941, -29.4600, -27.1180, -27.8299, -27.9553, -30.2660]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25757 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1381\n",
      "181 5 True\n",
      "x_t:  1 [0.1125     0.3375     0.090625   0.38333333]\n",
      "Q values:  tensor([[-34.7659, -36.7442, -37.5096, -35.4078, -36.9050, -35.9593]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12516 231 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181 10 False\n",
      "x_t:  0 [0.884375   0.39583333 0.103125   0.34166667]\n",
      "Q values:  tensor([[-30.7120, -32.3853, -32.9921, -33.6695, -31.2387, -32.2362]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19931 539 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  496\n",
      "181 12 False\n",
      "x_t:  3 [0.796875   0.3625     0.171875   0.41666667]\n",
      "Q values:  tensor([[-31.0952, -32.8567, -32.8380, -30.7508, -33.4917, -32.6340]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7716 212 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  989\n",
      "181 15 False\n",
      "x_t:  4 [0.0625     0.39166667 0.096875   0.29583333]\n",
      "Q values:  tensor([[-27.6316, -33.3727, -30.5050, -29.1508, -27.4909, -28.3246]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9822 647 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2247\n",
      "181 22 False\n",
      "x_t:  1 [0.715625 0.325    0.16875  0.4375  ]\n",
      "Q values:  tensor([[-28.9875, -26.2519, -29.2692, -28.3340, -30.4849, -28.4248]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22945 1100 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1541\n",
      "182 0 False\n",
      "x_t:  3 [0.846875   0.34583333 0.15       0.425     ]\n",
      "Q values:  tensor([[-35.3157, -36.1892, -35.2205, -34.7814, -36.1055, -35.2438]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16812 223 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 182: ep_len:223 episode reward: total was -52.200000. running mean: -378.810799\n",
      "startIDX:  312\n",
      "182 1 False\n",
      "x_t:  1 [0.696875   0.27916667 0.146875   0.59583333]\n",
      "Q values:  tensor([[-34.5158, -31.5781, -34.4074, -32.9056, -32.0891, -32.9480]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28111 318 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 182: ep_len:318 episode reward: total was -221.300000. running mean: -377.235691\n",
      "startIDX:  789\n",
      "182 5 False\n",
      "x_t:  4 [0.10625    0.40416667 0.115625   0.4       ]\n",
      "Q values:  tensor([[-32.1549, -32.6224, -29.7832, -33.0926, -27.4817, -29.4025]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10024 622 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 182: ep_len:622 episode reward: total was -395.400000. running mean: -377.417334\n",
      "startIDX:  161\n",
      "182 10 False\n",
      "x_t:  4 [0.015625   0.35833333 0.0625     0.25833333]\n",
      "Q values:  tensor([[-30.8708, -31.6423, -30.4106, -28.8049, -28.0255, -29.8846]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4546 467 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 182: ep_len:467 episode reward: total was -284.600000. running mean: -376.489161\n",
      "startIDX:  540\n",
      "182 12 False\n",
      "x_t:  2 [0.24375    0.40833333 0.065625   0.25833333]\n",
      "Q values:  tensor([[-22.7231, -23.1049, -21.9536, -23.9640, -24.5076, -22.1627]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9863 1058 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 182: ep_len:1058 episode reward: total was -644.400000. running mean: -379.168269\n",
      "startIDX:  2531\n",
      "182 15 False\n",
      "x_t:  3 [0.459375   0.28333333 0.065625   0.30416667]\n",
      "Q values:  tensor([[-5.4798, -4.4407, -5.1287, -2.1329, -3.6359, -5.3911]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19730 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 182: ep_len:200 episode reward: total was -85.700000. running mean: -376.233587\n",
      "startIDX:  560\n",
      "182 22 False\n",
      "x_t:  3 [0.88125    0.34583333 0.109375   0.4125    ]\n",
      "Q values:  tensor([[-29.2807, -27.3604, -24.7260, -24.1239, -25.0088, -26.9997]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7051 208 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 182: ep_len:208 episode reward: total was -113.500000. running mean: -373.606251\n",
      "startIDX:  824\n",
      "183 0 False\n",
      "x_t:  1 [0.571875   0.32083333 0.146875   0.43333333]\n",
      "Q values:  tensor([[-26.0834, -24.0468, -24.3507, -27.3657, -26.6447, -24.0505]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9471 250 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1060\n",
      "183 1 False\n",
      "x_t:  3 [0.78125    0.30416667 0.121875   0.4125    ]\n",
      "Q values:  tensor([[-23.7566, -22.8663, -25.2566, -22.2076, -22.7289, -23.3912]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35909 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1369\n",
      "183 5 True\n",
      "x_t:  1 [0.2875     0.325      0.146875   0.37916667]\n",
      "Q values:  tensor([[-26.9403, -25.8151, -23.8777, -27.4301, -26.1392, -24.4051]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12537 239 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2534\n",
      "183 10 False\n",
      "x_t:  1 [0.896875   0.28333333 0.1        0.3375    ]\n",
      "Q values:  tensor([[-26.6471, -22.8646, -23.8111, -25.0791, -25.7952, -24.8407]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22465 1105 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1314\n",
      "183 12 False\n",
      "x_t:  3 [0.7625     0.35416667 0.103125   0.4375    ]\n",
      "Q values:  tensor([[-23.6662, -24.6322, -22.4859, -21.0469, -24.1564, -22.1306]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17855 230 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  495\n",
      "183 15 False\n",
      "x_t:  1 [0.9375     0.29583333 0.053125   0.27083333]\n",
      "Q values:  tensor([[-26.6534, -24.8927, -26.1721, -27.8544, -25.4925, -25.4207]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5162 725 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1363\n",
      "183 22 False\n",
      "x_t:  3 [0.1        0.25416667 0.0625     0.27916667]\n",
      "Q values:  tensor([[-19.1199, -18.9617, -17.9157, -16.3021, -19.8502, -17.1868]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15207 1285 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  831\n",
      "184 0 True\n",
      "x_t:  1 [0.01875    0.36666667 0.13125    0.4       ]\n",
      "Q values:  tensor([[-30.6463, -27.0847, -27.0029, -27.5734, -28.6575, -27.3687]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9408 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 184: ep_len:203 episode reward: total was -117.100000. running mean: -368.659678\n",
      "startIDX:  1006\n",
      "184 1 False\n",
      "x_t:  3 [0.746875   0.3        0.13125    0.40416667]\n",
      "Q values:  tensor([[-24.4481, -24.8752, -25.1408, -22.8639, -23.2671, -22.9071]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35914 228 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 184: ep_len:228 episode reward: total was -154.400000. running mean: -366.517081\n",
      "startIDX:  124\n",
      "184 5 False\n",
      "x_t:  2 [0.071875   0.37916667 0.175      0.4375    ]\n",
      "Q values:  tensor([[-21.5195, -20.8774, -18.3478, -21.3932, -21.4749, -19.0133]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2062 851 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 184: ep_len:851 episode reward: total was -470.100000. running mean: -367.552910\n",
      "startIDX:  2519\n",
      "184 10 False\n",
      "x_t:  1 [0.571875   0.30416667 0.13125    0.32083333]\n",
      "Q values:  tensor([[-23.0725, -20.5318, -21.3067, -21.7833, -21.0301, -22.2144]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22501 1143 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 184: ep_len:1143 episode reward: total was -673.000000. running mean: -370.607381\n",
      "startIDX:  883\n",
      "184 12 False\n",
      "x_t:  1 [0.80625 0.35    0.1375  0.525  ]\n",
      "Q values:  tensor([[-26.4390, -23.0335, -24.1699, -23.1680, -25.1502, -24.0487]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12918 620 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 184: ep_len:620 episode reward: total was -343.400000. running mean: -370.335307\n",
      "startIDX:  1264\n",
      "184 15 True\n",
      "x_t:  3 [0.596875 0.3      0.075    0.3375  ]\n",
      "Q values:  tensor([[-23.9879, -24.5338, -25.1813, -25.1239, -25.9297, -23.6964]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10382 261 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 184: ep_len:261 episode reward: total was -187.100000. running mean: -368.502954\n",
      "startIDX:  639\n",
      "184 22 False\n",
      "x_t:  2 [0.065625   0.41666667 0.103125   0.25416667]\n",
      "Q values:  tensor([[-25.0060, -25.0152, -24.2862, -25.6107, -25.7861, -24.5363]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8929 934 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 184: ep_len:934 episode reward: total was -437.200000. running mean: -369.189925\n",
      "startIDX:  755\n",
      "185 0 False\n",
      "x_t:  1 [0.01875    0.36666667 0.13125    0.39583333]\n",
      "Q values:  tensor([[-25.1157, -24.2611, -27.4294, -28.6003, -25.0223, -25.7733]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9409 258 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1142\n",
      "startIDX:  2997\n",
      "startIDX:  1611\n",
      "185 10 True\n",
      "x_t:  3 [0.803125   0.30416667 0.090625   0.40416667]\n",
      "Q values:  tensor([[-19.5602, -19.4727, -19.5721, -20.6051, -21.0298, -19.7856]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16411 289 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1615\n",
      "185 12 True\n",
      "x_t:  2 [0.003125   0.4125     0.10625    0.27916667]\n",
      "Q values:  tensor([[-23.1598, -23.7198, -21.1617, -21.9073, -24.2309, -21.1900]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19379 699 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  463\n",
      "185 15 True\n",
      "x_t:  1 [0.859375 0.3      0.046875 0.2625  ]\n",
      "Q values:  tensor([[-20.6199, -22.4854, -23.9652, -20.6038, -23.2881, -21.6358]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5172 757 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  1584\n",
      "185 22 True\n",
      "x_t:  3 [0.86875    0.3625     0.125      0.40416667]\n",
      "Q values:  tensor([[-26.9296, -26.5532, -25.7768, -28.1800, -26.7018, -25.1517]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16843 250 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  751\n",
      "186 0 False\n",
      "x_t:  1 [0.584375   0.325      0.1625     0.42083333]\n",
      "Q values:  tensor([[-26.9656, -24.9379, -26.2556, -27.0079, -27.7107, -25.4988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9475 279 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 186: ep_len:279 episode reward: total was -172.700000. running mean: -355.530284\n",
      "startIDX:  143\n",
      "186 1 False\n",
      "x_t:  2 [0.1125     0.36666667 0.128125   0.44583333]\n",
      "Q values:  tensor([[-28.3692, -27.5261, -26.8217, -28.7757, -27.7043, -27.8016]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27448 870 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 186: ep_len:870 episode reward: total was -471.400000. running mean: -356.688981\n",
      "startIDX:  492\n",
      "186 5 True\n",
      "x_t:  1 [0.853125   0.275      0.078125   0.39166667]\n",
      "Q values:  tensor([[-22.9066, -25.5951, -24.9308, -24.0001, -24.0407, -24.0574]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5032 668 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 186: ep_len:668 episode reward: total was -406.800000. running mean: -357.190091\n",
      "startIDX:  2536\n",
      "ep 186: ep_len:51 episode reward: total was -37.900000. running mean: -353.997191\n",
      "startIDX:  904\n",
      "186 12 False\n",
      "x_t:  1 [0.565625   0.3625     0.115625   0.50416667]\n",
      "Q values:  tensor([[-31.6592, -30.8780, -31.4879, -33.1459, -34.5196, -31.0276]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12931 619 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 186: ep_len:619 episode reward: total was -396.300000. running mean: -354.420219\n",
      "startIDX:  1327\n",
      "186 15 False\n",
      "x_t:  3 [0.88125    0.34583333 0.115625   0.39166667]\n",
      "Q values:  tensor([[-24.7029, -25.1766, -24.1402, -22.4126, -23.4592, -24.5787]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10336 209 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 186: ep_len:209 episode reward: total was -118.200000. running mean: -352.058016\n",
      "startIDX:  1249\n",
      "186 22 False\n",
      "x_t:  2 [0.78125    0.40833333 0.09375    0.2625    ]\n",
      "Q values:  tensor([[-30.8049, -30.6580, -27.5331, -28.6555, -29.8517, -28.2834]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12589 318 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 186: ep_len:318 episode reward: total was -216.900000. running mean: -350.706436\n",
      "startIDX:  751\n",
      "187 0 False\n",
      "x_t:  1 [0.11875    0.35833333 0.14375    0.39583333]\n",
      "Q values:  tensor([[-30.0390, -27.3251, -30.2961, -30.3753, -30.4941, -29.1609]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9422 256 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  15\n",
      "187 1 True\n",
      "x_t:  3 [0.39375    0.25416667 0.090625   0.35      ]\n",
      "Q values:  tensor([[-27.4426, -26.9025, -25.9984, -29.0589, -28.4364, -28.6062]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25706 212 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2299\n",
      "187 5 False\n",
      "x_t:  3 [0.25       0.2625     0.1125     0.32916667]\n",
      "Q values:  tensor([[-28.2404, -26.9882, -27.4567, -25.7480, -26.5887, -25.9397]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19967 208 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1423\n",
      "187 10 False\n",
      "x_t:  4 [0.00625    0.36666667 0.1125     0.275     ]\n",
      "Q values:  tensor([[-23.3505, -23.4361, -23.1347, -24.3430, -21.4562, -23.8606]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15705 508 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  696\n",
      "187 12 True\n",
      "x_t:  1 [0.003125   0.39583333 0.153125   0.47083333]\n",
      "Q values:  tensor([[-22.4551, -22.5430, -22.7072, -25.6725, -21.6571, -22.8843]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10304 210 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  410\n",
      "187 15 False\n",
      "x_t:  0 [0.903125   0.39583333 0.0625     0.35      ]\n",
      "Q values:  tensor([[-19.4032, -23.7802, -22.8287, -22.2387, -22.9352, -23.4062]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3657 445 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2315\n",
      "187 22 True\n",
      "x_t:  1 [0.253125 0.35     0.115625 0.4625  ]\n",
      "Q values:  tensor([[-28.8646, -26.8984, -28.4410, -28.6305, -29.8698, -29.0081]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22990 1104 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1852\n",
      "188 0 False\n",
      "x_t:  2 [0.003125   0.40416667 0.053125   0.25416667]\n",
      "Q values:  tensor([[-30.0794, -30.4368, -29.0381, -31.8908, -30.9549, -29.6275]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18390 702 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 188: ep_len:702 episode reward: total was -560.500000. running mean: -348.849714\n",
      "startIDX:  618\n",
      "188 1 False\n",
      "x_t:  2 [0.809375   0.38333333 0.10625    0.30833333]\n",
      "Q values:  tensor([[-31.3351, -30.9599, -27.6853, -31.7302, -29.8065, -30.5563]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31461 356 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 188: ep_len:356 episode reward: total was -281.800000. running mean: -348.179217\n",
      "startIDX:  1662\n",
      "188 5 False\n",
      "x_t:  1 [0.8125     0.29166667 0.121875   0.30416667]\n",
      "Q values:  tensor([[-25.7983, -24.5287, -28.9720, -28.4776, -27.2195, -26.5051]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14928 657 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 188: ep_len:657 episode reward: total was -466.200000. running mean: -349.359425\n",
      "startIDX:  1255\n",
      "188 10 True\n",
      "x_t:  3 [0.078125 0.225    0.059375 0.25    ]\n",
      "Q values:  tensor([[-42.6590, -44.0057, -38.9681, -40.4551, -40.3021, -37.7190]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14578 1232 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 188: ep_len:1232 episode reward: total was -958.300000. running mean: -355.448831\n",
      "startIDX:  628\n",
      "188 12 False\n",
      "x_t:  2 [0.1625     0.42083333 0.109375   0.24166667]\n",
      "Q values:  tensor([[-38.9305, -35.7998, -35.1430, -36.9683, -39.5744, -38.3320]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9854 1000 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 188: ep_len:1000 episode reward: total was -747.600000. running mean: -359.370342\n",
      "startIDX:  1545\n",
      "188 15 False\n",
      "x_t:  2 [0.003125   0.4125     0.08125    0.25416667]\n",
      "Q values:  tensor([[-39.2665, -36.3061, -35.1577, -38.5423, -36.4969, -40.0953]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 11910 736 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 188: ep_len:736 episode reward: total was -505.500000. running mean: -360.831639\n",
      "startIDX:  1137\n",
      "188 22 False\n",
      "x_t:  1 [0.875      0.29583333 0.0875     0.5       ]\n",
      "Q values:  tensor([[-27.9060, -25.2939, -26.3414, -26.4017, -26.3767, -27.6484]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11917 700 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 188: ep_len:700 episode reward: total was -502.500000. running mean: -362.248322\n",
      "startIDX:  1496\n",
      "189 0 False\n",
      "x_t:  3 [0.734375   0.32916667 0.125      0.4125    ]\n",
      "Q values:  tensor([[-28.6062, -30.7047, -31.1160, -28.5261, -30.0709, -29.8850]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16826 269 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  612\n",
      "189 1 False\n",
      "x_t:  2 [0.809375   0.38333333 0.06875    0.30833333]\n",
      "Q values:  tensor([[-26.9371, -30.3477, -26.0778, -29.2484, -29.7656, -26.8401]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31466 380 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1526\n",
      "189 5 False\n",
      "x_t:  0 [0.934375   0.38333333 0.0625     0.34166667]\n",
      "Q values:  tensor([[-30.1150, -32.3161, -31.7268, -30.1884, -31.3097, -30.4402]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13495 460 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  837\n",
      "189 10 False\n",
      "x_t:  0 [0.896875   0.39583333 0.096875   0.32083333]\n",
      "Q values:  tensor([[-28.7588, -32.8160, -30.1607, -30.4682, -31.6762, -30.5037]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8106 474 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  375\n",
      "189 12 True\n",
      "x_t:  4 [0.271875 0.425    0.14375  0.375   ]\n",
      "Q values:  tensor([[-26.0021, -27.6211, -25.5414, -27.8017, -30.6388, -26.3859]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7210 717 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1354\n",
      "189 15 False\n",
      "x_t:  3 [0.540625   0.2875     0.1        0.34583333]\n",
      "Q values:  tensor([[-28.9416, -28.0345, -28.1743, -28.0332, -30.1954, -29.4840]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10391 223 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1035\n",
      "189 22 True\n",
      "x_t:  0 [0.665625   0.4125     0.05       0.30416667]\n",
      "Q values:  tensor([[-29.5856, -25.5885, -25.6905, -28.8208, -30.5741, -28.5088]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10446 442 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  1581.8531222343445\n",
      "startIDX:  1507\n",
      "190 0 False\n",
      "x_t:  3 [0.19375    0.27083333 0.075      0.27916667]\n",
      "Q values:  tensor([[-23.6050, -22.1678, -23.4498, -20.9044, -22.7079, -22.3500]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16921 297 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 190: ep_len:297 episode reward: total was -196.600000. running mean: -356.735924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  725\n",
      "190 1 True\n",
      "x_t:  3 [0.140625   0.24166667 0.08125    0.3125    ]\n",
      "Q values:  tensor([[-25.4559, -22.6703, -25.1038, -24.4837, -26.8005, -23.7071]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34330 1404 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 190: ep_len:1404 episode reward: total was -934.200000. running mean: -362.510565\n",
      "startIDX:  1094\n",
      "190 5 False\n",
      "x_t:  3 [0.128125   0.24166667 0.1375     0.27083333]\n",
      "Q values:  tensor([[-28.5313, -27.2573, -30.1120, -25.8240, -27.4334, -27.8505]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10594 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 190: ep_len:203 episode reward: total was -146.600000. running mean: -360.351459\n",
      "startIDX:  2138\n",
      "190 10 True\n",
      "x_t:  0 [0.94375    0.37916667 0.046875   0.35833333]\n",
      "Q values:  tensor([[-28.1846, -28.1373, -27.8429, -29.2148, -32.3073, -27.8650]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19927 546 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 190: ep_len:546 episode reward: total was -369.800000. running mean: -360.445944\n",
      "startIDX:  2021\n",
      "ep 190: ep_len:27 episode reward: total was 3.000000. running mean: -356.811485\n",
      "startIDX:  2543\n",
      "190 15 False\n",
      "x_t:  3 [0.3125     0.27083333 0.084375   0.27083333]\n",
      "Q values:  tensor([[-34.1231, -35.0446, -33.8567, -31.9251, -33.6373, -33.9260]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19760 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 190: ep_len:200 episode reward: total was -124.500000. running mean: -354.488370\n",
      "startIDX:  176\n",
      "190 22 False\n",
      "x_t:  2 [0.6875     0.40833333 0.0875     0.24583333]\n",
      "Q values:  tensor([[-27.4071, -29.7581, -26.8942, -28.3331, -27.8902, -27.1800]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2299 356 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 190: ep_len:356 episode reward: total was -234.700000. running mean: -353.290486\n",
      "startIDX:  457\n",
      "191 0 False\n",
      "x_t:  3 [0.85       0.39583333 0.146875   0.43333333]\n",
      "Q values:  tensor([[-24.2916, -26.7267, -23.9131, -23.8425, -27.9022, -26.9890]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 6989 1037 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  940\n",
      "191 1 False\n",
      "x_t:  4 [0.0125     0.39583333 0.109375   0.4       ]\n",
      "Q values:  tensor([[-31.4075, -30.5384, -34.1520, -30.1152, -27.6803, -28.9585]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35425 487 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1104\n",
      "191 5 False\n",
      "x_t:  2 [0.109375   0.39583333 0.0875     0.275     ]\n",
      "Q values:  tensor([[-27.2035, -25.8672, -24.5908, -27.1936, -25.7936, -25.4344]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12018 899 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  287\n",
      "191 10 False\n",
      "x_t:  3 [0.60625    0.29166667 0.090625   0.35      ]\n",
      "Q values:  tensor([[-26.0656, -25.8544, -27.9328, -24.9272, -25.7672, -25.4444]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5067 251 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1518\n",
      "191 12 True\n",
      "x_t:  2 [0.003125   0.4125     0.10625    0.27916667]\n",
      "Q values:  tensor([[-25.9273, -25.0351, -26.7800, -27.7396, -26.0092, -25.0276]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19379 746 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1053\n",
      "191 15 False\n",
      "x_t:  4 [0.071875   0.39166667 0.103125   0.3       ]\n",
      "Q values:  tensor([[-20.5827, -21.6355, -23.1152, -21.5566, -20.3936, -22.0549]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9824 591 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2800\n",
      "startIDX:  750\n",
      "192 0 True\n",
      "x_t:  1 [0.103125   0.35833333 0.14375    0.40416667]\n",
      "Q values:  tensor([[-23.3028, -22.1559, -25.1534, -22.1340, -19.9983, -21.0291]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9418 258 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 192: ep_len:258 episode reward: total was -185.000000. running mean: -351.262717\n",
      "startIDX:  359\n",
      "192 1 False\n",
      "x_t:  0 [0.765625   0.375      0.109375   0.39166667]\n",
      "Q values:  tensor([[-18.1082, -23.0488, -20.8943, -21.1351, -22.8568, -20.2259]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29109 794 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 192: ep_len:794 episode reward: total was -542.200000. running mean: -353.172090\n",
      "startIDX:  2325\n",
      "192 5 False\n",
      "x_t:  3 [0.178125   0.25       0.08125    0.30416667]\n",
      "Q values:  tensor([[-23.8184, -25.3666, -26.3412, -22.1715, -23.3718, -25.5890]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19985 206 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 192: ep_len:206 episode reward: total was -99.700000. running mean: -350.637369\n",
      "startIDX:  283\n",
      "192 10 True\n",
      "x_t:  3 [0.84375    0.33333333 0.146875   0.3875    ]\n",
      "Q values:  tensor([[-24.8963, -25.1775, -25.3494, -24.3174, -25.2971, -24.9415]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5035 248 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 192: ep_len:248 episode reward: total was -65.700000. running mean: -347.787995\n",
      "startIDX:  157\n",
      "192 12 False\n",
      "x_t:  2 [0.790625 0.4125   0.059375 0.2375  ]\n",
      "Q values:  tensor([[-31.6337, -33.9394, -28.4427, -31.9446, -30.8818, -31.4075]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2811 285 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 192: ep_len:285 episode reward: total was -216.100000. running mean: -346.471115\n",
      "startIDX:  463\n",
      "192 15 True\n",
      "x_t:  1 [0.796875   0.30416667 0.103125   0.27083333]\n",
      "Q values:  tensor([[-33.0494, -33.7997, -29.4402, -31.8443, -30.8966, -30.0903]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5177 757 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 192: ep_len:757 episode reward: total was -531.000000. running mean: -348.316404\n",
      "startIDX:  1231\n",
      "192 22 False\n",
      "x_t:  2 [0.796875   0.40416667 0.078125   0.25      ]\n",
      "Q values:  tensor([[-29.7555, -29.4906, -28.8916, -30.4987, -31.8337, -29.2240]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12588 332 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 192: ep_len:332 episode reward: total was -246.300000. running mean: -347.296240\n",
      "startIDX:  1831\n",
      "193 0 False\n",
      "x_t:  2 [0.0125     0.4125     0.1125     0.24166667]\n",
      "Q values:  tensor([[-28.4097, -30.1944, -24.2937, -28.1844, -29.9768, -24.3817]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18395 755 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  53\n",
      "193 1 False\n",
      "x_t:  3 [0.284375   0.25       0.1125     0.32083333]\n",
      "Q values:  tensor([[-16.2970, -18.0418, -17.2208, -14.3110, -17.2779, -17.3246]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25726 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2804\n",
      "193 5 False\n",
      "x_t:  0 [0.94375 0.3875  0.04375 0.3125 ]\n",
      "Q values:  tensor([[-25.8627, -26.8751, -28.4716, -26.7143, -27.7236, -28.5216]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23147 501 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2284\n",
      "193 10 False\n",
      "x_t:  1 [0.546875   0.30833333 0.128125   0.325     ]\n",
      "Q values:  tensor([[-29.5052, -25.8757, -27.4852, -26.1394, -28.3327, -28.1983]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22505 1262 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2016\n",
      "startIDX:  185\n",
      "193 15 False\n",
      "x_t:  2 [0.01875    0.4125     0.115625   0.33333333]\n",
      "Q values:  tensor([[-29.3590, -28.4141, -25.0982, -29.0199, -27.6330, -28.7828]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2196 791 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1498\n",
      "193 22 True\n",
      "x_t:  4 [0.003125   0.39583333 0.09375    0.30416667]\n",
      "Q values:  tensor([[-32.7647, -34.0476, -29.9587, -33.9619, -32.5841, -28.7450]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16324 527 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2006\n",
      "194 0 False\n",
      "x_t:  0 [0.853125   0.40416667 0.121875   0.34583333]\n",
      "Q values:  tensor([[-25.3281, -27.0202, -26.0149, -27.1406, -27.0225, -26.6295]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20632 850 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 194: ep_len:850 episode reward: total was -612.900000. running mean: -353.374758\n",
      "startIDX:  344\n",
      "194 1 False\n",
      "x_t:  1 [0.496875 0.3      0.240625 0.575   ]\n",
      "Q values:  tensor([[-33.1752, -26.1454, -27.1975, -31.6675, -30.9618, -30.4489]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28099 302 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 194: ep_len:302 episode reward: total was -217.700000. running mean: -352.018010\n",
      "startIDX:  486\n",
      "194 5 False\n",
      "x_t:  1 [0.675      0.29166667 0.121875   0.35833333]\n",
      "Q values:  tensor([[-27.7531, -24.8692, -28.6393, -26.6709, -26.1145, -29.1885]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5051 668 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 194: ep_len:668 episode reward: total was -482.500000. running mean: -353.322830\n",
      "startIDX:  2322\n",
      "194 10 True\n",
      "x_t:  1 [0.65625    0.29166667 0.0875     0.325     ]\n",
      "Q values:  tensor([[-23.8524, -23.7824, -25.1658, -22.1780, -22.5608, -22.9166]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22495 1243 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 194: ep_len:1243 episode reward: total was -793.900000. running mean: -357.728602\n",
      "startIDX:  2032\n",
      "ep 194: ep_len:18 episode reward: total was -10.000000. running mean: -354.251316\n",
      "startIDX:  1988\n",
      "194 15 True\n",
      "x_t:  1 [0.928125   0.29166667 0.06875    0.31666667]\n",
      "Q values:  tensor([[-27.1170, -31.0748, -27.1921, -28.7971, -31.8287, -27.0224]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14837 678 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 194: ep_len:678 episode reward: total was -463.000000. running mean: -355.338803\n",
      "startIDX:  686\n",
      "194 22 False\n",
      "x_t:  2 [0.003125   0.41666667 0.078125   0.25416667]\n",
      "Q values:  tensor([[-24.0956, -24.5836, -23.2149, -27.1201, -25.6210, -24.1059]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8914 878 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 194: ep_len:878 episode reward: total was -484.100000. running mean: -356.626415\n",
      "startIDX:  527\n",
      "195 0 False\n",
      "x_t:  3 [0.809375 0.375    0.109375 0.45    ]\n",
      "Q values:  tensor([[-22.5528, -25.8682, -24.9860, -22.5458, -24.3224, -24.4398]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 6997 1004 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  857\n",
      "195 1 False\n",
      "x_t:  4 [0.346875   0.36666667 0.08125    0.40833333]\n",
      "Q values:  tensor([[-25.8298, -27.8551, -27.1213, -28.4371, -25.7127, -25.9324]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35471 557 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2766\n",
      "195 5 False\n",
      "x_t:  0 [0.93125    0.3875     0.0625     0.30833333]\n",
      "Q values:  tensor([[-30.3539, -31.2935, -32.3275, -33.7487, -30.3549, -30.9464]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23151 509 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1833\n",
      "195 10 False\n",
      "x_t:  2 [0.096875   0.39583333 0.05625    0.25      ]\n",
      "Q values:  tensor([[-24.0177, -24.3010, -23.0795, -24.6585, -24.3255, -23.1969]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18160 843 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1277\n",
      "195 12 False\n",
      "x_t:  4 [0.165625   0.42916667 0.1375     0.35416667]\n",
      "Q values:  tensor([[-29.1673, -27.0929, -26.9360, -27.2704, -26.0639, -26.0949]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17407 473 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2405\n",
      "195 15 True\n",
      "x_t:  4 [0.1125     0.40833333 0.084375   0.35      ]\n",
      "Q values:  tensor([[-21.7454, -24.8753, -23.4373, -22.3614, -23.6486, -21.9228]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19263 502 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  95\n",
      "195 22 False\n",
      "x_t:  1 [0.934375   0.2875     0.0625     0.41666667]\n",
      "Q values:  tensor([[-21.8527, -19.4737, -21.6875, -21.1011, -20.6815, -20.6221]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1575 677 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1787\n",
      "196 0 False\n",
      "x_t:  2 [0.003125   0.40833333 0.103125   0.25      ]\n",
      "Q values:  tensor([[-15.9882, -18.3722, -15.6368, -17.7302, -17.0686, -16.2657]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18392 755 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 196: ep_len:755 episode reward: total was -406.800000. running mean: -358.936789\n",
      "startIDX:  942\n",
      "196 1 False\n",
      "x_t:  4 [0.040625   0.39166667 0.090625   0.40833333]\n",
      "Q values:  tensor([[-21.9512, -22.1096, -21.1172, -23.4181, -20.6720, -22.2483]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35428 499 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 196: ep_len:499 episode reward: total was -309.800000. running mean: -358.445421\n",
      "startIDX:  96\n",
      "196 5 False\n",
      "x_t:  2 [0.04375    0.3875     0.19375    0.42083333]\n",
      "Q values:  tensor([[-17.6083, -17.7185, -16.1777, -18.2685, -17.8460, -16.7769]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2060 901 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 196: ep_len:901 episode reward: total was -457.000000. running mean: -359.430967\n",
      "startIDX:  1217\n",
      "196 10 True\n",
      "x_t:  3 [0.134375   0.225      0.0625     0.27083333]\n",
      "Q values:  tensor([[-19.4371, -18.8240, -18.0533, -19.9262, -19.9730, -18.2244]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14598 1268 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 196: ep_len:1268 episode reward: total was -669.000000. running mean: -362.526657\n",
      "startIDX:  174\n",
      "196 12 True\n",
      "x_t:  3 [0.315625   0.29166667 0.1125     0.30416667]\n",
      "Q values:  tensor([[-18.9051, -17.4737, -17.6640, -19.4136, -18.3341, -17.3112]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5715 1452 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 196: ep_len:1452 episode reward: total was -786.500000. running mean: -366.766391\n",
      "startIDX:  1485\n",
      "196 15 False\n",
      "x_t:  2 [0.05       0.40416667 0.065625   0.25833333]\n",
      "Q values:  tensor([[-22.8172, -22.1984, -21.6421, -24.1711, -22.7779, -23.5759]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 11916 769 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 196: ep_len:769 episode reward: total was -377.100000. running mean: -366.869727\n",
      "startIDX:  1057\n",
      "196 22 False\n",
      "x_t:  1 [0.475      0.34583333 0.178125   0.48333333]\n",
      "Q values:  tensor([[-27.4250, -23.1475, -26.7614, -26.7320, -25.9098, -25.1793]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11948 765 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 196: ep_len:765 episode reward: total was -374.400000. running mean: -366.945030\n",
      "startIDX:  2140\n",
      "197 0 False\n",
      "x_t:  1 [0.8125     0.3        0.11875    0.52916667]\n",
      "Q values:  tensor([[-20.9763, -19.0329, -20.2735, -21.6596, -19.7053, -20.3302]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22924 1114 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  449\n",
      "197 1 False\n",
      "x_t:  1 [0.85625    0.26666667 0.140625   0.45833333]\n",
      "Q values:  tensor([[-25.0292, -22.3635, -25.2308, -23.6347, -25.7241, -22.6650]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30680 775 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  229\n",
      "197 5 False\n",
      "x_t:  1 [0.003125   0.37083333 0.190625   0.49583333]\n",
      "Q values:  tensor([[-24.7924, -23.8968, -24.0875, -24.2596, -27.6420, -24.0821]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2516 209 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  297\n",
      "197 10 True\n",
      "x_t:  3 [0.625      0.29583333 0.134375   0.36666667]\n",
      "Q values:  tensor([[-28.0417, -26.6602, -28.8225, -25.5537, -27.3367, -26.4597]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5061 247 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1975\n",
      "startIDX:  3057\n",
      "startIDX:  1168\n",
      "197 22 False\n",
      "x_t:  1 [0.75       0.31666667 0.090625   0.4875    ]\n",
      "Q values:  tensor([[-19.8841, -17.8704, -18.6868, -19.1258, -19.4150, -18.9257]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11929 697 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1103\n",
      "198 0 False\n",
      "x_t:  2 [0.7375     0.40833333 0.071875   0.28333333]\n",
      "Q values:  tensor([[-25.0478, -23.9577, -21.2496, -24.3842, -22.1191, -22.8082]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12642 348 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 198: ep_len:348 episode reward: total was -226.700000. running mean: -355.282037\n",
      "startIDX:  592\n",
      "198 1 True\n",
      "x_t:  2 [0.496875   0.38333333 0.103125   0.30833333]\n",
      "Q values:  tensor([[-24.8418, -23.2301, -23.2803, -25.1490, -23.2974, -23.7769]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31511 409 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 198: ep_len:409 episode reward: total was -270.300000. running mean: -354.432217\n",
      "startIDX:  2026\n",
      "198 5 False\n",
      "x_t:  3 [0.1125     0.25833333 0.0875     0.30416667]\n",
      "Q values:  tensor([[-23.7697, -22.3324, -20.4162, -19.2211, -21.5017, -19.8816]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18217 1241 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 198: ep_len:1241 episode reward: total was -719.000000. running mean: -358.077895\n",
      "startIDX:  968\n",
      "198 10 True\n",
      "x_t:  1 [0.88125    0.275      0.1125     0.34583333]\n",
      "Q values:  tensor([[-21.3784, -21.4379, -19.6000, -20.9061, -20.4355, -19.7044]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11325 1566 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 198: ep_len:1566 episode reward: total was -892.100000. running mean: -363.418116\n",
      "startIDX:  1446\n",
      "198 12 False\n",
      "x_t:  3 [0.09375    0.25       0.075      0.26666667]\n",
      "Q values:  tensor([[-31.2351, -30.1326, -31.3886, -28.7398, -28.9564, -30.9134]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17985 228 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 198: ep_len:228 episode reward: total was -150.400000. running mean: -361.287935\n",
      "startIDX:  1294\n",
      "198 15 False\n",
      "x_t:  3 [0.7125     0.325      0.096875   0.37083333]\n",
      "Q values:  tensor([[-28.8335, -28.1708, -28.6055, -25.9569, -28.0901, -26.0021]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10359 242 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 198: ep_len:242 episode reward: total was -81.800000. running mean: -358.493055\n",
      "startIDX:  2029\n",
      "198 22 False\n",
      "x_t:  1 [0.228125   0.34583333 0.125      0.38333333]\n",
      "Q values:  tensor([[-28.0674, -24.8819, -26.5661, -28.7941, -28.0584, -26.3440]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19016 248 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 198: ep_len:248 episode reward: total was -151.500000. running mean: -356.423125\n",
      "startIDX:  1519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 0 True\n",
      "x_t:  3 [0.80625    0.34583333 0.190625   0.42083333]\n",
      "Q values:  tensor([[-21.3043, -22.1840, -22.1489, -22.6671, -24.9924, -22.0691]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16816 247 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  452\n",
      "199 1 False\n",
      "x_t:  1 [0.75       0.275      0.165625   0.45416667]\n",
      "Q values:  tensor([[-22.1420, -21.8404, -23.5952, -23.6820, -25.0957, -23.5178]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30692 779 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  730\n",
      "199 5 False\n",
      "x_t:  3 [0.15       0.27083333 0.1125     0.33333333]\n",
      "Q values:  tensor([[-21.9547, -21.7361, -22.0733, -21.0676, -22.8615, -21.6422]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8775 1308 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  608\n",
      "199 10 False\n",
      "x_t:  2 [0.071875   0.4        0.065625   0.26666667]\n",
      "Q values:  tensor([[-20.1362, -19.9877, -18.8893, -19.9504, -20.4836, -19.6355]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6596 735 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1275\n",
      "199 12 True\n",
      "x_t:  4 [0.021875   0.43333333 0.125      0.3625    ]\n",
      "Q values:  tensor([[-23.5550, -24.9042, -26.3624, -25.1217, -24.1487, -22.6716]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17392 465 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  528\n",
      "199 15 False\n",
      "x_t:  1 [0.878125   0.29583333 0.096875   0.27916667]\n",
      "Q values:  tensor([[-24.6526, -22.9428, -22.9915, -23.0122, -24.3671, -24.2194]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5167 712 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2579\n",
      "199 22 False\n",
      "x_t:  3 [0.0625   0.2375   0.059375 0.2375  ]\n",
      "Q values:  tensor([[-22.2131, -22.6089, -24.6680, -21.3534, -23.3386, -22.7688]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26172 1222 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  1670.0595400333405\n",
      "startIDX:  2516\n",
      "ep 200: ep_len:36 episode reward: total was 24.000000. running mean: -358.840179\n",
      "startIDX:  516\n",
      "200 1 False\n",
      "x_t:  1 [0.85625    0.26666667 0.140625   0.45833333]\n",
      "Q values:  tensor([[-27.0456, -26.6337, -28.5683, -28.4949, -28.5712, -27.9423]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30680 757 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 200: ep_len:757 episode reward: total was -442.900000. running mean: -359.680777\n",
      "startIDX:  1654\n",
      "200 5 False\n",
      "x_t:  1 [0.846875   0.27916667 0.0875     0.325     ]\n",
      "Q values:  tensor([[-23.1605, -22.2142, -25.0009, -24.7942, -23.8627, -23.2024]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14926 664 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 200: ep_len:664 episode reward: total was -318.500000. running mean: -359.268969\n",
      "startIDX:  1342\n",
      "200 10 False\n",
      "x_t:  4 [0.028125   0.36666667 0.103125   0.275     ]\n",
      "Q values:  tensor([[-25.7736, -26.2527, -24.2910, -27.4907, -23.5459, -25.4962]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15710 560 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 200: ep_len:560 episode reward: total was -253.500000. running mean: -358.211280\n",
      "startIDX:  353\n",
      "200 12 False\n",
      "x_t:  4 [0.046875   0.44583333 0.14375    0.3625    ]\n",
      "Q values:  tensor([[-20.1133, -19.8271, -20.4318, -22.7191, -18.7397, -20.4313]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7189 710 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 200: ep_len:710 episode reward: total was -385.000000. running mean: -358.479167\n",
      "startIDX:  365\n",
      "200 15 False\n",
      "x_t:  1 [0.51875    0.34166667 0.196875   0.525     ]\n",
      "Q values:  tensor([[-27.2004, -24.3780, -28.2984, -27.9502, -27.7219, -25.2414]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2793 258 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 200: ep_len:258 episode reward: total was -161.100000. running mean: -356.505375\n",
      "startIDX:  864\n",
      "200 22 False\n",
      "x_t:  1 [0.01875    0.36666667 0.171875   0.39583333]\n",
      "Q values:  tensor([[-29.5538, -24.1232, -25.0892, -26.2586, -25.8478, -24.7736]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9487 265 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 200: ep_len:265 episode reward: total was -161.300000. running mean: -354.553321\n",
      "startIDX:  222\n",
      "201 0 False\n",
      "x_t:  2 [0.796875   0.39583333 0.046875   0.3       ]\n",
      "Q values:  tensor([[-22.0678, -22.4896, -21.1606, -23.2954, -21.4474, -21.3940]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2327 331 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  887\n",
      "201 1 False\n",
      "x_t:  4 [0.003125   0.39583333 0.11875    0.40833333]\n",
      "Q values:  tensor([[-22.3734, -21.5208, -22.1670, -25.2651, -20.0576, -22.4072]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35421 512 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1325\n",
      "201 5 False\n",
      "x_t:  1 [0.246875   0.32083333 0.071875   0.39166667]\n",
      "Q values:  tensor([[-25.9672, -24.4100, -25.2383, -26.6559, -25.9730, -24.8751]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12529 266 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  43\n",
      "201 10 False\n",
      "x_t:  3 [0.059375 0.2375   0.065625 0.25    ]\n",
      "Q values:  tensor([[-23.1012, -24.5792, -24.0150, -21.0365, -21.8519, -22.4723]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3580 1088 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  251\n",
      "201 12 False\n",
      "x_t:  3 [0.0875     0.25833333 0.071875   0.275     ]\n",
      "Q values:  tensor([[-21.5433, -22.8478, -21.6067, -21.1290, -22.6791, -22.1797]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5671 1355 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1930\n",
      "201 15 True\n",
      "x_t:  1 [0.828125   0.30833333 0.0875     0.29583333]\n",
      "Q values:  tensor([[-22.4089, -20.4195, -20.6349, -22.2563, -22.0984, -20.0424]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14849 700 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1153\n",
      "201 22 True\n",
      "x_t:  1 [0.75     0.325    0.178125 0.475   ]\n",
      "Q values:  tensor([[-21.7612, -21.9680, -24.3340, -22.6816, -23.0941, -21.6867]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11925 718 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  835\n",
      "202 0 True\n",
      "x_t:  1 [0.134375   0.35416667 0.134375   0.39583333]\n",
      "Q values:  tensor([[-21.3493, -22.1211, -23.7107, -24.4032, -22.8703, -21.3644]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9423 208 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 202: ep_len:208 episode reward: total was -128.500000. running mean: -353.736693\n",
      "startIDX:  130\n",
      "202 1 False\n",
      "x_t:  2 [0.1        0.35833333 0.103125   0.45416667]\n",
      "Q values:  tensor([[-21.3728, -22.2765, -19.6811, -20.8533, -20.7443, -20.6483]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27445 899 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 202: ep_len:899 episode reward: total was -438.200000. running mean: -354.581326\n",
      "startIDX:  879\n",
      "202 5 True\n",
      "x_t:  4 [0.003125   0.41666667 0.10625    0.37083333]\n",
      "Q values:  tensor([[-22.6861, -21.9868, -21.3204, -24.2240, -20.6432, -21.2624]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10011 562 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 202: ep_len:562 episode reward: total was -314.900000. running mean: -354.184513\n",
      "startIDX:  100\n",
      "202 10 True\n",
      "x_t:  3 [0.0625     0.23333333 0.065625   0.25416667]\n",
      "Q values:  tensor([[-26.8426, -25.0477, -27.0143, -24.2759, -27.0223, -25.9003]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3582 1061 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 202: ep_len:1061 episode reward: total was -593.900000. running mean: -356.581668\n",
      "startIDX:  1831\n",
      "202 12 False\n",
      "x_t:  0 [0.9125     0.40833333 0.08125    0.37083333]\n",
      "Q values:  tensor([[-23.2908, -28.8345, -27.6457, -26.7690, -23.8931, -24.2038]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21089 558 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 202: ep_len:558 episode reward: total was -332.700000. running mean: -356.342851\n",
      "startIDX:  2600\n",
      "202 15 True\n",
      "x_t:  2 [0.08125    0.40833333 0.121875   0.33333333]\n",
      "Q values:  tensor([[-22.1774, -22.4577, -19.6700, -22.3358, -22.5376, -20.1827]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21485 892 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 202: ep_len:892 episode reward: total was -421.400000. running mean: -356.993423\n",
      "startIDX:  2518\n",
      "202 22 False\n",
      "x_t:  3 [0.125      0.24583333 0.046875   0.25416667]\n",
      "Q values:  tensor([[-28.2305, -29.7634, -27.0597, -26.1903, -29.1914, -26.8245]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26192 1251 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 202: ep_len:1251 episode reward: total was -705.800000. running mean: -360.481489\n",
      "startIDX:  679\n",
      "203 0 True\n",
      "x_t:  2 [0.11875    0.4125     0.1        0.25833333]\n",
      "Q values:  tensor([[-28.3548, -29.0303, -27.6768, -30.0527, -28.0788, -25.3740]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8888 890 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  667\n",
      "203 1 False\n",
      "x_t:  3 [0.065625 0.225    0.065625 0.2875  ]\n",
      "Q values:  tensor([[-24.2008, -25.5517, -23.3906, -19.4925, -23.5188, -22.7231]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34304 1425 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  620\n",
      "203 5 False\n",
      "x_t:  2 [0.878125   0.3875     0.040625   0.22083333]\n",
      "Q values:  tensor([[-21.2786, -19.9521, -18.7013, -19.8668, -20.7803, -20.6842]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6021 438 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2282\n",
      "203 10 False\n",
      "x_t:  1 [0.8875  0.2875  0.10625 0.3375 ]\n",
      "Q values:  tensor([[-22.5296, -19.8495, -19.9588, -20.5633, -21.8151, -22.2588]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22469 1249 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1993\n",
      "startIDX:  3115\n",
      "startIDX:  258\n",
      "203 22 True\n",
      "x_t:  3 [0.0625     0.24166667 0.046875   0.23333333]\n",
      "Q values:  tensor([[-23.4818, -25.1905, -26.4257, -24.6340, -26.1195, -24.2073]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4868 1271 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1259\n",
      "204 0 False\n",
      "x_t:  3 [0.0625     0.25       0.059375   0.24583333]\n",
      "Q values:  tensor([[-27.6867, -28.7913, -27.6526, -27.5834, -28.1629, -28.3750]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15154 1232 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 204: ep_len:1232 episode reward: total was -747.700000. running mean: -368.882139\n",
      "startIDX:  603\n",
      "204 1 False\n",
      "x_t:  2 [0.6625     0.3875     0.109375   0.31666667]\n",
      "Q values:  tensor([[-24.9117, -25.7489, -24.1654, -26.4562, -26.8334, -24.4143]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31484 392 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 204: ep_len:392 episode reward: total was -283.000000. running mean: -368.023318\n",
      "startIDX:  2980\n",
      "ep 204: ep_len:47 episode reward: total was 4.100000. running mean: -364.302084\n",
      "startIDX:  1198\n",
      "204 10 True\n",
      "x_t:  3 [0.10625    0.23333333 0.06875    0.25833333]\n",
      "Q values:  tensor([[-30.5297, -30.1800, -27.7386, -30.1046, -29.5608, -24.7627]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14591 1280 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 204: ep_len:1280 episode reward: total was -838.700000. running mean: -369.046064\n",
      "startIDX:  991\n",
      "204 12 False\n",
      "x_t:  2 [0.734375   0.4125     0.0875     0.24583333]\n",
      "Q values:  tensor([[-27.0192, -26.5138, -24.1304, -27.4823, -26.1775, -26.7788]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13584 323 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 204: ep_len:323 episode reward: total was -236.000000. running mean: -367.715603\n",
      "startIDX:  356\n",
      "204 15 False\n",
      "x_t:  1 [0.003125   0.38333333 0.128125   0.48333333]\n",
      "Q values:  tensor([[-31.3083, -27.1523, -28.0342, -31.4086, -29.9810, -27.9279]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2752 243 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 204: ep_len:243 episode reward: total was -165.600000. running mean: -365.694447\n",
      "startIDX:  1294\n",
      "204 22 False\n",
      "x_t:  3 [0.1        0.25416667 0.06875    0.28333333]\n",
      "Q values:  tensor([[-28.0589, -29.8843, -30.6603, -26.4519, -31.0767, -28.8103]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15208 1330 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 204: ep_len:1330 episode reward: total was -874.600000. running mean: -370.783503\n",
      "startIDX:  2213\n",
      "205 0 True\n",
      "x_t:  1 [0.503125   0.33333333 0.2        0.5125    ]\n",
      "Q values:  tensor([[-25.8889, -24.4898, -25.4225, -27.5467, -23.2552, -24.9509]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22945 1102 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  264\n",
      "205 1 False\n",
      "x_t:  2 [0.19375    0.35833333 0.103125   0.4375    ]\n",
      "Q values:  tensor([[-23.3408, -22.9317, -22.8376, -23.1946, -24.9401, -23.2220]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27462 852 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1593\n",
      "205 5 False\n",
      "x_t:  1 [0.628125   0.29166667 0.053125   0.29583333]\n",
      "Q values:  tensor([[-32.4053, -27.0919, -27.9000, -32.3184, -30.9529, -29.3010]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14961 699 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1355\n",
      "205 10 True\n",
      "x_t:  4 [0.00625    0.36666667 0.1125     0.275     ]\n",
      "Q values:  tensor([[-33.6432, -33.7797, -31.4951, -30.7720, -31.4327, -30.7743]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15705 548 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2061\n",
      "startIDX:  2754\n",
      "205 15 False\n",
      "x_t:  2 [0.065625 0.4      0.065625 0.3375  ]\n",
      "Q values:  tensor([[-26.2762, -29.4845, -26.0868, -27.1056, -27.0596, -26.3764]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21481 824 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2961\n",
      "startIDX:  517\n",
      "206 0 False\n",
      "x_t:  3 [0.828125   0.37916667 0.1125     0.44166667]\n",
      "Q values:  tensor([[-26.3688, -27.4392, -29.1429, -26.2316, -26.9850, -27.6986]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 6996 1018 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 206: ep_len:1018 episode reward: total was -737.100000. running mean: -375.605091\n",
      "startIDX:  629\n",
      "206 1 True\n",
      "x_t:  2 [0.725      0.38333333 0.109375   0.3125    ]\n",
      "Q values:  tensor([[-29.3759, -29.6989, -27.8620, -31.1697, -32.0607, -28.3749]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31474 374 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 206: ep_len:374 episode reward: total was -293.400000. running mean: -374.783040\n",
      "startIDX:  859\n",
      "206 5 False\n",
      "x_t:  4 [0.01875    0.42083333 0.140625   0.35833333]\n",
      "Q values:  tensor([[-29.3337, -29.6560, -30.6722, -29.9531, -26.5218, -27.6187]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10014 578 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 206: ep_len:578 episode reward: total was -401.800000. running mean: -375.053210\n",
      "startIDX:  1695\n",
      "206 10 True\n",
      "x_t:  3 [0.721875   0.30416667 0.128125   0.3875    ]\n",
      "Q values:  tensor([[-29.4152, -30.2377, -30.4253, -30.9703, -32.4222, -29.2090]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16420 254 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 206: ep_len:254 episode reward: total was -149.700000. running mean: -372.799678\n",
      "startIDX:  219\n",
      "206 12 False\n",
      "x_t:  3 [0.11875    0.26666667 0.084375   0.28333333]\n",
      "Q values:  tensor([[-23.7316, -25.2721, -24.5344, -22.7464, -24.4464, -23.8006]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5678 1410 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 206: ep_len:1410 episode reward: total was -984.800000. running mean: -378.919681\n",
      "startIDX:  3\n",
      "206 15 True\n",
      "x_t:  3 [0.75       0.34166667 0.1375     0.43333333]\n",
      "Q values:  tensor([[-28.4070, -28.7316, -28.8967, -30.7989, -31.5709, -28.5295]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 531 247 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 206: ep_len:247 episode reward: total was -122.100000. running mean: -376.351484\n",
      "startIDX:  2861\n",
      "ep 206: ep_len:76 episode reward: total was 54.000000. running mean: -372.047969\n",
      "startIDX:  1551\n",
      "207 0 False\n",
      "x_t:  3 [0.590625   0.32916667 0.146875   0.38333333]\n",
      "Q values:  tensor([[-32.0140, -33.3752, -33.4585, -30.5628, -32.6567, -34.9228]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16842 240 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  609\n",
      "207 1 False\n",
      "x_t:  2 [0.78125    0.37083333 0.084375   0.33333333]\n",
      "Q values:  tensor([[-33.5676, -34.1901, -30.9111, -32.6719, -35.3030, -31.2641]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31468 381 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  911\n",
      "207 5 False\n",
      "x_t:  3 [0.709375   0.31666667 0.184375   0.39166667]\n",
      "Q values:  tensor([[-33.1204, -35.4676, -32.7517, -29.8969, -33.2505, -31.3873]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10498 245 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  624\n",
      "207 10 False\n",
      "x_t:  2 [0.13125    0.40416667 0.06875    0.25833333]\n",
      "Q values:  tensor([[-27.4320, -25.1910, -24.7841, -28.9749, -27.7895, -24.9869]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6605 729 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  961\n",
      "207 12 False\n",
      "x_t:  1 [0.83125    0.35833333 0.165625   0.5125    ]\n",
      "Q values:  tensor([[-30.4695, -28.7691, -31.9107, -31.1262, -31.2070, -30.1461]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12914 595 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  156\n",
      "207 15 True\n",
      "x_t:  2 [0.159375   0.39583333 0.071875   0.34583333]\n",
      "Q values:  tensor([[-28.6320, -26.0745, -27.4848, -26.6116, -27.7466, -25.1441]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2213 812 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1700\n",
      "207 22 False\n",
      "x_t:  3 [0.615625   0.32083333 0.14375    0.37916667]\n",
      "Q values:  tensor([[-28.8367, -27.5096, -30.9208, -26.7370, -30.1912, -29.0455]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16879 215 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  131\n",
      "208 0 False\n",
      "x_t:  1 [0.85625    0.3        0.121875   0.42916667]\n",
      "Q values:  tensor([[-29.5030, -28.2882, -32.3640, -29.9770, -30.6981, -28.4758]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1613 696 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 208: ep_len:696 episode reward: total was -404.800000. running mean: -365.511098\n",
      "startIDX:  825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208 1 False\n",
      "x_t:  4 [0.003125 0.4      0.121875 0.4     ]\n",
      "Q values:  tensor([[-27.0311, -26.3258, -26.3764, -25.4105, -24.3747, -26.1683]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35423 550 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 208: ep_len:550 episode reward: total was -239.400000. running mean: -364.249987\n",
      "startIDX:  2730\n",
      "208 5 False\n",
      "x_t:  1 [0.01875  0.35     0.128125 0.525   ]\n",
      "Q values:  tensor([[-26.7167, -25.6594, -27.0971, -28.6650, -29.8226, -26.4503]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22107 220 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 208: ep_len:220 episode reward: total was -130.400000. running mean: -361.911487\n",
      "startIDX:  2429\n",
      "208 10 True\n",
      "x_t:  1 [0.66875    0.30416667 0.1        0.31666667]\n",
      "Q values:  tensor([[-24.3472, -22.9111, -25.3000, -22.1281, -23.9379, -20.8144]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22494 1190 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 208: ep_len:1190 episode reward: total was -561.700000. running mean: -363.909372\n",
      "startIDX:  419\n",
      "208 12 False\n",
      "x_t:  3 [0.265625 0.2875   0.11875  0.3     ]\n",
      "Q values:  tensor([[-21.8756, -21.4944, -22.1616, -19.8540, -20.5982, -20.9584]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7792 287 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 208: ep_len:287 episode reward: total was -126.000000. running mean: -361.530278\n",
      "startIDX:  149\n",
      "208 15 False\n",
      "x_t:  2 [0.053125 0.4      0.090625 0.3375  ]\n",
      "Q values:  tensor([[-22.2894, -22.2648, -20.1434, -22.8162, -21.6289, -20.6755]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2201 829 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 208: ep_len:829 episode reward: total was -358.400000. running mean: -361.498976\n",
      "startIDX:  976\n",
      "208 22 False\n",
      "x_t:  0 [0.7625     0.4125     0.1125     0.32083333]\n",
      "Q values:  tensor([[-20.7669, -21.0887, -20.9158, -22.7223, -21.4943, -20.7846]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10418 456 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 208: ep_len:456 episode reward: total was -252.100000. running mean: -360.404986\n",
      "startIDX:  2238\n",
      "209 0 False\n",
      "x_t:  2 [0.878125   0.40416667 0.05625    0.17916667]\n",
      "Q values:  tensor([[-21.6311, -20.5706, -19.0610, -20.9742, -21.2578, -19.6338]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23576 317 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  536\n",
      "209 1 False\n",
      "x_t:  1 [0.740625   0.275      0.096875   0.45416667]\n",
      "Q values:  tensor([[-20.5649, -20.0824, -21.6000, -22.0098, -21.2846, -20.1145]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30698 754 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1833\n",
      "209 5 True\n",
      "x_t:  2 [0.778125   0.39583333 0.0875     0.2625    ]\n",
      "Q values:  tensor([[-18.7695, -18.6052, -20.3401, -19.1373, -20.6762, -18.7780]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15653 349 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1279\n",
      "209 10 False\n",
      "x_t:  3 [0.165625   0.22916667 0.065625   0.27083333]\n",
      "Q values:  tensor([[-25.2450, -24.0339, -25.7428, -23.8724, -25.5716, -24.7277]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14607 1209 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  167\n",
      "209 12 True\n",
      "x_t:  2 [0.275      0.40416667 0.065625   0.25      ]\n",
      "Q values:  tensor([[-22.2770, -22.9934, -22.3008, -22.6935, -23.9741, -22.8946]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2888 298 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2766\n",
      "209 15 True\n",
      "x_t:  1 [0.259375   0.35833333 0.115625   0.51666667]\n",
      "Q values:  tensor([[-24.9725, -23.6641, -23.1692, -22.2642, -24.8684, -23.9747]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22057 285 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2850\n",
      "Time elapsed:  1758.2849349975586\n",
      "startIDX:  960\n",
      "210 0 False\n",
      "x_t:  1 [0.809375   0.30416667 0.175      0.43333333]\n",
      "Q values:  tensor([[-24.5577, -23.6441, -24.1773, -24.5043, -25.6953, -25.2432]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11950 815 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 210: ep_len:815 episode reward: total was -491.800000. running mean: -354.256264\n",
      "startIDX:  17\n",
      "210 1 False\n",
      "x_t:  3 [0.534375   0.26666667 0.10625    0.37916667]\n",
      "Q values:  tensor([[-19.7487, -18.8591, -20.6613, -17.5272, -20.2316, -19.9170]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25680 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 210: ep_len:200 episode reward: total was -67.300000. running mean: -351.386702\n",
      "startIDX:  307\n",
      "210 5 False\n",
      "x_t:  0 [0.803125   0.39583333 0.1375     0.36666667]\n",
      "Q values:  tensor([[-22.8373, -26.0254, -25.0423, -24.5015, -24.5069, -23.0801]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3568 500 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 210: ep_len:500 episode reward: total was -327.500000. running mean: -351.147835\n",
      "startIDX:  1089\n",
      "210 10 True\n",
      "x_t:  2 [0.8375     0.39583333 0.053125   0.25      ]\n",
      "Q values:  tensor([[-21.0476, -21.3916, -20.8733, -22.3166, -23.0414, -21.4576]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12058 349 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 210: ep_len:349 episode reward: total was -209.600000. running mean: -349.732356\n",
      "startIDX:  1038\n",
      "210 12 False\n",
      "x_t:  2 [0.8875     0.39166667 0.0625     0.22083333]\n",
      "Q values:  tensor([[-24.9983, -24.6679, -24.5586, -24.7216, -25.7962, -26.7595]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13565 294 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 210: ep_len:294 episode reward: total was -172.300000. running mean: -347.958033\n",
      "startIDX:  2568\n",
      "210 15 False\n",
      "x_t:  3 [0.29375    0.25833333 0.065625   0.26666667]\n",
      "Q values:  tensor([[-29.3946, -27.9009, -29.3870, -25.1066, -27.4447, -25.8384]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19766 206 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 210: ep_len:206 episode reward: total was -141.100000. running mean: -345.889452\n",
      "startIDX:  2254\n",
      "210 22 True\n",
      "x_t:  1 [0.86875    0.3        0.128125   0.44583333]\n",
      "Q values:  tensor([[-25.4075, -24.1996, -23.7987, -24.4845, -22.4876, -22.0471]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22930 1084 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 210: ep_len:1084 episode reward: total was -619.400000. running mean: -348.624558\n",
      "startIDX:  115\n",
      "211 0 True\n",
      "x_t:  1 [0.86875    0.3        0.128125   0.42916667]\n",
      "Q values:  tensor([[-23.3423, -23.2393, -25.9719, -24.1608, -22.2218, -22.9646]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1607 689 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  867\n",
      "211 1 False\n",
      "x_t:  4 [0.096875   0.37916667 0.134375   0.4125    ]\n",
      "Q values:  tensor([[-28.2008, -24.3524, -25.9944, -26.3186, -24.3069, -24.4056]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35439 539 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  779\n",
      "211 5 False\n",
      "x_t:  4 [0.003125   0.41666667 0.13125    0.37083333]\n",
      "Q values:  tensor([[-28.0985, -27.4351, -26.0451, -26.8224, -24.0563, -25.9499]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10012 623 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2103\n",
      "211 10 False\n",
      "x_t:  0 [0.865625 0.3875   0.05625  0.35    ]\n",
      "Q values:  tensor([[-26.1386, -26.9216, -27.9933, -26.2065, -27.4457, -26.8612]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19943 567 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  567\n",
      "211 12 False\n",
      "x_t:  2 [0.10625    0.41666667 0.08125    0.25833333]\n",
      "Q values:  tensor([[-28.6749, -28.9112, -25.6224, -27.0025, -27.3082, -26.6238]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9844 1030 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  490\n",
      "211 15 False\n",
      "x_t:  1 [0.9375     0.29583333 0.053125   0.27083333]\n",
      "Q values:  tensor([[-31.0630, -28.4052, -29.5388, -30.1936, -29.2495, -28.8370]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5162 741 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1177\n",
      "211 22 False\n",
      "x_t:  1 [0.4125     0.32916667 0.096875   0.50833333]\n",
      "Q values:  tensor([[-26.9518, -25.1431, -25.6316, -27.7071, -25.5539, -25.2683]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11955 718 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1535\n",
      "212 0 False\n",
      "x_t:  3 [0.734375   0.32916667 0.125      0.4125    ]\n",
      "Q values:  tensor([[-27.5074, -26.7174, -26.6128, -25.5760, -27.0330, -26.1198]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16826 241 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 212: ep_len:241 episode reward: total was -111.000000. running mean: -350.398140\n",
      "startIDX:  399\n",
      "212 1 False\n",
      "x_t:  0 [0.915625   0.375      0.06875    0.39583333]\n",
      "Q values:  tensor([[-21.1100, -23.5069, -21.9017, -23.4602, -23.0107, -21.5180]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29090 499 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 212: ep_len:499 episode reward: total was -331.200000. running mean: -350.206159\n",
      "startIDX:  1102\n",
      "212 5 False\n",
      "x_t:  3 [0.065625   0.22083333 0.075      0.25416667]\n",
      "Q values:  tensor([[-22.2739, -22.2726, -23.8459, -21.5499, -21.6377, -22.4715]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10614 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 212: ep_len:200 episode reward: total was -136.000000. running mean: -348.064097\n",
      "startIDX:  1076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212 10 False\n",
      "x_t:  2 [0.803125   0.4        0.084375   0.24583333]\n",
      "Q values:  tensor([[-23.8462, -22.3756, -21.1188, -23.7976, -23.1578, -23.0942]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12060 362 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 212: ep_len:362 episode reward: total was -255.500000. running mean: -347.138456\n",
      "startIDX:  949\n",
      "212 12 False\n",
      "x_t:  1 [0.525      0.35833333 0.146875   0.5125    ]\n",
      "Q values:  tensor([[-28.3740, -27.5151, -27.9409, -29.7844, -28.2180, -28.1513]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12932 614 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 212: ep_len:614 episode reward: total was -411.200000. running mean: -347.779072\n",
      "startIDX:  1364\n",
      "212 15 False\n",
      "x_t:  3 [0.540625   0.29166667 0.075      0.325     ]\n",
      "Q values:  tensor([[-23.7928, -24.0637, -25.7426, -23.4128, -24.2450, -24.2660]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10393 224 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 212: ep_len:224 episode reward: total was -144.200000. running mean: -345.743281\n",
      "startIDX:  218\n",
      "212 22 True\n",
      "x_t:  2 [0.74375    0.40833333 0.071875   0.24166667]\n",
      "Q values:  tensor([[-31.1289, -26.8367, -28.0989, -29.2508, -30.1132, -29.1597]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2289 329 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 212: ep_len:329 episode reward: total was -250.200000. running mean: -344.787848\n",
      "startIDX:  1128\n",
      "213 0 False\n",
      "x_t:  2 [0.715625   0.40833333 0.09375    0.28333333]\n",
      "Q values:  tensor([[-27.1782, -28.3842, -26.4971, -29.6089, -29.0172, -26.9024]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12643 333 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  104\n",
      "213 1 True\n",
      "x_t:  3 [0.121875   0.225      0.071875   0.28333333]\n",
      "Q values:  tensor([[-27.7779, -27.3781, -28.4642, -28.4781, -26.7692, -27.3305]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25775 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2025\n",
      "213 5 False\n",
      "x_t:  3 [0.1        0.25416667 0.1        0.30833333]\n",
      "Q values:  tensor([[-32.2836, -34.9408, -32.9771, -30.5109, -34.8111, -31.8171]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18213 1235 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2226\n",
      "213 10 False\n",
      "x_t:  0 [0.909375   0.39166667 0.08125    0.35416667]\n",
      "Q values:  tensor([[-24.9688, -28.4042, -31.8464, -27.9893, -27.1433, -26.8238]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19928 492 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1439\n",
      "213 12 False\n",
      "x_t:  3 [0.38125  0.2875   0.071875 0.325   ]\n",
      "Q values:  tensor([[-31.3798, -29.6371, -30.1714, -28.5772, -29.9333, -31.7803]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17915 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1684\n",
      "213 15 False\n",
      "x_t:  1 [0.134375   0.35416667 0.125      0.3875    ]\n",
      "Q values:  tensor([[-28.2841, -28.1636, -34.4327, -28.6839, -31.3473, -29.9823]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12459 248 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1588\n",
      "213 22 False\n",
      "x_t:  3 [0.85   0.3375 0.075  0.425 ]\n",
      "Q values:  tensor([[-29.7855, -26.3277, -29.5370, -25.8940, -26.6961, -29.3016]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16850 251 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1250\n",
      "214 0 False\n",
      "x_t:  3 [0.0625     0.24166667 0.06875    0.2625    ]\n",
      "Q values:  tensor([[-27.9039, -27.4172, -27.1328, -26.4980, -27.8550, -27.7066]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15158 1242 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 214: ep_len:1242 episode reward: total was -870.800000. running mean: -346.555945\n",
      "startIDX:  999\n",
      "214 1 True\n",
      "x_t:  3 [0.878125   0.30833333 0.115625   0.42916667]\n",
      "Q values:  tensor([[-31.2084, -33.5355, -33.6896, -33.0490, -28.6904, -30.9214]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35894 229 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 214: ep_len:229 episode reward: total was -88.500000. running mean: -343.975386\n",
      "startIDX:  1405\n",
      "214 5 False\n",
      "x_t:  1 [0.14375    0.32916667 0.10625    0.4       ]\n",
      "Q values:  tensor([[-31.5618, -29.0617, -33.3317, -33.6171, -32.8193, -33.0659]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12519 217 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 214: ep_len:217 episode reward: total was -159.500000. running mean: -342.130632\n",
      "startIDX:  1965\n",
      "214 10 False\n",
      "x_t:  1 [0.003125   0.35833333 0.10625    0.40416667]\n",
      "Q values:  tensor([[-29.3006, -28.1957, -29.8292, -28.4825, -29.0443, -28.3380]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18807 314 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 214: ep_len:314 episode reward: total was -217.900000. running mean: -340.888326\n",
      "startIDX:  1792\n",
      "214 12 True\n",
      "x_t:  0 [0.484375 0.4125   0.14375  0.35    ]\n",
      "Q values:  tensor([[-23.8677, -26.5453, -25.3917, -25.0041, -25.5775, -25.5418]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21140 607 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 214: ep_len:607 episode reward: total was -380.000000. running mean: -341.279442\n",
      "startIDX:  327\n",
      "214 15 False\n",
      "x_t:  1 [0.159375   0.37083333 0.125      0.5       ]\n",
      "Q values:  tensor([[-27.4070, -25.0818, -27.2252, -29.2241, -27.2538, -27.2752]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2763 259 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 214: ep_len:259 episode reward: total was -158.100000. running mean: -339.447648\n",
      "startIDX:  1371\n",
      "214 22 False\n",
      "x_t:  3 [0.1125     0.26666667 0.078125   0.28333333]\n",
      "Q values:  tensor([[-22.5009, -25.5432, -22.8711, -21.8562, -21.9635, -22.9022]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15215 1277 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 214: ep_len:1277 episode reward: total was -822.400000. running mean: -344.277171\n",
      "startIDX:  2310\n",
      "215 0 True\n",
      "x_t:  3 [0.14375    0.24583333 0.065625   0.25833333]\n",
      "Q values:  tensor([[-31.8385, -28.1820, -30.2287, -30.0104, -27.9933, -29.4799]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26116 1274 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  560\n",
      "215 1 False\n",
      "x_t:  1 [0.73125    0.27916667 0.121875   0.44583333]\n",
      "Q values:  tensor([[-30.3235, -26.9521, -30.3980, -27.1684, -30.8708, -27.7562]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30697 747 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2864\n",
      "startIDX:  834\n",
      "215 10 True\n",
      "x_t:  0 [0.896875   0.39166667 0.059375   0.32916667]\n",
      "Q values:  tensor([[-25.4198, -25.0170, -26.4774, -23.8348, -23.7526, -23.5624]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8110 482 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  37\n",
      "215 12 False\n",
      "x_t:  1 [0.015625   0.38333333 0.103125   0.475     ]\n",
      "Q values:  tensor([[-27.2451, -25.7417, -26.8897, -26.8052, -26.2028, -25.9387]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2284 669 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  458\n",
      "215 15 False\n",
      "x_t:  1 [0.95625    0.29166667 0.040625   0.2875    ]\n",
      "Q values:  tensor([[-21.2601, -19.2297, -20.5584, -19.2673, -21.1423, -21.1324]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5160 741 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2090\n",
      "215 22 False\n",
      "x_t:  1 [0.228125   0.34583333 0.125      0.38333333]\n",
      "Q values:  tensor([[-28.2798, -26.4393, -26.6685, -29.6705, -27.5425, -26.4527]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19016 215 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1827\n",
      "216 0 False\n",
      "x_t:  2 [0.003125   0.40416667 0.053125   0.25416667]\n",
      "Q values:  tensor([[-17.3885, -17.5917, -17.2287, -18.3082, -18.9017, -18.1373]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18390 749 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 216: ep_len:749 episode reward: total was -413.500000. running mean: -343.990133\n",
      "startIDX:  734\n",
      "216 1 False\n",
      "x_t:  3 [0.0625     0.23333333 0.059375   0.275     ]\n",
      "Q values:  tensor([[-21.7435, -21.0017, -20.9236, -18.9725, -19.7198, -20.4319]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34301 1383 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 216: ep_len:1383 episode reward: total was -805.500000. running mean: -348.605232\n",
      "startIDX:  2861\n",
      "ep 216: ep_len:107 episode reward: total was 51.000000. running mean: -344.609180\n",
      "startIDX:  1450\n",
      "216 10 True\n",
      "x_t:  4 [0.134375   0.36666667 0.071875   0.2625    ]\n",
      "Q values:  tensor([[-25.3947, -26.0125, -25.7279, -24.6746, -26.2169, -24.0702]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15725 504 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 216: ep_len:504 episode reward: total was -304.000000. running mean: -344.203088\n",
      "startIDX:  1387\n",
      "216 12 False\n",
      "x_t:  3 [0.684375   0.35       0.14375    0.42916667]\n",
      "Q values:  tensor([[-19.1031, -20.2318, -19.4301, -18.1400, -20.4017, -19.9280]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17861 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 216: ep_len:204 episode reward: total was -81.800000. running mean: -341.579057\n",
      "startIDX:  1361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216 15 False\n",
      "x_t:  3 [0.796875   0.33333333 0.1        0.38333333]\n",
      "Q values:  tensor([[-23.9649, -25.8075, -25.9126, -22.2517, -24.6889, -23.3418]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10347 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 216: ep_len:200 episode reward: total was -73.000000. running mean: -338.893266\n",
      "startIDX:  181\n",
      "216 22 False\n",
      "x_t:  2 [0.803125   0.40416667 0.046875   0.25      ]\n",
      "Q values:  tensor([[-23.6356, -22.4737, -22.2269, -25.6667, -24.1284, -23.0431]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2283 336 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 216: ep_len:336 episode reward: total was -222.600000. running mean: -337.730334\n",
      "startIDX:  2243\n",
      "217 0 True\n",
      "x_t:  2 [0.878125   0.40416667 0.05625    0.17916667]\n",
      "Q values:  tensor([[-20.1779, -21.2144, -20.3071, -22.6101, -19.6241, -20.3364]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23576 326 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  301\n",
      "217 1 False\n",
      "x_t:  1 [0.63125    0.29166667 0.18125    0.57916667]\n",
      "Q values:  tensor([[-27.2066, -25.3867, -26.5719, -27.5009, -25.4921, -25.6539]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28106 322 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  397\n",
      "217 5 True\n",
      "x_t:  1 [0.8625     0.28333333 0.084375   0.3875    ]\n",
      "Q values:  tensor([[-20.0317, -23.3951, -21.5365, -22.0059, -21.2496, -21.3878]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5031 699 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1498\n",
      "217 10 False\n",
      "x_t:  3 [0.846875   0.33333333 0.146875   0.4       ]\n",
      "Q values:  tensor([[-23.9264, -23.2929, -23.3365, -22.9939, -23.1829, -23.7014]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16402 345 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1798\n",
      "217 12 False\n",
      "x_t:  0 [0.64375    0.41666667 0.10625    0.3375    ]\n",
      "Q values:  tensor([[-20.2444, -23.0128, -22.3615, -22.2604, -21.8917, -21.5618]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21125 602 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  766\n",
      "217 15 False\n",
      "x_t:  2 [0.765625   0.40416667 0.084375   0.29583333]\n",
      "Q values:  tensor([[-24.0847, -27.4804, -23.3848, -25.4403, -26.6499, -24.2596]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5972 352 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1955\n",
      "217 22 False\n",
      "x_t:  2 [0.009375   0.40833333 0.08125    0.27083333]\n",
      "Q values:  tensor([[-24.9363, -24.5987, -21.6448, -21.8724, -24.9853, -22.5698]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18455 720 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  574\n",
      "218 0 False\n",
      "x_t:  2 [0.003125   0.40833333 0.053125   0.27083333]\n",
      "Q values:  tensor([[-28.8985, -27.8481, -25.7656, -29.9565, -29.4894, -28.8711]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8868 937 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 218: ep_len:937 episode reward: total was -562.600000. running mean: -337.099122\n",
      "startIDX:  682\n",
      "218 1 False\n",
      "x_t:  3 [0.078125   0.22916667 0.06875    0.29166667]\n",
      "Q values:  tensor([[-34.1852, -37.3811, -34.8491, -34.1257, -37.9048, -35.0673]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34307 1420 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 218: ep_len:1420 episode reward: total was -968.700000. running mean: -343.415131\n",
      "startIDX:  421\n",
      "218 5 False\n",
      "x_t:  1 [0.8625     0.28333333 0.084375   0.3875    ]\n",
      "Q values:  tensor([[-33.3613, -30.7569, -32.0743, -31.3506, -35.3465, -31.2819]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5031 676 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 218: ep_len:676 episode reward: total was -430.500000. running mean: -344.285980\n",
      "startIDX:  766\n",
      "218 10 False\n",
      "x_t:  1 [0.20625    0.325      0.084375   0.36666667]\n",
      "Q values:  tensor([[-30.7883, -28.7600, -31.6525, -30.9456, -31.6674, -32.3464]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7125 225 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 218: ep_len:225 episode reward: total was -142.000000. running mean: -342.263120\n",
      "startIDX:  497\n",
      "218 12 True\n",
      "x_t:  3 [0.78125    0.3375     0.06875    0.41666667]\n",
      "Q values:  tensor([[-27.9443, -26.7573, -28.4701, -29.8941, -31.0574, -27.5420]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7724 213 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 218: ep_len:213 episode reward: total was -131.000000. running mean: -340.150489\n",
      "startIDX:  2353\n",
      "218 15 False\n",
      "x_t:  4 [0.24375    0.38333333 0.08125    0.3       ]\n",
      "Q values:  tensor([[-30.3943, -27.5250, -29.4307, -28.2368, -26.7558, -28.5415]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19291 541 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 218: ep_len:541 episode reward: total was -303.900000. running mean: -339.787984\n",
      "startIDX:  56\n",
      "218 22 True\n",
      "x_t:  1 [0.85       0.30416667 0.13125    0.40416667]\n",
      "Q values:  tensor([[-24.5380, -27.6698, -25.4617, -24.8864, -25.3065, -22.2087]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1582 706 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 218: ep_len:706 episode reward: total was -411.500000. running mean: -340.505104\n",
      "startIDX:  1664\n",
      "219 0 False\n",
      "x_t:  3 [0.2875     0.27916667 0.103125   0.30833333]\n",
      "Q values:  tensor([[-24.5510, -24.7023, -26.2236, -23.7067, -27.2516, -25.1745]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16899 212 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  648\n",
      "219 1 True\n",
      "x_t:  2 [0.809375   0.38333333 0.071875   0.30833333]\n",
      "Q values:  tensor([[-25.7669, -26.8271, -27.1288, -27.2308, -27.9650, -24.7314]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31465 352 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1687\n",
      "219 5 False\n",
      "x_t:  1 [0.846875   0.27916667 0.0875     0.325     ]\n",
      "Q values:  tensor([[-27.7985, -25.2499, -27.3721, -27.3681, -27.6821, -25.5510]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14926 629 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  918\n",
      "219 10 False\n",
      "x_t:  1 [0.940625   0.27916667 0.05625    0.34166667]\n",
      "Q values:  tensor([[-23.8275, -22.4170, -25.3532, -23.4161, -23.1979, -23.0694]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11322 1587 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1246\n",
      "219 12 True\n",
      "x_t:  4 [0.165625   0.42916667 0.15625    0.35      ]\n",
      "Q values:  tensor([[-30.5323, -29.7218, -30.6816, -29.3313, -32.2661, -29.4515]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17409 495 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3080\n",
      "startIDX:  297\n",
      "219 22 False\n",
      "x_t:  3 [0.0625     0.24166667 0.046875   0.23333333]\n",
      "Q values:  tensor([[-28.8972, -26.0856, -27.8232, -25.9455, -30.9884, -26.6828]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4868 1244 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  1838.632083415985\n",
      "startIDX:  819\n",
      "220 0 True\n",
      "x_t:  1 [0.003125   0.36666667 0.1125     0.40416667]\n",
      "Q values:  tensor([[-32.2849, -29.8018, -30.1219, -32.1391, -32.6014, -29.8123]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9405 219 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 220: ep_len:219 episode reward: total was -134.500000. running mean: -342.059552\n",
      "startIDX:  546\n",
      "220 1 False\n",
      "x_t:  1 [0.6875     0.27083333 0.109375   0.4625    ]\n",
      "Q values:  tensor([[-31.2727, -26.6951, -29.7233, -27.8401, -28.0286, -28.2521]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30700 739 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 220: ep_len:739 episode reward: total was -475.100000. running mean: -343.389956\n",
      "startIDX:  2986\n",
      "ep 220: ep_len:43 episode reward: total was 11.000000. running mean: -339.846057\n",
      "startIDX:  1857\n",
      "220 10 False\n",
      "x_t:  2 [0.05       0.39583333 0.09375    0.25      ]\n",
      "Q values:  tensor([[-29.7622, -26.7205, -24.4871, -26.7016, -27.6762, -25.0995]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18152 827 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 220: ep_len:827 episode reward: total was -470.000000. running mean: -341.147596\n",
      "startIDX:  1968\n",
      "ep 220: ep_len:61 episode reward: total was 15.000000. running mean: -337.586120\n",
      "startIDX:  2998\n",
      "ep 220: ep_len:87 episode reward: total was 57.000000. running mean: -333.640259\n",
      "startIDX:  939\n",
      "220 22 False\n",
      "x_t:  1 [0.375      0.32083333 0.103125   0.425     ]\n",
      "Q values:  tensor([[-29.2597, -28.2444, -30.9897, -29.3054, -32.2730, -28.7622]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9520 240 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 220: ep_len:240 episode reward: total was -147.700000. running mean: -331.780856\n",
      "startIDX:  1513\n",
      "221 0 False\n",
      "x_t:  3 [0.734375   0.32916667 0.125      0.4125    ]\n",
      "Q values:  tensor([[-24.3429, -24.4419, -26.6119, -23.6353, -25.3946, -24.2429]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16826 256 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  468\n",
      "221 1 False\n",
      "x_t:  1 [0.85625    0.26666667 0.140625   0.4625    ]\n",
      "Q values:  tensor([[-27.8525, -25.6341, -28.6309, -26.4657, -27.8881, -25.9354]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30679 774 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  1854\n",
      "221 5 False\n",
      "x_t:  2 [0.76875    0.39583333 0.078125   0.25416667]\n",
      "Q values:  tensor([[-26.0516, -24.0545, -21.8744, -24.0221, -24.8587, -25.0044]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15656 348 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1844\n",
      "221 10 False\n",
      "x_t:  2 [0.05       0.39583333 0.0875     0.25416667]\n",
      "Q values:  tensor([[-26.1418, -24.6605, -23.5199, -25.5188, -27.1463, -23.7962]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18151 838 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  417\n",
      "221 12 False\n",
      "x_t:  3 [0.40625    0.29166667 0.071875   0.32916667]\n",
      "Q values:  tensor([[-24.2638, -23.9512, -23.4824, -23.1437, -23.7699, -23.8325]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7773 279 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1282\n",
      "221 15 True\n",
      "x_t:  3 [0.75       0.33333333 0.128125   0.375     ]\n",
      "Q values:  tensor([[-23.3808, -20.7383, -21.8303, -22.1744, -23.1634, -20.4954]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10353 250 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1715\n",
      "221 22 False\n",
      "x_t:  3 [0.428125   0.29166667 0.084375   0.325     ]\n",
      "Q values:  tensor([[-22.2665, -23.9271, -23.1511, -20.7679, -22.8977, -21.4733]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16911 218 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  51\n",
      "222 0 False\n",
      "x_t:  1 [0.615625   0.31666667 0.146875   0.41666667]\n",
      "Q values:  tensor([[-18.9461, -16.8320, -18.1074, -20.3179, -17.8071, -17.6163]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1634 749 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 222: ep_len:749 episode reward: total was -353.600000. running mean: -322.863699\n",
      "startIDX:  631\n",
      "222 1 True\n",
      "x_t:  2 [0.7125     0.37916667 0.065625   0.3125    ]\n",
      "Q values:  tensor([[-24.2140, -21.2045, -22.0673, -22.2253, -20.3315, -20.5590]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31481 369 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 222: ep_len:369 episode reward: total was -208.300000. running mean: -321.718062\n",
      "startIDX:  615\n",
      "222 5 False\n",
      "x_t:  2 [0.825 0.375 0.1   0.3  ]\n",
      "Q values:  tensor([[-17.7915, -16.3497, -15.9213, -16.9842, -17.4759, -16.5039]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6033 443 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 222: ep_len:443 episode reward: total was -261.700000. running mean: -321.117881\n",
      "startIDX:  1497\n",
      "222 10 False\n",
      "x_t:  3 [0.703125   0.29583333 0.08125    0.37083333]\n",
      "Q values:  tensor([[-19.5815, -19.8023, -20.0798, -18.2060, -19.3925, -18.7868]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16425 353 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 222: ep_len:353 episode reward: total was -39.800000. running mean: -318.304703\n",
      "startIDX:  367\n",
      "222 12 False\n",
      "x_t:  4 [0.08125 0.425   0.1125  0.3875 ]\n",
      "Q values:  tensor([[-23.1895, -20.7017, -22.1112, -21.9154, -20.6537, -20.7470]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7191 716 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 222: ep_len:716 episode reward: total was -428.700000. running mean: -319.408656\n",
      "startIDX:  2424\n",
      "222 15 False\n",
      "x_t:  4 [0.0625     0.41666667 0.125      0.37916667]\n",
      "Q values:  tensor([[-22.3314, -22.2907, -21.7584, -23.7708, -21.2941, -21.5722]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19258 493 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 222: ep_len:493 episode reward: total was -312.800000. running mean: -319.342569\n",
      "startIDX:  1358\n",
      "222 22 True\n",
      "x_t:  3 [0.096875   0.25833333 0.084375   0.27916667]\n",
      "Q values:  tensor([[-22.2378, -21.9521, -22.6538, -22.0107, -21.5447, -22.1759]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15210 1291 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 222: ep_len:1291 episode reward: total was -849.400000. running mean: -324.643143\n",
      "startIDX:  1531\n",
      "223 0 False\n",
      "x_t:  3 [0.590625   0.325      0.14375    0.38333333]\n",
      "Q values:  tensor([[-20.2913, -20.2509, -20.9809, -20.2048, -21.7982, -20.5589]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16843 254 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  364\n",
      "223 1 True\n",
      "x_t:  1 [0.565625   0.30833333 0.2375     0.5625    ]\n",
      "Q values:  tensor([[-26.7850, -27.3056, -27.4388, -26.7637, -23.5867, -25.9635]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28102 301 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  552\n",
      "223 5 False\n",
      "x_t:  2 [0.878125   0.3875     0.040625   0.22083333]\n",
      "Q values:  tensor([[-28.9284, -25.8587, -25.5923, -29.9143, -29.2048, -27.9474]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6021 475 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  630\n",
      "223 10 False\n",
      "x_t:  2 [0.003125   0.40833333 0.103125   0.25      ]\n",
      "Q values:  tensor([[-34.1830, -33.6171, -31.2067, -33.3614, -33.8002, -33.3435]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6586 723 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1093\n",
      "223 12 True\n",
      "x_t:  3 [0.06875 0.2625  0.06875 0.25   ]\n",
      "Q values:  tensor([[-33.2411, -34.9354, -35.1242, -34.2833, -35.8306, -33.8808]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16374 1367 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1163\n",
      "223 15 False\n",
      "x_t:  4 [0.003125   0.39583333 0.084375   0.29166667]\n",
      "Q values:  tensor([[-27.1670, -28.4839, -27.7987, -31.1643, -25.8721, -28.2433]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9810 534 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  88\n",
      "223 22 False\n",
      "x_t:  1 [0.815625 0.3      0.075    0.4     ]\n",
      "Q values:  tensor([[-30.5449, -28.6281, -31.3012, -30.0562, -30.7531, -29.7998]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1587 682 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1848\n",
      "224 0 True\n",
      "x_t:  2 [0.003125   0.4125     0.04375    0.24583333]\n",
      "Q values:  tensor([[-28.6434, -29.5536, -30.2679, -29.8010, -33.7446, -28.1469]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18389 716 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 224: ep_len:716 episode reward: total was -560.600000. running mean: -333.646021\n",
      "startIDX:  585\n",
      "224 1 False\n",
      "x_t:  2 [0.815625   0.38333333 0.103125   0.31666667]\n",
      "Q values:  tensor([[-25.7250, -26.3137, -24.2302, -28.5741, -28.4620, -26.7784]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31460 384 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 224: ep_len:384 episode reward: total was -289.400000. running mean: -333.203561\n",
      "startIDX:  2686\n",
      "224 5 False\n",
      "x_t:  1 [0.003125   0.34583333 0.121875   0.51666667]\n",
      "Q values:  tensor([[-29.7172, -26.4586, -28.2578, -30.8661, -27.5199, -28.9607]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22105 233 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 224: ep_len:233 episode reward: total was -144.400000. running mean: -331.315525\n",
      "startIDX:  1425\n",
      "224 10 False\n",
      "x_t:  4 [0.084375   0.35833333 0.0625     0.27916667]\n",
      "Q values:  tensor([[-27.9429, -30.1527, -28.2074, -31.6444, -27.8191, -30.6548]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15715 513 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 224: ep_len:513 episode reward: total was -339.600000. running mean: -331.398370\n",
      "startIDX:  808\n",
      "224 12 True\n",
      "x_t:  0 [0.790625 0.4125   0.128125 0.3     ]\n",
      "Q values:  tensor([[-32.0572, -30.5620, -32.2643, -30.5392, -30.8971, -32.5385]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11649 666 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 224: ep_len:666 episode reward: total was -489.700000. running mean: -332.981386\n",
      "startIDX:  362\n",
      "224 15 False\n",
      "x_t:  1 [0.175      0.36666667 0.13125    0.5       ]\n",
      "Q values:  tensor([[-31.3893, -28.6931, -29.5219, -32.6508, -32.1853, -31.6483]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2764 248 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 224: ep_len:248 episode reward: total was -177.700000. running mean: -331.428573\n",
      "startIDX:  461\n",
      "224 22 False\n",
      "x_t:  4 [0.00625    0.42083333 0.09375    0.36666667]\n",
      "Q values:  tensor([[-29.4972, -28.5746, -28.8963, -28.7355, -26.6190, -27.3837]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 6654 851 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 224: ep_len:851 episode reward: total was -562.900000. running mean: -333.743287\n",
      "startIDX:  210\n",
      "225 0 False\n",
      "x_t:  2 [0.796875   0.40833333 0.1        0.2875    ]\n",
      "Q values:  tensor([[-28.4994, -29.1237, -24.7673, -30.0126, -32.5314, -26.8735]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2320 336 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  779\n",
      "225 1 False\n",
      "x_t:  3 [0.0625     0.22916667 0.059375   0.28333333]\n",
      "Q values:  tensor([[-28.8890, -29.7908, -32.2813, -28.7550, -30.5015, -28.8404]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34302 1355 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2279\n",
      "225 5 False\n",
      "x_t:  3 [0.446875   0.29166667 0.096875   0.36666667]\n",
      "Q values:  tensor([[-28.3078, -27.4819, -30.1419, -26.1369, -26.2330, -26.7439]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19934 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225 10 False\n",
      "x_t:  3 [0.20625    0.24583333 0.090625   0.27916667]\n",
      "Q values:  tensor([[-26.7256, -27.6613, -26.5024, -25.4909, -28.1567, -27.0638]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5143 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  711\n",
      "225 12 True\n",
      "x_t:  1 [0.046875   0.39166667 0.190625   0.47916667]\n",
      "Q values:  tensor([[-33.0087, -31.8821, -36.2513, -33.3655, -36.8314, -32.2656]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10308 215 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  415\n",
      "225 15 True\n",
      "x_t:  0 [0.375      0.425      0.059375   0.25833333]\n",
      "Q values:  tensor([[-28.4769, -26.0386, -28.1958, -26.7528, -26.0388, -24.5971]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3741 477 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  42\n",
      "225 22 False\n",
      "x_t:  1 [0.85       0.30416667 0.13125    0.40416667]\n",
      "Q values:  tensor([[-33.0118, -31.9255, -33.6866, -32.3825, -34.9900, -32.6902]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1582 727 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2188\n",
      "226 0 False\n",
      "x_t:  1 [0.7      0.325    0.221875 0.5125  ]\n",
      "Q values:  tensor([[-33.2810, -30.5935, -32.7463, -31.4601, -33.9636, -31.3162]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22928 1119 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 226: ep_len:1119 episode reward: total was -672.400000. running mean: -335.596431\n",
      "startIDX:  1019\n",
      "226 1 False\n",
      "x_t:  3 [0.83125  0.3      0.153125 0.425   ]\n",
      "Q values:  tensor([[-24.9841, -26.3551, -25.9423, -23.3626, -25.8581, -26.3551]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35900 219 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 226: ep_len:219 episode reward: total was -74.600000. running mean: -332.986467\n",
      "startIDX:  1514\n",
      "226 5 False\n",
      "x_t:  0 [0.9375     0.3875     0.059375   0.34583333]\n",
      "Q values:  tensor([[-23.9369, -25.1535, -24.8288, -24.9835, -26.2113, -23.9464]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13493 451 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 226: ep_len:451 episode reward: total was -272.300000. running mean: -332.379602\n",
      "startIDX:  1382\n",
      "226 10 True\n",
      "x_t:  4 [0.34375    0.34583333 0.0875     0.25      ]\n",
      "Q values:  tensor([[-23.5514, -22.6504, -24.3420, -24.0853, -24.2010, -22.0966]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15765 559 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 226: ep_len:559 episode reward: total was -292.100000. running mean: -331.976806\n",
      "startIDX:  795\n",
      "226 12 False\n",
      "x_t:  0 [0.9125  0.4125  0.08125 0.3    ]\n",
      "Q values:  tensor([[-21.0150, -21.3113, -22.6077, -21.2588, -23.9247, -22.5957]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11628 652 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 226: ep_len:652 episode reward: total was -396.900000. running mean: -332.626038\n",
      "startIDX:  1343\n",
      "226 15 False\n",
      "x_t:  3 [0.853125   0.34166667 0.103125   0.38333333]\n",
      "Q values:  tensor([[-22.1580, -22.2219, -23.1138, -20.5613, -22.1040, -21.7855]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10342 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 226: ep_len:204 episode reward: total was -57.300000. running mean: -329.872778\n",
      "startIDX:  1057\n",
      "226 22 False\n",
      "x_t:  1 [0.8875     0.30416667 0.109375   0.5       ]\n",
      "Q values:  tensor([[-21.9935, -20.6187, -21.7812, -21.1755, -22.0102, -20.7705]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11916 767 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 226: ep_len:767 episode reward: total was -372.000000. running mean: -330.294050\n",
      "startIDX:  2557\n",
      "startIDX:  298\n",
      "227 1 False\n",
      "x_t:  1 [0.740625   0.28333333 0.16875    0.59166667]\n",
      "Q values:  tensor([[-26.5445, -25.6935, -26.1298, -27.1300, -27.5736, -26.3378]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28116 341 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1392\n",
      "227 5 False\n",
      "x_t:  1 [0.246875   0.32083333 0.071875   0.39166667]\n",
      "Q values:  tensor([[-21.7660, -19.2465, -21.3124, -23.4758, -24.7558, -21.6369]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12529 234 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  345\n",
      "227 10 True\n",
      "x_t:  3 [0.8125     0.32916667 0.165625   0.375     ]\n",
      "Q values:  tensor([[-23.6239, -21.3218, -23.9099, -23.7175, -23.5912, -22.7707]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5039 218 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1324\n",
      "227 12 False\n",
      "x_t:  3 [0.728125   0.35416667 0.125      0.44583333]\n",
      "Q values:  tensor([[-22.2182, -22.8611, -23.9984, -21.7293, -24.9468, -22.6108]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17856 237 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  358\n",
      "227 15 False\n",
      "x_t:  1 [0.034375   0.37916667 0.15625    0.4875    ]\n",
      "Q values:  tensor([[-24.5494, -21.8773, -22.4351, -23.0357, -26.8163, -23.1756]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2755 238 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1726\n",
      "227 22 False\n",
      "x_t:  3 [0.68125    0.32916667 0.1125     0.37916667]\n",
      "Q values:  tensor([[-26.7733, -23.0337, -25.5956, -22.2208, -25.3886, -23.8568]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16871 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1655\n",
      "228 0 False\n",
      "x_t:  3 [0.278125   0.26666667 0.0875     0.3125    ]\n",
      "Q values:  tensor([[-26.5932, -25.8843, -25.8392, -22.7307, -26.2593, -25.9149]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16902 214 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 228: ep_len:214 episode reward: total was -123.300000. running mean: -313.490402\n",
      "startIDX:  721\n",
      "228 1 False\n",
      "x_t:  3 [0.096875   0.23333333 0.078125   0.3       ]\n",
      "Q values:  tensor([[-28.1376, -27.5991, -27.2679, -25.8107, -28.2285, -26.9482]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34314 1400 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 228: ep_len:1400 episode reward: total was -882.400000. running mean: -319.179498\n",
      "startIDX:  714\n",
      "228 5 False\n",
      "x_t:  3 [0.3375     0.29166667 0.11875    0.38333333]\n",
      "Q values:  tensor([[-29.7807, -28.4347, -29.4960, -28.0964, -31.4135, -29.2673]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8814 1334 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 228: ep_len:1334 episode reward: total was -880.100000. running mean: -324.788703\n",
      "startIDX:  1154\n",
      "228 10 False\n",
      "x_t:  2 [0.8625     0.39583333 0.08125    0.24583333]\n",
      "Q values:  tensor([[-27.4277, -27.8862, -27.1065, -29.2594, -30.2249, -27.3497]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12052 304 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 228: ep_len:304 episode reward: total was -198.100000. running mean: -323.521816\n",
      "startIDX:  1032\n",
      "228 12 True\n",
      "x_t:  2 [0.790625   0.41666667 0.0875     0.2375    ]\n",
      "Q values:  tensor([[-26.3513, -28.5374, -26.2075, -28.3626, -27.6758, -27.1266]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13576 296 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 228: ep_len:296 episode reward: total was -203.100000. running mean: -322.317598\n",
      "startIDX:  3084\n",
      "ep 228: ep_len:41 episode reward: total was 25.000000. running mean: -318.844422\n",
      "startIDX:  972\n",
      "228 22 False\n",
      "x_t:  0 [0.903125 0.4      0.053125 0.3375  ]\n",
      "Q values:  tensor([[-27.2202, -29.0567, -29.2914, -30.6475, -29.2503, -29.1179]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10402 465 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 228: ep_len:465 episode reward: total was -319.200000. running mean: -318.847978\n",
      "startIDX:  1479\n",
      "229 0 False\n",
      "x_t:  3 [0.803125   0.34166667 0.159375   0.4125    ]\n",
      "Q values:  tensor([[-27.7135, -26.8566, -26.8215, -26.3722, -27.8618, -26.9489]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16819 266 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  486\n",
      "229 1 False\n",
      "x_t:  1 [0.85625    0.26666667 0.140625   0.4625    ]\n",
      "Q values:  tensor([[-25.0421, -23.0016, -25.0616, -25.2150, -26.9086, -23.6108]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30679 750 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  105\n",
      "229 5 False\n",
      "x_t:  2 [0.003125   0.37916667 0.125      0.42916667]\n",
      "Q values:  tensor([[-26.5203, -26.9485, -25.4164, -26.5544, -28.1209, -27.1123]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2055 867 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  30\n",
      "229 10 True\n",
      "x_t:  3 [0.0625     0.23333333 0.0625     0.25416667]\n",
      "Q values:  tensor([[-26.9477, -26.4342, -29.8671, -29.5263, -31.3194, -28.4116]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3581 1099 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1737\n",
      "229 12 False\n",
      "x_t:  1 [0.259375   0.34166667 0.0875     0.375     ]\n",
      "Q values:  tensor([[-31.0529, -30.3465, -30.9532, -32.4948, -33.2559, -30.8561]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19896 207 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1824\n",
      "229 15 False\n",
      "x_t:  0 [0.828125   0.4        0.096875   0.32916667]\n",
      "Q values:  tensor([[-27.6902, -27.8685, -27.7435, -30.9564, -28.9426, -28.6794]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13376 432 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229 22 False\n",
      "x_t:  4 [0.128125   0.39583333 0.1        0.30833333]\n",
      "Q values:  tensor([[-29.3498, -27.6814, -29.0060, -28.0758, -26.8833, -28.4132]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27283 517 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  1912.6766414642334\n",
      "startIDX:  1001\n",
      "230 0 False\n",
      "x_t:  1 [0.68125    0.32083333 0.165625   0.43333333]\n",
      "Q values:  tensor([[-32.3648, -32.0299, -32.7331, -34.6378, -33.6987, -32.8549]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11964 789 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 230: ep_len:789 episode reward: total was -481.500000. running mean: -324.905436\n",
      "startIDX:  631\n",
      "230 1 False\n",
      "x_t:  2 [0.634375   0.37916667 0.096875   0.3125    ]\n",
      "Q values:  tensor([[-31.0760, -28.1783, -26.9776, -30.0801, -30.5621, -28.7988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31491 377 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 230: ep_len:377 episode reward: total was -268.700000. running mean: -324.343381\n",
      "startIDX:  1430\n",
      "230 5 False\n",
      "x_t:  1 [0.06875    0.34583333 0.13125    0.4       ]\n",
      "Q values:  tensor([[-35.3036, -32.0471, -32.5088, -33.4907, -34.1269, -33.8046]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12513 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 230: ep_len:202 episode reward: total was -150.900000. running mean: -322.608947\n",
      "startIDX:  27\n",
      "230 10 False\n",
      "x_t:  3 [0.059375 0.2375   0.065625 0.25    ]\n",
      "Q values:  tensor([[-28.4841, -27.5147, -30.0744, -26.1434, -27.2810, -27.3349]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3580 1087 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 230: ep_len:1087 episode reward: total was -692.700000. running mean: -326.309858\n",
      "startIDX:  371\n",
      "230 12 False\n",
      "x_t:  4 [0.046875   0.44583333 0.14375    0.3625    ]\n",
      "Q values:  tensor([[-24.7689, -23.7053, -24.5154, -24.8378, -22.4822, -22.5262]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7189 716 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 230: ep_len:716 episode reward: total was -477.800000. running mean: -327.824759\n",
      "startIDX:  2894\n",
      "230 15 False\n",
      "x_t:  0 [0.925      0.39583333 0.06875    0.3625    ]\n",
      "Q values:  tensor([[-23.8417, -25.7204, -25.6435, -27.7320, -23.9605, -24.6551]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23067 513 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 230: ep_len:513 episode reward: total was -351.200000. running mean: -328.058512\n",
      "startIDX:  1132\n",
      "230 22 False\n",
      "x_t:  1 [0.8875     0.30416667 0.109375   0.5       ]\n",
      "Q values:  tensor([[-25.1003, -23.6608, -23.8329, -24.3289, -25.0348, -25.0017]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11916 715 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 230: ep_len:715 episode reward: total was -431.400000. running mean: -329.091927\n",
      "startIDX:  2298\n",
      "231 0 False\n",
      "x_t:  3 [0.071875   0.2375     0.071875   0.24166667]\n",
      "Q values:  tensor([[-19.3005, -18.6681, -19.4124, -17.3127, -17.5015, -18.8694]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26095 1266 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  574\n",
      "231 1 True\n",
      "x_t:  2 [0.75625    0.37916667 0.09375    0.32916667]\n",
      "Q values:  tensor([[-23.3137, -23.4631, -22.7826, -21.1369, -21.3159, -21.1280]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31470 397 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1380\n",
      "231 5 False\n",
      "x_t:  1 [0.1625     0.32916667 0.125      0.38333333]\n",
      "Q values:  tensor([[-30.0949, -26.3983, -27.8405, -30.3162, -28.2124, -29.4384]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12521 230 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1607\n",
      "231 10 False\n",
      "x_t:  3 [0.734375   0.31666667 0.1375     0.3875    ]\n",
      "Q values:  tensor([[-23.4133, -23.7999, -25.0638, -23.1719, -24.4055, -23.9347]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16417 293 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  989\n",
      "231 12 False\n",
      "x_t:  2 [0.7        0.40833333 0.05       0.25      ]\n",
      "Q values:  tensor([[-28.9207, -25.2996, -24.9774, -26.4844, -25.1535, -25.2701]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13593 326 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1922\n",
      "231 15 True\n",
      "x_t:  1 [0.915625   0.2875     0.078125   0.31666667]\n",
      "Q values:  tensor([[-31.2022, -30.2968, -26.4246, -30.3477, -29.0940, -29.6490]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14838 719 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  298\n",
      "231 22 False\n",
      "x_t:  3 [0.06875  0.2375   0.053125 0.2375  ]\n",
      "Q values:  tensor([[-23.8301, -22.5487, -21.2681, -19.8305, -23.4123, -20.9596]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4873 1271 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  166\n",
      "232 0 True\n",
      "x_t:  2 [0.725      0.4125     0.109375   0.28333333]\n",
      "Q values:  tensor([[-31.8020, -30.3957, -28.6922, -31.9951, -31.7584, -28.9106]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2333 362 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 232: ep_len:362 episode reward: total was -239.700000. running mean: -332.082074\n",
      "startIDX:  503\n",
      "232 1 False\n",
      "x_t:  1 [0.859375   0.25833333 0.1375     0.47083333]\n",
      "Q values:  tensor([[-30.5244, -28.5313, -32.9302, -28.9028, -29.8090, -29.5986]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30678 767 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 232: ep_len:767 episode reward: total was -412.600000. running mean: -332.887253\n",
      "startIDX:  790\n",
      "232 5 False\n",
      "x_t:  4 [0.003125   0.41666667 0.13125    0.37083333]\n",
      "Q values:  tensor([[-26.6998, -27.7972, -29.4857, -26.6452, -25.5766, -27.5937]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10012 621 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 232: ep_len:621 episode reward: total was -327.500000. running mean: -332.833381\n",
      "startIDX:  946\n",
      "232 10 False\n",
      "x_t:  1 [0.796875   0.27916667 0.090625   0.34166667]\n",
      "Q values:  tensor([[-25.1917, -22.9984, -26.8315, -25.9965, -25.4821, -25.2442]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11338 1575 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 232: ep_len:1575 episode reward: total was -864.100000. running mean: -338.146047\n",
      "startIDX:  1130\n",
      "232 12 False\n",
      "x_t:  3 [0.075      0.26666667 0.078125   0.2875    ]\n",
      "Q values:  tensor([[-21.6919, -23.1415, -25.1100, -20.1371, -21.9651, -23.0359]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16376 1343 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 232: ep_len:1343 episode reward: total was -812.500000. running mean: -342.889586\n",
      "startIDX:  1329\n",
      "232 15 False\n",
      "x_t:  3 [0.796875   0.33333333 0.1        0.38333333]\n",
      "Q values:  tensor([[-22.8879, -23.0960, -22.3028, -19.8453, -21.2556, -20.0749]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10347 218 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 232: ep_len:218 episode reward: total was -62.800000. running mean: -340.088691\n",
      "startIDX:  9\n",
      "232 22 False\n",
      "x_t:  1 [0.6125     0.32083333 0.146875   0.3875    ]\n",
      "Q values:  tensor([[-20.7940, -19.2020, -22.2772, -21.0738, -21.4017, -23.0489]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1605 738 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 232: ep_len:738 episode reward: total was -381.700000. running mean: -340.504804\n",
      "startIDX:  228\n",
      "233 0 False\n",
      "x_t:  2 [0.79375    0.40416667 0.075      0.28333333]\n",
      "Q values:  tensor([[-22.8007, -22.6901, -21.8103, -21.9646, -23.4701, -23.7299]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2324 327 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  620\n",
      "233 1 False\n",
      "x_t:  2 [0.8125     0.38333333 0.1125     0.30833333]\n",
      "Q values:  tensor([[-26.6862, -24.3560, -22.9827, -23.7807, -25.2709, -24.2013]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31459 359 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1644\n",
      "233 5 False\n",
      "x_t:  1 [0.896875   0.27083333 0.059375   0.32916667]\n",
      "Q values:  tensor([[-28.9044, -25.5977, -27.5036, -27.0983, -26.4677, -27.2954]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14922 639 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  4\n",
      "233 10 False\n",
      "x_t:  3 [0.0625     0.24166667 0.059375   0.24583333]\n",
      "Q values:  tensor([[-22.5776, -21.4236, -25.9516, -20.4035, -24.4348, -21.0465]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3578 1113 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  995\n",
      "233 12 False\n",
      "x_t:  2 [0.83125    0.40833333 0.075      0.25      ]\n",
      "Q values:  tensor([[-23.9286, -24.9668, -23.6100, -25.2868, -24.5749, -24.9029]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13571 320 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1640\n",
      "233 15 False\n",
      "x_t:  1 [0.003125   0.375      0.121875   0.40416667]\n",
      "Q values:  tensor([[-17.8703, -17.1965, -18.5974, -18.4802, -18.4597, -18.4129]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12446 258 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1739\n",
      "233 22 True\n",
      "x_t:  3 [0.515625   0.30416667 0.096875   0.35      ]\n",
      "Q values:  tensor([[-24.8551, -21.1041, -25.1219, -26.5591, -23.4724, -22.1513]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16897 207 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234 0 False\n",
      "x_t:  3 [0.646875   0.37083333 0.159375   0.44583333]\n",
      "Q values:  tensor([[-16.7041, -15.9638, -17.4959, -15.8123, -18.1652, -16.2784]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7010 1017 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 234: ep_len:1017 episode reward: total was -542.800000. running mean: -335.808184\n",
      "startIDX:  588\n",
      "234 1 False\n",
      "x_t:  2 [0.809375   0.38333333 0.071875   0.30833333]\n",
      "Q values:  tensor([[-23.9084, -22.6807, -22.6203, -24.5707, -24.1765, -23.1441]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31465 399 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 234: ep_len:399 episode reward: total was -223.200000. running mean: -334.682102\n",
      "startIDX:  764\n",
      "234 5 False\n",
      "x_t:  4 [0.21875    0.40416667 0.1125     0.375     ]\n",
      "Q values:  tensor([[-21.2140, -19.7967, -20.9354, -20.9534, -19.6052, -20.5824]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10039 653 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 234: ep_len:653 episode reward: total was -288.400000. running mean: -334.219281\n",
      "startIDX:  2060\n",
      "234 10 True\n",
      "x_t:  1 [0.003125 0.35     0.121875 0.4125  ]\n",
      "Q values:  tensor([[-23.3055, -20.5800, -22.6015, -21.2662, -22.2200, -21.6985]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18808 277 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 234: ep_len:277 episode reward: total was -149.600000. running mean: -332.373088\n",
      "startIDX:  973\n",
      "234 12 False\n",
      "x_t:  2 [0.628125   0.4125     0.103125   0.24166667]\n",
      "Q values:  tensor([[-22.0800, -20.5385, -18.6913, -21.9130, -21.5949, -19.8480]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13601 339 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 234: ep_len:339 episode reward: total was -195.600000. running mean: -331.005358\n",
      "startIDX:  2946\n",
      "234 15 False\n",
      "x_t:  0 [0.65625    0.40833333 0.065625   0.36666667]\n",
      "Q values:  tensor([[-20.7078, -21.9216, -22.7707, -21.2963, -23.8516, -21.3599]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23110 512 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 234: ep_len:512 episode reward: total was -319.700000. running mean: -330.892304\n",
      "startIDX:  2244\n",
      "234 22 False\n",
      "x_t:  1 [0.7625     0.31666667 0.13125    0.45416667]\n",
      "Q values:  tensor([[-24.8678, -21.6278, -24.8852, -23.1336, -22.1595, -22.3422]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22941 1104 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 234: ep_len:1104 episode reward: total was -603.600000. running mean: -333.619381\n",
      "startIDX:  1574\n",
      "235 0 True\n",
      "x_t:  3 [0.5875     0.33333333 0.15       0.375     ]\n",
      "Q values:  tensor([[-24.2601, -23.1164, -26.0886, -24.6071, -24.4215, -23.5923]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16841 228 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  614\n",
      "235 1 True\n",
      "x_t:  2 [0.71875    0.38333333 0.06875    0.3125    ]\n",
      "Q values:  tensor([[-27.7403, -28.4458, -27.8864, -28.0005, -26.3298, -26.1297]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31480 388 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1916\n",
      "235 5 False\n",
      "x_t:  2 [0.371875   0.39583333 0.08125    0.25      ]\n",
      "Q values:  tensor([[-26.6055, -25.9383, -25.3994, -25.8195, -27.4483, -25.4369]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15718 352 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2309\n",
      "235 10 True\n",
      "x_t:  1 [0.825      0.28333333 0.096875   0.3375    ]\n",
      "Q values:  tensor([[-22.9310, -20.8423, -21.6330, -21.9404, -21.3507, -19.9863]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22475 1228 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  702\n",
      "235 12 False\n",
      "x_t:  1 [0.003125   0.39583333 0.153125   0.47083333]\n",
      "Q values:  tensor([[-23.7767, -22.3658, -24.9859, -24.3800, -26.2914, -23.6815]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10304 220 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  349\n",
      "235 15 True\n",
      "x_t:  1 [0.003125   0.38333333 0.128125   0.48333333]\n",
      "Q values:  tensor([[-25.3775, -24.9134, -24.7173, -24.3949, -23.6799, -23.7715]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2752 244 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2447\n",
      "235 22 False\n",
      "x_t:  2 [0.71875    0.40416667 0.078125   0.25416667]\n",
      "Q values:  tensor([[-28.6834, -27.4767, -24.9522, -27.5867, -25.5932, -26.7052]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23653 335 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1938\n",
      "236 0 False\n",
      "x_t:  1 [0.003125 0.3625   0.128125 0.425   ]\n",
      "Q values:  tensor([[-23.9113, -19.9442, -24.7954, -22.6359, -22.3255, -23.3714]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18922 237 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 236: ep_len:237 episode reward: total was -112.800000. running mean: -323.909191\n",
      "startIDX:  508\n",
      "236 1 False\n",
      "x_t:  1 [0.8625  0.2625  0.10625 0.4625 ]\n",
      "Q values:  tensor([[-24.9253, -23.7634, -23.8720, -24.9054, -25.3917, -24.1351]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30683 767 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 236: ep_len:767 episode reward: total was -480.300000. running mean: -325.473099\n",
      "startIDX:  2502\n",
      "236 5 False\n",
      "x_t:  2 [0.0625     0.4        0.1        0.26666667]\n",
      "Q values:  tensor([[-21.8231, -23.1491, -21.8071, -24.0435, -22.1329, -22.4774]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21558 819 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 236: ep_len:819 episode reward: total was -457.600000. running mean: -326.794368\n",
      "startIDX:  2026\n",
      "236 10 True\n",
      "x_t:  1 [0.028125   0.34583333 0.109375   0.375     ]\n",
      "Q values:  tensor([[-29.2403, -29.2274, -29.1409, -26.4718, -29.8250, -27.1682]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18814 284 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 236: ep_len:284 episode reward: total was -154.300000. running mean: -325.069425\n",
      "startIDX:  1729\n",
      "236 12 False\n",
      "x_t:  1 [0.15       0.3625     0.159375   0.35416667]\n",
      "Q values:  tensor([[-26.5089, -23.7836, -24.6053, -26.0011, -28.1002, -24.8503]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19888 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 236: ep_len:200 episode reward: total was -128.300000. running mean: -323.101730\n",
      "startIDX:  471\n",
      "236 15 False\n",
      "x_t:  1 [0.86875    0.29583333 0.053125   0.27916667]\n",
      "Q values:  tensor([[-24.8425, -21.1786, -22.4760, -23.6596, -21.5408, -22.0409]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5171 745 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 236: ep_len:745 episode reward: total was -403.600000. running mean: -323.906713\n",
      "startIDX:  2971\n",
      "ep 236: ep_len:24 episode reward: total was 20.000000. running mean: -320.467646\n",
      "startIDX:  1352\n",
      "237 0 False\n",
      "x_t:  4 [0.003125 0.4      0.09375  0.275   ]\n",
      "Q values:  tensor([[-24.8307, -24.1213, -26.7906, -24.5176, -23.7555, -24.5220]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16284 554 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  605\n",
      "237 1 False\n",
      "x_t:  2 [0.725      0.37916667 0.1125     0.3125    ]\n",
      "Q values:  tensor([[-28.1379, -28.1854, -25.9319, -29.5199, -26.2204, -26.6833]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31476 394 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1595\n",
      "237 5 False\n",
      "x_t:  1 [0.909375   0.27083333 0.084375   0.3375    ]\n",
      "Q values:  tensor([[-22.5658, -22.5589, -25.8609, -24.1682, -25.8165, -22.9526]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14916 673 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2077\n",
      "237 10 False\n",
      "x_t:  1 [0.09375    0.34583333 0.084375   0.38333333]\n",
      "Q values:  tensor([[-27.7942, -26.7126, -27.0176, -30.1061, -26.9850, -28.5201]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18819 267 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  199\n",
      "237 12 False\n",
      "x_t:  3 [0.165625   0.27916667 0.109375   0.275     ]\n",
      "Q values:  tensor([[-26.1677, -23.4702, -24.7631, -22.4703, -25.5832, -23.8711]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5688 1415 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1225\n",
      "237 15 True\n",
      "x_t:  3 [0.865625   0.34583333 0.13125    0.39166667]\n",
      "Q values:  tensor([[-26.8826, -26.0131, -27.1863, -24.0110, -25.5367, -24.9948]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10338 263 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2200\n",
      "237 22 True\n",
      "x_t:  0 [0.834375   0.40416667 0.065625   0.32083333]\n",
      "Q values:  tensor([[-27.6276, -28.5381, -29.1001, -27.5662, -28.1477, -27.7086]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20711 804 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  37\n",
      "238 0 True\n",
      "x_t:  1 [0.859375   0.30416667 0.134375   0.425     ]\n",
      "Q values:  tensor([[-30.4892, -31.1768, -28.6439, -30.8422, -30.8670, -28.9675]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1608 729 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 238: ep_len:729 episode reward: total was -365.000000. running mean: -322.949617\n",
      "startIDX:  652\n",
      "238 1 False\n",
      "x_t:  2 [0.815625   0.38333333 0.103125   0.31666667]\n",
      "Q values:  tensor([[-26.4712, -27.3806, -25.0208, -27.2107, -27.5194, -26.1409]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31460 345 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 238: ep_len:345 episode reward: total was -217.800000. running mean: -321.898120\n",
      "startIDX:  2257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238 5 False\n",
      "x_t:  3 [0.4875     0.3        0.140625   0.38333333]\n",
      "Q values:  tensor([[-20.4538, -21.7592, -21.8356, -20.1047, -21.3856, -20.2523]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19926 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 238: ep_len:204 episode reward: total was 0.400000. running mean: -318.675139\n",
      "startIDX:  735\n",
      "238 10 True\n",
      "x_t:  1 [0.1      0.35     0.128125 0.375   ]\n",
      "Q values:  tensor([[-26.0453, -26.1913, -24.6005, -25.7715, -26.0837, -24.2073]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7115 224 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 238: ep_len:224 episode reward: total was -93.800000. running mean: -316.426388\n",
      "startIDX:  1848\n",
      "238 12 False\n",
      "x_t:  0 [0.2        0.42916667 0.06875    0.30833333]\n",
      "Q values:  tensor([[-25.7550, -27.3078, -27.3785, -29.9730, -30.1659, -26.7222]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 22989 945 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 238: ep_len:945 episode reward: total was -549.800000. running mean: -318.760124\n",
      "startIDX:  1755\n",
      "238 15 True\n",
      "x_t:  0 [0.8625     0.40416667 0.1        0.325     ]\n",
      "Q values:  tensor([[-24.4177, -23.3534, -28.0114, -23.6781, -24.8585, -23.0446]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13371 464 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 238: ep_len:464 episode reward: total was -283.000000. running mean: -318.402523\n",
      "startIDX:  1647\n",
      "238 22 True\n",
      "x_t:  3 [0.83125    0.3375     0.090625   0.42083333]\n",
      "Q values:  tensor([[-29.7285, -28.4761, -32.2332, -28.0601, -29.2472, -27.4499]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16851 230 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 238: ep_len:230 episode reward: total was -38.600000. running mean: -315.604498\n",
      "startIDX:  15\n",
      "239 0 False\n",
      "x_t:  1 [0.578125   0.325      0.175      0.41666667]\n",
      "Q values:  tensor([[-23.5809, -22.3715, -26.1567, -25.4828, -23.8468, -25.0090]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1638 770 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  408\n",
      "239 1 False\n",
      "x_t:  0 [0.50625    0.37083333 0.1375     0.44583333]\n",
      "Q values:  tensor([[-20.6114, -22.7458, -21.7061, -24.8404, -21.9861, -21.3919]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29154 522 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1619\n",
      "239 5 True\n",
      "x_t:  1 [0.828125   0.28333333 0.109375   0.32083333]\n",
      "Q values:  tensor([[-25.0711, -23.6946, -22.5027, -24.8247, -23.5824, -22.5594]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14927 662 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1055\n",
      "239 10 True\n",
      "x_t:  1 [0.578125   0.29583333 0.10625    0.34166667]\n",
      "Q values:  tensor([[-25.1810, -24.6195, -23.4613, -23.8262, -25.4557, -22.6877]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11366 1506 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1685\n",
      "239 12 False\n",
      "x_t:  1 [0.0375     0.37083333 0.1375     0.35416667]\n",
      "Q values:  tensor([[-23.8116, -22.5735, -24.1435, -25.2661, -27.0135, -23.5560]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19875 228 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  888\n",
      "239 15 False\n",
      "x_t:  3 [0.0625     0.23333333 0.05625    0.22916667]\n",
      "Q values:  tensor([[-24.2260, -24.7484, -25.0029, -22.2713, -24.9176, -23.3927]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8494 1221 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2737\n",
      "239 22 False\n",
      "x_t:  4 [0.259375   0.3875     0.11875    0.30833333]\n",
      "Q values:  tensor([[-25.2322, -26.0934, -26.6233, -24.8521, -23.1234, -23.8660]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27305 507 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  1998.205938577652\n",
      "startIDX:  2160\n",
      "240 0 False\n",
      "x_t:  1 [0.846875   0.30416667 0.146875   0.5375    ]\n",
      "Q values:  tensor([[-21.6092, -18.0067, -20.2427, -18.6852, -19.6672, -19.6147]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22919 1123 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 240: ep_len:1123 episode reward: total was -623.800000. running mean: -325.432754\n",
      "startIDX:  696\n",
      "240 1 False\n",
      "x_t:  3 [0.09375    0.2375     0.08125    0.29583333]\n",
      "Q values:  tensor([[-25.6630, -26.8840, -26.1696, -22.5807, -24.9514, -24.5146]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34312 1392 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 240: ep_len:1392 episode reward: total was -788.700000. running mean: -330.065427\n",
      "startIDX:  2016\n",
      "240 5 False\n",
      "x_t:  3 [0.0625     0.25416667 0.08125    0.25833333]\n",
      "Q values:  tensor([[-24.7622, -24.9208, -23.8330, -22.3069, -26.0780, -23.3259]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18202 1244 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 240: ep_len:1244 episode reward: total was -696.400000. running mean: -333.728772\n",
      "startIDX:  1612\n",
      "240 10 False\n",
      "x_t:  3 [0.803125   0.30416667 0.090625   0.40416667]\n",
      "Q values:  tensor([[-22.5836, -20.5384, -21.0822, -19.9912, -22.5270, -21.1751]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16411 281 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 240: ep_len:281 episode reward: total was -79.400000. running mean: -331.185485\n",
      "startIDX:  309\n",
      "240 12 False\n",
      "x_t:  4 [0.09375    0.425      0.096875   0.37916667]\n",
      "Q values:  tensor([[-29.0213, -28.7201, -27.5784, -28.3164, -26.3622, -27.4071]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7192 739 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 240: ep_len:739 episode reward: total was -378.700000. running mean: -331.660630\n",
      "startIDX:  1202\n",
      "240 15 False\n",
      "x_t:  4 [0.05625    0.3875     0.0625     0.29583333]\n",
      "Q values:  tensor([[-26.0642, -26.6088, -26.9726, -24.6592, -24.1310, -24.9671]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9820 517 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 240: ep_len:517 episode reward: total was -290.700000. running mean: -331.251024\n",
      "startIDX:  13\n",
      "240 22 False\n",
      "x_t:  1 [0.85       0.30833333 0.14375    0.40833333]\n",
      "Q values:  tensor([[-24.0215, -21.9819, -22.1522, -24.1687, -23.9089, -22.3348]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1581 738 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 240: ep_len:738 episode reward: total was -343.700000. running mean: -331.375513\n",
      "startIDX:  2144\n",
      "241 0 True\n",
      "x_t:  1 [0.4        0.3375     0.171875   0.50833333]\n",
      "Q values:  tensor([[-24.5623, -21.6508, -21.7591, -22.5874, -19.0983, -21.6677]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22953 1157 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  553\n",
      "241 1 True\n",
      "x_t:  1 [0.853125   0.26666667 0.14375    0.4625    ]\n",
      "Q values:  tensor([[-19.5411, -22.5009, -22.3601, -21.7005, -19.0588, -19.5812]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30681 733 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2235\n",
      "241 5 False\n",
      "x_t:  3 [0.43125    0.2875     0.078125   0.35833333]\n",
      "Q values:  tensor([[-21.4765, -19.2908, -19.4453, -18.8485, -19.9229, -19.4462]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19938 225 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  483\n",
      "241 10 False\n",
      "x_t:  3 [0.15625    0.2375     0.059375   0.26666667]\n",
      "Q values:  tensor([[-23.7492, -22.5404, -22.6807, -21.0709, -22.5534, -21.3937]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5161 208 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1501\n",
      "241 12 False\n",
      "x_t:  2 [0.078125 0.4125   0.1      0.2875  ]\n",
      "Q values:  tensor([[-24.5553, -25.0067, -21.7084, -25.6835, -23.1808, -21.7936]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19391 779 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  395\n",
      "241 15 False\n",
      "x_t:  0 [0.85       0.40416667 0.1125     0.34166667]\n",
      "Q values:  tensor([[-24.5432, -25.0756, -24.9976, -26.1169, -24.8034, -25.5761]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3658 453 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  155\n",
      "241 22 False\n",
      "x_t:  2 [0.734375   0.40833333 0.05       0.24166667]\n",
      "Q values:  tensor([[-24.7225, -24.1001, -22.2438, -23.9093, -22.4838, -22.9956]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2295 344 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  642\n",
      "242 0 False\n",
      "x_t:  2 [0.003125   0.40833333 0.059375   0.275     ]\n",
      "Q values:  tensor([[-25.4965, -27.0760, -23.5572, -28.6388, -27.1246, -26.7293]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8869 906 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 242: ep_len:906 episode reward: total was -523.500000. running mean: -330.958338\n",
      "startIDX:  1073\n",
      "242 1 False\n",
      "x_t:  3 [0.659375   0.29583333 0.13125    0.39166667]\n",
      "Q values:  tensor([[-20.5584, -20.4561, -20.4639, -18.6200, -21.0152, -20.2215]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35926 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 242: ep_len:201 episode reward: total was -106.000000. running mean: -328.708755\n",
      "startIDX:  1891\n",
      "242 5 False\n",
      "x_t:  2 [0.6375 0.4    0.0875 0.25  ]\n",
      "Q values:  tensor([[-25.8538, -28.0400, -23.6875, -30.3374, -27.3702, -26.3557]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15675 332 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 242: ep_len:332 episode reward: total was -201.600000. running mean: -327.437667\n",
      "startIDX:  97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242 10 False\n",
      "x_t:  3 [0.078125   0.24166667 0.071875   0.2625    ]\n",
      "Q values:  tensor([[-25.3929, -25.8641, -27.5923, -24.8632, -27.0629, -25.5594]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3587 1065 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 242: ep_len:1065 episode reward: total was -625.500000. running mean: -330.418291\n",
      "startIDX:  1316\n",
      "242 12 False\n",
      "x_t:  3 [0.825    0.375    0.171875 0.4375  ]\n",
      "Q values:  tensor([[-23.1799, -23.4890, -22.7259, -22.0336, -24.7313, -22.1503]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17843 229 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 242: ep_len:229 episode reward: total was -41.200000. running mean: -327.526108\n",
      "startIDX:  1316\n",
      "242 15 True\n",
      "x_t:  3 [0.415625   0.28333333 0.065625   0.29166667]\n",
      "Q values:  tensor([[-24.1882, -21.1932, -22.3163, -22.6582, -22.5473, -22.1673]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10419 256 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 242: ep_len:256 episode reward: total was -88.000000. running mean: -325.130847\n",
      "startIDX:  2890\n",
      "ep 242: ep_len:63 episode reward: total was 14.100000. running mean: -321.738538\n",
      "startIDX:  1655\n",
      "243 0 False\n",
      "x_t:  3 [0.334375   0.27083333 0.071875   0.325     ]\n",
      "Q values:  tensor([[-22.6879, -22.3209, -21.9831, -21.3203, -26.1257, -21.9367]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16891 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  23\n",
      "243 1 False\n",
      "x_t:  3 [0.471875   0.26666667 0.0875     0.35416667]\n",
      "Q values:  tensor([[-21.9954, -20.2042, -21.6375, -19.2080, -22.5617, -21.2415]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25692 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1048\n",
      "243 5 False\n",
      "x_t:  3 [0.190625   0.24166667 0.0875     0.275     ]\n",
      "Q values:  tensor([[-25.5017, -25.3463, -28.7896, -24.3650, -28.1817, -25.8583]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10586 216 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  459\n",
      "243 10 False\n",
      "x_t:  3 [0.2625     0.24583333 0.09375    0.3       ]\n",
      "Q values:  tensor([[-28.0821, -27.2694, -27.2971, -25.2283, -27.8733, -26.9228]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5129 207 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1188\n",
      "243 12 True\n",
      "x_t:  4 [0.08125    0.42916667 0.125      0.3625    ]\n",
      "Q values:  tensor([[-23.9658, -24.5722, -25.7809, -25.2658, -26.2196, -25.7611]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17400 507 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1849\n",
      "243 15 False\n",
      "x_t:  0 [0.696875   0.4125     0.103125   0.32916667]\n",
      "Q values:  tensor([[-22.4736, -25.3181, -22.9370, -23.4489, -25.7931, -24.0044]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13396 432 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2699\n",
      "243 22 True\n",
      "x_t:  4 [0.340625   0.38333333 0.103125   0.30416667]\n",
      "Q values:  tensor([[-27.2500, -26.9335, -28.0231, -25.0525, -25.9258, -26.6670]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27316 532 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1571\n",
      "244 0 False\n",
      "x_t:  3 [0.83125    0.35       0.165625   0.41666667]\n",
      "Q values:  tensor([[-24.2146, -25.0695, -26.3435, -24.0015, -26.6250, -26.8636]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16813 224 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 244: ep_len:224 episode reward: total was -103.000000. running mean: -309.445094\n",
      "startIDX:  1074\n",
      "244 1 False\n",
      "x_t:  3 [0.475      0.27916667 0.071875   0.33333333]\n",
      "Q values:  tensor([[-27.4661, -26.8156, -28.7625, -24.1002, -28.8330, -25.7226]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35967 217 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 244: ep_len:217 episode reward: total was -122.500000. running mean: -307.575643\n",
      "startIDX:  1890\n",
      "244 5 False\n",
      "x_t:  2 [0.69375    0.39583333 0.084375   0.25416667]\n",
      "Q values:  tensor([[-26.1595, -26.0277, -24.9034, -27.1380, -25.5566, -26.3266]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15668 330 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 244: ep_len:330 episode reward: total was -249.600000. running mean: -306.995886\n",
      "startIDX:  2067\n",
      "244 10 False\n",
      "x_t:  1 [0.003125   0.35       0.1375     0.40833333]\n",
      "Q values:  tensor([[-30.1166, -27.5257, -28.2275, -30.5082, -28.9131, -28.5513]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18811 274 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 244: ep_len:274 episode reward: total was -192.800000. running mean: -305.853927\n",
      "startIDX:  803\n",
      "244 12 True\n",
      "x_t:  0 [0.7      0.4125   0.059375 0.2875  ]\n",
      "Q values:  tensor([[-32.3098, -31.3876, -31.8186, -30.8306, -32.2230, -32.8112]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11666 665 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 244: ep_len:665 episode reward: total was -524.800000. running mean: -308.043388\n",
      "startIDX:  107\n",
      "244 15 False\n",
      "x_t:  3 [0.81875    0.34166667 0.09375    0.42916667]\n",
      "Q values:  tensor([[-16.0737, -16.0524, -16.1832, -14.9448, -16.0748, -17.5408]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 526 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 244: ep_len:200 episode reward: total was -159.900000. running mean: -306.561954\n",
      "startIDX:  1241\n",
      "244 22 False\n",
      "x_t:  2 [0.775      0.40833333 0.075      0.25833333]\n",
      "Q values:  tensor([[-31.6361, -29.6452, -27.2260, -29.3957, -31.6042, -28.8188]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12594 324 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 244: ep_len:324 episode reward: total was -258.100000. running mean: -306.077335\n",
      "startIDX:  595\n",
      "245 0 False\n",
      "x_t:  2 [0.121875   0.40833333 0.109375   0.26666667]\n",
      "Q values:  tensor([[-33.2588, -32.9489, -30.9718, -32.8653, -33.6353, -31.2341]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8889 947 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1026\n",
      "245 1 False\n",
      "x_t:  3 [0.840625   0.30416667 0.153125   0.42916667]\n",
      "Q values:  tensor([[-31.4432, -31.4986, -31.7375, -26.8648, -32.4313, -30.2090]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35897 210 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1093\n",
      "245 5 False\n",
      "x_t:  3 [0.084375   0.225      0.0625     0.25833333]\n",
      "Q values:  tensor([[-21.3328, -22.6858, -23.1178, -20.8318, -21.1812, -23.7516]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10612 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  488\n",
      "245 10 False\n",
      "x_t:  3 [0.103125   0.225      0.06875    0.25416667]\n",
      "Q values:  tensor([[-13.7898, -12.2817, -13.7257, -10.1044, -14.5889, -14.4519]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5174 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1879\n",
      "245 12 True\n",
      "x_t:  0 [0.240625   0.42916667 0.065625   0.2875    ]\n",
      "Q values:  tensor([[-36.0190, -36.6751, -35.9132, -32.5433, -33.7936, -33.6364]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 22995 919 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1224\n",
      "245 15 False\n",
      "x_t:  3 [0.865625   0.34583333 0.13125    0.39166667]\n",
      "Q values:  tensor([[-30.2679, -31.0030, -32.4529, -30.1329, -30.7711, -31.1333]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10338 268 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1610\n",
      "245 22 False\n",
      "x_t:  3 [0.83125    0.3375     0.090625   0.42083333]\n",
      "Q values:  tensor([[-32.9468, -32.8920, -31.6501, -29.0823, -30.2440, -30.6600]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16851 243 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  822\n",
      "246 0 False\n",
      "x_t:  1 [0.003125   0.36666667 0.1125     0.40416667]\n",
      "Q values:  tensor([[-27.2074, -24.9491, -26.5193, -26.8419, -26.3480, -25.0747]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9405 215 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 246: ep_len:215 episode reward: total was -126.100000. running mean: -298.781755\n",
      "startIDX:  883\n",
      "246 1 False\n",
      "x_t:  4 [0.30625    0.37916667 0.121875   0.39166667]\n",
      "Q values:  tensor([[-24.4655, -26.7646, -26.1830, -27.2257, -23.2301, -24.5669]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35467 541 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 246: ep_len:541 episode reward: total was -337.600000. running mean: -299.169938\n",
      "startIDX:  2742\n",
      "246 5 True\n",
      "x_t:  0 [0.93125    0.38333333 0.059375   0.32083333]\n",
      "Q values:  tensor([[-29.8355, -31.7431, -29.5277, -28.8963, -29.9729, -28.5651]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23150 538 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 246: ep_len:538 episode reward: total was -362.300000. running mean: -299.801238\n",
      "startIDX:  2463\n",
      "246 10 True\n",
      "x_t:  1 [0.846875   0.275      0.078125   0.34583333]\n",
      "Q values:  tensor([[-30.1526, -31.8808, -29.3679, -30.3289, -30.3897, -30.8418]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22474 1151 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 246: ep_len:1151 episode reward: total was -755.200000. running mean: -304.355226\n",
      "startIDX:  431\n",
      "246 12 False\n",
      "x_t:  3 [0.784375   0.34166667 0.071875   0.40833333]\n",
      "Q values:  tensor([[-31.6290, -31.2398, -31.0944, -29.5562, -30.6378, -29.8728]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7723 248 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 246: ep_len:248 episode reward: total was -107.800000. running mean: -302.389674\n",
      "startIDX:  1031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246 15 True\n",
      "x_t:  4 [0.0875   0.3875   0.096875 0.3     ]\n",
      "Q values:  tensor([[-35.0564, -35.0637, -36.6006, -36.2358, -35.2416, -34.5066]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9829 620 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 246: ep_len:620 episode reward: total was -286.000000. running mean: -302.225777\n",
      "startIDX:  418\n",
      "246 22 False\n",
      "x_t:  4 [0.009375   0.41666667 0.090625   0.375     ]\n",
      "Q values:  tensor([[-29.7057, -31.1892, -32.8046, -31.9827, -28.6195, -30.3524]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 6626 860 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 246: ep_len:860 episode reward: total was -475.400000. running mean: -303.957519\n",
      "startIDX:  212\n",
      "247 0 False\n",
      "x_t:  2 [0.703125   0.40416667 0.059375   0.2875    ]\n",
      "Q values:  tensor([[-26.6347, -29.4347, -26.4739, -27.7318, -27.3677, -27.5716]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2341 347 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  329\n",
      "247 1 False\n",
      "x_t:  1 [0.865625   0.2625     0.128125   0.60833333]\n",
      "Q values:  tensor([[-29.0176, -27.0605, -29.3050, -28.5434, -30.5036, -29.2522]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28124 318 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1525\n",
      "247 5 False\n",
      "x_t:  0 [0.8125     0.38333333 0.084375   0.34166667]\n",
      "Q values:  tensor([[-25.4599, -27.2220, -28.1656, -26.6565, -26.2698, -25.5544]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13517 465 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1727\n",
      "247 10 False\n",
      "x_t:  3 [0.4125     0.28333333 0.103125   0.32916667]\n",
      "Q values:  tensor([[-22.5725, -20.8253, -21.1294, -19.1493, -22.9172, -20.7600]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16468 258 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  831\n",
      "247 12 False\n",
      "x_t:  0 [0.915625   0.40833333 0.08125    0.30416667]\n",
      "Q values:  tensor([[-23.4443, -26.7271, -25.8067, -27.6182, -27.5510, -25.6853]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11631 631 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  376\n",
      "247 15 False\n",
      "x_t:  1 [0.4        0.34166667 0.18125    0.53333333]\n",
      "Q values:  tensor([[-24.8072, -23.1389, -25.4465, -26.1343, -24.3938, -24.3934]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2780 245 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2132\n",
      "247 22 False\n",
      "x_t:  0 [0.909375   0.4        0.084375   0.34583333]\n",
      "Q values:  tensor([[-21.9982, -26.0229, -24.5715, -26.9515, -23.4343, -22.7870]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20686 838 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1595\n",
      "248 0 True\n",
      "x_t:  3 [0.696875   0.34166667 0.1625     0.4       ]\n",
      "Q values:  tensor([[-25.1172, -25.8996, -26.1605, -26.2623, -26.0644, -24.9039]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16828 216 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 248: ep_len:216 episode reward: total was -55.600000. running mean: -298.285548\n",
      "startIDX:  1060\n",
      "248 1 True\n",
      "x_t:  3 [0.603125   0.29583333 0.115625   0.36666667]\n",
      "Q values:  tensor([[-27.0130, -24.5793, -25.6165, -25.6560, -25.7308, -22.7820]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35940 211 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 248: ep_len:211 episode reward: total was -79.100000. running mean: -296.093692\n",
      "startIDX:  2953\n",
      "ep 248: ep_len:60 episode reward: total was 52.000000. running mean: -292.612755\n",
      "startIDX:  510\n",
      "248 10 False\n",
      "x_t:  2 [0.103125   0.40833333 0.096875   0.25833333]\n",
      "Q values:  tensor([[-22.1488, -23.8655, -21.5636, -24.0163, -24.4980, -21.6698]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6603 784 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 248: ep_len:784 episode reward: total was -336.000000. running mean: -293.046628\n",
      "startIDX:  2017\n",
      "ep 248: ep_len:40 episode reward: total was 0.200000. running mean: -290.114161\n",
      "startIDX:  2895\n",
      "248 15 False\n",
      "x_t:  0 [0.85625    0.40416667 0.071875   0.35833333]\n",
      "Q values:  tensor([[-22.3939, -24.6742, -22.5503, -23.7172, -23.1298, -22.7512]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23080 513 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 248: ep_len:513 episode reward: total was -253.000000. running mean: -289.743020\n",
      "startIDX:  2084\n",
      "248 22 True\n",
      "x_t:  1 [0.065625   0.35833333 0.090625   0.4       ]\n",
      "Q values:  tensor([[-20.4962, -19.2200, -21.7736, -20.8841, -21.2443, -19.4709]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18996 218 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 248: ep_len:218 episode reward: total was -106.300000. running mean: -287.908590\n",
      "startIDX:  873\n",
      "249 0 False\n",
      "x_t:  0 [0.88125    0.4        0.1125     0.37083333]\n",
      "Q values:  tensor([[-20.7866, -20.9061, -23.7292, -24.8139, -23.9232, -20.9688]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10331 445 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  543\n",
      "249 1 False\n",
      "x_t:  1 [0.846875 0.2625   0.08125  0.4625  ]\n",
      "Q values:  tensor([[-21.3675, -20.3168, -21.0977, -22.8476, -23.3211, -20.3186]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30685 727 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2540\n",
      "249 5 False\n",
      "x_t:  2 [0.003125   0.4        0.075      0.25833333]\n",
      "Q values:  tensor([[-22.1807, -21.7144, -19.6675, -23.0626, -22.9148, -20.2945]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21545 797 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2286\n",
      "249 10 False\n",
      "x_t:  1 [0.546875   0.30833333 0.128125   0.325     ]\n",
      "Q values:  tensor([[-20.3349, -19.2949, -21.7096, -21.5228, -21.3088, -19.6751]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22505 1272 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1966\n",
      "startIDX:  150\n",
      "249 15 False\n",
      "x_t:  2 [0.103125   0.40416667 0.096875   0.34166667]\n",
      "Q values:  tensor([[-20.0245, -19.3827, -19.2669, -22.7272, -21.0652, -19.6382]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2206 816 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  422\n",
      "249 22 False\n",
      "x_t:  4 [0.00625    0.42083333 0.09375    0.36666667]\n",
      "Q values:  tensor([[-21.1213, -19.5581, -22.7488, -20.8037, -19.5309, -19.8630]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 6654 876 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  2073.106846809387\n",
      "startIDX:  590\n",
      "250 0 False\n",
      "x_t:  2 [0.025      0.40833333 0.1125     0.275     ]\n",
      "Q values:  tensor([[-20.6539, -19.9086, -18.5890, -20.7381, -19.9684, -19.7268]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8877 937 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 250: ep_len:937 episode reward: total was -407.000000. running mean: -290.084006\n",
      "startIDX:  69\n",
      "250 1 False\n",
      "x_t:  3 [0.24375    0.2375     0.0875     0.32083333]\n",
      "Q values:  tensor([[-18.2509, -17.8935, -17.5696, -16.8919, -17.9245, -17.3596]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25739 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 250: ep_len:204 episode reward: total was -86.800000. running mean: -288.051166\n",
      "startIDX:  2006\n",
      "250 5 True\n",
      "x_t:  3 [0.33125 0.2875  0.0875  0.375  ]\n",
      "Q values:  tensor([[-16.9973, -17.4343, -18.9297, -19.7150, -17.7616, -17.9107]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18269 1282 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 250: ep_len:1282 episode reward: total was -619.000000. running mean: -291.360655\n",
      "startIDX:  596\n",
      "250 10 False\n",
      "x_t:  2 [0.078125   0.39583333 0.075      0.26666667]\n",
      "Q values:  tensor([[-21.1818, -20.7880, -19.7776, -21.3000, -23.0369, -20.6695]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6597 735 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 250: ep_len:735 episode reward: total was -316.200000. running mean: -291.609048\n",
      "startIDX:  2018\n",
      "ep 250: ep_len:41 episode reward: total was 3.000000. running mean: -288.662958\n",
      "startIDX:  2317\n",
      "250 15 True\n",
      "x_t:  3 [0.175      0.28333333 0.1        0.32083333]\n",
      "Q values:  tensor([[-23.7947, -21.5899, -23.1264, -23.9477, -21.9794, -22.3769]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18196 1259 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 250: ep_len:1259 episode reward: total was -640.100000. running mean: -292.177328\n",
      "startIDX:  1921\n",
      "250 22 True\n",
      "x_t:  2 [0.378125   0.40833333 0.078125   0.2625    ]\n",
      "Q values:  tensor([[-22.6512, -22.0599, -22.8459, -24.8461, -22.6362, -21.0894]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18511 778 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 250: ep_len:778 episode reward: total was -375.100000. running mean: -293.006555\n",
      "startIDX:  2335\n",
      "startIDX:  102\n",
      "251 1 True\n",
      "x_t:  3 [0.16875    0.22916667 0.078125   0.29583333]\n",
      "Q values:  tensor([[-19.2209, -19.2138, -18.8318, -20.4454, -20.4673, -18.5892]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25760 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1364\n",
      "251 5 False\n",
      "x_t:  1 [0.078125   0.3375     0.11875    0.39166667]\n",
      "Q values:  tensor([[-18.9157, -16.3895, -17.8590, -18.9345, -18.2831, -16.8159]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12514 236 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251 10 True\n",
      "x_t:  3 [0.54375    0.29166667 0.09375    0.34583333]\n",
      "Q values:  tensor([[-18.3776, -18.0514, -19.6128, -19.5516, -18.4467, -17.1634]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16449 310 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  399\n",
      "251 12 True\n",
      "x_t:  3 [0.5        0.30833333 0.10625    0.35833333]\n",
      "Q values:  tensor([[-17.2464, -16.2576, -17.1465, -18.0021, -16.6848, -16.0657]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7756 276 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3033\n",
      "startIDX:  646\n",
      "251 22 False\n",
      "x_t:  2 [0.159375   0.41666667 0.09375    0.25833333]\n",
      "Q values:  tensor([[-25.7477, -22.4751, -21.8422, -22.8603, -21.9070, -23.2130]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8943 946 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  658\n",
      "252 0 True\n",
      "x_t:  2 [0.0875     0.40416667 0.059375   0.27083333]\n",
      "Q values:  tensor([[-24.8182, -25.1247, -26.1676, -23.1323, -26.1280, -22.6472]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8883 911 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 252: ep_len:911 episode reward: total was -474.400000. running mean: -288.163574\n",
      "startIDX:  1101\n",
      "ep 252: ep_len:220 episode reward: total was -133.100000. running mean: -286.612938\n",
      "startIDX:  1190\n",
      "252 5 False\n",
      "x_t:  2 [0.15     0.4      0.078125 0.275   ]\n",
      "Q values:  tensor([[-23.1194, -23.8215, -22.3057, -24.7923, -25.8504, -22.8235]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12023 771 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 252: ep_len:771 episode reward: total was -343.000000. running mean: -287.176809\n",
      "startIDX:  1042\n",
      "252 10 False\n",
      "x_t:  1 [0.75625    0.28333333 0.06875    0.34166667]\n",
      "Q values:  tensor([[-27.3091, -26.4304, -27.5527, -27.7548, -28.7170, -26.9858]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11347 1546 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 252: ep_len:1546 episode reward: total was -933.400000. running mean: -293.639041\n",
      "startIDX:  257\n",
      "252 12 False\n",
      "x_t:  3 [0.06875    0.25833333 0.06875    0.27083333]\n",
      "Q values:  tensor([[-26.1516, -24.3505, -24.7262, -24.1520, -25.7427, -25.7991]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5667 1366 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 252: ep_len:1366 episode reward: total was -822.100000. running mean: -298.923650\n",
      "startIDX:  2913\n",
      "252 15 False\n",
      "x_t:  0 [0.65       0.4125     0.075      0.36666667]\n",
      "Q values:  tensor([[-19.3167, -23.1824, -23.0007, -21.6533, -23.3202, -22.5433]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23109 520 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 252: ep_len:520 episode reward: total was -293.700000. running mean: -298.871414\n",
      "startIDX:  2739\n",
      "252 22 False\n",
      "x_t:  4 [0.015625   0.40833333 0.109375   0.30416667]\n",
      "Q values:  tensor([[-24.9503, -26.3802, -24.0906, -25.5654, -23.7413, -24.3674]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27268 479 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 252: ep_len:479 episode reward: total was -242.400000. running mean: -298.306700\n",
      "startIDX:  1374\n",
      "253 0 False\n",
      "x_t:  4 [0.13125    0.38333333 0.075      0.29583333]\n",
      "Q values:  tensor([[-26.4610, -26.6703, -28.5358, -27.1831, -24.8737, -25.2433]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16304 546 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  335\n",
      "253 1 True\n",
      "x_t:  1 [0.515625   0.3        0.24375    0.57916667]\n",
      "Q values:  tensor([[-20.2551, -17.6548, -18.2498, -18.5341, -18.2075, -18.5185]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28100 301 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  212\n",
      "253 5 True\n",
      "x_t:  1 [0.54375    0.3125     0.128125   0.55416667]\n",
      "Q values:  tensor([[-25.6402, -25.6405, -24.8789, -25.2044, -26.9657, -25.2410]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2549 233 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1698\n",
      "253 10 True\n",
      "x_t:  3 [0.640625   0.3        0.13125    0.36666667]\n",
      "Q values:  tensor([[-21.3892, -21.5283, -20.5824, -20.7535, -19.5443, -19.2631]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16430 256 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  338\n",
      "253 12 False\n",
      "x_t:  4 [0.003125   0.44166667 0.13125    0.37083333]\n",
      "Q values:  tensor([[-26.1471, -25.6063, -26.1891, -25.1486, -24.3592, -24.7779]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7184 710 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2502\n",
      "253 15 False\n",
      "x_t:  3 [0.525  0.3    0.0875 0.325 ]\n",
      "Q values:  tensor([[-17.1715, -17.1655, -15.8191, -15.5290, -16.2480, -15.7926]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19714 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1575\n",
      "253 22 False\n",
      "x_t:  4 [0.053125   0.3875     0.109375   0.29583333]\n",
      "Q values:  tensor([[-20.9576, -21.8862, -24.3622, -21.0476, -20.6617, -22.3029]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16331 486 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1440\n",
      "254 0 False\n",
      "x_t:  4 [0.003125   0.39166667 0.090625   0.2875    ]\n",
      "Q values:  tensor([[-18.0468, -18.7984, -18.9078, -18.1419, -17.8229, -18.5777]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16285 499 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 254: ep_len:499 episode reward: total was -260.200000. running mean: -290.606882\n",
      "startIDX:  1071\n",
      "254 1 True\n",
      "x_t:  3 [0.73125    0.3        0.0875     0.39583333]\n",
      "Q values:  tensor([[-21.2113, -20.9081, -21.2983, -19.8432, -19.3623, -19.4116]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35919 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 254: ep_len:200 episode reward: total was -88.900000. running mean: -288.589813\n",
      "startIDX:  204\n",
      "254 5 False\n",
      "x_t:  1 [0.4        0.325      0.1375     0.54583333]\n",
      "Q values:  tensor([[-24.9887, -22.8806, -23.8804, -25.1543, -23.9722, -24.1752]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2538 246 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 254: ep_len:246 episode reward: total was -120.800000. running mean: -286.911915\n",
      "startIDX:  644\n",
      "254 10 True\n",
      "x_t:  2 [0.19375    0.40416667 0.090625   0.25833333]\n",
      "Q values:  tensor([[-19.8154, -19.1476, -21.0895, -20.6920, -19.3287, -19.3565]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6617 710 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 254: ep_len:710 episode reward: total was -401.100000. running mean: -288.053796\n",
      "startIDX:  1890\n",
      "254 12 False\n",
      "x_t:  0 [0.203125   0.43333333 0.06875    0.31666667]\n",
      "Q values:  tensor([[-18.0049, -19.2280, -18.2702, -19.1915, -18.5626, -18.2781]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 22987 923 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 254: ep_len:923 episode reward: total was -541.700000. running mean: -290.590258\n",
      "startIDX:  2552\n",
      "254 15 False\n",
      "x_t:  3 [0.175      0.25416667 0.078125   0.25416667]\n",
      "Q values:  tensor([[-21.0397, -21.3685, -22.3898, -20.3262, -21.6507, -20.6794]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19796 221 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 254: ep_len:221 episode reward: total was -136.400000. running mean: -289.048355\n",
      "startIDX:  401\n",
      "254 22 True\n",
      "x_t:  4 [0.0125     0.41666667 0.090625   0.375     ]\n",
      "Q values:  tensor([[-19.7990, -18.2880, -19.4029, -18.9379, -20.6928, -19.0004]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 6629 880 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 254: ep_len:880 episode reward: total was -460.800000. running mean: -290.765872\n",
      "startIDX:  2515\n",
      "startIDX:  339\n",
      "255 1 False\n",
      "x_t:  1 [0.771875   0.27916667 0.153125   0.59166667]\n",
      "Q values:  tensor([[-23.7732, -21.1383, -22.7415, -22.6804, -23.1310, -22.1105]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28118 303 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1991\n",
      "255 5 False\n",
      "x_t:  3 [0.1        0.25416667 0.1        0.30833333]\n",
      "Q values:  tensor([[-21.4841, -20.7404, -21.2424, -18.0310, -21.8328, -19.9032]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18213 1232 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2347\n",
      "255 10 True\n",
      "x_t:  1 [0.89375    0.27916667 0.103125   0.34166667]\n",
      "Q values:  tensor([[-25.1132, -25.7799, -25.1232, -23.9413, -24.0408, -24.2274]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22466 1192 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2016\n",
      "startIDX:  2472\n",
      "255 15 True\n",
      "x_t:  3 [0.81875    0.3375     0.134375   0.39166667]\n",
      "Q values:  tensor([[-22.2915, -21.1265, -21.6922, -22.7804, -24.6097, -22.1053]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19663 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1216\n",
      "255 22 False\n",
      "x_t:  2 [0.765625   0.40416667 0.04375    0.25416667]\n",
      "Q values:  tensor([[-28.1493, -27.8497, -25.5151, -28.5206, -28.6303, -25.5154]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12597 345 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1613\n",
      "256 0 False\n",
      "x_t:  3 [0.621875   0.32916667 0.121875   0.38333333]\n",
      "Q values:  tensor([[-15.1010, -15.6971, -15.4453, -14.2124, -16.4019, -14.9504]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16839 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 256: ep_len:201 episode reward: total was -78.800000. running mean: -285.201352\n",
      "startIDX:  720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 1 False\n",
      "x_t:  3 [0.096875   0.23333333 0.078125   0.3       ]\n",
      "Q values:  tensor([[-25.0001, -24.9781, -24.6480, -23.2606, -24.7156, -24.1989]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34314 1395 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 256: ep_len:1395 episode reward: total was -764.600000. running mean: -289.995338\n",
      "startIDX:  634\n",
      "256 5 False\n",
      "x_t:  3 [0.065625   0.25833333 0.071875   0.31666667]\n",
      "Q values:  tensor([[-25.2885, -27.5488, -26.7999, -24.5995, -26.7599, -26.6408]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8748 1356 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 256: ep_len:1356 episode reward: total was -713.400000. running mean: -294.229385\n",
      "startIDX:  2172\n",
      "256 10 False\n",
      "x_t:  0 [0.803125   0.3875     0.06875    0.34166667]\n",
      "Q values:  tensor([[-21.3982, -22.1269, -26.7455, -23.7313, -25.2499, -23.2779]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19955 535 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 256: ep_len:535 episode reward: total was -316.400000. running mean: -294.451091\n",
      "startIDX:  1405\n",
      "256 12 False\n",
      "x_t:  3 [0.525      0.32916667 0.115625   0.38333333]\n",
      "Q values:  tensor([[-11.8370, -12.4438, -12.6928, -10.6932, -12.0129, -12.0520]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17883 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 256: ep_len:201 episode reward: total was -62.900000. running mean: -292.135580\n",
      "startIDX:  1838\n",
      "256 15 False\n",
      "x_t:  0 [0.746875   0.39583333 0.065625   0.3375    ]\n",
      "Q values:  tensor([[-20.4365, -22.5507, -23.7189, -22.4832, -22.1708, -20.7628]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13391 427 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 256: ep_len:427 episode reward: total was -218.400000. running mean: -291.398224\n",
      "startIDX:  2747\n",
      "256 22 False\n",
      "x_t:  4 [0.0125     0.41666667 0.1125     0.29583333]\n",
      "Q values:  tensor([[-26.7647, -27.3386, -26.9622, -27.2069, -25.0707, -25.4564]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27267 488 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 256: ep_len:488 episode reward: total was -231.600000. running mean: -290.800242\n",
      "startIDX:  2461\n",
      "startIDX:  380\n",
      "257 1 False\n",
      "x_t:  1 [0.678125   0.27083333 0.153125   0.60416667]\n",
      "Q values:  tensor([[-21.6068, -21.1490, -23.1004, -24.2067, -23.6562, -21.6371]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28110 283 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2379\n",
      "257 5 False\n",
      "x_t:  2 [0.00625    0.39583333 0.06875    0.26666667]\n",
      "Q values:  tensor([[-23.3748, -22.8564, -21.8493, -25.0314, -22.0776, -23.9091]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21547 968 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2201\n",
      "257 10 False\n",
      "x_t:  0 [0.878125   0.3875     0.10625    0.35833333]\n",
      "Q values:  tensor([[-18.2502, -20.0629, -19.5457, -19.9290, -19.1105, -19.0670]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19933 515 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1864\n",
      "257 12 False\n",
      "x_t:  0 [0.2625     0.425      0.075      0.29583333]\n",
      "Q values:  tensor([[-24.7223, -25.7880, -26.7883, -25.3731, -27.7716, -25.2390]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 22996 952 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  70\n",
      "257 15 False\n",
      "x_t:  3 [0.809375 0.35     0.1      0.4125  ]\n",
      "Q values:  tensor([[-18.6177, -21.5492, -18.9658, -17.9223, -19.8097, -18.1619]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 527 221 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1021\n",
      "257 22 False\n",
      "x_t:  0 [0.921875   0.4        0.071875   0.34166667]\n",
      "Q values:  tensor([[-21.5341, -23.2586, -23.1496, -22.6667, -22.1514, -22.7311]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10399 441 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2176\n",
      "258 0 True\n",
      "x_t:  1 [0.4375     0.3375     0.1375     0.50833333]\n",
      "Q values:  tensor([[-24.5256, -26.0482, -26.3165, -26.3841, -24.5237, -24.1529]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22952 1126 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 258: ep_len:1126 episode reward: total was -718.100000. running mean: -292.686829\n",
      "startIDX:  666\n",
      "258 1 True\n",
      "x_t:  3 [0.065625 0.225    0.065625 0.2875  ]\n",
      "Q values:  tensor([[-24.0804, -24.7911, -24.7836, -24.9740, -25.8099, -23.6636]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34304 1411 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 258: ep_len:1411 episode reward: total was -806.600000. running mean: -297.825961\n",
      "startIDX:  2480\n",
      "258 5 False\n",
      "x_t:  2 [0.053125   0.40416667 0.109375   0.25833333]\n",
      "Q values:  tensor([[-26.7963, -26.5110, -23.7875, -27.6445, -26.3096, -24.9665]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21557 819 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 258: ep_len:819 episode reward: total was -430.500000. running mean: -299.152702\n",
      "startIDX:  1459\n",
      "258 10 False\n",
      "x_t:  4 [0.028125   0.36666667 0.103125   0.275     ]\n",
      "Q values:  tensor([[-24.0272, -24.9347, -26.1398, -25.2800, -22.8054, -24.5133]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15710 485 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 258: ep_len:485 episode reward: total was -302.000000. running mean: -299.181175\n",
      "startIDX:  41\n",
      "258 12 False\n",
      "x_t:  1 [0.825      0.30833333 0.16875    0.43333333]\n",
      "Q values:  tensor([[-29.1166, -25.9277, -27.1015, -28.3733, -27.9399, -26.3496]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2219 637 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 258: ep_len:637 episode reward: total was -386.700000. running mean: -300.056363\n",
      "startIDX:  1591\n",
      "258 15 False\n",
      "x_t:  2 [0.03125    0.40833333 0.065625   0.25833333]\n",
      "Q values:  tensor([[-29.6065, -27.2733, -27.0051, -29.5874, -28.0764, -28.2047]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 11913 722 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 258: ep_len:722 episode reward: total was -444.300000. running mean: -301.498799\n",
      "startIDX:  880\n",
      "258 22 False\n",
      "x_t:  1 [0.153125   0.35833333 0.159375   0.40833333]\n",
      "Q values:  tensor([[-28.8790, -27.0786, -30.9790, -29.6753, -28.3648, -29.2693]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9500 255 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 258: ep_len:255 episode reward: total was -82.500000. running mean: -299.308811\n",
      "startIDX:  666\n",
      "259 0 True\n",
      "x_t:  2 [0.021875   0.4125     0.115625   0.26666667]\n",
      "Q values:  tensor([[-27.8167, -30.8263, -27.7194, -29.6357, -29.1510, -28.5051]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8876 895 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  864\n",
      "259 1 False\n",
      "x_t:  4 [0.046875   0.3875     0.09375    0.41666667]\n",
      "Q values:  tensor([[-26.0057, -26.0969, -29.7162, -25.8808, -24.6217, -25.3563]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35429 530 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2606\n",
      "259 5 False\n",
      "x_t:  1 [0.490625   0.30416667 0.08125    0.52083333]\n",
      "Q values:  tensor([[-26.0498, -23.3802, -25.0100, -24.9378, -24.5681, -24.5793]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22145 301 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2603\n",
      "startIDX:  2020\n",
      "startIDX:  2541\n",
      "259 15 False\n",
      "x_t:  3 [0.396875   0.27083333 0.08125    0.29583333]\n",
      "Q values:  tensor([[-3.7528, -6.3017, -3.2024, -1.4996, -4.8108, -5.6549]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19742 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  174\n",
      "259 22 True\n",
      "x_t:  2 [0.821875   0.40833333 0.034375   0.25      ]\n",
      "Q values:  tensor([[-23.1528, -23.0606, -23.5951, -22.7919, -23.0964, -21.6083]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2281 338 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  2157.0744433403015\n",
      "startIDX:  2102\n",
      "260 0 False\n",
      "x_t:  1 [0.0125     0.38333333 0.1875     0.49166667]\n",
      "Q values:  tensor([[-22.6306, -21.1120, -22.7190, -22.3118, -22.4747, -21.2340]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22981 1160 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 260: ep_len:1160 episode reward: total was -728.800000. running mean: -295.251861\n",
      "startIDX:  10\n",
      "260 1 False\n",
      "x_t:  3 [0.471875   0.26666667 0.0875     0.35416667]\n",
      "Q values:  tensor([[-26.8833, -25.2783, -25.5931, -22.7073, -24.9937, -23.4920]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25692 209 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 260: ep_len:209 episode reward: total was -50.900000. running mean: -292.808343\n",
      "startIDX:  3022\n",
      "ep 260: ep_len:28 episode reward: total was 16.000000. running mean: -289.720259\n",
      "startIDX:  374\n",
      "260 10 False\n",
      "x_t:  3 [0.809375   0.29583333 0.084375   0.4       ]\n",
      "Q values:  tensor([[-24.1345, -25.2198, -26.0054, -23.2817, -25.1906, -24.6780]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5043 205 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 260: ep_len:205 episode reward: total was -83.300000. running mean: -287.656056\n",
      "startIDX:  229\n",
      "260 12 False\n",
      "x_t:  3 [0.0625     0.2625     0.071875   0.26666667]\n",
      "Q values:  tensor([[-30.6234, -28.7209, -28.4858, -25.2965, -29.0181, -27.9495]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5664 1386 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 260: ep_len:1386 episode reward: total was -929.000000. running mean: -294.069496\n",
      "startIDX:  1803\n",
      "260 15 False\n",
      "x_t:  0 [0.865625   0.40416667 0.0875     0.31666667]\n",
      "Q values:  tensor([[-25.1391, -28.7591, -27.3127, -26.3578, -28.2154, -27.2724]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13368 429 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 260: ep_len:429 episode reward: total was -268.100000. running mean: -293.809801\n",
      "startIDX:  2782\n",
      "260 22 False\n",
      "x_t:  4 [0.00625    0.40833333 0.115625   0.3       ]\n",
      "Q values:  tensor([[-30.5977, -33.6431, -34.9106, -32.2326, -30.3010, -32.8838]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27265 462 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 260: ep_len:462 episode reward: total was -274.100000. running mean: -293.612703\n",
      "startIDX:  1101\n",
      "261 0 True\n",
      "x_t:  2 [0.7625     0.40416667 0.078125   0.2875    ]\n",
      "Q values:  tensor([[-23.7282, -24.4791, -23.1031, -26.4792, -24.8068, -25.8513]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12638 345 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  6\n",
      "261 1 False\n",
      "x_t:  3 [0.66875    0.29166667 0.13125    0.40416667]\n",
      "Q values:  tensor([[-16.0921, -15.3162, -16.0001, -13.9904, -15.0477, -15.6325]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25658 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  186\n",
      "261 5 True\n",
      "x_t:  1 [0.25       0.35833333 0.1875     0.50833333]\n",
      "Q values:  tensor([[-27.6737, -28.1179, -28.4441, -27.6457, -27.2141, -26.4614]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2532 239 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  180\n",
      "261 10 False\n",
      "x_t:  4 [0.078125   0.3625     0.08125    0.24166667]\n",
      "Q values:  tensor([[-25.7552, -25.3778, -28.1286, -27.8717, -23.9119, -25.2879]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4558 484 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  453\n",
      "261 12 True\n",
      "x_t:  3 [0.7875     0.3375     0.0875     0.42083333]\n",
      "Q values:  tensor([[-21.0059, -22.4706, -22.6825, -21.2744, -22.3463, -20.3648]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7722 241 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2280\n",
      "261 15 False\n",
      "x_t:  3 [0.140625   0.275      0.078125   0.31666667]\n",
      "Q values:  tensor([[-28.5674, -27.7656, -27.6609, -26.0199, -26.8500, -26.2408]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18190 1281 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1012\n",
      "261 22 True\n",
      "x_t:  0 [0.90625    0.4        0.05       0.33333333]\n",
      "Q values:  tensor([[-22.1747, -22.7589, -23.3796, -20.9221, -22.9306, -21.7756]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10403 442 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2032\n",
      "262 0 False\n",
      "x_t:  0 [0.85     0.4      0.115625 0.35    ]\n",
      "Q values:  tensor([[-19.1701, -19.6159, -21.0466, -20.3223, -20.7001, -20.9772]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20635 840 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 262: ep_len:840 episode reward: total was -346.100000. running mean: -288.693856\n",
      "startIDX:  669\n",
      "262 1 False\n",
      "x_t:  3 [0.10625    0.22916667 0.075      0.30416667]\n",
      "Q values:  tensor([[-21.8431, -19.4442, -22.0163, -18.7086, -21.3708, -20.0040]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34317 1440 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 262: ep_len:1440 episode reward: total was -597.500000. running mean: -291.781918\n",
      "startIDX:  1520\n",
      "262 5 True\n",
      "x_t:  0 [0.671875   0.40416667 0.103125   0.33333333]\n",
      "Q values:  tensor([[-18.3846, -18.8391, -19.4673, -18.7153, -19.3368, -18.3489]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13538 473 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 262: ep_len:473 episode reward: total was -178.600000. running mean: -290.650099\n",
      "startIDX:  950\n",
      "262 10 True\n",
      "x_t:  1 [0.671875 0.2875   0.121875 0.3375  ]\n",
      "Q values:  tensor([[-15.7581, -15.3567, -14.6332, -16.2366, -15.9623, -15.4320]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11353 1593 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 262: ep_len:1593 episode reward: total was -661.200000. running mean: -294.355598\n",
      "startIDX:  1363\n",
      "262 12 True\n",
      "x_t:  3 [0.6625     0.3375     0.09375    0.40833333]\n",
      "Q values:  tensor([[-18.5533, -17.1621, -17.7484, -15.9504, -16.9789, -15.0928]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17867 214 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 262: ep_len:214 episode reward: total was -22.500000. running mean: -291.637042\n",
      "startIDX:  2203\n",
      "262 15 False\n",
      "x_t:  3 [0.084375   0.27083333 0.065625   0.30833333]\n",
      "Q values:  tensor([[-18.1495, -19.2295, -20.2387, -17.5601, -18.8276, -18.0597]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18177 1298 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 262: ep_len:1298 episode reward: total was -408.000000. running mean: -292.800671\n",
      "startIDX:  1202\n",
      "262 22 False\n",
      "x_t:  1 [0.74375    0.3125     0.075      0.47916667]\n",
      "Q values:  tensor([[-17.1758, -15.2747, -16.4915, -18.2327, -17.3354, -16.7468]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11930 687 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 262: ep_len:687 episode reward: total was -222.300000. running mean: -292.095665\n",
      "startIDX:  777\n",
      "263 0 True\n",
      "x_t:  1 [0.109375 0.3625   0.15     0.4     ]\n",
      "Q values:  tensor([[-16.5757, -16.2285, -17.7845, -17.0023, -17.0223, -15.2401]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9419 239 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  672\n",
      "263 1 False\n",
      "x_t:  3 [0.0625     0.22916667 0.059375   0.28333333]\n",
      "Q values:  tensor([[-21.1194, -19.3785, -20.9573, -18.4029, -19.4967, -19.6742]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34302 1437 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1030\n",
      "263 5 True\n",
      "x_t:  3 [0.45       0.2875     0.11875    0.31666667]\n",
      "Q values:  tensor([[ 1.0649, -0.3684,  2.9835,  3.9385,  1.4349, -0.5223]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10537 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  495\n",
      "263 10 False\n",
      "x_t:  3 [0.15625    0.2375     0.078125   0.26666667]\n",
      "Q values:  tensor([[-6.7855, -6.1905, -5.5327, -1.5400, -4.7024, -4.9455]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5157 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  175\n",
      "263 12 True\n",
      "x_t:  3 [0.315625   0.29166667 0.1125     0.30416667]\n",
      "Q values:  tensor([[-13.1646, -14.5998, -14.6363, -13.9241, -15.1462, -13.1973]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5715 1466 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  622\n",
      "263 15 True\n",
      "x_t:  1 [0.721875   0.3        0.078125   0.27916667]\n",
      "Q values:  tensor([[-12.5837, -12.9910, -12.5830, -12.6038, -11.7916, -11.3992]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5192 685 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1980\n",
      "263 22 False\n",
      "x_t:  1 [0.44375    0.32916667 0.128125   0.3625    ]\n",
      "Q values:  tensor([[-8.9700, -8.2022, -9.2696, -8.9803, -8.9513, -8.2555]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19038 283 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  124\n",
      "264 0 True\n",
      "x_t:  1 [0.86875    0.3        0.128125   0.42916667]\n",
      "Q values:  tensor([[ -9.1162,  -8.7229, -10.1030, -10.0264,  -9.5051,  -9.0536]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1607 689 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 264: ep_len:689 episode reward: total was -126.100000. running mean: -279.074737\n",
      "startIDX:  596\n",
      "264 1 True\n",
      "x_t:  2 [0.7125     0.37916667 0.065625   0.3125    ]\n",
      "Q values:  tensor([[-7.6944, -8.3727, -8.5047, -8.0196, -8.0360, -7.3110]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31481 394 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 264: ep_len:394 episode reward: total was -94.500000. running mean: -277.228989\n",
      "startIDX:  1406\n",
      "264 5 True\n",
      "x_t:  0 [0.9375     0.3875     0.059375   0.34583333]\n",
      "Q values:  tensor([[ -9.4580, -10.4135,  -9.8309, -10.4957, -10.0664,  -8.9964]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13493 690 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 264: ep_len:690 episode reward: total was -168.600000. running mean: -276.142699\n",
      "startIDX:  2012\n",
      "264 10 True\n",
      "x_t:  1 [0.309375   0.31666667 0.11875    0.34583333]\n",
      "Q values:  tensor([[-8.1590, -8.1237, -9.0969, -8.3531, -8.3069, -7.6241]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18852 322 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 264: ep_len:322 episode reward: total was -48.600000. running mean: -273.867272\n",
      "startIDX:  126\n",
      "264 12 False\n",
      "x_t:  2 [0.5        0.4125     0.075      0.24166667]\n",
      "Q values:  tensor([[-7.9566, -8.4126, -7.2091, -8.1998, -8.6790, -7.2877]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2857 923 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 264: ep_len:923 episode reward: total was -186.400000. running mean: -272.992600\n",
      "startIDX:  2497\n",
      "264 15 False\n",
      "x_t:  3 [0.515625   0.29166667 0.071875   0.3125    ]\n",
      "Q values:  tensor([[ 1.7380,  1.7426,  4.2073,  5.3681,  5.3139, -0.0182]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19717 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 264: ep_len:200 episode reward: total was -16.200000. running mean: -270.424674\n",
      "startIDX:  2315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264 22 True\n",
      "x_t:  2 [0.75       0.40416667 0.053125   0.25      ]\n",
      "Q values:  tensor([[-10.2711, -10.8687, -10.1993, -10.3474, -10.9810,  -9.8001]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23650 1433 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 264: ep_len:1433 episode reward: total was -321.200000. running mean: -270.932427\n",
      "startIDX:  2108\n",
      "265 0 True\n",
      "x_t:  2 [0.78125    0.40416667 0.096875   0.23333333]\n",
      "Q values:  tensor([[-11.5771,  -9.9460, -10.3966, -10.6944, -10.5923,  -9.4433]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23589 1459 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  391\n",
      "265 1 True\n",
      "x_t:  0 [0.6625     0.38333333 0.121875   0.39166667]\n",
      "Q values:  tensor([[ -8.6783, -10.3010, -10.3230, -10.6754,  -9.4268,  -8.7569]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29128 798 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2313\n",
      "265 5 False\n",
      "x_t:  3 [0.16875    0.25       0.08125    0.30833333]\n",
      "Q values:  tensor([[ 0.4926, -0.7293,  1.2177,  2.9478,  1.8120, -0.5809]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19988 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  926\n",
      "265 10 True\n",
      "x_t:  1 [0.85       0.28333333 0.09375    0.32916667]\n",
      "Q values:  tensor([[-14.8596, -14.9105, -14.8656, -14.8816, -16.0622, -13.2448]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11333 1581 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  564\n",
      "265 12 True\n",
      "x_t:  2 [0.753125   0.41666667 0.1        0.25      ]\n",
      "Q values:  tensor([[-11.3595, -10.6642,  -9.8647, -11.0194, -10.7033,  -9.3259]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9942 1089 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1078\n",
      "265 15 True\n",
      "x_t:  4 [0.0625     0.39166667 0.096875   0.29583333]\n",
      "Q values:  tensor([[-8.5795, -8.5153, -9.1608, -8.2601, -8.1087, -7.1945]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9822 579 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1362\n",
      "265 22 True\n",
      "x_t:  3 [0.1        0.25416667 0.05625    0.275     ]\n",
      "Q values:  tensor([[-10.3030, -10.5698, -10.7725, -10.0703, -10.4608,  -9.3760]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15206 1271 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2107\n",
      "266 0 True\n",
      "x_t:  1 [0.4375     0.3375     0.1375     0.50833333]\n",
      "Q values:  tensor([[-10.2043, -10.0820, -10.3444, -10.1964,  -9.8158,  -8.7971]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22952 1148 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 266: ep_len:1148 episode reward: total was -138.000000. running mean: -262.024305\n",
      "startIDX:  116\n",
      "266 1 False\n",
      "x_t:  2 [0.525      0.36666667 0.08125    0.4375    ]\n",
      "Q values:  tensor([[-7.0828, -7.1017, -7.0766, -7.8162, -8.0825, -7.1212]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27503 929 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 266: ep_len:929 episode reward: total was -75.500000. running mean: -260.159062\n",
      "startIDX:  0\n",
      "266 5 False\n",
      "x_t:  0 [0.7125     0.39583333 0.1375     0.375     ]\n",
      "Q values:  tensor([[ -9.3462, -10.5790, -11.0604, -10.0262, -10.7040,  -9.4356]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3575 1672 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 266: ep_len:1672 episode reward: total was -198.000000. running mean: -259.537472\n",
      "startIDX:  519\n",
      "266 10 True\n",
      "x_t:  2 [0.059375 0.4      0.059375 0.25    ]\n",
      "Q values:  tensor([[-7.9213, -7.4198, -7.0354, -7.3194, -7.3145, -6.4665]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6594 775 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 266: ep_len:775 episode reward: total was -40.500000. running mean: -257.347097\n",
      "startIDX:  174\n",
      "266 12 True\n",
      "x_t:  3 [0.384375   0.29583333 0.10625    0.32916667]\n",
      "Q values:  tensor([[-10.2938,  -9.7618,  -9.1342,  -9.8733,  -8.8821,  -7.6847]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5724 1455 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 266: ep_len:1455 episode reward: total was -266.500000. running mean: -257.438626\n",
      "startIDX:  357\n",
      "266 15 True\n",
      "x_t:  0 [0.76875    0.39583333 0.140625   0.5125    ]\n",
      "Q values:  tensor([[-6.9247, -6.5510, -7.2054, -6.7838, -6.6927, -6.3151]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3868 778 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 266: ep_len:778 episode reward: total was -210.000000. running mean: -256.964240\n",
      "startIDX:  1598\n",
      "266 22 True\n",
      "x_t:  3 [0.7625     0.32916667 0.071875   0.39166667]\n",
      "Q values:  tensor([[-4.4069, -4.3176, -4.5760, -4.5745, -3.9116, -3.9063]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16861 255 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 266: ep_len:255 episode reward: total was 37.300000. running mean: -254.021597\n",
      "startIDX:  1926\n",
      "267 0 True\n",
      "x_t:  1 [0.859375   0.29166667 0.078125   0.37916667]\n",
      "Q values:  tensor([[-6.3086, -6.0525, -5.8084, -6.3902, -5.7544, -5.5341]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19013 276 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  280\n",
      "267 1 True\n",
      "x_t:  0 [0.915625   0.375      0.06875    0.39583333]\n",
      "Q values:  tensor([[-7.5245, -8.1631, -7.8117, -7.2387, -7.3359, -6.3198]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29090 1653 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  766\n",
      "267 5 True\n",
      "x_t:  4 [0.134375   0.40416667 0.15       0.38333333]\n",
      "Q values:  tensor([[-5.6796, -5.8368, -6.0954, -5.8495, -5.9823, -4.9137]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10029 636 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  854\n",
      "267 10 True\n",
      "x_t:  0 [0.728125   0.39583333 0.06875    0.30833333]\n",
      "Q values:  tensor([[-6.1216, -6.0270, -6.4905, -6.0791, -5.4504, -4.9682]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8136 477 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  14\n",
      "267 12 True\n",
      "x_t:  1 [0.68125    0.32083333 0.0875     0.44166667]\n",
      "Q values:  tensor([[-6.7624, -7.3017, -7.1649, -7.6289, -6.2464, -5.7685]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2234 646 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1902\n",
      "267 15 True\n",
      "x_t:  1 [0.675      0.3        0.065625   0.30833333]\n",
      "Q values:  tensor([[-8.1325, -8.5822, -8.5024, -8.4811, -7.7304, -6.9507]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14872 719 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1205\n",
      "267 22 False\n",
      "x_t:  1 [0.575      0.32916667 0.084375   0.49583333]\n",
      "Q values:  tensor([[-9.3227, -8.1072, -9.0041, -8.7279, -8.8309, -8.1339]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11942 696 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2375\n",
      "268 0 True\n",
      "x_t:  3 [0.0625     0.23333333 0.05625    0.2375    ]\n",
      "Q values:  tensor([[ -9.3581,  -9.2718, -10.4705,  -9.8423,  -9.4011,  -8.4679]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26091 1209 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 268: ep_len:1209 episode reward: total was -123.300000. running mean: -241.832799\n",
      "startIDX:  282\n",
      "268 1 True\n",
      "x_t:  0 [0.5375     0.36666667 0.1125     0.51666667]\n",
      "Q values:  tensor([[-8.8403, -8.7776, -8.3571, -9.0846, -7.8639, -7.3565]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29197 892 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 268: ep_len:892 episode reward: total was -115.900000. running mean: -240.573471\n",
      "startIDX:  2489\n",
      "268 5 True\n",
      "x_t:  2 [0.0375     0.39583333 0.090625   0.275     ]\n",
      "Q values:  tensor([[-7.8498, -7.9795, -9.3871, -8.1254, -7.9489, -7.2533]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21552 820 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 268: ep_len:820 episode reward: total was -53.100000. running mean: -238.698736\n",
      "startIDX:  2605\n",
      "ep 268: ep_len:15 episode reward: total was -13.900000. running mean: -236.450749\n",
      "startIDX:  1259\n",
      "268 12 True\n",
      "x_t:  4 [0.128125   0.42083333 0.084375   0.37083333]\n",
      "Q values:  tensor([[-7.3193, -7.0289, -6.4177, -7.4280, -6.4999, -6.1044]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17402 473 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 268: ep_len:473 episode reward: total was -36.800000. running mean: -234.454242\n",
      "startIDX:  1379\n",
      "268 15 True\n",
      "x_t:  3 [0.24375    0.25833333 0.075      0.275     ]\n",
      "Q values:  tensor([[-5.4832, -5.5091, -5.8364, -5.4273, -5.4392, -4.7527]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10456 240 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 268: ep_len:240 episode reward: total was -66.400000. running mean: -232.773699\n",
      "startIDX:  1693\n",
      "268 22 True\n",
      "x_t:  3 [0.63125    0.32083333 0.121875   0.37916667]\n",
      "Q values:  tensor([[-5.2049, -4.9380, -5.4367, -5.4454, -5.2624, -4.1467]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16878 214 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 268: ep_len:214 episode reward: total was -5.500000. running mean: -230.500962\n",
      "startIDX:  1019\n",
      "269 0 True\n",
      "x_t:  2 [0.675      0.40833333 0.1        0.29166667]\n",
      "Q values:  tensor([[-6.5239, -6.5304, -6.5439, -6.7897, -5.9414, -5.8187]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12650 1119 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  943\n",
      "269 1 False\n",
      "x_t:  4 [0.35625    0.36666667 0.09375    0.4125    ]\n",
      "Q values:  tensor([[-5.7017, -5.6800, -5.9161, -5.9971, -4.7830, -4.8385]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35474 517 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  92\n",
      "269 5 True\n",
      "x_t:  2 [0.74375  0.3875   0.159375 0.475   ]\n",
      "Q values:  tensor([[-5.1657, -5.3385, -5.1328, -5.2738, -5.4812, -4.5680]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2122 917 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1164\n",
      "269 10 True\n",
      "x_t:  2 [0.121875   0.39583333 0.05625    0.25      ]\n",
      "Q values:  tensor([[-5.1186, -4.8088, -5.0018, -5.0218, -4.3605, -4.1381]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12172 374 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  867\n",
      "269 12 True\n",
      "x_t:  1 [0.746875   0.35416667 0.15       0.50833333]\n",
      "Q values:  tensor([[-5.7450, -5.8265, -5.7806, -5.9302, -6.0250, -4.7651]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12921 629 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2487\n",
      "269 15 True\n",
      "x_t:  3 [0.24375    0.25833333 0.059375   0.2625    ]\n",
      "Q values:  tensor([[-5.3426, -5.0619, -5.6345, -5.1369, -5.1463, -4.5945]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19780 249 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  117\n",
      "269 22 True\n",
      "x_t:  1 [0.821875 0.3      0.075    0.3875  ]\n",
      "Q values:  tensor([[-5.1201, -5.3654, -6.2936, -5.2247, -5.3959, -5.1184]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1586 679 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  2260.135601758957\n",
      "startIDX:  2192\n",
      "270 0 True\n",
      "x_t:  2 [0.503125   0.40833333 0.065625   0.2625    ]\n",
      "Q values:  tensor([[-7.8664, -8.1430, -7.6622, -7.9873, -8.1002, -6.5199]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23640 1470 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 270: ep_len:1470 episode reward: total was -179.400000. running mean: -219.674492\n",
      "startIDX:  763\n",
      "ep 270: ep_len:2216 episode reward: total was -386.400000. running mean: -221.341747\n",
      "startIDX:  1366\n",
      "270 5 True\n",
      "x_t:  1 [0.375      0.30416667 0.06875    0.37916667]\n",
      "Q values:  tensor([[-6.2119, -6.2951, -6.4702, -6.4216, -6.5474, -5.4509]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12542 255 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 270: ep_len:255 episode reward: total was -15.700000. running mean: -219.285329\n",
      "startIDX:  495\n",
      "270 10 True\n",
      "x_t:  3 [0.08125    0.225      0.071875   0.25416667]\n",
      "Q values:  tensor([[-5.1464, -5.2791, -6.0446, -5.6225, -4.8100, -4.4420]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5182 209 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 270: ep_len:209 episode reward: total was -95.400000. running mean: -218.046476\n",
      "startIDX:  985\n",
      "270 12 True\n",
      "x_t:  2 [0.79375    0.4125     0.096875   0.24583333]\n",
      "Q values:  tensor([[-5.7360, -5.6315, -6.5024, -6.6247, -5.8023, -5.0882]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13574 315 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 270: ep_len:315 episode reward: total was -51.600000. running mean: -216.382011\n",
      "startIDX:  591\n",
      "270 15 True\n",
      "x_t:  1 [0.93125    0.29583333 0.05625    0.27916667]\n",
      "Q values:  tensor([[-6.7005, -6.7636, -6.9135, -6.8718, -6.5526, -6.0795]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5163 692 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 270: ep_len:692 episode reward: total was -31.800000. running mean: -214.536191\n",
      "startIDX:  476\n",
      "270 22 False\n",
      "x_t:  3 [0.771875   0.34583333 0.153125   0.38333333]\n",
      "Q values:  tensor([[-9.3650, -8.5886, -8.1347, -7.9605, -8.6407, -8.1313]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7061 1074 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 270: ep_len:1074 episode reward: total was -113.200000. running mean: -213.522829\n",
      "startIDX:  1572\n",
      "271 0 True\n",
      "x_t:  3 [0.66875 0.325   0.08125 0.3875 ]\n",
      "Q values:  tensor([[-5.3973, -5.2612, -5.5869, -5.5408, -4.7244, -4.2264]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16837 228 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  421\n",
      "271 1 True\n",
      "x_t:  1 [0.640625   0.275      0.153125   0.46666667]\n",
      "Q values:  tensor([[-9.0597, -8.8982, -8.5513, -9.1749, -7.8817, -8.0385]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30702 1280 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2127\n",
      "271 5 True\n",
      "x_t:  4 [0.1        0.42916667 0.18125    0.40416667]\n",
      "Q values:  tensor([[-7.7788, -7.5584, -7.8383, -7.6791, -8.0131, -6.3522]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19476 604 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1972\n",
      "271 10 True\n",
      "x_t:  1 [0.10625    0.33333333 0.140625   0.36666667]\n",
      "Q values:  tensor([[-6.3418, -6.5218, -6.3622, -6.2682, -5.7869, -5.1120]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18825 323 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  29\n",
      "271 12 True\n",
      "x_t:  1 [0.94375    0.3        0.05       0.43333333]\n",
      "Q values:  tensor([[-7.6492, -6.4108, -7.5016, -7.2498, -7.2690, -6.1363]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2214 642 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  728\n",
      "271 15 True\n",
      "x_t:  2 [0.728125   0.40416667 0.0875     0.29583333]\n",
      "Q values:  tensor([[-7.2992, -7.0913, -7.2503, -7.1263, -7.4095, -6.2604]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5980 386 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  990\n",
      "271 22 True\n",
      "x_t:  0 [0.853125   0.40416667 0.09375    0.32916667]\n",
      "Q values:  tensor([[-7.0734, -7.2317, -7.5359, -7.1423, -7.8117, -6.4233]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10406 459 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  365\n",
      "272 0 True\n",
      "x_t:  3 [0.078125   0.23333333 0.06875    0.2375    ]\n",
      "Q values:  tensor([[-9.6703, -8.6043, -9.0904, -8.4382, -8.5929, -7.7714]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4842 1204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 272: ep_len:1204 episode reward: total was -113.100000. running mean: -201.728295\n",
      "startIDX:  426\n",
      "272 1 True\n",
      "x_t:  2 [0.634375   0.37916667 0.084375   0.32083333]\n",
      "Q values:  tensor([[-8.2275, -7.2466, -7.1941, -8.0989, -7.5195, -6.7003]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31492 1227 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 272: ep_len:1227 episode reward: total was -116.800000. running mean: -200.879012\n",
      "startIDX:  277\n",
      "272 5 True\n",
      "x_t:  0 [0.578125 0.4      0.15625  0.375   ]\n",
      "Q values:  tensor([[-5.3353, -5.7084, -6.0719, -5.7481, -5.7358, -4.8866]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3592 527 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 272: ep_len:527 episode reward: total was -77.700000. running mean: -199.647222\n",
      "startIDX:  1486\n",
      "272 10 True\n",
      "x_t:  3 [0.884375   0.325      0.1125     0.40416667]\n",
      "Q values:  tensor([[-5.6013, -5.2898, -5.8995, -5.3113, -5.1931, -4.8272]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16400 338 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 272: ep_len:338 episode reward: total was 65.800000. running mean: -196.992750\n",
      "startIDX:  1883\n",
      "272 12 True\n",
      "x_t:  0 [0.628125   0.40833333 0.08125    0.3125    ]\n",
      "Q values:  tensor([[-6.1422, -6.1256, -5.5872, -5.4131, -6.5044, -5.0314]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23060 959 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 272: ep_len:959 episode reward: total was -102.700000. running mean: -196.049823\n",
      "startIDX:  2808\n",
      "272 15 True\n",
      "x_t:  1 [0.009375 0.3875   0.2      0.4875  ]\n",
      "Q values:  tensor([[-5.1934, -5.0838, -5.3606, -5.1980, -4.6004, -4.6692]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22039 257 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 272: ep_len:257 episode reward: total was -1.900000. running mean: -194.108324\n",
      "startIDX:  1140\n",
      "272 22 False\n",
      "x_t:  2 [0.69375    0.40833333 0.071875   0.25833333]\n",
      "Q values:  tensor([[-5.6997, -5.4528, -4.8976, -5.6037, -5.5015, -5.0616]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12607 1080 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 272: ep_len:1080 episode reward: total was -108.000000. running mean: -193.247241\n",
      "startIDX:  1078\n",
      "273 0 True\n",
      "x_t:  2 [0.671875   0.40416667 0.065625   0.3       ]\n",
      "Q values:  tensor([[-6.3708, -6.0361, -6.3748, -5.9588, -6.7398, -5.3591]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12652 1096 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  904\n",
      "273 1 True\n",
      "x_t:  4 [0.184375   0.37916667 0.1375     0.40416667]\n",
      "Q values:  tensor([[-6.0248, -5.8401, -5.9879, -5.4869, -6.4199, -4.5708]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35449 505 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1990\n",
      "273 5 True\n",
      "x_t:  3 [0.0625     0.25       0.084375   0.27083333]\n",
      "Q values:  tensor([[-6.0039, -5.4253, -5.0646, -5.4646, -5.6107, -4.6357]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18204 1246 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1391\n",
      "273 10 True\n",
      "x_t:  4 [0.103125   0.37083333 0.1        0.27083333]\n",
      "Q values:  tensor([[-5.6548, -5.5506, -5.5993, -5.8349, -5.0848, -4.7545]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15720 539 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  659\n",
      "273 12 True\n",
      "x_t:  1 [0.6625     0.33333333 0.1625     0.52916667]\n",
      "Q values:  tensor([[-5.1305, -4.9794, -5.4494, -5.6556, -5.2892, -4.4938]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10348 262 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2789\n",
      "273 15 True\n",
      "x_t:  1 [0.04375    0.3875     0.14375    0.48333333]\n",
      "Q values:  tensor([[-4.8538, -4.6775, -4.6901, -4.7413, -4.5781, -3.7635]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22041 264 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  180\n",
      "273 22 True\n",
      "x_t:  2 [0.5        0.40416667 0.05625    0.25833333]\n",
      "Q values:  tensor([[-4.6601, -4.4814, -4.3750, -4.8549, -4.3894, -3.8336]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2334 366 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1820\n",
      "274 0 True\n",
      "x_t:  2 [0.246875   0.4        0.05625    0.25416667]\n",
      "Q values:  tensor([[-6.2390, -6.7402, -6.8953, -6.6514, -6.7144, -5.2684]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18426 753 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 274: ep_len:753 episode reward: total was -84.800000. running mean: -182.718919\n",
      "startIDX:  510\n",
      "274 1 True\n",
      "x_t:  2 [0.809375   0.38333333 0.071875   0.30833333]\n",
      "Q values:  tensor([[-8.1167, -7.5076, -6.9239, -7.2860, -7.1210, -6.6056]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31465 1147 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 274: ep_len:1147 episode reward: total was -159.600000. running mean: -182.487730\n",
      "startIDX:  1570\n",
      "274 5 True\n",
      "x_t:  1 [0.490625   0.3        0.09375    0.29583333]\n",
      "Q values:  tensor([[-6.3955, -5.6200, -5.7186, -5.3536, -5.9983, -4.8950]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14980 716 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 274: ep_len:716 episode reward: total was -119.100000. running mean: -181.853852\n",
      "startIDX:  1376\n",
      "274 10 True\n",
      "x_t:  4 [0.078125   0.3625     0.05625    0.27083333]\n",
      "Q values:  tensor([[-5.5235, -4.9585, -5.3696, -5.0045, -4.7703, -4.5987]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15714 542 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 274: ep_len:542 episode reward: total was -41.900000. running mean: -180.454314\n",
      "startIDX:  1963\n",
      "ep 274: ep_len:62 episode reward: total was 15.500000. running mean: -178.494771\n",
      "startIDX:  2880\n",
      "274 15 True\n",
      "x_t:  0 [0.321875   0.425      0.084375   0.25416667]\n",
      "Q values:  tensor([[-6.8826, -5.9888, -6.0609, -6.0973, -6.1507, -5.2722]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23155 550 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 274: ep_len:550 episode reward: total was -96.200000. running mean: -177.671823\n",
      "startIDX:  721\n",
      "274 22 False\n",
      "x_t:  2 [0.0375     0.4125     0.059375   0.25833333]\n",
      "Q values:  tensor([[-7.3282, -7.3469, -6.5451, -7.4471, -7.6197, -6.6026]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8920 862 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 274: ep_len:862 episode reward: total was -109.800000. running mean: -176.993105\n",
      "startIDX:  166\n",
      "275 0 True\n",
      "x_t:  2 [0.425      0.40833333 0.078125   0.30833333]\n",
      "Q values:  tensor([[-6.0629, -5.7551, -6.1071, -5.4130, -6.7980, -5.0767]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2381 389 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  280\n",
      "275 1 False\n",
      "x_t:  2 [0.128125   0.36666667 0.15       0.44583333]\n",
      "Q values:  tensor([[-8.6728, -7.3793, -7.2300, -8.2272, -7.5524, -7.4442]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27453 810 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2636\n",
      "275 5 True\n",
      "x_t:  1 [0.3625     0.33333333 0.184375   0.51666667]\n",
      "Q values:  tensor([[-6.6076, -6.1383, -6.6372, -6.4437, -6.7945, -5.7595]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22137 260 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  319\n",
      "275 10 True\n",
      "x_t:  3 [0.61875    0.30416667 0.13125    0.35416667]\n",
      "Q values:  tensor([[-4.9457, -5.4816, -5.6217, -5.3160, -5.1690, -4.6679]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5063 232 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1034\n",
      "275 12 True\n",
      "x_t:  2 [0.70625    0.40416667 0.05       0.25416667]\n",
      "Q values:  tensor([[-6.3818, -5.2825, -6.1154, -5.5020, -6.9220, -5.3677]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13592 296 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  621\n",
      "275 15 False\n",
      "x_t:  1 [0.884375   0.29583333 0.096875   0.27916667]\n",
      "Q values:  tensor([[-9.6229, -7.5717, -9.0493, -8.3503, -8.2370, -7.7726]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5166 659 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2650\n",
      "275 22 True\n",
      "x_t:  4 [0.184375   0.39583333 0.11875    0.30833333]\n",
      "Q values:  tensor([[-10.7031,  -8.7090,  -9.3790,  -9.7870,  -9.1153,  -8.0474]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27291 550 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1077\n",
      "276 0 False\n",
      "x_t:  1 [0.671875   0.30416667 0.125      0.4625    ]\n",
      "Q values:  tensor([[-10.0038,  -8.4085,  -9.4340,  -9.9528,  -9.6708,  -8.4451]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11969 760 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 276: ep_len:760 episode reward: total was -123.200000. running mean: -168.367058\n",
      "startIDX:  652\n",
      "276 1 False\n",
      "x_t:  2 [0.6625     0.3875     0.109375   0.31666667]\n",
      "Q values:  tensor([[-9.0375, -8.6968, -8.0293, -8.8316, -9.2492, -8.1699]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31484 373 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 276: ep_len:373 episode reward: total was -57.500000. running mean: -167.258387\n",
      "startIDX:  417\n",
      "276 5 False\n",
      "x_t:  1 [0.85       0.275      0.06875    0.37916667]\n",
      "Q values:  tensor([[-8.4526, -7.7889, -8.6671, -9.5809, -8.3573, -7.8487]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5033 681 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 276: ep_len:681 episode reward: total was -55.100000. running mean: -166.136803\n",
      "startIDX:  2142\n",
      "276 10 True\n",
      "x_t:  0 [0.9    0.3875 0.0875 0.3625]\n",
      "Q values:  tensor([[-9.5029, -9.7321, -9.1794, -9.4549, -9.7308, -7.7754]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19929 536 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 276: ep_len:536 episode reward: total was -97.200000. running mean: -165.447435\n",
      "startIDX:  1770\n",
      "276 12 True\n",
      "x_t:  0 [0.265625   0.42083333 0.08125    0.275     ]\n",
      "Q values:  tensor([[-10.3201,  -9.0600,  -9.5656,  -9.6820,  -9.4189,  -8.2346]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21171 630 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 276: ep_len:630 episode reward: total was -129.900000. running mean: -165.091961\n",
      "startIDX:  480\n",
      "276 15 True\n",
      "x_t:  2 [0.76875    0.4        0.071875   0.30416667]\n",
      "Q values:  tensor([[-10.7639, -11.2739, -10.1280, -11.4089, -11.8216,  -9.7341]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5974 1135 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 276: ep_len:1135 episode reward: total was -200.700000. running mean: -165.448041\n",
      "startIDX:  1656\n",
      "276 22 True\n",
      "x_t:  3 [0.265625   0.28333333 0.096875   0.29583333]\n",
      "Q values:  tensor([[-5.0386, -4.9283, -5.8999, -5.7362, -5.4189, -4.7028]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16942 267 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 276: ep_len:267 episode reward: total was -18.600000. running mean: -163.979561\n",
      "startIDX:  2488\n",
      "startIDX:  502\n",
      "277 1 True\n",
      "x_t:  1 [0.59375    0.28333333 0.15       0.46666667]\n",
      "Q values:  tensor([[-7.6098, -7.1052, -7.1929, -7.2183, -7.5702, -5.9483]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30709 761 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2548\n",
      "277 5 True\n",
      "x_t:  2 [0.434375   0.39583333 0.096875   0.26666667]\n",
      "Q values:  tensor([[-9.9014, -8.7716, -9.4915, -9.9400, -9.0279, -7.9734]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21620 811 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1620\n",
      "277 10 True\n",
      "x_t:  3 [0.53125    0.2875     0.0625     0.34583333]\n",
      "Q values:  tensor([[-6.1259, -5.3032, -5.3986, -5.3862, -5.2534, -4.2127]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16453 302 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  116\n",
      "277 12 True\n",
      "x_t:  1 [0.8875     0.30833333 0.109375   0.42916667]\n",
      "Q values:  tensor([[-6.4541, -6.5625, -7.0597, -7.1200, -7.3229, -6.0049]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2216 595 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2186\n",
      "277 15 True\n",
      "x_t:  2 [0.671875   0.40833333 0.05       0.25833333]\n",
      "Q values:  tensor([[-5.8291, -5.6257, -6.0066, -6.8450, -5.8430, -5.1227]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15588 315 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1668\n",
      "277 22 True\n",
      "x_t:  3 [0.790625   0.34166667 0.125      0.4125    ]\n",
      "Q values:  tensor([[-5.4577, -5.3191, -5.2524, -5.7937, -5.8864, -4.4088]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16855 222 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1484\n",
      "278 0 True\n",
      "x_t:  3 [0.69375    0.33333333 0.121875   0.4       ]\n",
      "Q values:  tensor([[-5.2188, -4.9198, -5.5962, -5.0481, -5.8230, -4.5321]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16833 275 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 278: ep_len:275 episode reward: total was 43.200000. running mean: -152.787615\n",
      "startIDX:  348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278 1 True\n",
      "x_t:  1 [0.859375   0.25833333 0.1375     0.46666667]\n",
      "Q values:  tensor([[ -9.7600,  -9.8097, -10.5560,  -9.6403, -10.3291,  -8.8765]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30677 1579 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 278: ep_len:1579 episode reward: total was -257.600000. running mean: -153.835739\n",
      "startIDX:  963\n",
      "278 5 True\n",
      "x_t:  3 [0.084375   0.225      0.0625     0.25833333]\n",
      "Q values:  tensor([[-5.2028, -4.9640, -5.2129, -5.0166, -5.2569, -4.1622]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10612 275 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 278: ep_len:275 episode reward: total was -14.800000. running mean: -152.445381\n",
      "startIDX:  2580\n",
      "ep 278: ep_len:29 episode reward: total was -23.900000. running mean: -151.159928\n",
      "startIDX:  812\n",
      "278 12 True\n",
      "x_t:  0 [0.75       0.40833333 0.08125    0.30416667]\n",
      "Q values:  tensor([[-7.1116, -6.9258, -7.0824, -7.5076, -7.2310, -6.4057]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11659 664 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 278: ep_len:664 episode reward: total was -92.400000. running mean: -150.572328\n",
      "startIDX:  1374\n",
      "278 15 True\n",
      "x_t:  3 [0.5375     0.2875     0.075      0.32083333]\n",
      "Q values:  tensor([[-5.1135, -4.4282, -4.5448, -4.5979, -5.0907, -3.9584]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10394 222 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 278: ep_len:222 episode reward: total was -25.700000. running mean: -149.323605\n",
      "startIDX:  2233\n",
      "278 22 True\n",
      "x_t:  1 [0.321875   0.35833333 0.153125   0.45416667]\n",
      "Q values:  tensor([[-9.1546, -8.2323, -7.3331, -7.6710, -8.1499, -6.7418]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22984 1144 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 278: ep_len:1144 episode reward: total was -70.000000. running mean: -148.530369\n",
      "startIDX:  1571\n",
      "279 0 True\n",
      "x_t:  3 [0.5875     0.3125     0.109375   0.38333333]\n",
      "Q values:  tensor([[-4.3877, -4.2874, -4.8534, -3.9996, -4.4066, -4.0295]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16847 231 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  665\n",
      "279 1 True\n",
      "x_t:  3 [0.0625     0.23333333 0.059375   0.275     ]\n",
      "Q values:  tensor([[-9.6302, -8.5153, -8.0799, -8.9220, -9.5035, -7.8295]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34301 1438 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1013\n",
      "279 5 True\n",
      "x_t:  3 [0.5375     0.2875     0.153125   0.35833333]\n",
      "Q values:  tensor([[2.2000, 0.3335, 4.0322, 3.0815, 1.6174, 1.0635]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 10521 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2592\n",
      "startIDX:  1724\n",
      "279 12 False\n",
      "x_t:  1 [0.36875    0.33333333 0.075      0.37083333]\n",
      "Q values:  tensor([[-4.5881, -3.7643, -4.0550, -4.3055, -4.4675, -3.7779]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19907 211 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1320\n",
      "279 15 True\n",
      "x_t:  3 [0.915625   0.35       0.078125   0.38333333]\n",
      "Q values:  tensor([[-4.5147, -4.3234, -4.8325, -4.6043, -4.4245, -3.5977]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10334 219 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2867\n",
      "Time elapsed:  2346.7743244171143\n",
      "startIDX:  1557\n",
      "280 0 True\n",
      "x_t:  3 [0.678125   0.33333333 0.0875     0.38333333]\n",
      "Q values:  tensor([[-4.2604, -4.0415, -4.5126, -3.9420, -3.9788, -3.5725]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16836 242 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 280: ep_len:242 episode reward: total was 11.400000. running mean: -137.936434\n",
      "startIDX:  72\n",
      "280 1 True\n",
      "x_t:  2 [0.003125   0.36666667 0.10625    0.45833333]\n",
      "Q values:  tensor([[-5.0464, -5.1146, -5.4610, -5.7789, -5.7923, -4.8959]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27432 1048 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 280: ep_len:1048 episode reward: total was -159.800000. running mean: -138.155070\n",
      "startIDX:  359\n",
      "280 5 True\n",
      "x_t:  1 [0.859375   0.28333333 0.10625    0.39583333]\n",
      "Q values:  tensor([[-5.4173, -5.1303, -4.8966, -5.8651, -5.1720, -4.7521]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5030 707 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 280: ep_len:707 episode reward: total was -15.600000. running mean: -136.929519\n",
      "startIDX:  1659\n",
      "280 10 False\n",
      "x_t:  3 [0.15625    0.24166667 0.0625     0.26666667]\n",
      "Q values:  tensor([[-4.5101, -4.4123, -5.1024, -3.7749, -4.7320, -4.1055]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16532 327 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 280: ep_len:327 episode reward: total was -63.600000. running mean: -136.196224\n",
      "startIDX:  434\n",
      "280 12 True\n",
      "x_t:  3 [0.4875     0.30416667 0.075      0.34166667]\n",
      "Q values:  tensor([[-5.0022, -4.6800, -5.2888, -5.0096, -5.3337, -4.2206]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7760 266 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 280: ep_len:266 episode reward: total was -27.300000. running mean: -135.107262\n",
      "startIDX:  2084\n",
      "280 15 True\n",
      "x_t:  2 [0.74375    0.40833333 0.059375   0.25833333]\n",
      "Q values:  tensor([[-4.8519, -4.4603, -4.7913, -4.7353, -5.0676, -3.9343]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15576 357 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 280: ep_len:357 episode reward: total was -68.900000. running mean: -134.445189\n",
      "startIDX:  1671\n",
      "280 22 True\n",
      "x_t:  3 [0.778125   0.33333333 0.096875   0.40416667]\n",
      "Q values:  tensor([[-3.7432, -3.8763, -4.5154, -4.3702, -4.2661, -3.5465]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16859 212 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 280: ep_len:212 episode reward: total was 1.800000. running mean: -133.082737\n",
      "startIDX:  1886\n",
      "281 0 True\n",
      "x_t:  1 [0.40625 0.3375  0.15    0.375  ]\n",
      "Q values:  tensor([[-4.2939, -4.1319, -4.3364, -4.6464, -5.0853, -4.0912]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18964 276 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  420\n",
      "281 1 True\n",
      "x_t:  0 [0.671875   0.37916667 0.1125     0.4       ]\n",
      "Q values:  tensor([[-5.1016, -5.0223, -5.5114, -5.1910, -5.2294, -4.1966]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29125 506 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2538\n",
      "281 5 True\n",
      "x_t:  2 [0.096875   0.39166667 0.06875    0.27083333]\n",
      "Q values:  tensor([[-5.1973, -4.8364, -5.0216, -4.4570, -5.4108, -4.5154]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21562 797 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2550\n",
      "startIDX:  1793\n",
      "281 12 True\n",
      "x_t:  0 [0.90625    0.40416667 0.0875     0.3625    ]\n",
      "Q values:  tensor([[-6.4387, -5.9902, -6.0180, -5.7564, -5.7663, -5.4756]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21091 587 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1752\n",
      "281 15 True\n",
      "x_t:  0 [0.909375   0.40416667 0.05       0.32083333]\n",
      "Q values:  tensor([[-5.8169, -5.5767, -5.1885, -5.4398, -5.6054, -4.7016]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13367 459 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2225\n",
      "281 22 True\n",
      "x_t:  1 [0.6        0.32916667 0.165625   0.43333333]\n",
      "Q values:  tensor([[-6.2366, -6.6531, -6.4326, -6.6329, -6.4189, -5.7651]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22955 1130 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2452\n",
      "ep 282: ep_len:66 episode reward: total was 44.000000. running mean: -125.770329\n",
      "startIDX:  206\n",
      "282 1 True\n",
      "x_t:  2 [0.328125   0.37083333 0.140625   0.42916667]\n",
      "Q values:  tensor([[-6.6220, -6.5651, -6.8243, -6.1595, -7.0079, -5.4167]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27479 872 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 282: ep_len:872 episode reward: total was -79.600000. running mean: -125.308625\n",
      "startIDX:  2295\n",
      "282 5 False\n",
      "x_t:  3 [0.446875   0.29583333 0.15       0.375     ]\n",
      "Q values:  tensor([[ 1.9970, -0.3295,  1.8620,  2.6565,  0.6589,  0.8060]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19930 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 282: ep_len:200 episode reward: total was 1.600000. running mean: -124.039539\n",
      "startIDX:  906\n",
      "282 10 True\n",
      "x_t:  1 [0.74375    0.28333333 0.059375   0.33333333]\n",
      "Q values:  tensor([[-7.6495, -7.2920, -6.9438, -6.8137, -7.4785, -6.3902]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11348 1617 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 282: ep_len:1617 episode reward: total was -167.400000. running mean: -124.473144\n",
      "startIDX:  661\n",
      "282 12 True\n",
      "x_t:  1 [0.365625   0.35833333 0.10625    0.5125    ]\n",
      "Q values:  tensor([[-5.1840, -4.4566, -5.3258, -5.6020, -4.9561, -4.3579]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10327 246 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 282: ep_len:246 episode reward: total was 23.600000. running mean: -122.992412\n",
      "startIDX:  2909\n",
      "282 15 False\n",
      "x_t:  0 [0.675      0.4125     0.128125   0.35416667]\n",
      "Q values:  tensor([[-4.3341, -5.1314, -5.7434, -5.0610, -5.0961, -4.7079]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23103 518 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 282: ep_len:518 episode reward: total was -79.900000. running mean: -122.561488\n",
      "startIDX:  2860\n",
      "ep 282: ep_len:78 episode reward: total was 52.000000. running mean: -120.815873\n",
      "startIDX:  153\n",
      "283 0 False\n",
      "x_t:  1 [0.371875   0.33333333 0.13125    0.42916667]\n",
      "Q values:  tensor([[-5.1772, -4.9065, -6.1544, -5.5689, -6.0241, -4.9451]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1661 709 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  493\n",
      "283 1 True\n",
      "x_t:  1 [0.859375   0.25833333 0.1375     0.46666667]\n",
      "Q values:  tensor([[-6.2496, -6.1241, -6.2268, -6.3639, -6.4617, -5.5913]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30677 765 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2722\n",
      "283 5 True\n",
      "x_t:  1 [0.3875     0.32083333 0.18125    0.52083333]\n",
      "Q values:  tensor([[-5.6535, -5.2812, -5.5868, -5.5028, -5.5325, -4.5711]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22141 243 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1780\n",
      "283 10 True\n",
      "x_t:  2 [0.596875   0.39583333 0.078125   0.25      ]\n",
      "Q values:  tensor([[-6.1002, -6.7525, -6.2233, -7.1915, -7.3756, -5.9206]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18254 901 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1268\n",
      "283 12 True\n",
      "x_t:  4 [0.39375    0.37916667 0.084375   0.30416667]\n",
      "Q values:  tensor([[-6.0548, -5.6641, -5.9673, -5.3807, -6.4536, -5.4154]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17445 498 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2045\n",
      "283 15 True\n",
      "x_t:  1 [0.6625     0.30833333 0.075      0.29583333]\n",
      "Q values:  tensor([[-6.9034, -6.5635, -7.3745, -7.3737, -7.3096, -6.5645]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14873 666 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3007\n",
      "startIDX:  2245\n",
      "284 0 True\n",
      "x_t:  2 [0.7625     0.40416667 0.0625     0.2375    ]\n",
      "Q values:  tensor([[-6.5994, -6.6397, -6.9921, -6.9949, -7.0729, -5.3933]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23598 334 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 284: ep_len:334 episode reward: total was -49.700000. running mean: -117.076649\n",
      "startIDX:  449\n",
      "284 1 True\n",
      "x_t:  1 [0.603125   0.28333333 0.125      0.47083333]\n",
      "Q values:  tensor([[-7.4633, -6.8773, -7.8803, -7.7457, -8.2565, -7.3225]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30710 809 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 284: ep_len:809 episode reward: total was -43.800000. running mean: -116.343882\n",
      "startIDX:  1607\n",
      "284 5 True\n",
      "x_t:  1 [0.896875   0.27083333 0.059375   0.32916667]\n",
      "Q values:  tensor([[-7.9608, -7.4928, -7.6396, -7.9279, -7.7091, -7.3443]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14922 668 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 284: ep_len:668 episode reward: total was -88.700000. running mean: -116.067444\n",
      "startIDX:  709\n",
      "284 10 False\n",
      "x_t:  1 [0.096875   0.34583333 0.14375    0.36666667]\n",
      "Q values:  tensor([[-7.2323, -5.8666, -7.1577, -7.4890, -6.9146, -5.9303]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7117 245 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 284: ep_len:245 episode reward: total was 15.500000. running mean: -114.751769\n",
      "startIDX:  997\n",
      "284 12 True\n",
      "x_t:  2 [0.60625  0.4125   0.053125 0.25    ]\n",
      "Q values:  tensor([[-5.1273, -5.6344, -6.2542, -5.7024, -6.5358, -5.3848]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13607 347 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 284: ep_len:347 episode reward: total was -61.600000. running mean: -114.220252\n",
      "startIDX:  1427\n",
      "284 15 False\n",
      "x_t:  3 [0.3125     0.2625     0.090625   0.29583333]\n",
      "Q values:  tensor([[-4.0801, -4.3342, -4.8719, -3.7998, -5.0662, -4.0857]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10439 207 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 284: ep_len:207 episode reward: total was -64.300000. running mean: -113.721049\n",
      "startIDX:  79\n",
      "284 22 False\n",
      "x_t:  1 [0.85       0.30833333 0.14375    0.40833333]\n",
      "Q values:  tensor([[-9.3552, -8.3023, -8.8088, -8.5773, -9.5332, -8.4987]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1581 688 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 284: ep_len:688 episode reward: total was -57.800000. running mean: -113.161839\n",
      "startIDX:  2392\n",
      "285 0 True\n",
      "x_t:  3 [0.190625   0.25       0.06875    0.27083333]\n",
      "Q values:  tensor([[-13.0271, -12.5501, -12.6722, -12.2402, -13.4590, -11.1827]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26130 1218 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1017\n",
      "285 1 True\n",
      "x_t:  3 [0.5625     0.28333333 0.090625   0.35833333]\n",
      "Q values:  tensor([[-6.5863, -6.3904, -6.2042, -5.8027, -6.3016, -5.2969]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35948 245 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1074\n",
      "285 5 True\n",
      "x_t:  2 [0.040625   0.3875     0.065625   0.27916667]\n",
      "Q values:  tensor([[-8.8084, -8.6201, -9.6168, -9.0796, -9.3889, -7.9262]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12008 911 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  31\n",
      "285 10 False\n",
      "x_t:  3 [0.296875   0.27083333 0.078125   0.32083333]\n",
      "Q values:  tensor([[ -9.8202, -10.6568,  -9.5627,  -8.7666, -10.8082,  -8.8316]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3645 1141 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  825\n",
      "285 12 True\n",
      "x_t:  0 [0.9125  0.4125  0.08125 0.3    ]\n",
      "Q values:  tensor([[-7.3139, -6.8050, -7.2138, -7.7315, -7.2313, -6.4765]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11628 642 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1425\n",
      "285 15 False\n",
      "x_t:  2 [0.159375   0.40833333 0.08125    0.2625    ]\n",
      "Q values:  tensor([[-7.5189, -8.4799, -7.5173, -8.0212, -8.3065, -7.6027]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 11934 963 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  556\n",
      "285 22 True\n",
      "x_t:  3 [0.796875   0.3375     0.128125   0.39583333]\n",
      "Q values:  tensor([[-5.0934, -4.9347, -4.8777, -5.4757, -5.4227, -4.2628]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7058 213 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1943\n",
      "286 0 True\n",
      "x_t:  1 [0.18125    0.35       0.140625   0.39583333]\n",
      "Q values:  tensor([[-7.0889, -6.3806, -7.0203, -6.6823, -7.2130, -5.6239]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18942 236 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 286: ep_len:236 episode reward: total was -4.000000. running mean: -111.038631\n",
      "startIDX:  468\n",
      "286 1 True\n",
      "x_t:  1 [0.46875    0.29166667 0.109375   0.475     ]\n",
      "Q values:  tensor([[-6.6533, -6.1919, -6.4158, -5.9832, -7.0225, -5.6866]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30725 791 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 286: ep_len:791 episode reward: total was -40.000000. running mean: -110.328245\n",
      "startIDX:  1737\n",
      "286 5 True\n",
      "x_t:  1 [0.909375   0.27083333 0.084375   0.3375    ]\n",
      "Q values:  tensor([[-6.0992, -5.1279, -5.9770, -6.1640, -5.5761, -5.0061]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14916 596 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 286: ep_len:596 episode reward: total was -20.200000. running mean: -109.426962\n",
      "startIDX:  1787\n",
      "286 10 True\n",
      "x_t:  2 [0.128125   0.4        0.084375   0.24583333]\n",
      "Q values:  tensor([[-7.0601, -6.6291, -6.3271, -6.6102, -6.2479, -5.4232]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18166 871 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 286: ep_len:871 episode reward: total was -83.500000. running mean: -109.167693\n",
      "startIDX:  2001\n",
      "ep 286: ep_len:49 episode reward: total was -14.600000. running mean: -108.222016\n",
      "startIDX:  2931\n",
      "286 15 True\n",
      "x_t:  0 [0.925      0.39583333 0.06875    0.3625    ]\n",
      "Q values:  tensor([[-5.5738, -5.0238, -5.1141, -5.4936, -5.4383, -4.1856]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23067 485 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 286: ep_len:485 episode reward: total was -46.500000. running mean: -107.604796\n",
      "startIDX:  1242\n",
      "286 22 True\n",
      "x_t:  2 [0.765625   0.40416667 0.04375    0.25416667]\n",
      "Q values:  tensor([[-5.4560, -4.9953, -5.7181, -5.1836, -5.8850, -4.5730]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12597 325 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 286: ep_len:325 episode reward: total was -46.900000. running mean: -106.997748\n",
      "startIDX:  844\n",
      "287 0 True\n",
      "x_t:  1 [0.459375   0.32083333 0.134375   0.43333333]\n",
      "Q values:  tensor([[-5.1434, -4.8666, -5.0170, -4.8429, -4.7224, -4.0563]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9458 227 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  464\n",
      "287 1 True\n",
      "x_t:  1 [0.8625  0.2625  0.10625 0.4625 ]\n",
      "Q values:  tensor([[-5.6984, -5.0995, -5.1658, -4.6379, -5.6038, -4.5082]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30683 772 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  112\n",
      "287 5 False\n",
      "x_t:  2 [0.734375   0.375      0.115625   0.47083333]\n",
      "Q values:  tensor([[-4.7359, -5.5073, -4.4939, -5.0056, -5.2531, -4.6578]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2117 921 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  920\n",
      "287 10 True\n",
      "x_t:  2 [0.74375    0.39583333 0.06875    0.25      ]\n",
      "Q values:  tensor([[-8.9144, -8.2612, -8.7827, -8.5516, -9.5108, -7.7408]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12072 1967 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  397\n",
      "287 12 True\n",
      "x_t:  3 [0.0625     0.25416667 0.053125   0.24166667]\n",
      "Q values:  tensor([[-3.8205, -3.6243, -4.0745, -3.5412, -3.7476, -3.2548]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7846 333 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2660\n",
      "287 15 False\n",
      "x_t:  1 [0.075      0.37916667 0.1125     0.49166667]\n",
      "Q values:  tensor([[-5.2033, -4.8463, -5.6342, -5.2037, -5.1425, -4.8601]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22043 1131 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2500\n",
      "287 22 False\n",
      "x_t:  3 [0.21875    0.27083333 0.096875   0.27916667]\n",
      "Q values:  tensor([[-6.4157, -6.5237, -6.1795, -5.7032, -6.5920, -5.7372]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26223 1297 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  961\n",
      "288 0 False\n",
      "x_t:  1 [0.36875    0.34166667 0.159375   0.475     ]\n",
      "Q values:  tensor([[-5.1178, -4.2646, -4.7512, -4.9526, -5.1939, -4.3843]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11996 841 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 288: ep_len:841 episode reward: total was -51.100000. running mean: -105.747713\n",
      "startIDX:  416\n",
      "288 1 True\n",
      "x_t:  0 [0.740625   0.38333333 0.140625   0.39166667]\n",
      "Q values:  tensor([[-5.6493, -5.3257, -5.4730, -5.5031, -5.9620, -4.5013]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29113 489 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 288: ep_len:489 episode reward: total was -67.000000. running mean: -105.360236\n",
      "startIDX:  1266\n",
      "288 5 True\n",
      "x_t:  2 [0.14375    0.39166667 0.06875    0.27916667]\n",
      "Q values:  tensor([[-7.0187, -7.0797, -6.5860, -6.4278, -6.6970, -5.6128]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12022 723 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 288: ep_len:723 episode reward: total was -59.900000. running mean: -104.905634\n",
      "startIDX:  1026\n",
      "288 10 False\n",
      "x_t:  1 [0.871875   0.28333333 0.121875   0.34583333]\n",
      "Q values:  tensor([[-10.3663,  -9.6225, -11.7915, -11.1001, -11.3715,  -9.7575]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11326 1539 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 288: ep_len:1539 episode reward: total was -189.500000. running mean: -105.751577\n",
      "startIDX:  1814\n",
      "288 12 False\n",
      "x_t:  0 [0.6875     0.41666667 0.121875   0.34583333]\n",
      "Q values:  tensor([[-5.6691, -6.3085, -6.4849, -6.2927, -6.1709, -5.8135]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21118 589 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 288: ep_len:589 episode reward: total was -84.500000. running mean: -105.539062\n",
      "startIDX:  1888\n",
      "288 15 True\n",
      "x_t:  1 [0.49375    0.30833333 0.065625   0.30416667]\n",
      "Q values:  tensor([[-8.1081, -7.4348, -7.7467, -7.5913, -7.9887, -6.6293]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14894 749 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 288: ep_len:749 episode reward: total was -56.400000. running mean: -105.047671\n",
      "startIDX:  2185\n",
      "288 22 True\n",
      "x_t:  0 [0.69375    0.40833333 0.059375   0.30833333]\n",
      "Q values:  tensor([[-8.4153, -7.6351, -8.0218, -7.2180, -7.9324, -6.6244]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20757 852 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 288: ep_len:852 episode reward: total was -131.900000. running mean: -105.316194\n",
      "startIDX:  1407\n",
      "289 0 True\n",
      "x_t:  4 [0.421875   0.36666667 0.096875   0.275     ]\n",
      "Q values:  tensor([[-6.7277, -7.2238, -7.4924, -6.9226, -7.7118, -6.0995]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16353 554 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  584\n",
      "289 1 True\n",
      "x_t:  2 [0.725      0.38333333 0.109375   0.3125    ]\n",
      "Q values:  tensor([[-5.9620, -5.7263, -5.7089, -5.0967, -5.9796, -4.9313]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31474 391 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1771\n",
      "289 5 False\n",
      "x_t:  1 [0.859375   0.27916667 0.078125   0.31666667]\n",
      "Q values:  tensor([[-7.2636, -6.0752, -6.7626, -6.3772, -6.5272, -6.1297]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14925 581 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  492\n",
      "289 10 False\n",
      "x_t:  2 [0.003125   0.40833333 0.115625   0.25416667]\n",
      "Q values:  tensor([[-8.2757, -7.7806, -6.7831, -7.6003, -8.0006, -6.8563]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6588 893 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1000\n",
      "289 12 True\n",
      "x_t:  2 [0.715625 0.4125   0.06875  0.25    ]\n",
      "Q values:  tensor([[-5.5632, -5.0001, -5.0255, -4.9891, -4.7844, -4.2785]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13590 330 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1236\n",
      "289 15 True\n",
      "x_t:  3 [0.634375   0.3125     0.09375    0.35416667]\n",
      "Q values:  tensor([[-5.5740, -5.0849, -5.4067, -5.3068, -5.3576, -4.5093]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10372 272 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1892\n",
      "289 22 False\n",
      "x_t:  2 [0.496875 0.4      0.046875 0.2625  ]\n",
      "Q values:  tensor([[ -9.5949,  -9.3543,  -8.9303,  -9.8458, -10.0891,  -9.1015]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18526 791 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  2435.6274468898773\n",
      "startIDX:  1658\n",
      "290 0 False\n",
      "x_t:  3 [0.365625   0.29166667 0.11875    0.32083333]\n",
      "Q values:  tensor([[-3.0331, -3.3614, -3.6403, -2.3383, -3.5150, -3.1761]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16882 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 290: ep_len:203 episode reward: total was -38.100000. running mean: -103.283226\n",
      "startIDX:  422\n",
      "290 1 True\n",
      "x_t:  0 [0.8375     0.37083333 0.13125    0.40416667]\n",
      "Q values:  tensor([[-9.2572, -8.7679, -8.9480, -8.5761, -9.5130, -7.9507]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29098 504 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 290: ep_len:504 episode reward: total was -68.600000. running mean: -102.936394\n",
      "startIDX:  930\n",
      "290 5 True\n",
      "x_t:  3 [0.38125    0.2625     0.153125   0.32916667]\n",
      "Q values:  tensor([[-5.8999, -6.0449, -6.6299, -5.6338, -6.0507, -4.9275]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10544 254 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 290: ep_len:254 episode reward: total was -8.000000. running mean: -101.987030\n",
      "startIDX:  1283\n",
      "290 10 True\n",
      "x_t:  3 [0.084375   0.22083333 0.059375   0.24583333]\n",
      "Q values:  tensor([[-14.5669, -12.0930, -13.4395, -13.9497, -14.3396, -12.1587]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14581 1206 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 290: ep_len:1206 episode reward: total was -158.300000. running mean: -102.550160\n",
      "startIDX:  1946\n",
      "ep 290: ep_len:78 episode reward: total was -2.300000. running mean: -101.547658\n",
      "startIDX:  3087\n",
      "ep 290: ep_len:39 episode reward: total was 27.000000. running mean: -100.262181\n",
      "startIDX:  716\n",
      "290 22 False\n",
      "x_t:  2 [0.578125 0.4      0.0625   0.2625  ]\n",
      "Q values:  tensor([[-10.1372,  -9.3455,  -9.0049,  -9.5258, -10.7058,  -9.5437]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9009 920 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 290: ep_len:920 episode reward: total was -146.000000. running mean: -100.719560\n",
      "startIDX:  268\n",
      "291 0 False\n",
      "x_t:  3 [0.065625   0.23333333 0.0625     0.22916667]\n",
      "Q values:  tensor([[-11.2483, -11.7546, -12.8513, -10.3446, -13.4955, -10.9049]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4836 1231 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1018\n",
      "291 1 True\n",
      "x_t:  3 [0.628125   0.29583333 0.103125   0.3625    ]\n",
      "Q values:  tensor([[-7.8335, -6.5776, -8.1541, -8.3388, -8.0585, -6.6779]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35936 238 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  586\n",
      "291 5 True\n",
      "x_t:  2 [0.59375    0.39583333 0.10625    0.30416667]\n",
      "Q values:  tensor([[-7.8206, -7.9160, -7.2240, -7.6082, -8.3982, -6.9812]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6066 477 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1204\n",
      "291 10 True\n",
      "x_t:  3 [0.134375   0.225      0.0625     0.27083333]\n",
      "Q values:  tensor([[-11.0547, -10.2284, -11.3651, -11.1832, -11.3177,  -9.2176]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14598 1231 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1057\n",
      "291 12 False\n",
      "x_t:  3 [0.190625   0.28333333 0.09375    0.31666667]\n",
      "Q values:  tensor([[-11.6025, -11.5261, -12.7962, -10.9012, -13.0322, -11.2142]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16403 1406 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2317\n",
      "291 15 True\n",
      "x_t:  3 [0.075      0.27916667 0.075      0.29583333]\n",
      "Q values:  tensor([[-10.9889, -11.5324, -12.2654, -10.9789, -10.9117,  -9.9468]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18175 1256 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  2329\n",
      "291 22 False\n",
      "x_t:  1 [0.89375    0.30416667 0.103125   0.44583333]\n",
      "Q values:  tensor([[-9.5962, -8.3793, -9.1908, -9.1781, -9.9193, -8.9155]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22929 1052 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1154\n",
      "292 0 True\n",
      "x_t:  2 [0.76875    0.40833333 0.096875   0.2875    ]\n",
      "Q values:  tensor([[-5.7833, -5.3102, -5.7880, -5.6849, -5.5076, -5.1619]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12635 313 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 292: ep_len:313 episode reward: total was -43.700000. running mean: -101.382322\n",
      "startIDX:  653\n",
      "292 1 True\n",
      "x_t:  2 [0.734375   0.38333333 0.109375   0.3125    ]\n",
      "Q values:  tensor([[-6.1610, -5.4538, -5.9699, -5.7038, -5.6562, -5.0139]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31475 357 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 292: ep_len:357 episode reward: total was -36.000000. running mean: -100.728499\n",
      "startIDX:  1842\n",
      "292 5 True\n",
      "x_t:  2 [0.640625 0.4      0.08125  0.25    ]\n",
      "Q values:  tensor([[-4.3313, -3.6531, -4.2860, -4.5714, -3.9588, -3.6518]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15674 345 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 292: ep_len:345 episode reward: total was -55.200000. running mean: -100.273214\n",
      "startIDX:  962\n",
      "292 10 True\n",
      "x_t:  1 [0.5375   0.3      0.090625 0.35    ]\n",
      "Q values:  tensor([[-7.9051, -7.8445, -7.9234, -8.1021, -8.0136, -7.1796]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11373 1610 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 292: ep_len:1610 episode reward: total was -156.000000. running mean: -100.830482\n",
      "startIDX:  1106\n",
      "292 12 False\n",
      "x_t:  3 [0.084375   0.26666667 0.090625   0.2875    ]\n",
      "Q values:  tensor([[-7.1911, -6.3615, -6.4967, -6.1151, -7.5505, -6.1477]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16378 1393 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 292: ep_len:1393 episode reward: total was -112.000000. running mean: -100.942177\n",
      "startIDX:  1906\n",
      "292 15 True\n",
      "x_t:  1 [0.53125    0.31666667 0.1        0.30416667]\n",
      "Q values:  tensor([[-5.0478, -5.1602, -5.3516, -5.1687, -4.6405, -4.3007]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14888 740 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 292: ep_len:740 episode reward: total was -37.400000. running mean: -100.306755\n",
      "startIDX:  1761\n",
      "292 22 False\n",
      "x_t:  3 [0.51875    0.32083333 0.1125     0.33333333]\n",
      "Q values:  tensor([[-0.6704, -1.3616, -1.2448,  1.1532, -0.5890, -0.9475]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16895 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 292: ep_len:200 episode reward: total was -3.600000. running mean: -99.339688\n",
      "startIDX:  691\n",
      "293 0 True\n",
      "x_t:  2 [0.1375     0.4125     0.1        0.26666667]\n",
      "Q values:  tensor([[-5.7908, -5.1764, -5.2145, -5.6556, -5.4853, -4.8923]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8892 903 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  668\n",
      "293 1 True\n",
      "x_t:  3 [0.0625     0.22916667 0.059375   0.28333333]\n",
      "Q values:  tensor([[-4.8300, -6.1916, -6.2050, -5.6578, -5.2496, -4.3572]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34302 1415 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  885\n",
      "293 5 True\n",
      "x_t:  4 [0.4        0.375      0.121875   0.37083333]\n",
      "Q values:  tensor([[-3.8135, -4.1344, -4.4335, -3.6941, -3.9337, -3.5696]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10069 601 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  621\n",
      "293 10 False\n",
      "x_t:  1 [0.75     0.2875   0.053125 0.3375  ]\n",
      "Q values:  tensor([[-4.0214, -3.7859, -4.2985, -3.9664, -4.3705, -3.8420]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7188 1014 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  814\n",
      "293 12 True\n",
      "x_t:  0 [0.7      0.4125   0.059375 0.2875  ]\n",
      "Q values:  tensor([[-4.7391, -5.1188, -4.5530, -5.0979, -4.5828, -4.1158]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11666 659 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  527\n",
      "293 15 True\n",
      "x_t:  1 [0.5625 0.3125 0.0875 0.2875]\n",
      "Q values:  tensor([[-4.9781, -4.3797, -4.8937, -4.5714, -4.7253, -3.6873]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5215 739 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  488\n",
      "293 22 True\n",
      "x_t:  3 [0.875      0.33333333 0.078125   0.40416667]\n",
      "Q values:  tensor([[-5.7513, -5.0342, -5.5017, -5.6950, -5.4730, -4.7510]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7054 1024 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1485\n",
      "294 0 True\n",
      "x_t:  3 [0.41875    0.29583333 0.0875     0.34166667]\n",
      "Q values:  tensor([[-4.4935, -3.8466, -4.0974, -4.5227, -4.2290, -3.3558]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16875 293 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 294: ep_len:293 episode reward: total was 34.800000. running mean: -97.168425\n",
      "startIDX:  730\n",
      "294 1 True\n",
      "x_t:  3 [0.065625   0.22916667 0.0625     0.28333333]\n",
      "Q values:  tensor([[-8.0174, -7.3751, -7.6229, -7.7261, -7.9397, -6.2378]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34303 1396 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 294: ep_len:1396 episode reward: total was -105.200000. running mean: -97.248741\n",
      "startIDX:  2166\n",
      "294 5 True\n",
      "x_t:  4 [0.303125   0.4        0.109375   0.39583333]\n",
      "Q values:  tensor([[-5.2965, -4.7480, -4.8866, -4.9558, -4.8367, -4.0252]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19491 603 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 294: ep_len:603 episode reward: total was -53.900000. running mean: -96.815254\n",
      "startIDX:  555\n",
      "294 10 True\n",
      "x_t:  2 [0.334375   0.39583333 0.05625    0.2625    ]\n",
      "Q values:  tensor([[-5.5880, -5.1565, -5.7471, -5.4243, -4.6313, -4.8141]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6635 783 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 294: ep_len:783 episode reward: total was -54.800000. running mean: -96.395101\n",
      "startIDX:  721\n",
      "294 12 True\n",
      "x_t:  1 [0.1        0.37916667 0.15       0.49583333]\n",
      "Q values:  tensor([[-4.6505, -4.5234, -5.0862, -4.9130, -4.8324, -3.9231]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10312 217 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 294: ep_len:217 episode reward: total was -3.900000. running mean: -95.470150\n",
      "startIDX:  301\n",
      "294 15 False\n",
      "x_t:  0 [0.36875 0.425   0.06875 0.2625 ]\n",
      "Q values:  tensor([[-5.3357, -5.6410, -6.0539, -6.1416, -5.8783, -5.3828]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3740 757 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 294: ep_len:757 episode reward: total was -114.400000. running mean: -95.659449\n",
      "startIDX:  1322\n",
      "294 22 False\n",
      "x_t:  3 [0.06875    0.25833333 0.071875   0.2625    ]\n",
      "Q values:  tensor([[-8.0933, -7.5111, -7.6822, -6.7314, -7.4852, -6.7795]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15199 1288 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 294: ep_len:1288 episode reward: total was -122.400000. running mean: -95.926854\n",
      "startIDX:  1362\n",
      "295 0 False\n",
      "x_t:  4 [0.153125   0.3875     0.10625    0.27916667]\n",
      "Q values:  tensor([[-4.9793, -4.3172, -5.0897, -4.7945, -4.1388, -4.1816]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16308 568 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  402\n",
      "295 1 True\n",
      "x_t:  0 [0.853125   0.375      0.09375    0.40833333]\n",
      "Q values:  tensor([[-6.5776, -6.5613, -6.7594, -6.0301, -6.0308, -5.0938]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29100 514 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1362\n",
      "295 5 True\n",
      "x_t:  0 [0.49375 0.4     0.0875  0.3125 ]\n",
      "Q values:  tensor([[-7.8080, -7.0911, -7.6736, -6.9647, -7.3409, -6.2617]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13573 781 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  917\n",
      "295 10 False\n",
      "x_t:  1 [0.8625     0.28333333 0.128125   0.3375    ]\n",
      "Q values:  tensor([[-10.5595,  -8.8215,  -9.4950,  -9.2621, -10.8467,  -9.0783]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11328 1596 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  992\n",
      "295 12 True\n",
      "x_t:  2 [0.8        0.41666667 0.09375    0.2375    ]\n",
      "Q values:  tensor([[-5.9091, -5.4325, -5.6265, -5.6967, -4.9825, -4.4507]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13572 313 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1343\n",
      "295 15 True\n",
      "x_t:  3 [0.609375   0.31666667 0.10625    0.34583333]\n",
      "Q values:  tensor([[-4.7712, -4.7795, -4.7410, -5.2406, -4.8336, -4.2468]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10374 227 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  641\n",
      "295 22 True\n",
      "x_t:  2 [0.378125   0.40833333 0.090625   0.26666667]\n",
      "Q values:  tensor([[-8.7286, -7.9140, -8.5535, -8.8340, -8.2862, -7.2157]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8977 955 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1902\n",
      "296 0 True\n",
      "x_t:  1 [0.778125   0.29166667 0.13125    0.3875    ]\n",
      "Q values:  tensor([[-5.4163, -5.5399, -5.3483, -5.6591, -5.6857, -4.7650]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19004 289 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 296: ep_len:289 episode reward: total was -22.100000. running mean: -93.548292\n",
      "startIDX:  57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296 1 True\n",
      "x_t:  3 [0.103125   0.225      0.08125    0.27916667]\n",
      "Q values:  tensor([[-4.0221, -4.1056, -4.6447, -3.7668, -3.7168, -3.4551]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25778 227 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 296: ep_len:227 episode reward: total was -64.400000. running mean: -93.256809\n",
      "startIDX:  1185\n",
      "296 5 True\n",
      "x_t:  2 [0.065625   0.4        0.090625   0.27083333]\n",
      "Q values:  tensor([[-7.9205, -7.6573, -7.6148, -7.7610, -7.6936, -6.5186]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12012 764 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 296: ep_len:764 episode reward: total was -25.000000. running mean: -92.574241\n",
      "startIDX:  797\n",
      "296 10 True\n",
      "x_t:  1 [0.246875   0.33333333 0.1125     0.34166667]\n",
      "Q values:  tensor([[-4.9628, -4.8029, -5.4206, -4.9843, -4.8897, -4.5493]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7130 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 296: ep_len:203 episode reward: total was -39.500000. running mean: -92.043499\n",
      "startIDX:  898\n",
      "296 12 True\n",
      "x_t:  1 [0.646875   0.38333333 0.1625     0.48333333]\n",
      "Q values:  tensor([[-6.3411, -6.4457, -6.9901, -6.4631, -7.1459, -5.8467]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12926 627 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 296: ep_len:627 episode reward: total was -35.400000. running mean: -91.477064\n",
      "startIDX:  597\n",
      "296 15 False\n",
      "x_t:  1 [0.821875   0.29583333 0.084375   0.27916667]\n",
      "Q values:  tensor([[-5.6475, -5.1320, -5.9592, -6.0291, -5.4397, -5.1868]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5175 681 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 296: ep_len:681 episode reward: total was -43.300000. running mean: -90.995293\n",
      "startIDX:  573\n",
      "296 22 True\n",
      "x_t:  3 [0.44375 0.2875  0.10625 0.3125 ]\n",
      "Q values:  tensor([[-5.7641, -5.2643, -5.6902, -5.6052, -5.1855, -4.7254]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7128 242 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 296: ep_len:242 episode reward: total was -47.500000. running mean: -90.560340\n",
      "startIDX:  322\n",
      "297 0 True\n",
      "x_t:  3 [0.134375   0.24166667 0.059375   0.25416667]\n",
      "Q values:  tensor([[-9.6420, -8.8229, -9.9424, -9.5107, -9.0952, -8.1899]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4862 1244 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  538\n",
      "297 1 True\n",
      "x_t:  1 [0.028125   0.325      0.146875   0.54166667]\n",
      "Q values:  tensor([[-6.0427, -6.5746, -6.2942, -6.3697, -5.9692, -5.4349]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30765 783 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2113\n",
      "297 5 True\n",
      "x_t:  4 [0.4875 0.3875 0.1    0.3875]\n",
      "Q values:  tensor([[-7.7001, -6.8697, -7.4309, -7.3302, -7.0342, -6.3605]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19508 633 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1155\n",
      "297 10 True\n",
      "x_t:  2 [0.29375    0.39583333 0.046875   0.25      ]\n",
      "Q values:  tensor([[-6.5654, -5.6087, -6.0806, -5.9967, -5.3533, -5.1755]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12146 364 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  477\n",
      "297 12 True\n",
      "x_t:  3 [0.1     0.25    0.06875 0.2625 ]\n",
      "Q values:  tensor([[-4.6604, -4.8655, -5.0505, -5.2346, -4.7589, -4.1174]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7832 275 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  785\n",
      "297 15 False\n",
      "x_t:  3 [0.1      0.2375   0.053125 0.2375  ]\n",
      "Q values:  tensor([[-10.4824,  -9.7735, -10.3335,  -8.5710,  -9.8070,  -8.7217]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8511 1618 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  873\n",
      "297 22 True\n",
      "x_t:  1 [0.053125 0.3625   0.14375  0.4     ]\n",
      "Q values:  tensor([[-6.7196, -6.2124, -6.6149, -6.2387, -6.3942, -5.3082]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9490 257 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  332\n",
      "298 0 False\n",
      "x_t:  3 [0.134375   0.24166667 0.059375   0.25416667]\n",
      "Q values:  tensor([[-9.3492, -8.7908, -9.3375, -8.0884, -9.6361, -8.1755]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4862 1240 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 298: ep_len:1240 episode reward: total was -135.000000. running mean: -91.424857\n",
      "startIDX:  723\n",
      "298 1 False\n",
      "x_t:  3 [0.10625    0.22916667 0.08125    0.30416667]\n",
      "Q values:  tensor([[-9.6786, -9.4289, -9.7194, -8.3780, -9.5239, -8.5676]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34318 1404 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 298: ep_len:1404 episode reward: total was -131.100000. running mean: -91.821609\n",
      "startIDX:  2958\n",
      "ep 298: ep_len:57 episode reward: total was 39.000000. running mean: -90.513392\n",
      "startIDX:  2421\n",
      "ep 298: ep_len:1226 episode reward: total was -142.200000. running mean: -91.030259\n",
      "startIDX:  1706\n",
      "298 12 True\n",
      "x_t:  1 [0.6875     0.32083333 0.140625   0.375     ]\n",
      "Q values:  tensor([[-4.9962, -4.8896, -5.3368, -5.2154, -5.1506, -4.4127]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19940 236 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 298: ep_len:236 episode reward: total was -43.600000. running mean: -90.555956\n",
      "startIDX:  691\n",
      "298 15 True\n",
      "x_t:  2 [0.53125    0.40416667 0.053125   0.29583333]\n",
      "Q values:  tensor([[-5.9590, -6.1492, -6.5182, -5.8146, -6.0948, -5.2252]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6012 415 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 298: ep_len:415 episode reward: total was -98.100000. running mean: -90.631396\n",
      "startIDX:  2403\n",
      "298 22 True\n",
      "x_t:  2 [0.675    0.4125   0.090625 0.25    ]\n",
      "Q values:  tensor([[-5.5653, -4.9815, -5.8911, -5.3009, -5.5955, -4.7681]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23660 363 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 298: ep_len:363 episode reward: total was -81.800000. running mean: -90.543082\n",
      "startIDX:  1069\n",
      "299 0 True\n",
      "x_t:  1 [0.553125   0.32916667 0.165625   0.4375    ]\n",
      "Q values:  tensor([[-6.0099, -5.8563, -6.0012, -5.6609, -6.3197, -5.5103]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11977 758 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  832\n",
      "299 1 True\n",
      "x_t:  4 [0.296875 0.375    0.121875 0.4     ]\n",
      "Q values:  tensor([[-6.3329, -6.1623, -6.7885, -6.2934, -6.5412, -5.9229]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35463 564 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  988\n",
      "299 5 False\n",
      "x_t:  3 [0.703125   0.32083333 0.18125    0.39166667]\n",
      "Q values:  tensor([[-3.5820, -3.3134, -4.0200, -2.9583, -3.6801, -3.3023]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10499 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1313\n",
      "299 10 True\n",
      "x_t:  4 [0.384375   0.34166667 0.05625    0.25416667]\n",
      "Q values:  tensor([[-5.9965, -5.4312, -5.4618, -5.3082, -5.5940, -4.8004]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15769 587 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1243\n",
      "299 12 True\n",
      "x_t:  4 [0.165625   0.42916667 0.15625    0.35      ]\n",
      "Q values:  tensor([[-4.5072, -4.6918, -5.1374, -5.1962, -4.5105, -4.4234]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17409 473 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2690\n",
      "299 15 True\n",
      "x_t:  2 [0.39375    0.40416667 0.1125     0.325     ]\n",
      "Q values:  tensor([[-6.1251, -5.6123, -5.6480, -5.2976, -6.3235, -5.1135]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21528 882 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1207\n",
      "299 22 True\n",
      "x_t:  1 [0.23125    0.35416667 0.128125   0.51666667]\n",
      "Q values:  tensor([[-6.5579, -6.3434, -6.2662, -6.3052, -6.2826, -5.5079]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11969 697 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  2536.794492006302\n",
      "startIDX:  1973\n",
      "300 0 True\n",
      "x_t:  1 [0.296875   0.35       0.146875   0.37916667]\n",
      "Q values:  tensor([[-5.3583, -4.8338, -5.8010, -5.0754, -5.6460, -4.9289]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18954 220 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 300: ep_len:220 episode reward: total was -22.000000. running mean: -86.724938\n",
      "startIDX:  605\n",
      "300 1 True\n",
      "x_t:  2 [0.475      0.3875     0.103125   0.30833333]\n",
      "Q values:  tensor([[-6.0992, -5.7198, -6.1411, -5.4685, -6.0846, -5.1436]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31517 397 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 300: ep_len:397 episode reward: total was -96.000000. running mean: -86.817689\n",
      "startIDX:  1047\n",
      "300 5 False\n",
      "x_t:  3 [0.23125    0.24166667 0.109375   0.29583333]\n",
      "Q values:  tensor([[-1.0883, -2.4276, -2.3949,  0.9409, -1.3937, -2.2427]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10574 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 300: ep_len:200 episode reward: total was 8.800000. running mean: -85.861512\n",
      "startIDX:  500\n",
      "300 10 False\n",
      "x_t:  3 [0.1625     0.23333333 0.084375   0.27083333]\n",
      "Q values:  tensor([[1.2241, 0.0749, 3.3555, 7.6809, 3.0056, 1.8862]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 5156 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 300: ep_len:200 episode reward: total was 29.500000. running mean: -84.707897\n",
      "startIDX:  156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 12 True\n",
      "x_t:  2 [0.090625   0.40833333 0.084375   0.25      ]\n",
      "Q values:  tensor([[-7.7503, -6.7881, -7.2676, -8.2291, -7.2293, -6.6207]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2914 342 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 300: ep_len:342 episode reward: total was -80.400000. running mean: -84.664818\n",
      "startIDX:  2208\n",
      "300 15 False\n",
      "x_t:  3 [0.103125   0.27083333 0.090625   0.3125    ]\n",
      "Q values:  tensor([[-8.0870, -8.6674, -8.6929, -7.9735, -9.0291, -8.2095]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18183 1313 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 300: ep_len:1313 episode reward: total was -218.300000. running mean: -86.001169\n",
      "startIDX:  2254\n",
      "300 22 False\n",
      "x_t:  1 [0.33125    0.35416667 0.16875    0.45      ]\n",
      "Q values:  tensor([[-8.8369, -7.5994, -8.7391, -8.4529, -8.6750, -8.0307]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22981 1099 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 300: ep_len:1099 episode reward: total was -180.800000. running mean: -86.949158\n",
      "startIDX:  1841\n",
      "301 0 False\n",
      "x_t:  1 [0.896875   0.29166667 0.096875   0.3875    ]\n",
      "Q values:  tensor([[-10.5462,  -9.1567,  -9.9192, -10.6389, -10.0218,  -9.3041]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19017 1035 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  507\n",
      "301 1 True\n",
      "x_t:  1 [0.79375    0.275      0.125      0.45416667]\n",
      "Q values:  tensor([[-8.6315, -6.8761, -8.1055, -7.6820, -7.8872, -7.4563]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30688 748 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1088\n",
      "301 5 False\n",
      "x_t:  3 [0.121875   0.22916667 0.071875   0.27083333]\n",
      "Q values:  tensor([[3.4556, 0.4638, 3.1869, 6.2449, 2.4860, 0.5139]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 10600 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2550\n",
      "startIDX:  1054\n",
      "301 12 False\n",
      "x_t:  3 [0.084375   0.26666667 0.084375   0.29166667]\n",
      "Q values:  tensor([[-14.0706, -15.3008, -15.5539, -13.1423, -16.2018, -14.3509]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16377 1403 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1501\n",
      "301 15 True\n",
      "x_t:  2 [0.596875   0.40416667 0.05       0.27916667]\n",
      "Q values:  tensor([[-13.1587, -12.5410, -12.4473, -12.4515, -13.1178, -11.5050]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 11998 809 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  702\n",
      "301 22 False\n",
      "x_t:  2 [0.159375   0.41666667 0.09375    0.25833333]\n",
      "Q values:  tensor([[-12.7307, -11.8788, -11.6960, -12.0745, -13.3465, -12.2573]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8943 911 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  929\n",
      "302 0 False\n",
      "x_t:  0 [0.75625    0.40416667 0.140625   0.35833333]\n",
      "Q values:  tensor([[-12.2984, -13.1351, -13.7419, -12.4488, -12.8689, -12.3484]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10350 438 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 302: ep_len:438 episode reward: total was -91.700000. running mean: -91.641451\n",
      "startIDX:  388\n",
      "302 1 False\n",
      "x_t:  0 [0.49375    0.375      0.115625   0.44583333]\n",
      "Q values:  tensor([[-14.1218, -15.9453, -17.6136, -14.7246, -14.2111, -14.4377]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29172 829 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 302: ep_len:829 episode reward: total was -257.100000. running mean: -93.296037\n",
      "startIDX:  2908\n",
      "ep 302: ep_len:85 episode reward: total was 5.000000. running mean: -92.313076\n",
      "startIDX:  469\n",
      "302 10 False\n",
      "x_t:  3 [0.278125   0.24583333 0.090625   0.29583333]\n",
      "Q values:  tensor([[ 0.5524, -0.0821,  1.9994,  5.0806,  1.1032,  0.0428]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5126 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 302: ep_len:200 episode reward: total was -30.400000. running mean: -91.693946\n",
      "startIDX:  1979\n",
      "ep 302: ep_len:51 episode reward: total was -8.400000. running mean: -90.861006\n",
      "startIDX:  2295\n",
      "302 15 False\n",
      "x_t:  3 [0.190625   0.2875     0.084375   0.32083333]\n",
      "Q values:  tensor([[-18.4033, -17.4716, -17.5265, -17.2590, -19.2442, -17.6956]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18200 1257 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 302: ep_len:1257 episode reward: total was -363.200000. running mean: -93.584396\n",
      "startIDX:  999\n",
      "302 22 True\n",
      "x_t:  0 [0.571875   0.40833333 0.071875   0.3375    ]\n",
      "Q values:  tensor([[-10.0369,  -9.4164, -10.4871, -10.7371, -10.5584,  -9.4872]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10488 478 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 302: ep_len:478 episode reward: total was -135.600000. running mean: -94.004552\n",
      "startIDX:  335\n",
      "303 0 False\n",
      "x_t:  3 [0.059375   0.23333333 0.0625     0.22916667]\n",
      "Q values:  tensor([[-17.3372, -16.8375, -17.3064, -15.5628, -19.0536, -16.1345]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4830 1221 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  959\n",
      "303 1 True\n",
      "x_t:  4 [0.190625 0.3875   0.134375 0.4     ]\n",
      "Q values:  tensor([[-11.7082, -11.4406, -11.0822, -11.2864, -11.0070, -11.1221]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35450 492 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1490\n",
      "303 5 True\n",
      "x_t:  0 [0.73125    0.39166667 0.075      0.33333333]\n",
      "Q values:  tensor([[-11.5630, -12.0191, -11.1157, -12.2892, -11.3056, -11.2009]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13529 488 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1700\n",
      "303 10 False\n",
      "x_t:  3 [0.728125   0.30416667 0.134375   0.39166667]\n",
      "Q values:  tensor([[-7.2356, -7.4955, -7.9242, -7.1784, -8.2187, -7.2475]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16419 246 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1340\n",
      "303 12 True\n",
      "x_t:  3 [0.803125   0.35416667 0.0875     0.44583333]\n",
      "Q values:  tensor([[-9.0312, -9.0108, -9.6305, -8.7227, -9.4132, -8.0807]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17852 226 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  17\n",
      "303 15 False\n",
      "x_t:  3 [0.65       0.325      0.096875   0.39166667]\n",
      "Q values:  tensor([[-8.2308, -7.9664, -9.1443, -7.7793, -8.2127, -7.7930]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 549 257 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1301\n",
      "303 22 False\n",
      "x_t:  3 [0.16875    0.26666667 0.075      0.29166667]\n",
      "Q values:  tensor([[-22.0831, -21.5260, -20.8562, -18.4509, -19.7258, -18.4648]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15227 1306 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1080\n",
      "304 0 False\n",
      "x_t:  1 [0.509375   0.32916667 0.10625    0.44583333]\n",
      "Q values:  tensor([[-13.7825, -12.1315, -12.9104, -12.2331, -14.5011, -12.3654]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11985 761 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 304: ep_len:761 episode reward: total was -171.700000. running mean: -97.153259\n",
      "startIDX:  420\n",
      "304 1 True\n",
      "x_t:  0 [0.84375    0.37083333 0.128125   0.4       ]\n",
      "Q values:  tensor([[-10.2673, -10.6398, -11.8248, -11.1951, -11.4767,  -9.5473]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29097 488 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 304: ep_len:488 episode reward: total was -90.000000. running mean: -97.081726\n",
      "startIDX:  2004\n",
      "304 5 False\n",
      "x_t:  3 [0.153125   0.25833333 0.103125   0.325     ]\n",
      "Q values:  tensor([[-17.2918, -16.0493, -16.9821, -14.9113, -16.9799, -15.1498]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18227 1265 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 304: ep_len:1265 episode reward: total was -288.000000. running mean: -98.990909\n",
      "startIDX:  2453\n",
      "304 10 False\n",
      "x_t:  1 [0.7875     0.29166667 0.134375   0.32916667]\n",
      "Q values:  tensor([[-15.4828, -14.4975, -15.5930, -14.9498, -16.8571, -14.9338]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22477 1196 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 304: ep_len:1196 episode reward: total was -231.700000. running mean: -100.318000\n",
      "startIDX:  284\n",
      "304 12 True\n",
      "x_t:  4 [0.428125   0.39583333 0.090625   0.3375    ]\n",
      "Q values:  tensor([[-11.2593, -11.5545, -12.1966, -11.1668, -10.9570, -10.2338]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7237 787 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 304: ep_len:787 episode reward: total was -124.800000. running mean: -100.562820\n",
      "startIDX:  1172\n",
      "304 15 False\n",
      "x_t:  4 [0.2125     0.38333333 0.084375   0.29583333]\n",
      "Q values:  tensor([[-9.5178, -9.5405, -8.7931, -8.5796, -8.2373, -8.4415]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9849 559 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 304: ep_len:559 episode reward: total was -96.600000. running mean: -100.523192\n",
      "startIDX:  2\n",
      "304 22 False\n",
      "x_t:  1 [0.8625     0.30416667 0.134375   0.40833333]\n",
      "Q values:  tensor([[-9.0096, -7.9809, -9.4469, -9.3921, -9.7343, -8.3653]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1578 721 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 304: ep_len:721 episode reward: total was -141.200000. running mean: -100.929960\n",
      "startIDX:  1670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305 0 True\n",
      "x_t:  3 [0.41875    0.29583333 0.071875   0.325     ]\n",
      "Q values:  tensor([[-7.1088, -7.2198, -7.3502, -7.3645, -7.3996, -6.5778]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16876 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  282\n",
      "305 1 False\n",
      "x_t:  1 [0.6375     0.2875     0.175      0.58333333]\n",
      "Q values:  tensor([[-7.9318, -7.1594, -8.8025, -8.2578, -7.6740, -7.3518]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28107 340 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1312\n",
      "305 5 True\n",
      "x_t:  1 [0.003125   0.34583333 0.075      0.40416667]\n",
      "Q values:  tensor([[-11.3533, -11.0682, -11.4142, -10.5232, -10.2454,  -9.9959]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12504 940 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2411\n",
      "305 10 False\n",
      "x_t:  1 [0.8875  0.2875  0.10625 0.3375 ]\n",
      "Q values:  tensor([[-10.9585, -10.6700, -11.6027, -10.7222, -10.7815, -10.8858]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22469 1197 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  771\n",
      "305 12 True\n",
      "x_t:  1 [0.584375   0.33333333 0.21875    0.5375    ]\n",
      "Q values:  tensor([[-5.9371, -5.7736, -6.7830, -5.9422, -6.1130, -6.0490]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10343 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3122\n",
      "startIDX:  2754\n",
      "305 22 True\n",
      "x_t:  4 [0.075    0.4      0.090625 0.3125  ]\n",
      "Q values:  tensor([[-12.0677, -12.3143, -12.2362, -12.6964, -12.1527, -11.2148]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27274 482 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2206\n",
      "306 0 True\n",
      "x_t:  1 [0.690625   0.32083333 0.18125    0.5       ]\n",
      "Q values:  tensor([[-10.3953, -10.0913,  -9.3279, -10.7229, -11.4749,  -9.4808]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22932 1092 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 306: ep_len:1092 episode reward: total was -219.300000. running mean: -101.437183\n",
      "startIDX:  568\n",
      "306 1 False\n",
      "x_t:  1 [0.75       0.275      0.16875    0.45416667]\n",
      "Q values:  tensor([[-11.9412, -11.4143, -12.7121, -11.5436, -12.4973, -11.4312]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30691 727 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 306: ep_len:727 episode reward: total was -166.400000. running mean: -102.086811\n",
      "startIDX:  1599\n",
      "306 5 True\n",
      "x_t:  1 [0.8125     0.29166667 0.121875   0.30416667]\n",
      "Q values:  tensor([[-11.7859, -11.4945, -11.8480, -12.3337, -11.5793, -10.7624]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14928 692 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 306: ep_len:692 episode reward: total was -111.300000. running mean: -102.178943\n",
      "startIDX:  2270\n",
      "306 10 False\n",
      "x_t:  1 [0.759375   0.2875     0.096875   0.32916667]\n",
      "Q values:  tensor([[-12.4395, -11.6771, -13.0625, -12.8746, -12.5211, -11.7586]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22483 1279 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 306: ep_len:1279 episode reward: total was -163.600000. running mean: -102.793153\n",
      "startIDX:  401\n",
      "306 12 True\n",
      "x_t:  3 [0.69375    0.3375     0.14375    0.40833333]\n",
      "Q values:  tensor([[-9.9644, -8.9851, -9.1846, -8.7680, -9.3877, -9.2563]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7729 265 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 306: ep_len:265 episode reward: total was -15.100000. running mean: -101.916222\n",
      "startIDX:  1013\n",
      "306 15 False\n",
      "x_t:  4 [0.003125   0.4        0.065625   0.29166667]\n",
      "Q values:  tensor([[ -9.5798,  -8.9671, -10.0620,  -9.6823,  -8.9614,  -9.0122]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9808 621 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 306: ep_len:621 episode reward: total was -11.100000. running mean: -101.008060\n",
      "startIDX:  1627\n",
      "306 22 False\n",
      "x_t:  3 [0.7875     0.34583333 0.128125   0.4125    ]\n",
      "Q values:  tensor([[-6.9615, -7.5155, -8.6049, -6.9512, -7.3506, -7.1762]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16854 240 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 306: ep_len:240 episode reward: total was 22.100000. running mean: -99.776979\n",
      "startIDX:  2122\n",
      "307 0 True\n",
      "x_t:  1 [0.68125    0.32083333 0.159375   0.50416667]\n",
      "Q values:  tensor([[-13.1984, -12.6239, -12.7108, -13.6110, -13.2371, -12.4162]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22933 1141 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  13\n",
      "307 1 False\n",
      "x_t:  3 [0.559375   0.29166667 0.140625   0.375     ]\n",
      "Q values:  tensor([[ 1.0425, -0.5356,  1.2717,  2.2482, -0.0813,  0.1478]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25672 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2753\n",
      "307 5 True\n",
      "x_t:  0 [0.753125   0.39583333 0.096875   0.3125    ]\n",
      "Q values:  tensor([[-9.2105, -8.7265, -8.7077, -9.2836, -8.3618, -7.9498]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23187 536 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1803\n",
      "307 10 True\n",
      "x_t:  2 [0.05       0.39583333 0.0875     0.25416667]\n",
      "Q values:  tensor([[-10.4055, -12.3715, -11.5341, -11.4420, -11.1778, -10.5464]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18151 857 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1358\n",
      "307 12 True\n",
      "x_t:  3 [0.79375    0.37083333 0.165625   0.425     ]\n",
      "Q values:  tensor([[-6.9358, -7.5325, -6.9912, -7.5362, -6.3670, -6.6097]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17849 211 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1005\n",
      "307 15 True\n",
      "x_t:  4 [0.14375    0.3875     0.090625   0.29583333]\n",
      "Q values:  tensor([[-8.8245, -9.0279, -8.1571, -8.1951, -9.0055, -8.1809]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9836 618 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2174\n",
      "307 22 False\n",
      "x_t:  0 [0.834375   0.40416667 0.065625   0.32083333]\n",
      "Q values:  tensor([[ -9.4510, -11.1012, -11.7109,  -9.6344, -10.5466, -10.4523]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20711 813 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1701\n",
      "308 0 False\n",
      "x_t:  3 [0.2      0.2625   0.071875 0.2875  ]\n",
      "Q values:  tensor([[ 1.9838, -0.9809,  0.4947,  2.2879, -0.7068, -0.5492]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16920 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 308: ep_len:200 episode reward: total was -39.600000. running mean: -99.499078\n",
      "startIDX:  169\n",
      "308 1 False\n",
      "x_t:  2 [0.090625   0.3625     0.103125   0.44166667]\n",
      "Q values:  tensor([[-10.1044,  -9.4258,  -9.3237, -10.3073, -10.2158,  -9.3502]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27444 886 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 308: ep_len:886 episode reward: total was -180.100000. running mean: -100.305087\n",
      "startIDX:  2354\n",
      "308 5 False\n",
      "x_t:  3 [0.075      0.24166667 0.078125   0.27083333]\n",
      "Q values:  tensor([[-7.4910, -8.1710, -8.4322, -6.7339, -8.5039, -8.0229]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 20010 206 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 308: ep_len:206 episode reward: total was -2.500000. running mean: -99.327036\n",
      "startIDX:  709\n",
      "308 10 False\n",
      "x_t:  1 [0.7625     0.2875     0.11875    0.34583333]\n",
      "Q values:  tensor([[-8.8503, -8.2081, -9.2833, -8.6412, -9.3894, -8.4134]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7193 279 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 308: ep_len:279 episode reward: total was -77.100000. running mean: -99.104766\n",
      "startIDX:  1523\n",
      "308 12 False\n",
      "x_t:  2 [0.1625     0.41666667 0.115625   0.27916667]\n",
      "Q values:  tensor([[-10.0537,  -9.1762,  -8.6237,  -9.6924,  -9.4996,  -8.9033]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19405 761 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 308: ep_len:761 episode reward: total was -190.400000. running mean: -100.017718\n",
      "startIDX:  1870\n",
      "308 15 False\n",
      "x_t:  1 [0.78125    0.30416667 0.103125   0.30416667]\n",
      "Q values:  tensor([[-10.2669,  -9.6197, -11.3122, -11.2004, -11.2175,  -9.6979]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14855 739 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 308: ep_len:739 episode reward: total was -98.800000. running mean: -100.005541\n",
      "startIDX:  2849\n",
      "ep 308: ep_len:91 episode reward: total was 37.000000. running mean: -98.635486\n",
      "startIDX:  422\n",
      "309 0 True\n",
      "x_t:  3 [0.2        0.28333333 0.078125   0.32916667]\n",
      "Q values:  tensor([[-14.4728, -15.9417, -14.1275, -13.8831, -14.8841, -13.8523]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7092 1111 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  485\n",
      "309 1 True\n",
      "x_t:  1 [0.609375   0.275      0.184375   0.47916667]\n",
      "Q values:  tensor([[-15.1084, -15.0231, -15.0895, -14.4314, -14.9209, -14.4063]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30705 779 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  934\n",
      "309 5 False\n",
      "x_t:  3 [0.665625   0.29166667 0.1        0.38333333]\n",
      "Q values:  tensor([[-9.0346, -8.6105, -8.8326, -8.0506, -8.5750, -8.1333]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10507 232 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309 10 True\n",
      "x_t:  4 [0.09375    0.35416667 0.0625     0.24583333]\n",
      "Q values:  tensor([[-13.0909, -13.3776, -12.6515, -13.8859, -14.3184, -12.4399]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4559 466 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  155\n",
      "309 12 False\n",
      "x_t:  2 [0.825      0.40833333 0.084375   0.24583333]\n",
      "Q values:  tensor([[-13.2031, -11.0131, -10.9710, -12.8219, -13.5915, -11.4597]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2804 282 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3045\n",
      "startIDX:  302\n",
      "309 22 False\n",
      "x_t:  3 [0.0625     0.24166667 0.053125   0.23333333]\n",
      "Q values:  tensor([[-24.9664, -23.7969, -24.0765, -21.9675, -22.8325, -22.6926]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4869 1274 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  2625.472890138626\n",
      "startIDX:  2353\n",
      "310 0 True\n",
      "x_t:  3 [0.084375   0.24166667 0.075      0.24166667]\n",
      "Q values:  tensor([[-28.1333, -28.5603, -28.0041, -27.3986, -28.5771, -24.9783]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26101 1227 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 310: ep_len:1227 episode reward: total was -395.900000. running mean: -105.614007\n",
      "startIDX:  427\n",
      "310 1 False\n",
      "x_t:  1 [0.496875   0.2875     0.175      0.46666667]\n",
      "Q values:  tensor([[-18.1185, -16.4079, -16.8729, -17.8592, -18.0254, -17.2051]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30717 808 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 310: ep_len:808 episode reward: total was -193.100000. running mean: -106.488867\n",
      "startIDX:  1215\n",
      "310 5 True\n",
      "x_t:  2 [0.03125    0.4        0.071875   0.26666667]\n",
      "Q values:  tensor([[-18.0614, -17.0336, -16.0265, -15.5081, -17.2594, -15.4027]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12007 753 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 310: ep_len:753 episode reward: total was -196.500000. running mean: -107.388978\n",
      "startIDX:  870\n",
      "310 10 True\n",
      "x_t:  0 [0.659375 0.4      0.059375 0.2875  ]\n",
      "Q values:  tensor([[-12.6407, -14.1566, -12.9284, -11.7468, -13.2505, -12.1693]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8149 465 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 310: ep_len:465 episode reward: total was -126.600000. running mean: -107.581089\n",
      "startIDX:  1452\n",
      "310 12 False\n",
      "x_t:  3 [0.2875     0.27916667 0.0875     0.3125    ]\n",
      "Q values:  tensor([[-0.0562, -1.2614,  0.4729,  1.0172, -0.2812, -0.7564]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17935 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 310: ep_len:201 episode reward: total was -32.000000. running mean: -106.825278\n",
      "startIDX:  623\n",
      "310 15 True\n",
      "x_t:  1 [0.91875    0.29583333 0.065625   0.28333333]\n",
      "Q values:  tensor([[-12.1430, -11.4857, -12.8236, -12.8063, -13.0786, -12.0757]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5164 643 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 310: ep_len:643 episode reward: total was -158.500000. running mean: -107.342025\n",
      "startIDX:  2182\n",
      "310 22 False\n",
      "x_t:  0 [0.890625 0.4      0.0625   0.3375  ]\n",
      "Q values:  tensor([[-13.3503, -14.0103, -15.8430, -14.1158, -14.5353, -13.8314]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20697 805 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 310: ep_len:805 episode reward: total was -244.200000. running mean: -108.710605\n",
      "startIDX:  4\n",
      "311 0 True\n",
      "x_t:  1 [0.840625 0.3      0.078125 0.425   ]\n",
      "Q values:  tensor([[-10.2025, -11.1545, -11.5614, -10.7609, -10.9668, -10.3417]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1616 752 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  651\n",
      "311 1 False\n",
      "x_t:  2 [0.8125     0.38333333 0.1125     0.30833333]\n",
      "Q values:  tensor([[-8.6529, -8.9539, -7.9862, -8.5353, -8.1717, -8.5298]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31459 349 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  304\n",
      "311 5 True\n",
      "x_t:  0 [0.815625   0.38333333 0.14375    0.37916667]\n",
      "Q values:  tensor([[-13.9259, -13.2145, -13.2825, -13.7617, -13.4618, -11.9514]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3565 495 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  321\n",
      "311 10 True\n",
      "x_t:  3 [0.55625    0.2875     0.1125     0.34583333]\n",
      "Q values:  tensor([[-7.6792, -7.3449, -8.3218, -7.4775, -7.3673, -7.7827]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5071 236 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1023\n",
      "311 12 False\n",
      "x_t:  2 [0.790625   0.41666667 0.0875     0.2375    ]\n",
      "Q values:  tensor([[-11.6362, -10.4291,  -9.9221, -10.4694, -10.1388, -10.5626]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13576 303 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2100\n",
      "311 15 False\n",
      "x_t:  2 [0.3        0.41666667 0.09375    0.25416667]\n",
      "Q values:  tensor([[-10.0742, -10.5116,  -8.8822,  -9.4515,  -9.6285,  -9.8486]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15641 379 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1620\n",
      "311 22 True\n",
      "x_t:  3 [0.784375   0.34166667 0.121875   0.4125    ]\n",
      "Q values:  tensor([[-10.7571, -10.1961, -10.9895, -10.3540, -10.8084,  -9.6550]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16856 235 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  988\n",
      "312 0 False\n",
      "x_t:  1 [0.76875  0.3      0.084375 0.4375  ]\n",
      "Q values:  tensor([[-14.4453, -13.5164, -13.8606, -14.9763, -15.3204, -14.1146]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11959 805 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 312: ep_len:805 episode reward: total was -203.600000. running mean: -107.987527\n",
      "startIDX:  1108\n",
      "312 1 False\n",
      "x_t:  3 [0.496875   0.27916667 0.090625   0.3375    ]\n",
      "Q values:  tensor([[-3.9075, -4.0240, -3.6957, -2.8510, -3.3766, -4.4726]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35962 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 312: ep_len:200 episode reward: total was -78.900000. running mean: -107.696652\n",
      "startIDX:  2219\n",
      "312 5 True\n",
      "x_t:  3 [0.75       0.3375     0.16875    0.43333333]\n",
      "Q values:  tensor([[-11.6168, -11.3381, -12.2273, -11.4749, -11.8663, -10.2199]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19894 216 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 312: ep_len:216 episode reward: total was 31.400000. running mean: -106.305686\n",
      "startIDX:  1970\n",
      "312 10 False\n",
      "x_t:  1 [0.10625    0.33333333 0.140625   0.36666667]\n",
      "Q values:  tensor([[-12.2331, -10.3640, -11.9691, -12.0654, -10.9335, -10.6124]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18825 333 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 312: ep_len:333 episode reward: total was -18.400000. running mean: -105.426629\n",
      "startIDX:  506\n",
      "312 12 True\n",
      "x_t:  3 [0.521875   0.31666667 0.10625    0.3625    ]\n",
      "Q values:  tensor([[-11.0053, -10.1773, -10.5319,  -9.2063, -10.2319,  -8.6083]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7753 227 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 312: ep_len:227 episode reward: total was -82.400000. running mean: -105.196362\n",
      "startIDX:  2872\n",
      "312 15 True\n",
      "x_t:  0 [0.9125 0.4    0.0625 0.35  ]\n",
      "Q values:  tensor([[-11.4991, -12.5348, -11.1580, -12.4881, -12.4363, -11.5391]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23072 512 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 312: ep_len:512 episode reward: total was -159.200000. running mean: -105.736399\n",
      "startIDX:  109\n",
      "312 22 False\n",
      "x_t:  1 [0.90625  0.2875   0.090625 0.4125  ]\n",
      "Q values:  tensor([[-16.0447, -13.8066, -15.3173, -15.2367, -16.1189, -13.8915]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1576 660 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 312: ep_len:660 episode reward: total was -244.000000. running mean: -107.119035\n",
      "startIDX:  964\n",
      "313 0 False\n",
      "x_t:  1 [0.878125   0.3        0.109375   0.42916667]\n",
      "Q values:  tensor([[-15.2132, -11.6859, -12.4515, -12.5938, -13.2549, -12.7603]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11946 812 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1054\n",
      "313 1 True\n",
      "x_t:  3 [0.78125    0.30416667 0.121875   0.4125    ]\n",
      "Q values:  tensor([[-11.3273, -10.2751, -10.6646, -10.8264, -11.1358, -10.7691]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35909 206 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  149\n",
      "313 5 False\n",
      "x_t:  2 [0.003125   0.37916667 0.103125   0.43333333]\n",
      "Q values:  tensor([[-19.1178, -17.9289, -16.5055, -17.4486, -17.6744, -17.7730]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2053 843 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1731\n",
      "313 10 False\n",
      "x_t:  3 [0.81875    0.30416667 0.0875     0.4       ]\n",
      "Q values:  tensor([[-15.5848, -14.2567, -14.5502, -13.9772, -14.4695, -14.2910]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16410 227 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1347\n",
      "313 12 False\n",
      "x_t:  3 [0.60625    0.34166667 0.1375     0.39166667]\n",
      "Q values:  tensor([[-14.3882, -14.0072, -14.3650, -12.0092, -13.4302, -13.1879]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17872 221 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313 15 False\n",
      "x_t:  0 [0.83125    0.39583333 0.06875    0.35416667]\n",
      "Q values:  tensor([[-16.8305, -17.3941, -18.6294, -17.0373, -17.7662, -16.9204]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3668 456 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  897\n",
      "313 22 False\n",
      "x_t:  1 [0.284375 0.3375   0.153125 0.4     ]\n",
      "Q values:  tensor([[-17.9125, -17.8757, -18.6205, -18.2314, -18.3937, -18.0488]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9514 260 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1905\n",
      "314 0 False\n",
      "x_t:  1 [0.303125   0.34166667 0.14375    0.38333333]\n",
      "Q values:  tensor([[-15.8730, -14.7908, -15.0111, -15.1864, -14.8688, -14.8167]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18955 268 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 314: ep_len:268 episode reward: total was -86.800000. running mean: -111.226867\n",
      "startIDX:  623\n",
      "314 1 False\n",
      "x_t:  2 [0.815625   0.38333333 0.103125   0.31666667]\n",
      "Q values:  tensor([[-19.8624, -20.1759, -19.1058, -20.1233, -21.2702, -19.2748]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31460 371 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 314: ep_len:371 episode reward: total was -199.600000. running mean: -112.110598\n",
      "startIDX:  916\n",
      "314 5 False\n",
      "x_t:  3 [0.8125     0.325      0.1375     0.39583333]\n",
      "Q values:  tensor([[-15.4233, -14.5429, -14.9916, -14.0722, -16.0706, -14.5173]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10490 243 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 314: ep_len:243 episode reward: total was 18.800000. running mean: -110.801492\n",
      "startIDX:  818\n",
      "314 10 True\n",
      "x_t:  0 [0.590625   0.40416667 0.05625    0.2875    ]\n",
      "Q values:  tensor([[-21.1978, -21.3196, -19.2774, -20.5615, -20.0808, -20.9440]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8167 524 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 314: ep_len:524 episode reward: total was -310.000000. running mean: -112.793477\n",
      "startIDX:  450\n",
      "314 12 False\n",
      "x_t:  3 [0.7875     0.3375     0.128125   0.42083333]\n",
      "Q values:  tensor([[-15.1370, -15.5916, -16.5453, -14.7706, -15.5110, -14.8784]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7720 242 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 314: ep_len:242 episode reward: total was -99.600000. running mean: -112.661542\n",
      "startIDX:  1859\n",
      "314 15 False\n",
      "x_t:  1 [0.78125 0.3     0.08125 0.3    ]\n",
      "Q values:  tensor([[-27.4615, -25.4308, -29.5710, -27.1937, -27.9808, -26.2920]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14856 743 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 314: ep_len:743 episode reward: total was -348.600000. running mean: -115.020927\n",
      "startIDX:  390\n",
      "314 22 False\n",
      "x_t:  3 [0.89375    0.34166667 0.103125   0.41666667]\n",
      "Q values:  tensor([[-22.5323, -23.5640, -21.2997, -20.1360, -22.3129, -21.0470]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7050 1082 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 314: ep_len:1082 episode reward: total was -575.600000. running mean: -119.626718\n",
      "startIDX:  1487\n",
      "315 0 False\n",
      "x_t:  3 [0.809375   0.34166667 0.134375   0.4125    ]\n",
      "Q values:  tensor([[-20.0499, -19.7319, -20.7471, -18.4879, -20.6916, -19.3242]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16820 264 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  54\n",
      "315 1 False\n",
      "x_t:  3 [0.334375 0.25     0.08125  0.325   ]\n",
      "Q values:  tensor([[-8.6369, -9.1865, -9.8566, -8.0626, -9.5682, -9.2591]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25719 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2802\n",
      "315 5 True\n",
      "x_t:  0 [0.74375    0.39166667 0.096875   0.31666667]\n",
      "Q values:  tensor([[-26.1189, -24.4038, -26.1964, -26.8250, -27.7145, -24.9091]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23191 519 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2258\n",
      "315 10 False\n",
      "x_t:  1 [0.76875    0.2875     0.125      0.33333333]\n",
      "Q values:  tensor([[-35.8545, -32.5617, -36.2041, -33.2061, -36.4040, -34.8946]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22481 1274 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  957\n",
      "315 12 False\n",
      "x_t:  1 [0.765625   0.35       0.15       0.52083333]\n",
      "Q values:  tensor([[-24.6442, -22.8517, -23.2916, -27.5877, -23.9552, -23.2643]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12920 578 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  317\n",
      "315 15 False\n",
      "x_t:  1 [0.175      0.36666667 0.13125    0.5       ]\n",
      "Q values:  tensor([[-24.1217, -22.5298, -22.8323, -23.1688, -24.1788, -23.0728]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2764 265 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2187\n",
      "315 22 True\n",
      "x_t:  0 [0.909375   0.4        0.084375   0.34583333]\n",
      "Q values:  tensor([[-37.3383, -33.3930, -32.5932, -34.0576, -36.9470, -34.2476]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20686 807 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1654\n",
      "316 0 False\n",
      "x_t:  3 [0.428125   0.30833333 0.115625   0.34166667]\n",
      "Q values:  tensor([[-20.3376, -21.5910, -21.4293, -19.5299, -21.8988, -21.3107]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16869 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 316: ep_len:201 episode reward: total was -90.700000. running mean: -134.872807\n",
      "startIDX:  455\n",
      "316 1 False\n",
      "x_t:  1 [0.85625    0.26666667 0.140625   0.4625    ]\n",
      "Q values:  tensor([[-31.6099, -29.4311, -31.9547, -32.3281, -30.6126, -29.4482]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30679 772 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 316: ep_len:772 episode reward: total was -517.700000. running mean: -138.701079\n",
      "startIDX:  1183\n",
      "316 5 False\n",
      "x_t:  2 [0.0375     0.39166667 0.075      0.26666667]\n",
      "Q values:  tensor([[-28.8349, -30.7009, -26.9135, -27.9555, -27.3003, -29.6310]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12009 763 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 316: ep_len:763 episode reward: total was -490.800000. running mean: -142.222069\n",
      "startIDX:  2045\n",
      "316 10 True\n",
      "x_t:  1 [0.09375    0.34583333 0.084375   0.38333333]\n",
      "Q values:  tensor([[-32.2395, -32.2576, -32.7563, -33.2898, -31.6337, -31.0997]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18819 278 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 316: ep_len:278 episode reward: total was -170.000000. running mean: -142.499848\n",
      "startIDX:  1028\n",
      "316 12 False\n",
      "x_t:  2 [0.8875     0.39166667 0.0625     0.22083333]\n",
      "Q values:  tensor([[-30.3319, -29.1785, -29.0591, -30.6974, -31.7285, -30.7245]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13565 296 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 316: ep_len:296 episode reward: total was -197.400000. running mean: -143.048849\n",
      "startIDX:  389\n",
      "316 15 False\n",
      "x_t:  0 [0.903125   0.39583333 0.0625     0.35      ]\n",
      "Q values:  tensor([[-28.1601, -31.5426, -31.2035, -30.7270, -31.2378, -30.7085]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3657 457 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 316: ep_len:457 episode reward: total was -324.000000. running mean: -144.858361\n",
      "startIDX:  1288\n",
      "316 22 False\n",
      "x_t:  3 [0.16875    0.27083333 0.078125   0.29166667]\n",
      "Q values:  tensor([[-36.9619, -36.4991, -37.0270, -33.6298, -35.4244, -34.5994]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15225 1329 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 316: ep_len:1329 episode reward: total was -1002.700000. running mean: -153.436777\n",
      "startIDX:  61\n",
      "317 0 True\n",
      "x_t:  1 [0.565625   0.325      0.084375   0.41666667]\n",
      "Q values:  tensor([[-28.6746, -26.1719, -29.0637, -26.4205, -27.6423, -28.1508]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1644 749 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  551\n",
      "317 1 False\n",
      "x_t:  1 [0.85625    0.26666667 0.140625   0.4625    ]\n",
      "Q values:  tensor([[-27.6561, -25.1715, -29.0491, -27.6645, -27.0441, -26.8460]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30679 734 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  8\n",
      "317 5 False\n",
      "x_t:  2 [0.003125   0.37916667 0.103125   0.43333333]\n",
      "Q values:  tensor([[-30.8592, -29.0151, -28.2722, -30.1697, -29.2806, -29.4570]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2053 912 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  722\n",
      "317 10 False\n",
      "x_t:  1 [0.0875     0.34583333 0.084375   0.37916667]\n",
      "Q values:  tensor([[-29.8116, -26.3141, -28.2319, -27.8726, -28.1638, -27.0968]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7113 234 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  808\n",
      "317 12 False\n",
      "x_t:  0 [0.9125     0.40416667 0.08125    0.3125    ]\n",
      "Q values:  tensor([[-27.9773, -29.0880, -31.2184, -30.0537, -30.4614, -29.5942]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11630 634 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3060\n",
      "startIDX:  197\n",
      "317 22 False\n",
      "x_t:  2 [0.5375     0.40416667 0.09375    0.25416667]\n",
      "Q values:  tensor([[-28.6960, -32.4691, -28.4314, -33.7737, -31.8314, -30.9431]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2325 348 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318 0 False\n",
      "x_t:  2 [0.76875    0.40833333 0.059375   0.27916667]\n",
      "Q values:  tensor([[-26.8369, -26.7528, -26.2206, -27.2194, -27.3160, -27.8443]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12639 346 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 318: ep_len:346 episode reward: total was -210.900000. running mean: -166.270709\n",
      "startIDX:  10\n",
      "318 1 False\n",
      "x_t:  3 [0.478125   0.25833333 0.08125    0.35833333]\n",
      "Q values:  tensor([[-30.9010, -29.0831, -31.8511, -28.6337, -31.4863, -29.9325]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25691 211 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 318: ep_len:211 episode reward: total was -67.300000. running mean: -165.281002\n",
      "startIDX:  2450\n",
      "318 5 False\n",
      "x_t:  2 [0.00625    0.39583333 0.06875    0.26666667]\n",
      "Q values:  tensor([[-27.6283, -27.3503, -25.2726, -26.6184, -28.3406, -25.8159]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21547 920 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 318: ep_len:920 episode reward: total was -562.200000. running mean: -169.250192\n",
      "startIDX:  2469\n",
      "318 10 True\n",
      "x_t:  1 [0.759375   0.2875     0.096875   0.32916667]\n",
      "Q values:  tensor([[-25.6926, -22.6871, -23.6393, -25.4615, -23.3315, -21.6735]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22483 1163 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 318: ep_len:1163 episode reward: total was -716.200000. running mean: -174.719690\n",
      "startIDX:  715\n",
      "318 12 False\n",
      "x_t:  1 [0.175      0.36666667 0.128125   0.50416667]\n",
      "Q values:  tensor([[-25.5579, -20.5663, -25.3128, -23.6020, -25.6032, -22.6099]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10316 220 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 318: ep_len:220 episode reward: total was -73.700000. running mean: -173.709493\n",
      "startIDX:  1377\n",
      "318 15 False\n",
      "x_t:  3 [0.753125   0.32916667 0.0625     0.3625    ]\n",
      "Q values:  tensor([[-15.9034, -16.0217, -15.8297, -15.1183, -16.8294, -15.7755]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10357 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 318: ep_len:200 episode reward: total was -73.800000. running mean: -172.710398\n",
      "startIDX:  2119\n",
      "318 22 False\n",
      "x_t:  0 [0.89375    0.40416667 0.059375   0.33333333]\n",
      "Q values:  tensor([[-26.8743, -28.1625, -30.9844, -29.5166, -27.6724, -26.8879]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20694 862 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 318: ep_len:862 episode reward: total was -486.600000. running mean: -175.849294\n",
      "startIDX:  886\n",
      "319 0 False\n",
      "x_t:  0 [0.6875     0.4        0.09375    0.35416667]\n",
      "Q values:  tensor([[-23.1233, -24.4957, -25.2696, -24.4777, -24.1401, -23.7822]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10366 459 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1044\n",
      "319 1 False\n",
      "x_t:  3 [0.73125    0.3        0.0875     0.39583333]\n",
      "Q values:  tensor([[-24.9722, -25.5336, -25.6182, -23.8822, -29.9000, -25.1264]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35919 208 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  720\n",
      "319 5 False\n",
      "x_t:  3 [0.228125   0.27916667 0.1        0.35833333]\n",
      "Q values:  tensor([[-31.0991, -32.5599, -33.6165, -30.4954, -34.7967, -31.9993]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8791 1349 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2595\n",
      "startIDX:  2063\n",
      "startIDX:  2247\n",
      "319 15 False\n",
      "x_t:  3 [0.096875   0.27083333 0.059375   0.30416667]\n",
      "Q values:  tensor([[-27.9948, -26.6909, -27.1465, -25.4286, -28.6518, -26.8775]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18179 1283 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1828\n",
      "319 22 False\n",
      "x_t:  2 [0.18125    0.41666667 0.103125   0.25833333]\n",
      "Q values:  tensor([[-23.3274, -21.7388, -20.9694, -22.1040, -22.5026, -21.5882]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18482 781 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  2703.8990244865417\n",
      "startIDX:  225\n",
      "320 0 False\n",
      "x_t:  2 [0.796875   0.40833333 0.1        0.2875    ]\n",
      "Q values:  tensor([[-22.2082, -20.4598, -19.0165, -20.2289, -19.3436, -19.8179]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2320 325 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 320: ep_len:325 episode reward: total was -155.700000. running mean: -182.942717\n",
      "startIDX:  639\n",
      "320 1 False\n",
      "x_t:  2 [0.7625     0.37916667 0.09375    0.32083333]\n",
      "Q values:  tensor([[-19.9898, -18.9141, -17.8662, -19.2482, -18.6147, -17.8969]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31469 358 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 320: ep_len:358 episode reward: total was -179.500000. running mean: -182.908290\n",
      "startIDX:  2335\n",
      "320 5 False\n",
      "x_t:  3 [0.15       0.25833333 0.09375    0.29583333]\n",
      "Q values:  tensor([[2.4274, 3.1695, 4.2562, 7.4624, 2.0386, 2.1345]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 19990 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 320: ep_len:201 episode reward: total was 28.100000. running mean: -180.798207\n",
      "startIDX:  1945\n",
      "320 10 False\n",
      "x_t:  1 [0.103125   0.34166667 0.13125    0.375     ]\n",
      "Q values:  tensor([[-19.5294, -17.9771, -19.5733, -18.4242, -21.9422, -18.7277]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18822 333 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 320: ep_len:333 episode reward: total was -54.800000. running mean: -179.538225\n",
      "startIDX:  1632\n",
      "320 12 False\n",
      "x_t:  2 [0.153125   0.41666667 0.121875   0.27916667]\n",
      "Q values:  tensor([[-25.6279, -23.7478, -23.3526, -26.6707, -24.1595, -23.7255]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19403 695 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 320: ep_len:695 episode reward: total was -302.900000. running mean: -180.771843\n",
      "startIDX:  1263\n",
      "320 15 True\n",
      "x_t:  3 [0.865625   0.34583333 0.13125    0.39166667]\n",
      "Q values:  tensor([[-17.6809, -17.0231, -17.9814, -18.1742, -17.0329, -17.0229]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10338 242 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 320: ep_len:242 episode reward: total was -77.800000. running mean: -179.742124\n",
      "startIDX:  1687\n",
      "320 22 False\n",
      "x_t:  3 [0.671875 0.325    0.0875   0.375   ]\n",
      "Q values:  tensor([[-19.8481, -19.5222, -20.5722, -18.3090, -21.4444, -18.9822]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16873 225 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 320: ep_len:225 episode reward: total was -71.000000. running mean: -178.654703\n",
      "startIDX:  437\n",
      "321 0 False\n",
      "x_t:  3 [0.6625   0.375    0.190625 0.45    ]\n",
      "Q values:  tensor([[-22.5425, -21.8457, -22.9124, -20.9230, -22.9109, -21.8740]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7005 1069 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  211\n",
      "321 1 False\n",
      "x_t:  2 [0.003125 0.3625   0.1      0.45    ]\n",
      "Q values:  tensor([[-20.2794, -18.2047, -17.6026, -18.8195, -18.9907, -17.8718]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27431 854 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  601\n",
      "321 5 False\n",
      "x_t:  2 [0.85625    0.37916667 0.078125   0.24166667]\n",
      "Q values:  tensor([[-16.0187, -16.1361, -14.4953, -15.7119, -15.7183, -16.2626]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6024 444 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1750\n",
      "321 10 True\n",
      "x_t:  3 [0.728125   0.30416667 0.134375   0.39166667]\n",
      "Q values:  tensor([[-18.6978, -17.3357, -17.9659, -17.1946, -17.3040, -17.4131]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16419 220 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1320\n",
      "321 12 False\n",
      "x_t:  3 [0.78125    0.35416667 0.078125   0.44166667]\n",
      "Q values:  tensor([[-17.2259, -17.0731, -19.0631, -14.9131, -16.7961, -16.1392]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17854 229 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  311\n",
      "321 15 False\n",
      "x_t:  1 [0.246875   0.36666667 0.18125    0.50416667]\n",
      "Q values:  tensor([[-22.5864, -21.1026, -23.1260, -22.3641, -22.4189, -21.2316]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2769 264 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  87\n",
      "321 22 False\n",
      "x_t:  1 [0.075      0.36666667 0.084375   0.42083333]\n",
      "Q values:  tensor([[-21.6990, -18.3322, -20.4932, -21.4771, -20.2229, -19.7084]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1661 732 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1025\n",
      "322 0 False\n",
      "x_t:  1 [0.521875   0.32916667 0.109375   0.44583333]\n",
      "Q values:  tensor([[-19.5985, -19.2335, -19.4107, -20.0002, -20.6031, -19.3635]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11984 790 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 322: ep_len:790 episode reward: total was -369.600000. running mean: -183.576413\n",
      "startIDX:  561\n",
      "322 1 False\n",
      "x_t:  1 [0.578125   0.28333333 0.09375    0.46666667]\n",
      "Q values:  tensor([[-19.2551, -17.3988, -17.5464, -18.9171, -17.6348, -18.0273]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30714 739 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 322: ep_len:739 episode reward: total was -339.400000. running mean: -185.134649\n",
      "startIDX:  2389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322 5 False\n",
      "x_t:  2 [0.096875   0.39166667 0.06875    0.27083333]\n",
      "Q values:  tensor([[-19.7327, -19.1654, -18.1196, -20.8780, -19.9993, -18.8568]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21562 951 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 322: ep_len:951 episode reward: total was -353.600000. running mean: -186.819303\n",
      "startIDX:  71\n",
      "322 10 False\n",
      "x_t:  3 [0.08125    0.24166667 0.075      0.2625    ]\n",
      "Q values:  tensor([[-20.7885, -23.1670, -23.5730, -20.5824, -21.0097, -21.3365]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3589 1093 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 322: ep_len:1093 episode reward: total was -502.400000. running mean: -189.975110\n",
      "startIDX:  787\n",
      "322 12 False\n",
      "x_t:  0 [0.628125   0.40833333 0.071875   0.30416667]\n",
      "Q values:  tensor([[-20.0847, -20.3473, -20.9394, -20.9419, -20.8311, -20.4727]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11680 858 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 322: ep_len:858 episode reward: total was -446.300000. running mean: -192.538359\n",
      "startIDX:  1702\n",
      "322 15 False\n",
      "x_t:  1 [0.259375   0.34166667 0.134375   0.37083333]\n",
      "Q values:  tensor([[-21.4959, -20.8551, -22.3290, -22.5435, -22.7481, -21.5733]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12476 247 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 322: ep_len:247 episode reward: total was -96.400000. running mean: -191.576975\n",
      "startIDX:  1518\n",
      "322 22 False\n",
      "x_t:  4 [0.0375     0.39166667 0.090625   0.30416667]\n",
      "Q values:  tensor([[-21.2854, -20.8460, -21.0047, -21.1163, -20.3275, -20.8391]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16329 514 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 322: ep_len:514 episode reward: total was -213.100000. running mean: -191.792205\n",
      "startIDX:  2137\n",
      "323 0 True\n",
      "x_t:  2 [0.903125   0.39166667 0.046875   0.19166667]\n",
      "Q values:  tensor([[-21.7545, -22.2542, -21.0143, -22.7212, -22.0117, -19.9698]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23573 1428 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  82\n",
      "323 1 False\n",
      "x_t:  3 [0.196875   0.22916667 0.0875     0.30833333]\n",
      "Q values:  tensor([[-7.5521, -8.4763, -7.0957, -6.4252, -7.6812, -8.6232]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25750 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1612\n",
      "323 5 True\n",
      "x_t:  1 [0.90625    0.27916667 0.090625   0.325     ]\n",
      "Q values:  tensor([[-20.8956, -23.1349, -22.4510, -22.9061, -20.9289, -22.1801]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14917 692 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1088\n",
      "323 10 True\n",
      "x_t:  2 [0.63125    0.40416667 0.0625     0.2375    ]\n",
      "Q values:  tensor([[-25.0523, -24.1724, -23.6106, -24.5909, -24.9856, -22.1231]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12091 366 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1706\n",
      "323 12 True\n",
      "x_t:  1 [0.20625    0.35       0.1125     0.35833333]\n",
      "Q values:  tensor([[-19.0994, -19.9391, -19.3905, -20.5494, -20.3525, -17.8796]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19892 228 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1661\n",
      "323 15 False\n",
      "x_t:  1 [0.134375   0.35416667 0.125      0.3875    ]\n",
      "Q values:  tensor([[-19.7174, -18.8142, -20.4443, -19.0636, -19.7732, -19.2906]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12459 258 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1596\n",
      "323 22 False\n",
      "x_t:  3 [0.83125    0.3375     0.090625   0.42083333]\n",
      "Q values:  tensor([[-19.2772, -19.9124, -18.3666, -18.1379, -18.7743, -18.2105]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16851 249 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1635\n",
      "324 0 False\n",
      "x_t:  3 [0.5125 0.3125 0.125  0.375 ]\n",
      "Q values:  tensor([[ 0.1623, -1.3465,  1.6026,  3.2344,  1.1473, -0.1305]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16856 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 324: ep_len:200 episode reward: total was -37.400000. running mean: -188.669484\n",
      "startIDX:  517\n",
      "324 1 False\n",
      "x_t:  1 [0.740625   0.275      0.096875   0.45416667]\n",
      "Q values:  tensor([[-16.3883, -15.6996, -17.5902, -16.3395, -17.6949, -16.3538]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30698 757 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 324: ep_len:757 episode reward: total was -189.200000. running mean: -188.674790\n",
      "startIDX:  1107\n",
      "324 5 False\n",
      "x_t:  3 [0.08125    0.22083333 0.05625    0.26666667]\n",
      "Q values:  tensor([[ 9.0428e-04, -9.1534e-01,  1.9244e+00,  3.7457e+00,  2.9493e-01,\n",
      "          7.1963e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10613 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 324: ep_len:200 episode reward: total was 28.900000. running mean: -186.499042\n",
      "startIDX:  2268\n",
      "324 10 True\n",
      "x_t:  1 [0.321875   0.32083333 0.1        0.33333333]\n",
      "Q values:  tensor([[-15.1140, -15.5062, -14.3960, -16.4023, -16.2175, -13.9639]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22531 1293 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 324: ep_len:1293 episode reward: total was -246.700000. running mean: -187.101051\n",
      "startIDX:  170\n",
      "324 12 False\n",
      "x_t:  3 [0.08125    0.25416667 0.065625   0.27916667]\n",
      "Q values:  tensor([[-16.3996, -17.3517, -15.8330, -15.3590, -18.0071, -16.4932]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5670 1424 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 324: ep_len:1424 episode reward: total was -429.200000. running mean: -189.522041\n",
      "startIDX:  84\n",
      "324 15 True\n",
      "x_t:  3 [0.78125    0.35       0.11875    0.42083333]\n",
      "Q values:  tensor([[-13.7003, -12.5657, -12.7384, -12.5730, -12.3171, -11.7569]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 529 210 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 324: ep_len:210 episode reward: total was -36.000000. running mean: -187.986820\n",
      "startIDX:  2557\n",
      "324 22 False\n",
      "x_t:  3 [0.10625    0.24583333 0.065625   0.25      ]\n",
      "Q values:  tensor([[-14.0163, -15.5858, -14.4791, -13.7053, -15.4334, -13.9509]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26187 1240 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 324: ep_len:1240 episode reward: total was -280.200000. running mean: -188.908952\n",
      "startIDX:  671\n",
      "325 0 True\n",
      "x_t:  2 [0.325      0.40833333 0.090625   0.25416667]\n",
      "Q values:  tensor([[-12.8107, -13.1342, -13.3721, -13.0934, -13.8058, -12.0178]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8918 912 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  746\n",
      "325 1 False\n",
      "x_t:  3 [0.059375   0.23333333 0.05625    0.27916667]\n",
      "Q values:  tensor([[-11.2801, -11.4068, -10.6006, -10.0393, -10.8707, -10.0617]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34300 1402 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2353\n",
      "325 5 False\n",
      "x_t:  3 [0.08125    0.24583333 0.06875    0.26666667]\n",
      "Q values:  tensor([[1.8569, 0.4630, 2.1035, 3.9326, 1.6529, 0.8244]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 20011 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2569\n",
      "startIDX:  644\n",
      "325 12 False\n",
      "x_t:  2 [0.1625     0.4125     0.1125     0.25416667]\n",
      "Q values:  tensor([[-9.0004, -9.4763, -8.2073, -9.1986, -8.9520, -8.3334]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9855 1009 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2107\n",
      "325 15 True\n",
      "x_t:  2 [0.425      0.40833333 0.05       0.25416667]\n",
      "Q values:  tensor([[-10.4305,  -9.6708, -10.1392, -10.1824,  -9.5014,  -8.6835]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15626 377 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  309\n",
      "325 22 True\n",
      "x_t:  3 [0.10625    0.2375     0.065625   0.25833333]\n",
      "Q values:  tensor([[-11.4574, -11.1856, -11.8306, -10.9423, -13.1148, -11.1545]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4885 1262 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  201\n",
      "326 0 False\n",
      "x_t:  3 [0.19375    0.24166667 0.06875    0.27083333]\n",
      "Q values:  tensor([[-12.6122, -11.6523, -12.0842, -11.1281, -13.0096, -11.3365]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4881 1626 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 326: ep_len:1626 episode reward: total was -430.600000. running mean: -189.292835\n",
      "startIDX:  1105\n",
      "326 1 False\n",
      "x_t:  3 [0.56875    0.28333333 0.084375   0.35416667]\n",
      "Q values:  tensor([[1.5875, 0.3819, 2.5776, 3.8102, 2.1380, 0.8392]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 35947 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 326: ep_len:201 episode reward: total was -37.600000. running mean: -187.775907\n",
      "startIDX:  2229\n",
      "326 5 False\n",
      "x_t:  3 [0.525      0.29166667 0.10625    0.39583333]\n",
      "Q values:  tensor([[-7.9879, -8.2515, -8.2423, -7.8855, -8.1703, -7.9076]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19923 224 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 326: ep_len:224 episode reward: total was 49.500000. running mean: -185.403148\n",
      "startIDX:  914\n",
      "326 10 True\n",
      "x_t:  1 [0.771875   0.2875     0.11875    0.33333333]\n",
      "Q values:  tensor([[-16.2380, -18.9574, -17.4598, -16.5573, -18.7679, -15.6056]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11340 1591 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 326: ep_len:1591 episode reward: total was -318.000000. running mean: -186.729116\n",
      "startIDX:  1565\n",
      "326 12 True\n",
      "x_t:  2 [0.1125     0.4125     0.08125    0.29166667]\n",
      "Q values:  tensor([[-11.1075, -11.4939, -12.3342, -11.6947, -11.5095, -10.6238]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19395 735 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 326: ep_len:735 episode reward: total was -121.000000. running mean: -186.071825\n",
      "startIDX:  2150\n",
      "326 15 True\n",
      "x_t:  2 [0.809375   0.40833333 0.06875    0.27916667]\n",
      "Q values:  tensor([[-10.3909,  -9.4878, -11.5028,  -9.2859, -10.8008,  -9.5768]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15565 318 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 326: ep_len:318 episode reward: total was -59.900000. running mean: -184.810107\n",
      "startIDX:  1594\n",
      "326 22 True\n",
      "x_t:  3 [0.521875   0.3125     0.121875   0.34583333]\n",
      "Q values:  tensor([[ -8.7497,  -9.2858, -10.1952,  -9.5686,  -9.2268,  -8.5786]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16893 283 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 326: ep_len:283 episode reward: total was 12.100000. running mean: -182.841006\n",
      "startIDX:  1635\n",
      "327 0 False\n",
      "x_t:  3 [0.278125 0.2625   0.075    0.3125  ]\n",
      "Q values:  tensor([[-9.0919, -9.0521, -9.6133, -8.1491, -8.2201, -8.3123]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16903 226 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  48\n",
      "327 1 False\n",
      "x_t:  3 [0.371875   0.25833333 0.090625   0.33333333]\n",
      "Q values:  tensor([[1.9915, 1.0175, 4.0145, 4.0448, 2.3994, 1.2996]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 25712 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1295\n",
      "327 5 True\n",
      "x_t:  2 [0.25       0.39583333 0.09375    0.27916667]\n",
      "Q values:  tensor([[-11.2499, -10.2764, -10.3898, -11.1793, -10.4136,  -9.6720]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12037 695 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  361\n",
      "327 10 False\n",
      "x_t:  3 [0.83125  0.3375   0.153125 0.375   ]\n",
      "Q values:  tensor([[-7.6726, -7.2695, -7.6033, -7.1462, -7.4828, -7.2562]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5036 210 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1482\n",
      "327 12 True\n",
      "x_t:  3 [0.16875    0.25416667 0.059375   0.27916667]\n",
      "Q values:  tensor([[ -9.9360,  -9.5640, -10.3354,  -9.5675,  -9.6570,  -8.2068]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17967 205 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1688\n",
      "327 15 True\n",
      "x_t:  1 [0.659375   0.30416667 0.06875    0.37083333]\n",
      "Q values:  tensor([[-7.5823, -7.6338, -7.9321, -6.3000, -6.8671, -6.5801]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12516 270 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1538\n",
      "327 22 True\n",
      "x_t:  4 [0.084375   0.39166667 0.090625   0.3       ]\n",
      "Q values:  tensor([[-7.7875, -7.6999, -8.3330, -8.1257, -8.1582, -6.8776]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16338 518 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  394\n",
      "328 0 True\n",
      "x_t:  3 [0.578125   0.35416667 0.121875   0.44583333]\n",
      "Q values:  tensor([[ -8.9255, -10.4059, -10.6002,  -9.4928,  -9.9528,  -8.5609]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7022 1095 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 328: ep_len:1095 episode reward: total was -179.200000. running mean: -174.491997\n",
      "startIDX:  1172\n",
      "ep 328: ep_len:16 episode reward: total was 2.000000. running mean: -172.727077\n",
      "startIDX:  1620\n",
      "328 5 True\n",
      "x_t:  1 [0.378125   0.31666667 0.121875   0.29583333]\n",
      "Q values:  tensor([[-9.4402, -9.5395, -9.6958, -8.7605, -9.4551, -8.4814]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14994 705 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 328: ep_len:705 episode reward: total was -133.800000. running mean: -172.337806\n",
      "startIDX:  1142\n",
      "328 10 True\n",
      "x_t:  2 [0.7875   0.4      0.065625 0.25    ]\n",
      "Q values:  tensor([[-8.3861, -8.6389, -8.9037, -8.8366, -8.7323, -7.8816]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12067 328 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 328: ep_len:328 episode reward: total was -91.600000. running mean: -171.530428\n",
      "startIDX:  439\n",
      "328 12 False\n",
      "x_t:  3 [0.9125     0.36666667 0.084375   0.425     ]\n",
      "Q values:  tensor([[-7.4935, -7.6552, -8.4454, -7.3204, -7.8169, -7.3809]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7709 226 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 328: ep_len:226 episode reward: total was -18.400000. running mean: -169.999123\n",
      "startIDX:  2318\n",
      "328 15 False\n",
      "x_t:  3 [0.1        0.27083333 0.084375   0.30833333]\n",
      "Q values:  tensor([[-10.6876, -10.8733, -10.9517, -10.3161, -11.1558, -10.5451]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18182 1234 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 328: ep_len:1234 episode reward: total was -308.000000. running mean: -171.379132\n",
      "startIDX:  2179\n",
      "328 22 False\n",
      "x_t:  0 [0.7        0.40833333 0.0625     0.30416667]\n",
      "Q values:  tensor([[-11.6020, -12.6290, -13.3842, -12.4517, -13.1719, -11.7236]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20753 830 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 328: ep_len:830 episode reward: total was -206.500000. running mean: -171.730341\n",
      "startIDX:  2451\n",
      "startIDX:  758\n",
      "329 1 True\n",
      "x_t:  3 [0.065625   0.22916667 0.0625     0.28333333]\n",
      "Q values:  tensor([[-12.9693, -13.0782, -13.3396, -13.4962, -13.4254, -12.1869]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34303 1368 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  905\n",
      "329 5 True\n",
      "x_t:  4 [0.21875    0.40416667 0.1125     0.375     ]\n",
      "Q values:  tensor([[-12.9563, -12.1992, -12.3662, -11.0365, -11.4223, -11.0604]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10039 573 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  872\n",
      "329 10 False\n",
      "x_t:  0 [0.896875   0.39583333 0.096875   0.32083333]\n",
      "Q values:  tensor([[-8.2622, -9.3336, -9.6539, -8.8337, -9.4554, -8.7618]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8106 456 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  493\n",
      "329 12 True\n",
      "x_t:  3 [0.7875     0.3625     0.165625   0.41666667]\n",
      "Q values:  tensor([[-9.1827, -9.3156, -9.3415, -9.7203, -9.7403, -8.4546]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7718 220 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1319\n",
      "329 15 True\n",
      "x_t:  3 [0.915625   0.35       0.078125   0.38333333]\n",
      "Q values:  tensor([[-8.8326, -9.2162, -9.5517, -8.4510, -9.5859, -7.9809]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10334 215 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  724\n",
      "329 22 False\n",
      "x_t:  2 [0.834375 0.4125   0.1125   0.25    ]\n",
      "Q values:  tensor([[-11.7503, -11.0575,  -9.7362, -11.2509, -11.0491,  -9.7699]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9055 935 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  2790.690315723419\n",
      "startIDX:  5\n",
      "330 0 True\n",
      "x_t:  2 [0.328125   0.41666667 0.134375   0.3       ]\n",
      "Q values:  tensor([[-12.1961, -11.3757, -10.3578, -10.7424, -11.1194,  -9.8313]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2390 1143 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 330: ep_len:1143 episode reward: total was -237.000000. running mean: -167.271475\n",
      "startIDX:  390\n",
      "330 1 True\n",
      "x_t:  0 [0.696875   0.37916667 0.09375    0.39583333]\n",
      "Q values:  tensor([[-11.3854, -11.0430, -11.3267, -10.6565, -11.7258,  -9.9048]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29123 787 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 330: ep_len:787 episode reward: total was -168.100000. running mean: -167.279761\n",
      "startIDX:  1684\n",
      "330 5 False\n",
      "x_t:  1 [0.903125   0.275      0.090625   0.32916667]\n",
      "Q values:  tensor([[-10.2291,  -8.7622,  -9.0070,  -9.6935,  -9.7423,  -9.4658]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14918 628 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 330: ep_len:628 episode reward: total was -102.700000. running mean: -166.633963\n",
      "startIDX:  1113\n",
      "330 10 True\n",
      "x_t:  2 [0.7875     0.40416667 0.1        0.24166667]\n",
      "Q values:  tensor([[-9.0425, -7.9051, -8.6797, -8.4245, -8.2380, -7.8588]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12062 346 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 330: ep_len:346 episode reward: total was -72.700000. running mean: -165.694623\n",
      "startIDX:  2054\n",
      "ep 330: ep_len:7 episode reward: total was -1.000000. running mean: -164.047677\n",
      "startIDX:  965\n",
      "330 15 True\n",
      "x_t:  4 [0.0625     0.39166667 0.096875   0.29583333]\n",
      "Q values:  tensor([[-10.1172,  -9.6399,  -9.9676,  -9.0795, -10.3194,  -8.6736]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9822 640 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 330: ep_len:640 episode reward: total was -32.300000. running mean: -162.730200\n",
      "startIDX:  95\n",
      "330 22 False\n",
      "x_t:  1 [0.625      0.32083333 0.14375    0.39583333]\n",
      "Q values:  tensor([[-10.2618,  -9.7937, -10.9352, -10.8755, -10.0586, -10.0075]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1603 682 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 330: ep_len:682 episode reward: total was -95.300000. running mean: -162.055898\n",
      "startIDX:  1010\n",
      "331 0 True\n",
      "x_t:  2 [0.484375   0.40833333 0.075      0.29583333]\n",
      "Q values:  tensor([[-11.7066, -12.1227, -12.6935, -12.4207, -12.1590, -11.8246]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12679 1158 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  534\n",
      "331 1 False\n",
      "x_t:  2 [0.546875   0.37916667 0.078125   0.325     ]\n",
      "Q values:  tensor([[-10.7671, -11.2471,  -9.9817, -10.7540, -12.0321, -10.1040]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31506 1144 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1119\n",
      "331 5 True\n",
      "x_t:  2 [0.25625    0.39583333 0.09375    0.28333333]\n",
      "Q values:  tensor([[-10.1588,  -9.6973,  -9.4604,  -9.2689, -10.4323,  -8.1075]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12038 899 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2240\n",
      "331 10 False\n",
      "x_t:  1 [0.88125    0.28333333 0.078125   0.34583333]\n",
      "Q values:  tensor([[-10.5084,  -9.7456, -12.3128, -10.8826, -11.6920, -10.1674]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22471 1271 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  8\n",
      "331 12 True\n",
      "x_t:  1 [0.671875   0.31666667 0.075      0.45      ]\n",
      "Q values:  tensor([[-10.4280,  -9.1909,  -9.8820, -10.3828, -10.2714,  -8.4591]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2235 647 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1338\n",
      "331 15 True\n",
      "x_t:  3 [0.540625   0.2875     0.1        0.34583333]\n",
      "Q values:  tensor([[-6.7840, -6.3911, -6.3382, -6.2003, -5.9930, -5.7567]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10391 235 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  592\n",
      "331 22 True\n",
      "x_t:  3 [0.6125     0.31666667 0.10625    0.35      ]\n",
      "Q values:  tensor([[-6.3536, -6.6136, -5.9995, -6.4485, -7.0559, -5.8147]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7089 207 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  240\n",
      "332 0 True\n",
      "x_t:  3 [0.115625   0.24583333 0.071875   0.24583333]\n",
      "Q values:  tensor([[-9.6836, -8.4194, -9.0386, -9.5961, -8.9713, -7.9018]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4858 1582 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 332: ep_len:1582 episode reward: total was -266.800000. running mean: -159.459465\n",
      "startIDX:  10\n",
      "332 1 False\n",
      "x_t:  3 [0.63125    0.275      0.08125    0.39583333]\n",
      "Q values:  tensor([[1.4224, 0.4850, 1.8158, 2.5015, 1.0505, 0.8887]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 25666 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 332: ep_len:201 episode reward: total was 18.800000. running mean: -157.676871\n",
      "startIDX:  2381\n",
      "332 5 False\n",
      "x_t:  3 [0.059375 0.2375   0.065625 0.2625  ]\n",
      "Q values:  tensor([[2.0884, 0.1845, 2.0559, 3.4783, 2.1957, 0.7539]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 20020 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 332: ep_len:200 episode reward: total was 30.600000. running mean: -155.794102\n",
      "startIDX:  916\n",
      "332 10 True\n",
      "x_t:  1 [0.44375    0.3125     0.090625   0.34583333]\n",
      "Q values:  tensor([[-6.5072, -6.9036, -6.7077, -6.2879, -6.5255, -5.6024]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11387 1630 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 332: ep_len:1630 episode reward: total was -137.700000. running mean: -155.613161\n",
      "startIDX:  1578\n",
      "332 12 False\n",
      "x_t:  2 [0.003125   0.4125     0.10625    0.27916667]\n",
      "Q values:  tensor([[-6.5889, -6.2288, -5.7809, -6.4805, -6.6748, -5.8873]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19379 727 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 332: ep_len:727 episode reward: total was -37.900000. running mean: -154.436029\n",
      "startIDX:  692\n",
      "332 15 False\n",
      "x_t:  2 [0.70625    0.41666667 0.109375   0.29166667]\n",
      "Q values:  tensor([[-4.4714, -4.9665, -4.3813, -5.3755, -5.2008, -4.4075]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5981 403 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 332: ep_len:403 episode reward: total was -83.700000. running mean: -153.728669\n",
      "startIDX:  1463\n",
      "332 22 False\n",
      "x_t:  4 [0.29375    0.38333333 0.09375    0.3125    ]\n",
      "Q values:  tensor([[-5.0579, -4.6547, -4.6441, -4.6762, -4.4561, -4.5138]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16372 556 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 332: ep_len:556 episode reward: total was -42.000000. running mean: -152.611382\n",
      "startIDX:  1053\n",
      "333 0 True\n",
      "x_t:  1 [0.665625   0.30833333 0.146875   0.45833333]\n",
      "Q values:  tensor([[-6.2356, -6.0131, -6.0246, -6.0610, -6.1896, -5.3535]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11968 780 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1081\n",
      "333 1 False\n",
      "x_t:  3 [0.684375 0.3      0.109375 0.3875  ]\n",
      "Q values:  tensor([[1.8811, 1.5975, 2.2848, 3.5524, 2.5898, 2.0274]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 35923 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  913\n",
      "333 5 False\n",
      "x_t:  3 [0.121875   0.23333333 0.059375   0.26666667]\n",
      "Q values:  tensor([[-4.6262, -4.1810, -4.4229, -3.7619, -4.6167, -3.8711]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10603 294 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2626\n",
      "startIDX:  1625\n",
      "333 12 True\n",
      "x_t:  2 [0.346875 0.4125   0.125    0.3     ]\n",
      "Q values:  tensor([[-4.2429, -4.0154, -3.9960, -4.1561, -4.3335, -3.4811]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19428 721 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2565\n",
      "333 15 False\n",
      "x_t:  3 [0.265625   0.25833333 0.0875     0.27916667]\n",
      "Q values:  tensor([[-0.2775, -0.1198,  1.0781,  3.3634,  1.3206, -0.8482]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19772 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  159\n",
      "333 22 True\n",
      "x_t:  3 [0.28125    0.26666667 0.075      0.29166667]\n",
      "Q values:  tensor([[-4.7020, -4.7920, -4.4312, -5.1974, -5.0260, -4.2331]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4933 1686 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1764\n",
      "334 0 True\n",
      "x_t:  2 [0.303125   0.4        0.084375   0.25416667]\n",
      "Q values:  tensor([[-4.4723, -4.2886, -4.0139, -4.4326, -4.5288, -3.7682]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18438 773 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 334: ep_len:773 episode reward: total was -53.100000. running mean: -146.052876\n",
      "startIDX:  187\n",
      "334 1 True\n",
      "x_t:  2 [0.1125     0.35833333 0.1125     0.45416667]\n",
      "Q values:  tensor([[-3.7008, -3.6853, -3.5099, -3.7056, -3.9701, -3.3831]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27447 847 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 334: ep_len:847 episode reward: total was -76.300000. running mean: -145.355347\n",
      "startIDX:  598\n",
      "334 5 True\n",
      "x_t:  2 [0.2125     0.3875     0.10625    0.30833333]\n",
      "Q values:  tensor([[-4.3072, -3.9616, -4.0619, -4.1044, -3.8496, -3.3895]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6117 483 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 334: ep_len:483 episode reward: total was -83.200000. running mean: -144.733793\n",
      "startIDX:  951\n",
      "334 10 False\n",
      "x_t:  1 [0.75     0.2875   0.128125 0.3375  ]\n",
      "Q values:  tensor([[-6.2913, -5.3861, -5.8800, -5.5506, -5.5420, -5.4313]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11343 1578 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 334: ep_len:1578 episode reward: total was -163.900000. running mean: -144.925455\n",
      "startIDX:  98\n",
      "334 12 False\n",
      "x_t:  1 [0.68125    0.325      0.121875   0.42916667]\n",
      "Q values:  tensor([[-7.0065, -5.9191, -6.1674, -6.6205, -6.6766, -6.0436]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2232 609 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 334: ep_len:609 episode reward: total was -75.300000. running mean: -144.229201\n",
      "startIDX:  438\n",
      "334 15 True\n",
      "x_t:  0 [0.85       0.40416667 0.1125     0.34166667]\n",
      "Q values:  tensor([[-6.0773, -6.3228, -6.0890, -5.7384, -6.0347, -5.2087]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3658 424 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 334: ep_len:424 episode reward: total was -31.500000. running mean: -143.101909\n",
      "startIDX:  2609\n",
      "334 22 False\n",
      "x_t:  3 [0.0625     0.2375     0.040625   0.23333333]\n",
      "Q values:  tensor([[-6.9485, -7.1547, -7.3064, -6.7262, -7.8311, -7.1307]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26169 1209 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 334: ep_len:1209 episode reward: total was -134.600000. running mean: -143.016890\n",
      "startIDX:  1772\n",
      "335 0 False\n",
      "x_t:  2 [0.10625    0.40833333 0.115625   0.24583333]\n",
      "Q values:  tensor([[-6.6912, -6.4151, -5.4835, -6.0222, -7.0626, -5.9922]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18409 770 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  6\n",
      "335 1 True\n",
      "x_t:  3 [0.496875   0.275      0.08125    0.35833333]\n",
      "Q values:  tensor([[-7.1779, -7.6155, -7.1868, -7.1958, -7.2046, -6.2142]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25689 208 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335 5 False\n",
      "x_t:  3 [0.215625   0.24166667 0.078125   0.29166667]\n",
      "Q values:  tensor([[0.7145, 0.2890, 2.4025, 3.8696, 2.5616, 0.9751]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 10580 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  394\n",
      "335 10 True\n",
      "x_t:  3 [0.240625   0.24583333 0.065625   0.28333333]\n",
      "Q values:  tensor([[-5.5715, -5.1709, -5.3389, -5.1473, -5.7662, -4.7563]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5137 240 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1041\n",
      "335 12 False\n",
      "x_t:  2 [0.865625   0.39166667 0.065625   0.23333333]\n",
      "Q values:  tensor([[-5.8113, -5.0233, -4.8768, -5.8497, -5.3095, -4.9532]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13567 284 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3157\n",
      "startIDX:  2920\n",
      "startIDX:  10\n",
      "336 0 True\n",
      "x_t:  2 [0.79375    0.40416667 0.075      0.28333333]\n",
      "Q values:  tensor([[-7.5404, -7.4597, -6.3753, -7.0323, -7.5375, -6.2743]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2325 1114 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 336: ep_len:1114 episode reward: total was -121.900000. running mean: -133.667080\n",
      "startIDX:  42\n",
      "336 1 False\n",
      "x_t:  3 [0.40625  0.2625   0.096875 0.3375  ]\n",
      "Q values:  tensor([[3.8761, 1.5150, 4.1621, 7.0691, 4.9598, 2.0028]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 25704 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 336: ep_len:200 episode reward: total was -5.800000. running mean: -132.388409\n",
      "startIDX:  668\n",
      "336 5 True\n",
      "x_t:  3 [0.415625   0.31666667 0.13125    0.375     ]\n",
      "Q values:  tensor([[-6.4161, -5.8577, -5.3430, -6.7044, -6.3357, -5.8474]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8830 1396 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 336: ep_len:1396 episode reward: total was -104.900000. running mean: -132.113525\n",
      "startIDX:  2307\n",
      "336 10 True\n",
      "x_t:  1 [0.884375   0.2875     0.1125     0.34166667]\n",
      "Q values:  tensor([[-5.6352, -5.7664, -5.7375, -5.6121, -6.4606, -5.1374]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22467 1239 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 336: ep_len:1239 episode reward: total was -39.500000. running mean: -131.187389\n",
      "startIDX:  1730\n",
      "336 12 True\n",
      "x_t:  1 [0.525   0.3375  0.15625 0.3625 ]\n",
      "Q values:  tensor([[-4.6980, -4.7554, -4.5320, -4.9492, -4.6170, -3.5595]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19924 219 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 336: ep_len:219 episode reward: total was -34.500000. running mean: -130.220516\n",
      "startIDX:  1404\n",
      "336 15 True\n",
      "x_t:  3 [0.253125   0.25833333 0.090625   0.275     ]\n",
      "Q values:  tensor([[-3.4224, -3.4324, -4.0003, -3.8543, -3.6783, -2.9088]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10453 240 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 336: ep_len:240 episode reward: total was -68.800000. running mean: -129.606310\n",
      "startIDX:  68\n",
      "336 22 False\n",
      "x_t:  2 [0.18125    0.40416667 0.075      0.2625    ]\n",
      "Q values:  tensor([[-4.4726, -4.9443, -4.3290, -4.8551, -5.3362, -4.3475]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2387 1099 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 336: ep_len:1099 episode reward: total was -154.600000. running mean: -129.856247\n",
      "startIDX:  1265\n",
      "337 0 True\n",
      "x_t:  3 [0.0625     0.25       0.059375   0.24583333]\n",
      "Q values:  tensor([[-4.5862, -4.4811, -3.9186, -4.8533, -4.6564, -4.0608]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15154 1214 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  543\n",
      "337 1 True\n",
      "x_t:  1 [0.2        0.32083333 0.15625    0.5       ]\n",
      "Q values:  tensor([[-3.7084, -3.8703, -3.9012, -3.7566, -3.5555, -3.2463]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30750 779 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  335\n",
      "337 5 True\n",
      "x_t:  1 [0.859375   0.28333333 0.10625    0.39583333]\n",
      "Q values:  tensor([[-4.7823, -4.4197, -4.5853, -4.7376, -4.6564, -3.6441]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5030 729 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  265\n",
      "337 10 True\n",
      "x_t:  4 [0.003125 0.3625   0.078125 0.25    ]\n",
      "Q values:  tensor([[-4.0528, -4.2994, -4.2959, -4.2396, -4.3796, -3.5284]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4545 418 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1987\n",
      "startIDX:  1913\n",
      "337 15 True\n",
      "x_t:  1 [0.234375 0.3375   0.10625  0.325   ]\n",
      "Q values:  tensor([[-3.9179, -3.8229, -3.8901, -4.2347, -3.9832, -3.1854]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14926 746 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2255\n",
      "337 22 True\n",
      "x_t:  1 [0.715625 0.325    0.16875  0.4375  ]\n",
      "Q values:  tensor([[-5.4864, -5.3912, -4.9623, -5.8207, -5.6411, -4.3815]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22945 1113 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2460\n",
      "ep 338: ep_len:58 episode reward: total was 26.000000. running mean: -122.695145\n",
      "startIDX:  820\n",
      "338 1 True\n",
      "x_t:  4 [0.275  0.375  0.0875 0.375 ]\n",
      "Q values:  tensor([[-5.6368, -4.9675, -5.2175, -5.3423, -5.1919, -4.0464]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35517 606 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 338: ep_len:606 episode reward: total was -21.100000. running mean: -121.679193\n",
      "startIDX:  957\n",
      "338 5 True\n",
      "x_t:  3 [0.525    0.2875   0.159375 0.3625  ]\n",
      "Q values:  tensor([[-4.9090, -4.4667, -5.2040, -4.7198, -4.9716, -3.8214]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10522 231 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 338: ep_len:231 episode reward: total was 44.300000. running mean: -120.019401\n",
      "startIDX:  852\n",
      "338 10 True\n",
      "x_t:  0 [0.728125 0.4      0.1125   0.3125  ]\n",
      "Q values:  tensor([[-4.5121, -4.6978, -4.4609, -4.6762, -4.5395, -3.8565]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8130 474 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 338: ep_len:474 episode reward: total was -39.700000. running mean: -119.216207\n",
      "startIDX:  1423\n",
      "338 12 True\n",
      "x_t:  3 [0.365625 0.3      0.1125   0.3375  ]\n",
      "Q values:  tensor([[2.2946, 1.3176, 3.4090, 4.6014, 3.0722, 2.6201]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 17911 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 338: ep_len:200 episode reward: total was 13.100000. running mean: -117.893045\n",
      "startIDX:  1214\n",
      "338 15 True\n",
      "x_t:  4 [0.0625     0.39166667 0.096875   0.29583333]\n",
      "Q values:  tensor([[-4.5293, -4.1172, -4.0277, -4.6215, -4.4814, -3.7657]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9822 518 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 338: ep_len:518 episode reward: total was -46.700000. running mean: -117.181115\n",
      "startIDX:  2100\n",
      "338 22 True\n",
      "x_t:  0 [0.759375   0.40416667 0.059375   0.3125    ]\n",
      "Q values:  tensor([[-5.3599, -5.1525, -4.3109, -4.9828, -5.0249, -3.8880]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20735 881 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 338: ep_len:881 episode reward: total was -109.400000. running mean: -117.103303\n",
      "startIDX:  983\n",
      "339 0 True\n",
      "x_t:  1 [0.521875   0.32916667 0.109375   0.44583333]\n",
      "Q values:  tensor([[-4.8636, -4.0525, -3.7598, -4.2563, -4.1263, -3.6146]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11984 813 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  157\n",
      "339 1 True\n",
      "x_t:  2 [0.003125 0.375    0.171875 0.4375  ]\n",
      "Q values:  tensor([[-5.6014, -5.3107, -4.8925, -5.5431, -5.7339, -4.5543]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27437 882 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  791\n",
      "339 5 True\n",
      "x_t:  4 [0.4        0.37916667 0.128125   0.375     ]\n",
      "Q values:  tensor([[-4.6683, -4.7202, -4.7644, -4.6730, -4.7842, -3.8550]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10070 650 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2481\n",
      "339 10 True\n",
      "x_t:  1 [0.778125   0.29166667 0.1375     0.32916667]\n",
      "Q values:  tensor([[-4.5631, -4.7027, -5.0672, -4.9041, -4.9549, -3.9699]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22479 1157 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  839\n",
      "339 12 True\n",
      "x_t:  0 [0.915625   0.40833333 0.08125    0.30416667]\n",
      "Q values:  tensor([[-5.9522, -5.0688, -5.6830, -5.6986, -6.2465, -4.7774]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11631 627 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2779\n",
      "339 15 True\n",
      "x_t:  1 [0.834375   0.30416667 0.084375   0.47083333]\n",
      "Q values:  tensor([[-3.8845, -4.0182, -4.2741, -3.9343, -3.7445, -2.9893]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22107 314 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2248\n",
      "339 22 True\n",
      "x_t:  1 [0.471875 0.3375   0.16875  0.4375  ]\n",
      "Q values:  tensor([[-5.4477, -5.3173, -4.6770, -5.5155, -5.5148, -4.3259]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22968 1116 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  2885.4494655132294\n",
      "startIDX:  96\n",
      "340 0 True\n",
      "x_t:  2 [0.4375     0.41666667 0.121875   0.29583333]\n",
      "Q values:  tensor([[-6.2479, -6.1441, -6.2274, -6.6009, -6.2774, -5.0170]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2376 1104 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 340: ep_len:1104 episode reward: total was -153.000000. running mean: -112.948400\n",
      "startIDX:  217\n",
      "340 1 True\n",
      "x_t:  2 [0.003125   0.375      0.09375    0.42916667]\n",
      "Q values:  tensor([[-5.1904, -4.8425, -4.5035, -4.4435, -4.5095, -3.8597]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27429 846 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 340: ep_len:846 episode reward: total was -71.900000. running mean: -112.537916\n",
      "startIDX:  580\n",
      "340 5 True\n",
      "x_t:  2 [0.809375   0.38333333 0.109375   0.2875    ]\n",
      "Q values:  tensor([[-5.2584, -4.4286, -4.4098, -4.6389, -4.5518, -3.7499]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6031 456 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 340: ep_len:456 episode reward: total was -48.100000. running mean: -111.893537\n",
      "startIDX:  620\n",
      "340 10 True\n",
      "x_t:  2 [0.0375     0.40416667 0.08125    0.25416667]\n",
      "Q values:  tensor([[-5.2977, -5.1761, -5.2574, -5.5672, -5.2442, -4.1998]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6592 721 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 340: ep_len:721 episode reward: total was -31.800000. running mean: -111.092601\n",
      "startIDX:  999\n",
      "340 12 True\n",
      "x_t:  2 [0.79375    0.40833333 0.078125   0.24583333]\n",
      "Q values:  tensor([[-4.5118, -4.3129, -4.6519, -4.0285, -4.7107, -3.4109]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13577 317 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 340: ep_len:317 episode reward: total was -40.400000. running mean: -110.385675\n",
      "startIDX:  2997\n",
      "ep 340: ep_len:82 episode reward: total was 44.000000. running mean: -108.841818\n",
      "startIDX:  300\n",
      "340 22 True\n",
      "x_t:  3 [0.146875   0.24583333 0.0625     0.2625    ]\n",
      "Q values:  tensor([[-5.6736, -5.4347, -5.7540, -6.2172, -5.8311, -4.9751]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4897 1263 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 340: ep_len:1263 episode reward: total was -75.400000. running mean: -108.507400\n",
      "startIDX:  1085\n",
      "341 0 True\n",
      "x_t:  1 [0.80625    0.3125     0.171875   0.42916667]\n",
      "Q values:  tensor([[-5.4605, -5.3292, -5.3483, -5.0074, -5.5463, -4.4705]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11952 752 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  543\n",
      "341 1 True\n",
      "x_t:  1 [0.85625    0.26666667 0.140625   0.45833333]\n",
      "Q values:  tensor([[-5.3934, -5.1421, -4.8634, -5.3245, -5.5379, -4.2560]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30680 724 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2903\n",
      "startIDX:  2121\n",
      "341 10 True\n",
      "x_t:  0 [0.675    0.4      0.053125 0.3125  ]\n",
      "Q values:  tensor([[-4.3613, -4.5024, -4.4320, -4.2075, -4.7202, -3.5123]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19991 570 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1382\n",
      "341 12 False\n",
      "x_t:  3 [0.671875   0.33333333 0.084375   0.41666667]\n",
      "Q values:  tensor([[2.5911, 1.1874, 3.5123, 3.9652, 3.1789, 1.9350]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 17866 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2154\n",
      "341 15 False\n",
      "x_t:  2 [0.859375   0.39166667 0.090625   0.25833333]\n",
      "Q values:  tensor([[-4.2352, -3.9401, -3.5490, -4.1720, -4.2396, -3.5859]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15558 320 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1771\n",
      "341 22 False\n",
      "x_t:  3 [0.384375   0.3        0.103125   0.30833333]\n",
      "Q values:  tensor([[2.7438, 1.1370, 2.7172, 3.1151, 2.6287, 2.0206]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 16919 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1942\n",
      "342 0 True\n",
      "x_t:  1 [0.246875   0.3375     0.078125   0.39166667]\n",
      "Q values:  tensor([[-4.9077, -4.5310, -4.2059, -4.6952, -4.2449, -3.6130]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18946 243 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 342: ep_len:243 episode reward: total was -6.600000. running mean: -102.772987\n",
      "startIDX:  939\n",
      "342 1 True\n",
      "x_t:  4 [0.321875   0.37916667 0.09375    0.3875    ]\n",
      "Q values:  tensor([[-4.1132, -3.7891, -4.2072, -4.2714, -4.2618, -3.4558]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35504 527 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 342: ep_len:527 episode reward: total was -63.200000. running mean: -102.377257\n",
      "startIDX:  765\n",
      "342 5 True\n",
      "x_t:  4 [0.228125   0.40416667 0.115625   0.38333333]\n",
      "Q values:  tensor([[-5.4830, -5.3142, -5.3283, -5.5087, -5.4231, -4.4447]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10040 634 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 342: ep_len:634 episode reward: total was -16.500000. running mean: -101.518485\n",
      "startIDX:  2559\n",
      "ep 342: ep_len:37 episode reward: total was -31.000000. running mean: -100.813300\n",
      "startIDX:  1720\n",
      "342 12 True\n",
      "x_t:  1 [0.25       0.34583333 0.06875    0.36666667]\n",
      "Q values:  tensor([[-3.2217, -3.2171, -3.6713, -3.1151, -3.4419, -2.9192]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19895 222 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 342: ep_len:222 episode reward: total was -24.600000. running mean: -100.051167\n",
      "startIDX:  2612\n",
      "342 15 False\n",
      "x_t:  2 [0.38125    0.40833333 0.115625   0.32916667]\n",
      "Q values:  tensor([[-3.9175, -3.1338, -3.1077, -3.6304, -3.7060, -3.1673]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21524 902 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 342: ep_len:902 episode reward: total was -60.600000. running mean: -99.656655\n",
      "startIDX:  7\n",
      "342 22 True\n",
      "x_t:  1 [0.075      0.36666667 0.084375   0.42083333]\n",
      "Q values:  tensor([[-4.6409, -3.8673, -4.6039, -4.7423, -4.7048, -3.5828]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1661 780 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 342: ep_len:780 episode reward: total was -42.100000. running mean: -99.081089\n",
      "startIDX:  1427\n",
      "343 0 True\n",
      "x_t:  3 [0.409375   0.3        0.075      0.32083333]\n",
      "Q values:  tensor([[-4.7346, -4.7138, -4.3984, -4.5168, -4.6364, -3.7907]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16877 819 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  386\n",
      "343 1 True\n",
      "x_t:  0 [0.48125    0.375      0.115625   0.45416667]\n",
      "Q values:  tensor([[-3.6716, -3.8939, -4.0035, -4.2062, -4.0774, -3.2358]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29178 816 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1227\n",
      "343 5 True\n",
      "x_t:  1 [0.509375   0.30833333 0.140625   0.38333333]\n",
      "Q values:  tensor([[-5.3626, -5.0227, -4.9224, -5.2472, -5.7525, -4.6799]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12560 1000 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2535\n",
      "startIDX:  1771\n",
      "343 12 True\n",
      "x_t:  0 [0.784375   0.40833333 0.075      0.35      ]\n",
      "Q values:  tensor([[-5.8648, -5.0894, -5.1805, -5.2479, -5.3397, -4.1939]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21110 612 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2501\n",
      "343 15 False\n",
      "x_t:  2 [0.003125   0.4125     0.125      0.32916667]\n",
      "Q values:  tensor([[-7.2739, -6.6645, -6.1657, -7.2711, -7.5098, -6.7153]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21475 1102 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1639\n",
      "343 22 True\n",
      "x_t:  3 [0.671875 0.3375   0.134375 0.375   ]\n",
      "Q values:  tensor([[-5.6082, -5.2238, -5.7214, -5.1703, -5.3719, -4.4456]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16870 244 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2126\n",
      "344 0 False\n",
      "x_t:  2 [0.7625     0.40416667 0.0625     0.2375    ]\n",
      "Q values:  tensor([[-11.9150, -11.9226,  -9.9456, -12.2062, -12.3359, -10.6480]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23598 1466 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 344: ep_len:1466 episode reward: total was -140.400000. running mean: -99.093364\n",
      "startIDX:  427\n",
      "344 1 True\n",
      "x_t:  1 [0.8625     0.25833333 0.0875     0.47083333]\n",
      "Q values:  tensor([[-10.0149,  -9.2063,  -9.1078,  -9.8827,  -9.3176,  -7.9486]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30684 794 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 344: ep_len:794 episode reward: total was -34.800000. running mean: -98.450430\n",
      "startIDX:  777\n",
      "344 5 True\n",
      "x_t:  4 [0.01875    0.42083333 0.140625   0.35833333]\n",
      "Q values:  tensor([[-8.4777, -8.4513, -8.1684, -8.0073, -8.9418, -6.8019]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10014 620 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 344: ep_len:620 episode reward: total was -13.700000. running mean: -97.602926\n",
      "startIDX:  1409\n",
      "344 10 True\n",
      "x_t:  4 [0.121875   0.37083333 0.0875     0.25416667]\n",
      "Q values:  tensor([[-9.3461, -8.0591, -7.8933, -9.6336, -8.7233, -6.6506]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15723 521 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 344: ep_len:521 episode reward: total was -29.700000. running mean: -96.923897\n",
      "startIDX:  403\n",
      "344 12 True\n",
      "x_t:  3 [0.796875   0.35833333 0.16875    0.4125    ]\n",
      "Q values:  tensor([[-6.0687, -5.4883, -5.9762, -5.8673, -6.0788, -4.7786]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7717 261 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 344: ep_len:261 episode reward: total was 16.700000. running mean: -95.787658\n",
      "startIDX:  823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344 15 True\n",
      "x_t:  3 [0.0625     0.23333333 0.034375   0.23333333]\n",
      "Q values:  tensor([[-11.0102,  -9.7086, -10.0086, -10.7628, -12.2097,  -9.5873]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8491 1263 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 344: ep_len:1263 episode reward: total was -99.100000. running mean: -95.820781\n",
      "startIDX:  1693\n",
      "344 22 True\n",
      "x_t:  3 [0.23125    0.2625     0.084375   0.29583333]\n",
      "Q values:  tensor([[-4.9312, -4.5179, -4.6171, -4.4695, -5.0406, -3.7668]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16952 260 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 344: ep_len:260 episode reward: total was -42.500000. running mean: -95.287573\n",
      "startIDX:  1493\n",
      "345 0 True\n",
      "x_t:  3 [0.809375   0.34166667 0.134375   0.4125    ]\n",
      "Q values:  tensor([[-4.5232, -4.4625, -4.5723, -4.5561, -4.5407, -3.6127]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16820 260 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  970\n",
      "345 1 True\n",
      "x_t:  4 [0.046875   0.38333333 0.1        0.425     ]\n",
      "Q values:  tensor([[-5.2517, -5.1826, -4.5503, -4.9502, -5.5061, -4.5898]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35430 474 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1285\n",
      "345 5 False\n",
      "x_t:  2 [0.190625   0.39583333 0.0875     0.27916667]\n",
      "Q values:  tensor([[-5.1354, -5.1870, -4.6507, -5.3997, -5.9252, -4.6996]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12030 703 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  454\n",
      "345 10 True\n",
      "x_t:  3 [0.25625    0.24583333 0.05625    0.28333333]\n",
      "Q values:  tensor([[-3.9578, -3.9845, -4.1045, -3.9066, -4.0524, -3.2566]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5134 211 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  778\n",
      "345 12 False\n",
      "x_t:  1 [0.06875    0.38333333 0.159375   0.4875    ]\n",
      "Q values:  tensor([[-5.8588, -4.9100, -5.7769, -5.3969, -6.8699, -5.0708]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12970 1487 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  568\n",
      "345 15 True\n",
      "x_t:  1 [0.91875    0.29583333 0.065625   0.28333333]\n",
      "Q values:  tensor([[-3.6452, -3.5020, -3.4858, -3.9810, -3.7841, -2.9285]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5164 704 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  580\n",
      "345 22 True\n",
      "x_t:  3 [0.44375    0.27916667 0.059375   0.29166667]\n",
      "Q values:  tensor([[-3.8862, -3.9123, -3.8530, -3.8092, -3.8843, -3.1827]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7141 243 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  655\n",
      "346 0 True\n",
      "x_t:  2 [0.00625    0.40833333 0.06875    0.27083333]\n",
      "Q values:  tensor([[-5.2907, -4.8110, -4.4976, -5.1763, -5.4008, -4.0473]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8870 892 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 346: ep_len:892 episode reward: total was -58.800000. running mean: -92.162443\n",
      "startIDX:  0\n",
      "346 1 True\n",
      "x_t:  3 [0.26875    0.2375     0.090625   0.31666667]\n",
      "Q values:  tensor([[-3.1902, -3.1077, -3.4780, -3.1416, -3.1674, -2.5669]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25731 231 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 346: ep_len:231 episode reward: total was -27.500000. running mean: -91.515819\n",
      "startIDX:  74\n",
      "346 5 True\n",
      "x_t:  1 [0.08125    0.35833333 0.196875   0.51666667]\n",
      "Q values:  tensor([[-5.6861, -5.4988, -5.2308, -5.2973, -5.3966, -4.1738]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2520 1112 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 346: ep_len:1112 episode reward: total was -87.800000. running mean: -91.478661\n",
      "startIDX:  874\n",
      "346 10 True\n",
      "x_t:  0 [0.659375 0.4      0.059375 0.2875  ]\n",
      "Q values:  tensor([[-3.2617, -2.9911, -3.2588, -3.2509, -3.1474, -2.7604]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8149 468 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 346: ep_len:468 episode reward: total was -45.800000. running mean: -91.021874\n",
      "startIDX:  301\n",
      "346 12 True\n",
      "x_t:  4 [0.003125 0.4125   0.084375 0.2875  ]\n",
      "Q values:  tensor([[-4.6608, -3.9906, -4.4207, -4.6780, -4.5151, -3.6872]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7308 803 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 346: ep_len:803 episode reward: total was -97.500000. running mean: -91.086655\n",
      "startIDX:  388\n",
      "346 15 True\n",
      "x_t:  0 [0.36875 0.425   0.06875 0.2625 ]\n",
      "Q values:  tensor([[-4.8904, -4.5853, -4.3530, -4.2613, -4.8582, -3.8112]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3740 485 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 346: ep_len:485 episode reward: total was -87.200000. running mean: -91.047789\n",
      "startIDX:  2419\n",
      "346 22 True\n",
      "x_t:  2 [0.603125 0.4125   0.096875 0.25    ]\n",
      "Q values:  tensor([[-4.2988, -4.2455, -4.3551, -4.7008, -4.6292, -3.4866]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23671 353 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 346: ep_len:353 episode reward: total was -73.300000. running mean: -90.870311\n",
      "startIDX:  1095\n",
      "347 0 True\n",
      "x_t:  3 [0.0875   0.25     0.071875 0.2625  ]\n",
      "Q values:  tensor([[-10.9630, -10.0653,  -9.6944,  -9.7370,  -9.6587,  -8.0678]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15165 2345 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1120\n",
      "startIDX:  830\n",
      "347 5 True\n",
      "x_t:  4 [0.2375     0.40416667 0.134375   0.38333333]\n",
      "Q values:  tensor([[-5.5081, -5.0981, -4.9029, -5.0694, -5.3292, -4.0530]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10043 628 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1167\n",
      "347 10 True\n",
      "x_t:  2 [0.234375   0.4        0.096875   0.24583333]\n",
      "Q values:  tensor([[-4.1142, -4.6824, -4.2312, -4.1673, -3.8911, -3.4741]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12151 356 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1798\n",
      "347 12 True\n",
      "x_t:  0 [0.60625    0.42083333 0.13125    0.32916667]\n",
      "Q values:  tensor([[-5.6519, -5.5422, -5.0640, -5.3840, -4.9465, -4.4259]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21129 600 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  761\n",
      "347 15 True\n",
      "x_t:  3 [0.225      0.24583333 0.065625   0.25833333]\n",
      "Q values:  tensor([[-8.5867, -8.5192, -8.1328, -8.2690, -8.3882, -7.4148]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8595 1666 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1232\n",
      "347 22 False\n",
      "x_t:  2 [0.6125     0.40833333 0.05       0.25833333]\n",
      "Q values:  tensor([[-4.9513, -4.8484, -4.2638, -5.4714, -4.9844, -4.3121]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12621 353 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  476\n",
      "348 0 True\n",
      "x_t:  3 [0.759375   0.375      0.109375   0.44583333]\n",
      "Q values:  tensor([[-5.3673, -4.9783, -4.9457, -5.4314, -5.8221, -4.5403]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7000 1028 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 348: ep_len:1028 episode reward: total was -58.100000. running mean: -92.803656\n",
      "startIDX:  855\n",
      "348 1 True\n",
      "x_t:  4 [0.321875   0.37916667 0.09375    0.37916667]\n",
      "Q values:  tensor([[-5.7325, -4.7555, -5.1071, -5.4469, -5.0950, -4.3077]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35506 577 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 348: ep_len:577 episode reward: total was -36.400000. running mean: -92.239620\n",
      "startIDX:  611\n",
      "348 5 True\n",
      "x_t:  2 [0.775      0.39583333 0.09375    0.2875    ]\n",
      "Q values:  tensor([[-5.1125, -5.6711, -5.9317, -5.1640, -5.5698, -4.7725]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6040 451 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 348: ep_len:451 episode reward: total was -46.600000. running mean: -91.783223\n",
      "startIDX:  892\n",
      "348 10 True\n",
      "x_t:  1 [0.534375   0.29583333 0.06875    0.35      ]\n",
      "Q values:  tensor([[-8.2116, -7.7029, -7.8764, -7.7153, -6.8151, -6.9668]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11375 1614 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 348: ep_len:1614 episode reward: total was -93.200000. running mean: -91.797391\n",
      "startIDX:  1123\n",
      "348 12 True\n",
      "x_t:  3 [0.18125    0.28333333 0.0875     0.31666667]\n",
      "Q values:  tensor([[-6.7680, -6.6679, -6.7486, -6.1165, -7.5452, -5.4323]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16402 1366 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 348: ep_len:1366 episode reward: total was -126.500000. running mean: -92.144417\n",
      "startIDX:  32\n",
      "348 15 True\n",
      "x_t:  3 [0.85       0.35416667 0.146875   0.42916667]\n",
      "Q values:  tensor([[-5.6847, -5.0570, -4.9705, -5.5670, -5.2739, -4.0871]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 517 237 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 348: ep_len:237 episode reward: total was 12.900000. running mean: -91.093973\n",
      "startIDX:  2680\n",
      "348 22 True\n",
      "x_t:  4 [0.41875    0.37916667 0.1        0.30833333]\n",
      "Q values:  tensor([[-6.1402, -5.7218, -5.0942, -5.3864, -5.0281, -4.5021]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27332 546 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 348: ep_len:546 episode reward: total was -34.600000. running mean: -90.529033\n",
      "startIDX:  793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349 0 True\n",
      "x_t:  0 [0.825      0.39583333 0.075      0.35833333]\n",
      "Q values:  tensor([[-5.1228, -5.1648, -4.1172, -5.4848, -4.9438, -4.2131]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10342 701 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  367\n",
      "349 1 True\n",
      "x_t:  0 [0.84375    0.37083333 0.128125   0.4       ]\n",
      "Q values:  tensor([[-5.0537, -5.3116, -5.1206, -5.2660, -5.4021, -4.2697]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29097 796 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1964\n",
      "349 5 True\n",
      "x_t:  3 [0.278125   0.27916667 0.08125    0.36666667]\n",
      "Q values:  tensor([[-6.4793, -5.6923, -5.5309, -5.5251, -5.6360, -4.8198]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18258 1284 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2000\n",
      "349 10 False\n",
      "x_t:  1 [0.1        0.3375     0.10625    0.38333333]\n",
      "Q values:  tensor([[-4.7709, -4.1388, -4.7411, -4.8151, -4.8978, -4.1458]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18820 302 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1416\n",
      "349 12 False\n",
      "x_t:  3 [0.446875   0.30833333 0.11875    0.3625    ]\n",
      "Q values:  tensor([[3.3120, 2.1827, 3.5247, 3.6559, 2.8645, 2.1926]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 17896 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1715\n",
      "349 15 True\n",
      "x_t:  1 [0.04375    0.3625     0.121875   0.40833333]\n",
      "Q values:  tensor([[-4.6965, -4.1886, -4.3599, -4.5234, -4.7484, -3.7171]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12452 218 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1047\n",
      "349 22 True\n",
      "x_t:  0 [0.759375   0.4125     0.10625    0.30833333]\n",
      "Q values:  tensor([[-5.5172, -5.4662, -5.0849, -5.4384, -4.9077, -4.2959]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10422 414 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  2978.0796225070953\n",
      "startIDX:  1735\n",
      "350 0 True\n",
      "x_t:  2 [0.0875     0.4        0.059375   0.25833333]\n",
      "Q values:  tensor([[-5.0749, -4.7767, -4.4705, -5.2074, -4.7435, -3.8195]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18402 776 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 350: ep_len:776 episode reward: total was -22.000000. running mean: -86.248873\n",
      "startIDX:  546\n",
      "350 1 True\n",
      "x_t:  1 [0.753125 0.275    0.165625 0.45    ]\n",
      "Q values:  tensor([[-4.9313, -4.9505, -5.0082, -4.5486, -4.7530, -3.8782]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30690 723 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 350: ep_len:723 episode reward: total was -48.300000. running mean: -85.869384\n",
      "startIDX:  2257\n",
      "350 5 True\n",
      "x_t:  3 [0.56875 0.3125  0.13125 0.4    ]\n",
      "Q values:  tensor([[-4.9888, -4.4786, -5.0143, -4.9873, -4.8248, -3.7493]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19914 205 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 350: ep_len:205 episode reward: total was 39.100000. running mean: -84.619691\n",
      "startIDX:  2174\n",
      "350 10 True\n",
      "x_t:  0 [0.7375     0.39166667 0.065625   0.32916667]\n",
      "Q values:  tensor([[-4.2784, -4.4221, -4.6995, -4.6230, -4.1224, -3.4878]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19972 542 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 350: ep_len:542 episode reward: total was -87.000000. running mean: -84.643494\n",
      "startIDX:  1882\n",
      "ep 350: ep_len:1009 episode reward: total was -123.300000. running mean: -85.030059\n",
      "startIDX:  1859\n",
      "350 15 True\n",
      "x_t:  1 [0.7875     0.30416667 0.053125   0.29166667]\n",
      "Q values:  tensor([[-4.9554, -4.7428, -5.1562, -4.8273, -4.6517, -3.7495]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14857 739 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 350: ep_len:739 episode reward: total was 0.300000. running mean: -84.176758\n",
      "startIDX:  2118\n",
      "350 22 True\n",
      "x_t:  0 [0.89375  0.4      0.059375 0.3375  ]\n",
      "Q values:  tensor([[-4.6989, -4.1832, -4.7152, -4.7998, -4.6647, -3.7115]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20695 844 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 350: ep_len:844 episode reward: total was -95.100000. running mean: -84.285991\n",
      "startIDX:  2232\n",
      "351 0 True\n",
      "x_t:  2 [0.625    0.4125   0.096875 0.25    ]\n",
      "Q values:  tensor([[-4.2764, -4.2991, -4.6150, -4.8985, -4.7408, -4.0782]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23620 348 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  774\n",
      "351 1 True\n",
      "x_t:  3 [0.078125   0.23333333 0.08125    0.29166667]\n",
      "Q values:  tensor([[-6.1215, -5.4291, -5.7883, -6.0278, -6.1334, -5.1396]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34308 1380 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1613\n",
      "351 5 True\n",
      "x_t:  1 [0.3875     0.3125     0.109375   0.29583333]\n",
      "Q values:  tensor([[-4.3595, -4.0245, -4.4821, -4.4835, -4.0890, -3.6049]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14993 722 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  52\n",
      "351 10 True\n",
      "x_t:  3 [0.1625     0.25416667 0.0875     0.28333333]\n",
      "Q values:  tensor([[-4.4705, -4.1649, -4.3232, -4.5952, -3.8863, -3.4349]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3611 1099 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1980\n",
      "startIDX:  1809\n",
      "351 15 True\n",
      "x_t:  0 [0.35       0.425      0.05625    0.25416667]\n",
      "Q values:  tensor([[-4.6254, -3.9864, -4.3750, -5.0774, -4.1654, -3.7510]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13452 476 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1284\n",
      "351 22 True\n",
      "x_t:  2 [0.59375    0.40833333 0.053125   0.25416667]\n",
      "Q values:  tensor([[-4.6121, -4.4819, -4.4600, -4.8308, -4.8564, -3.8410]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12624 323 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1523\n",
      "352 0 True\n",
      "x_t:  3 [0.275      0.26666667 0.075      0.3125    ]\n",
      "Q values:  tensor([[-4.3507, -3.8176, -3.7394, -4.2013, -3.6676, -3.3769]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16904 286 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 352: ep_len:286 episode reward: total was -87.600000. running mean: -82.806751\n",
      "startIDX:  173\n",
      "352 1 True\n",
      "x_t:  2 [0.003125   0.375      0.096875   0.42916667]\n",
      "Q values:  tensor([[-4.4927, -3.9577, -4.6288, -4.5306, -3.9636, -3.3858]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27430 870 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 352: ep_len:870 episode reward: total was -24.900000. running mean: -82.227683\n",
      "startIDX:  1854\n",
      "352 5 True\n",
      "x_t:  2 [0.446875   0.39166667 0.05       0.25      ]\n",
      "Q values:  tensor([[-4.3399, -4.0374, -3.9724, -4.1615, -3.5525, -3.3589]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15708 381 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 352: ep_len:381 episode reward: total was -86.700000. running mean: -82.272407\n",
      "startIDX:  2164\n",
      "352 10 True\n",
      "x_t:  0 [0.80625    0.3875     0.09375    0.35416667]\n",
      "Q values:  tensor([[-5.8172, -4.9995, -5.6003, -5.7953, -5.7529, -4.6778]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19952 552 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 352: ep_len:552 episode reward: total was -71.000000. running mean: -82.159682\n",
      "startIDX:  123\n",
      "352 12 False\n",
      "x_t:  1 [0.740625   0.3125     0.109375   0.43333333]\n",
      "Q values:  tensor([[-5.4550, -4.6967, -5.3452, -5.1567, -5.5049, -4.7365]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2228 599 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 352: ep_len:599 episode reward: total was -41.900000. running mean: -81.757086\n",
      "startIDX:  3128\n",
      "ep 352: ep_len:19 episode reward: total was 13.000000. running mean: -80.809515\n",
      "startIDX:  1069\n",
      "352 22 True\n",
      "x_t:  1 [0.315625   0.35       0.19375    0.50833333]\n",
      "Q values:  tensor([[-6.2874, -6.0231, -5.4817, -5.3225, -5.8355, -4.7834]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11959 745 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 352: ep_len:745 episode reward: total was -23.400000. running mean: -80.235420\n",
      "startIDX:  1777\n",
      "353 0 True\n",
      "x_t:  2 [0.00625    0.40833333 0.0875     0.24583333]\n",
      "Q values:  tensor([[-5.9378, -5.7551, -6.0576, -5.9403, -6.1073, -4.7930]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18391 738 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  175\n",
      "353 1 True\n",
      "x_t:  2 [0.1125     0.36666667 0.128125   0.44583333]\n",
      "Q values:  tensor([[-4.5100, -4.3444, -4.9091, -4.2649, -5.2283, -4.1791]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27448 868 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1435\n",
      "353 5 True\n",
      "x_t:  1 [0.584375   0.3        0.084375   0.36666667]\n",
      "Q values:  tensor([[-4.0056, -4.1453, -4.5062, -4.4809, -4.2262, -3.7218]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12566 226 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2207\n",
      "353 10 True\n",
      "x_t:  0 [0.840625   0.39166667 0.078125   0.35416667]\n",
      "Q values:  tensor([[-4.3918, -4.3196, -4.5190, -4.6718, -5.2708, -4.1279]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19945 516 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1443\n",
      "353 12 False\n",
      "x_t:  3 [0.3375     0.29166667 0.1        0.31666667]\n",
      "Q values:  tensor([[2.3342, 1.1693, 3.0198, 4.1940, 2.2410, 1.4801]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 17920 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353 15 True\n",
      "x_t:  3 [0.853125   0.34583333 0.1375     0.39583333]\n",
      "Q values:  tensor([[-4.4527, -4.9495, -4.8833, -4.7862, -4.8343, -3.8497]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10339 251 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  962\n",
      "353 22 True\n",
      "x_t:  0 [0.56875    0.40416667 0.075      0.32916667]\n",
      "Q values:  tensor([[-5.0136, -4.7744, -4.8663, -5.2595, -5.0918, -4.3573]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10466 496 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1520\n",
      "354 0 True\n",
      "x_t:  3 [0.715625   0.33333333 0.14375    0.4125    ]\n",
      "Q values:  tensor([[-4.6878, -4.2359, -4.5303, -4.8501, -4.1514, -3.4434]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16827 250 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 354: ep_len:250 episode reward: total was -34.300000. running mean: -77.150597\n",
      "startIDX:  549\n",
      "354 1 True\n",
      "x_t:  2 [0.3625     0.375      0.0625     0.31666667]\n",
      "Q values:  tensor([[-4.9417, -4.5902, -4.8783, -4.7602, -4.9406, -4.1142]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31536 1153 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 354: ep_len:1153 episode reward: total was -140.200000. running mean: -77.781091\n",
      "startIDX:  1721\n",
      "354 5 True\n",
      "x_t:  1 [0.675    0.2875   0.071875 0.3     ]\n",
      "Q values:  tensor([[-4.3114, -4.2197, -4.7364, -4.0382, -4.7180, -3.5607]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14952 616 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 354: ep_len:616 episode reward: total was -42.500000. running mean: -77.428280\n",
      "startIDX:  702\n",
      "354 10 False\n",
      "x_t:  1 [0.584375   0.3        0.09375    0.33333333]\n",
      "Q values:  tensor([[-4.4630, -3.9450, -4.7890, -4.3100, -4.2880, -4.0405]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7172 273 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 354: ep_len:273 episode reward: total was -7.400000. running mean: -76.727997\n",
      "startIDX:  1217\n",
      "354 12 True\n",
      "x_t:  4 [0.265625   0.4125     0.09375    0.35416667]\n",
      "Q values:  tensor([[-4.2444, -4.0986, -4.4333, -4.0324, -4.0850, -3.4122]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17418 508 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 354: ep_len:508 episode reward: total was -21.800000. running mean: -76.178717\n",
      "startIDX:  602\n",
      "354 15 True\n",
      "x_t:  1 [0.75625    0.3        0.06875    0.27083333]\n",
      "Q values:  tensor([[-5.5581, -5.4001, -5.1038, -5.5193, -5.3451, -4.4363]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5187 682 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 354: ep_len:682 episode reward: total was -32.100000. running mean: -75.737930\n",
      "startIDX:  2825\n",
      "ep 354: ep_len:95 episode reward: total was 53.000000. running mean: -74.450551\n",
      "startIDX:  2505\n",
      "startIDX:  225\n",
      "355 1 False\n",
      "x_t:  2 [0.2375  0.3625  0.13125 0.4375 ]\n",
      "Q values:  tensor([[-5.6340, -4.8179, -4.4320, -5.2506, -5.5074, -4.5569]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27469 844 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  435\n",
      "355 5 True\n",
      "x_t:  1 [0.75       0.28333333 0.0875     0.36666667]\n",
      "Q values:  tensor([[-6.0183, -5.1871, -5.3166, -5.8040, -5.5085, -4.5697]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5044 682 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1169\n",
      "355 10 True\n",
      "x_t:  2 [0.3125     0.40416667 0.1        0.24583333]\n",
      "Q values:  tensor([[-4.9768, -5.1711, -5.5964, -4.8517, -4.9384, -3.9875]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12139 361 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  169\n",
      "355 12 True\n",
      "x_t:  3 [0.125      0.26666667 0.084375   0.275     ]\n",
      "Q values:  tensor([[-6.7261, -6.2807, -6.4434, -7.2381, -7.0700, -5.4068]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5679 1449 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2103\n",
      "355 15 True\n",
      "x_t:  2 [0.3        0.41666667 0.09375    0.25416667]\n",
      "Q values:  tensor([[-4.7837, -4.5934, -4.7885, -4.9174, -4.7261, -4.1932]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15641 396 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1387\n",
      "355 22 True\n",
      "x_t:  3 [0.15625    0.2625     0.084375   0.29583333]\n",
      "Q values:  tensor([[-7.0719, -7.2685, -6.7039, -7.1793, -7.2745, -6.1113]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15222 1282 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  744\n",
      "356 0 True\n",
      "x_t:  1 [0.371875   0.33333333 0.190625   0.47083333]\n",
      "Q values:  tensor([[-6.6604, -7.2590, -6.7900, -6.5952, -6.7850, -6.0223]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11993 1562 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 356: ep_len:1562 episode reward: total was -211.500000. running mean: -75.420893\n",
      "startIDX:  62\n",
      "356 1 True\n",
      "x_t:  3 [0.0625     0.22083333 0.059375   0.2625    ]\n",
      "Q values:  tensor([[-5.4136, -4.6388, -4.9463, -5.0167, -4.9985, -3.9875]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25798 230 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 356: ep_len:230 episode reward: total was -80.900000. running mean: -75.475684\n",
      "startIDX:  2071\n",
      "356 5 True\n",
      "x_t:  3 [0.709375   0.37083333 0.20625    0.45833333]\n",
      "Q values:  tensor([[-6.9477, -6.1318, -5.9969, -7.3543, -6.5080, -5.5182]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18327 1277 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 356: ep_len:1277 episode reward: total was -153.000000. running mean: -76.250927\n",
      "startIDX:  910\n",
      "356 10 True\n",
      "x_t:  1 [0.646875   0.29166667 0.0875     0.34166667]\n",
      "Q values:  tensor([[-7.3140, -7.3536, -7.0823, -7.1930, -6.9066, -5.9190]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11360 1608 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 356: ep_len:1608 episode reward: total was -59.600000. running mean: -76.084418\n",
      "startIDX:  52\n",
      "356 12 True\n",
      "x_t:  3 [0.478125   0.30416667 0.121875   0.34166667]\n",
      "Q values:  tensor([[-11.0717,  -9.6067, -11.0678, -10.6441, -11.9044,  -9.2917]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5741 2374 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 356: ep_len:2374 episode reward: total was -228.500000. running mean: -77.608574\n",
      "startIDX:  3061\n",
      "ep 356: ep_len:53 episode reward: total was 27.000000. running mean: -76.562488\n",
      "startIDX:  1914\n",
      "356 22 True\n",
      "x_t:  2 [0.009375   0.40833333 0.08125    0.27083333]\n",
      "Q values:  tensor([[-7.0794, -6.5531, -6.4431, -6.8438, -7.0202, -5.5376]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18455 736 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 356: ep_len:736 episode reward: total was -41.400000. running mean: -76.210863\n",
      "startIDX:  1198\n",
      "357 0 True\n",
      "x_t:  4 [0.003125 0.4      0.09375  0.275   ]\n",
      "Q values:  tensor([[-8.0887, -8.1690, -8.7753, -8.3196, -8.3942, -6.8322]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16284 1805 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1019\n",
      "357 1 True\n",
      "x_t:  3 [0.45     0.2625   0.059375 0.3125  ]\n",
      "Q values:  tensor([[-3.6428, -2.8965, -3.5074, -3.5424, -3.3785, -2.7423]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35976 256 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  739\n",
      "357 5 True\n",
      "x_t:  3 [0.203125   0.26666667 0.096875   0.35833333]\n",
      "Q values:  tensor([[-5.3784, -5.2910, -4.5983, -4.9630, -5.3317, -4.1158]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8785 1324 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  825\n",
      "357 10 True\n",
      "x_t:  0 [0.7125     0.39166667 0.1125     0.32916667]\n",
      "Q values:  tensor([[-4.2520, -3.9397, -4.1015, -4.2650, -4.5089, -3.3217]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8250 554 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1378\n",
      "357 12 True\n",
      "x_t:  3 [0.803125   0.35416667 0.0875     0.44583333]\n",
      "Q values:  tensor([[-3.7032, -3.5027, -3.9304, -3.4117, -3.8148, -2.9063]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17852 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2298\n",
      "357 15 True\n",
      "x_t:  3 [0.165625   0.28333333 0.084375   0.30416667]\n",
      "Q values:  tensor([[-3.6633, -3.7559, -3.9953, -4.0979, -3.9476, -3.3336]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18194 1278 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2809\n",
      "startIDX:  11\n",
      "358 0 True\n",
      "x_t:  1 [0.71875    0.30833333 0.178125   0.41666667]\n",
      "Q values:  tensor([[-3.8631, -3.8150, -4.0383, -3.9430, -4.2439, -3.2359]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1623 759 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 358: ep_len:759 episode reward: total was -10.600000. running mean: -75.743933\n",
      "startIDX:  369\n",
      "358 1 True\n",
      "x_t:  0 [0.546875   0.375      0.13125    0.53333333]\n",
      "Q values:  tensor([[-4.7453, -4.3650, -4.5925, -4.2907, -4.7178, -3.6893]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29198 840 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 358: ep_len:840 episode reward: total was -130.700000. running mean: -76.293493\n",
      "startIDX:  1344\n",
      "358 5 True\n",
      "x_t:  0 [0.871875   0.39166667 0.096875   0.33333333]\n",
      "Q values:  tensor([[-4.0290, -3.7724, -3.8304, -4.1271, -3.9647, -3.1002]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13503 733 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 358: ep_len:733 episode reward: total was -54.200000. running mean: -76.072559\n",
      "startIDX:  226\n",
      "358 10 True\n",
      "x_t:  4 [0.065625   0.35833333 0.09375    0.25      ]\n",
      "Q values:  tensor([[-3.7233, -4.3085, -4.3638, -4.3742, -4.6649, -3.6047]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4556 441 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 358: ep_len:441 episode reward: total was -29.300000. running mean: -75.604833\n",
      "startIDX:  796\n",
      "358 12 True\n",
      "x_t:  0 [0.590625   0.40833333 0.084375   0.34583333]\n",
      "Q values:  tensor([[-4.3826, -4.8334, -4.5036, -5.0512, -5.3985, -4.1416]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11693 696 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 358: ep_len:696 episode reward: total was -95.800000. running mean: -75.806785\n",
      "startIDX:  2999\n",
      "ep 358: ep_len:82 episode reward: total was 46.000000. running mean: -74.588717\n",
      "startIDX:  105\n",
      "358 22 False\n",
      "x_t:  1 [0.875      0.29583333 0.121875   0.41666667]\n",
      "Q values:  tensor([[-5.0329, -4.4440, -4.8969, -5.2511, -5.0657, -4.5470]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1577 654 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 358: ep_len:654 episode reward: total was -60.100000. running mean: -74.443830\n",
      "startIDX:  48\n",
      "359 0 True\n",
      "x_t:  1 [0.315625   0.34166667 0.184375   0.43333333]\n",
      "Q values:  tensor([[-5.2942, -5.2505, -5.4392, -5.5955, -5.2937, -4.5283]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1664 768 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  198\n",
      "359 1 True\n",
      "x_t:  2 [0.259375 0.375    0.1125   0.425   ]\n",
      "Q values:  tensor([[-6.2280, -5.8914, -5.7179, -6.3804, -7.0597, -5.3253]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27471 874 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2638\n",
      "359 5 True\n",
      "x_t:  1 [0.575      0.3        0.15625    0.52916667]\n",
      "Q values:  tensor([[-5.7018, -5.2809, -5.8163, -5.8500, -5.4180, -4.8745]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22155 288 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2054\n",
      "359 10 True\n",
      "x_t:  1 [0.184375   0.325      0.075      0.36666667]\n",
      "Q values:  tensor([[-5.2406, -4.8455, -4.9257, -4.9379, -5.5058, -4.2149]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18833 288 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  698\n",
      "359 12 True\n",
      "x_t:  0 [0.76875    0.4        0.11875    0.39583333]\n",
      "Q values:  tensor([[-7.9349, -7.1102, -6.9899, -8.0080, -8.5727, -6.9773]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11733 936 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2486\n",
      "359 15 True\n",
      "x_t:  3 [0.31875    0.27083333 0.08125    0.28333333]\n",
      "Q values:  tensor([[-5.5718, -5.1098, -5.7980, -4.8486, -5.2002, -4.6066]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19758 249 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2839\n",
      "Time elapsed:  3068.8477971553802\n",
      "startIDX:  2220\n",
      "360 0 True\n",
      "x_t:  1 [0.546875   0.3375     0.19375    0.49166667]\n",
      "Q values:  tensor([[-8.7202, -8.5786, -8.7163, -8.5943, -8.5315, -7.1659]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22940 1096 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 360: ep_len:1096 episode reward: total was -106.400000. running mean: -72.145615\n",
      "startIDX:  625\n",
      "360 1 True\n",
      "x_t:  2 [0.7375     0.38333333 0.103125   0.31666667]\n",
      "Q values:  tensor([[-6.2798, -6.0607, -6.4433, -6.2682, -6.6618, -5.1719]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31473 387 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 360: ep_len:387 episode reward: total was -56.700000. running mean: -71.991159\n",
      "startIDX:  47\n",
      "360 5 True\n",
      "x_t:  1 [0.15625    0.3375     0.13125    0.52916667]\n",
      "Q values:  tensor([[-7.8111, -6.6815, -8.0087, -8.0730, -8.5132, -6.7596]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2524 1140 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 360: ep_len:1140 episode reward: total was -116.500000. running mean: -72.436247\n",
      "startIDX:  1467\n",
      "360 10 True\n",
      "x_t:  4 [0.00625    0.36666667 0.1125     0.275     ]\n",
      "Q values:  tensor([[-8.1557, -7.8583, -8.2844, -8.3161, -8.2742, -6.7912]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15705 497 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 360: ep_len:497 episode reward: total was -46.600000. running mean: -72.177885\n",
      "startIDX:  373\n",
      "360 12 True\n",
      "x_t:  4 [0.43125    0.39583333 0.09375    0.34166667]\n",
      "Q values:  tensor([[-7.3243, -6.4800, -6.9019, -6.5462, -7.5314, -6.6726]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7233 717 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 360: ep_len:717 episode reward: total was -61.300000. running mean: -72.069106\n",
      "startIDX:  2983\n",
      "ep 360: ep_len:90 episode reward: total was 60.000000. running mean: -70.748415\n",
      "startIDX:  203\n",
      "360 22 True\n",
      "x_t:  3 [0.278125 0.2625   0.075    0.2875  ]\n",
      "Q values:  tensor([[-10.3723,  -9.4455, -10.5383, -11.2048,  -9.8837,  -8.8188]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4932 1660 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 360: ep_len:1660 episode reward: total was -240.500000. running mean: -72.445931\n",
      "startIDX:  639\n",
      "361 0 True\n",
      "x_t:  2 [0.190625 0.4      0.053125 0.275   ]\n",
      "Q values:  tensor([[-8.0582, -7.3650, -8.6739, -7.7441, -7.7334, -6.5781]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8895 911 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  88\n",
      "361 1 True\n",
      "x_t:  2 [0.525      0.36666667 0.146875   0.4375    ]\n",
      "Q values:  tensor([[-7.1492, -7.6826, -8.0768, -7.7354, -7.9301, -6.5530]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27507 1096 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2682\n",
      "361 5 True\n",
      "x_t:  1 [0.64375    0.27916667 0.103125   0.54166667]\n",
      "Q values:  tensor([[-5.5278, -5.2039, -5.7012, -5.4650, -5.9985, -4.5741]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22161 262 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1750\n",
      "361 10 True\n",
      "x_t:  3 [0.225      0.25416667 0.09375    0.28333333]\n",
      "Q values:  tensor([[-5.7436, -6.1107, -6.1647, -5.8756, -5.6210, -4.8284]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16512 265 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  896\n",
      "361 12 False\n",
      "x_t:  1 [0.353125   0.40833333 0.196875   0.46666667]\n",
      "Q values:  tensor([[-6.1163, -5.2952, -6.1514, -6.3045, -5.8501, -5.3318]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12938 630 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2866\n",
      "361 15 True\n",
      "x_t:  0 [0.909375   0.40416667 0.0625     0.35      ]\n",
      "Q values:  tensor([[-6.3298, -5.8126, -6.0543, -6.1425, -6.7941, -4.9988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23070 740 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2947\n",
      "startIDX:  1286\n",
      "362 0 True\n",
      "x_t:  3 [0.4125     0.30416667 0.125      0.34166667]\n",
      "Q values:  tensor([[-6.6682, -6.6124, -7.2379, -7.6072, -7.6065, -6.3426]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15249 1244 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 362: ep_len:1244 episode reward: total was -143.800000. running mean: -73.189254\n",
      "startIDX:  782\n",
      "362 1 True\n",
      "x_t:  3 [0.084375   0.23333333 0.0875     0.29583333]\n",
      "Q values:  tensor([[-8.6428, -8.3560, -9.3745, -8.7265, -8.3648, -7.1949]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34310 1381 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 362: ep_len:1381 episode reward: total was -113.400000. running mean: -73.591361\n",
      "startIDX:  209\n",
      "362 5 True\n",
      "x_t:  0 [0.7        0.4        0.140625   0.37916667]\n",
      "Q values:  tensor([[-6.6766, -6.4242, -6.4897, -6.4583, -6.6801, -5.7502]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3581 763 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 362: ep_len:763 episode reward: total was -99.100000. running mean: -73.846448\n",
      "startIDX:  1293\n",
      "362 10 True\n",
      "x_t:  4 [0.403125   0.34166667 0.071875   0.24166667]\n",
      "Q values:  tensor([[-8.0157, -7.9353, -8.2566, -8.5607, -8.5524, -7.7986]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15890 1853 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 362: ep_len:1853 episode reward: total was -352.900000. running mean: -76.636983\n",
      "startIDX:  1885\n",
      "362 12 True\n",
      "x_t:  0 [0.584375   0.41666667 0.08125    0.3125    ]\n",
      "Q values:  tensor([[-6.3758, -6.5350, -6.8449, -7.1065, -6.7867, -6.0891]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23051 943 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 362: ep_len:943 episode reward: total was -62.100000. running mean: -76.491613\n",
      "startIDX:  1230\n",
      "362 15 True\n",
      "x_t:  3 [0.753125   0.3375     0.140625   0.37916667]\n",
      "Q values:  tensor([[-5.6589, -5.8753, -5.7396, -5.7103, -6.0365, -4.9473]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10350 266 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 362: ep_len:266 episode reward: total was 30.800000. running mean: -75.418697\n",
      "startIDX:  616\n",
      "362 22 True\n",
      "x_t:  2 [0.059375 0.4125   0.109375 0.2625  ]\n",
      "Q values:  tensor([[-7.3129, -7.4036, -7.0440, -7.0570, -6.9590, -6.2841]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8927 934 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 362: ep_len:934 episode reward: total was -20.100000. running mean: -74.865510\n",
      "startIDX:  1201\n",
      "363 0 True\n",
      "x_t:  3 [0.103125   0.25416667 0.0625     0.2625    ]\n",
      "Q values:  tensor([[ -9.1914,  -9.7905, -10.1003,  -9.8615, -10.2457,  -8.6789]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15170 1269 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  425\n",
      "363 1 True\n",
      "x_t:  0 [0.73125    0.37083333 0.090625   0.40833333]\n",
      "Q values:  tensor([[-7.6600, -6.5495, -6.6417, -6.8874, -6.4774, -5.5384]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29119 492 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2002\n",
      "363 5 True\n",
      "x_t:  4 [0.01875    0.42916667 0.1125     0.4       ]\n",
      "Q values:  tensor([[-11.0341, -11.2896, -11.0259, -10.8023, -10.6465,  -8.8195]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19467 1856 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  724\n",
      "363 10 False\n",
      "x_t:  1 [0.003125   0.3625     0.13125    0.37916667]\n",
      "Q values:  tensor([[-6.2019, -5.5140, -6.3735, -6.2483, -6.0797, -5.6778]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7106 235 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  613\n",
      "363 12 True\n",
      "x_t:  2 [0.45       0.40833333 0.075      0.25      ]\n",
      "Q values:  tensor([[-7.7404, -8.1303, -7.5915, -7.1149, -7.3191, -6.6776]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9895 1026 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  650\n",
      "363 15 False\n",
      "x_t:  1 [0.878125   0.29583333 0.096875   0.27916667]\n",
      "Q values:  tensor([[-6.4420, -5.3181, -6.0434, -6.5150, -6.2160, -5.4474]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5167 660 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2742\n",
      "363 22 True\n",
      "x_t:  4 [0.25625    0.38333333 0.103125   0.3125    ]\n",
      "Q values:  tensor([[-5.6570, -5.2787, -5.5564, -5.2551, -5.2409, -4.6447]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27301 506 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2285\n",
      "364 0 True\n",
      "x_t:  2 [0.303125   0.40833333 0.084375   0.25416667]\n",
      "Q values:  tensor([[-5.4935, -5.3139, -5.5431, -4.8565, -5.2474, -4.5261]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23668 339 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 364: ep_len:339 episode reward: total was -73.000000. running mean: -75.447925\n",
      "startIDX:  470\n",
      "364 1 True\n",
      "x_t:  2 [0.796875   0.37916667 0.075      0.30416667]\n",
      "Q values:  tensor([[-6.1391, -6.4839, -6.0142, -6.1578, -6.0810, -5.0278]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31467 1158 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 364: ep_len:1158 episode reward: total was -99.600000. running mean: -75.689445\n",
      "startIDX:  61\n",
      "364 5 True\n",
      "x_t:  1 [0.175      0.3375     0.128125   0.52916667]\n",
      "Q values:  tensor([[-6.6154, -6.1550, -6.2136, -6.3121, -5.8948, -5.5693]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2525 1123 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 364: ep_len:1123 episode reward: total was -82.800000. running mean: -75.760551\n",
      "startIDX:  700\n",
      "364 10 True\n",
      "x_t:  1 [0.1      0.35     0.128125 0.375   ]\n",
      "Q values:  tensor([[-4.2063, -4.1387, -4.3892, -4.3028, -4.3470, -3.6926]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7115 244 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 364: ep_len:244 episode reward: total was 23.500000. running mean: -74.767946\n",
      "startIDX:  568\n",
      "364 12 True\n",
      "x_t:  2 [0.128125   0.4125     0.05625    0.25833333]\n",
      "Q values:  tensor([[-4.1507, -4.3578, -4.9611, -3.6735, -4.1125, -3.8290]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9846 1039 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 364: ep_len:1039 episode reward: total was -65.300000. running mean: -74.673266\n",
      "startIDX:  2237\n",
      "364 15 False\n",
      "x_t:  3 [0.284375   0.30416667 0.078125   0.32916667]\n",
      "Q values:  tensor([[-6.5752, -6.8324, -6.5957, -6.1450, -7.0309, -6.2379]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18217 1282 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 364: ep_len:1282 episode reward: total was -67.300000. running mean: -74.599533\n",
      "startIDX:  2404\n",
      "364 22 True\n",
      "x_t:  3 [0.0625     0.2375     0.053125   0.24166667]\n",
      "Q values:  tensor([[-6.0054, -5.4580, -6.2129, -5.4050, -5.7848, -5.1271]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26171 1619 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 364: ep_len:1619 episode reward: total was -251.400000. running mean: -76.367538\n",
      "startIDX:  1944\n",
      "365 0 True\n",
      "x_t:  1 [0.471875   0.3125     0.1        0.37916667]\n",
      "Q values:  tensor([[-4.4450, -4.0758, -4.1020, -4.8779, -4.5456, -3.6484]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18971 246 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  242\n",
      "365 1 True\n",
      "x_t:  2 [0.003125   0.37916667 0.171875   0.43333333]\n",
      "Q values:  tensor([[-5.6582, -5.6251, -5.5691, -6.0316, -5.4345, -4.9572]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27438 832 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1415\n",
      "365 5 False\n",
      "x_t:  1 [0.753125   0.28333333 0.05       0.39166667]\n",
      "Q values:  tensor([[-4.6523, -3.9228, -4.8976, -4.5271, -4.8045, -3.9265]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12580 243 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2614\n",
      "startIDX:  423\n",
      "365 12 True\n",
      "x_t:  3 [0.6875   0.3375   0.109375 0.3875  ]\n",
      "Q values:  tensor([[-5.0226, -5.0036, -5.1418, -4.9505, -4.8433, -4.1909]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7732 256 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2561\n",
      "365 15 False\n",
      "x_t:  3 [0.28125    0.25416667 0.08125    0.275     ]\n",
      "Q values:  tensor([[2.1388, 0.5226, 2.2797, 2.8579, 1.8570, 1.7722]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 19768 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1730\n",
      "365 22 False\n",
      "x_t:  3 [0.60625    0.32083333 0.128125   0.36666667]\n",
      "Q values:  tensor([[1.8977, 1.5735, 1.8633, 3.0585, 2.0203, 1.8290]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 16882 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  870\n",
      "366 0 True\n",
      "x_t:  0 [0.8625     0.40833333 0.1        0.34583333]\n",
      "Q values:  tensor([[-4.5757, -4.6812, -4.1455, -4.7628, -4.1336, -3.8502]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10337 462 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 366: ep_len:462 episode reward: total was -64.600000. running mean: -72.742872\n",
      "startIDX:  565\n",
      "366 1 True\n",
      "x_t:  1 [0.325  0.3125 0.2125 0.4875]\n",
      "Q values:  tensor([[-5.5507, -5.1723, -5.8727, -5.5367, -5.7343, -4.5255]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30734 747 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 366: ep_len:747 episode reward: total was -93.300000. running mean: -72.948444\n",
      "startIDX:  393\n",
      "366 5 False\n",
      "x_t:  1 [0.05       0.35       0.08125    0.33333333]\n",
      "Q values:  tensor([[-4.5456, -4.2386, -4.9995, -5.2836, -5.3669, -4.3510]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5138 745 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 366: ep_len:745 episode reward: total was -49.500000. running mean: -72.713959\n",
      "startIDX:  1397\n",
      "366 10 True\n",
      "x_t:  4 [0.0625  0.3625  0.06875 0.275  ]\n",
      "Q values:  tensor([[-4.7675, -5.1262, -4.7900, -5.0335, -5.0277, -4.2411]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15712 540 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 366: ep_len:540 episode reward: total was -49.500000. running mean: -72.481820\n",
      "startIDX:  1990\n",
      "ep 366: ep_len:53 episode reward: total was -18.200000. running mean: -71.939001\n",
      "startIDX:  80\n",
      "366 15 True\n",
      "x_t:  3 [0.78125    0.35       0.11875    0.42083333]\n",
      "Q values:  tensor([[-3.7721, -3.8474, -3.7447, -4.1471, -3.9941, -3.4914]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 529 211 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 366: ep_len:211 episode reward: total was -23.600000. running mean: -71.455611\n",
      "startIDX:  82\n",
      "366 22 False\n",
      "x_t:  1 [0.6375     0.31666667 0.134375   0.39583333]\n",
      "Q values:  tensor([[-5.6738, -4.7236, -5.7339, -5.1681, -5.0925, -5.0563]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1602 694 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 366: ep_len:694 episode reward: total was -30.400000. running mean: -71.045055\n",
      "startIDX:  2177\n",
      "367 0 True\n",
      "x_t:  1 [0.575      0.32916667 0.16875    0.5125    ]\n",
      "Q values:  tensor([[-8.2295, -7.4107, -7.3647, -7.8792, -7.8583, -6.4989]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22939 1110 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  456\n",
      "367 1 True\n",
      "x_t:  1 [0.734375   0.27916667 0.171875   0.45      ]\n",
      "Q values:  tensor([[-5.3679, -5.4749, -5.6216, -6.1127, -6.3540, -5.2161]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30694 759 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1063\n",
      "367 5 False\n",
      "x_t:  3 [0.1875     0.2375     0.103125   0.29166667]\n",
      "Q values:  tensor([[2.8649, 1.8814, 2.3713, 3.5481, 1.9534, 2.0004]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 10584 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367 10 True\n",
      "x_t:  2 [0.421875   0.40833333 0.1        0.25      ]\n",
      "Q values:  tensor([[-6.6463, -7.0262, -7.3655, -7.2473, -6.4746, -5.8369]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6654 809 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1365\n",
      "367 12 False\n",
      "x_t:  3 [0.315625   0.27916667 0.071875   0.30833333]\n",
      "Q values:  tensor([[-4.8714, -4.4795, -4.5469, -4.0286, -4.8820, -4.0361]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17929 247 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  53\n",
      "367 15 True\n",
      "x_t:  3 [0.725    0.325    0.078125 0.4125  ]\n",
      "Q values:  tensor([[-4.3295, -3.7819, -3.9370, -4.0919, -4.3718, -3.3526]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 539 234 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1185\n",
      "367 22 True\n",
      "x_t:  1 [0.796875   0.30416667 0.15625    0.49166667]\n",
      "Q values:  tensor([[-5.1975, -5.8214, -5.2400, -5.6100, -5.5717, -4.8818]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11920 688 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1095\n",
      "368 0 True\n",
      "x_t:  1 [0.4875     0.325      0.0875     0.45416667]\n",
      "Q values:  tensor([[-6.6119, -7.1636, -7.5879, -6.8908, -7.2795, -6.3938]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11987 746 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 368: ep_len:746 episode reward: total was -83.100000. running mean: -69.031058\n",
      "startIDX:  14\n",
      "368 1 False\n",
      "x_t:  3 [0.484375   0.27083333 0.090625   0.35      ]\n",
      "Q values:  tensor([[1.5145, 0.3203, 1.1741, 1.7317, 1.1614, 0.7211]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 25690 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 368: ep_len:200 episode reward: total was 5.300000. running mean: -68.287747\n",
      "startIDX:  2932\n",
      "ep 368: ep_len:73 episode reward: total was -3.000000. running mean: -67.634870\n",
      "startIDX:  1760\n",
      "368 10 True\n",
      "x_t:  3 [0.38125    0.27083333 0.090625   0.31666667]\n",
      "Q values:  tensor([[-4.3179, -4.7482, -4.9316, -4.9026, -4.5598, -3.9866]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16476 244 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 368: ep_len:244 episode reward: total was -46.400000. running mean: -67.422521\n",
      "startIDX:  154\n",
      "368 12 True\n",
      "x_t:  2 [0.790625 0.4125   0.075    0.25    ]\n",
      "Q values:  tensor([[-5.5733, -5.4890, -5.8528, -5.8170, -5.8235, -4.8032]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2809 280 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 368: ep_len:280 episode reward: total was -19.500000. running mean: -66.943296\n",
      "startIDX:  2764\n",
      "368 15 True\n",
      "x_t:  0 [0.55625    0.40833333 0.078125   0.3625    ]\n",
      "Q values:  tensor([[-5.4942, -5.7508, -5.5200, -5.9541, -5.6161, -4.9522]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23120 832 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 368: ep_len:832 episode reward: total was -97.200000. running mean: -67.245863\n",
      "startIDX:  1773\n",
      "368 22 True\n",
      "x_t:  2 [0.003125   0.40833333 0.059375   0.2625    ]\n",
      "Q values:  tensor([[-6.9836, -6.1865, -6.6914, -6.7012, -7.1359, -5.8094]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18453 971 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 368: ep_len:971 episode reward: total was -86.400000. running mean: -67.437404\n",
      "startIDX:  1819\n",
      "369 0 True\n",
      "x_t:  2 [0.096875   0.40416667 0.103125   0.25416667]\n",
      "Q values:  tensor([[-6.0482, -5.4701, -6.9957, -5.8639, -6.2307, -5.2770]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18405 745 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  190\n",
      "369 1 False\n",
      "x_t:  2 [0.1375     0.36666667 0.1375     0.44166667]\n",
      "Q values:  tensor([[-5.4606, -5.5555, -4.8610, -5.0899, -5.8320, -4.9817]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27454 871 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1666\n",
      "369 5 False\n",
      "x_t:  2 [0.784375   0.4        0.1        0.25416667]\n",
      "Q values:  tensor([[-7.4238, -7.1779, -5.9533, -7.2790, -6.9218, -6.2078]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15651 994 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  353\n",
      "369 10 True\n",
      "x_t:  3 [0.271875   0.25       0.090625   0.29583333]\n",
      "Q values:  tensor([[-4.8582, -4.1091, -4.8045, -4.6381, -4.6501, -3.7573]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5127 255 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  454\n",
      "369 12 True\n",
      "x_t:  3 [0.796875   0.35833333 0.16875    0.4125    ]\n",
      "Q values:  tensor([[-4.8470, -4.6949, -4.9768, -5.0034, -5.4197, -4.2446]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7717 237 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  793\n",
      "369 15 True\n",
      "x_t:  2 [0.375      0.40833333 0.09375    0.29583333]\n",
      "Q values:  tensor([[-6.1289, -5.4294, -5.9218, -5.6671, -5.7260, -4.7327]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6032 372 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  371\n",
      "369 22 True\n",
      "x_t:  3 [0.103125   0.24166667 0.053125   0.24583333]\n",
      "Q values:  tensor([[-6.6994, -6.5112, -7.0000, -6.8824, -6.5311, -5.6071]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4883 1235 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  3162.219833612442\n",
      "startIDX:  738\n",
      "370 0 True\n",
      "x_t:  1 [0.334375 0.3375   0.165625 0.425   ]\n",
      "Q values:  tensor([[-5.0807, -4.9422, -4.9971, -5.2367, -5.4760, -4.4196]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9446 280 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 370: ep_len:280 episode reward: total was 13.200000. running mean: -66.538283\n",
      "startIDX:  911\n",
      "370 1 True\n",
      "x_t:  4 [0.221875   0.38333333 0.109375   0.39583333]\n",
      "Q values:  tensor([[-5.6522, -5.6486, -5.9637, -5.9581, -5.9801, -4.9199]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35454 521 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 370: ep_len:521 episode reward: total was -51.200000. running mean: -66.384900\n",
      "startIDX:  978\n",
      "370 5 True\n",
      "x_t:  3 [0.63125    0.30416667 0.13125    0.37916667]\n",
      "Q values:  tensor([[-4.5328, -3.7052, -4.5689, -4.3341, -4.1301, -3.6373]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10509 221 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 370: ep_len:221 episode reward: total was 36.100000. running mean: -65.360051\n",
      "startIDX:  180\n",
      "370 10 True\n",
      "x_t:  4 [0.225      0.35416667 0.084375   0.23333333]\n",
      "Q values:  tensor([[-5.7492, -6.0559, -5.6790, -6.5373, -6.1431, -5.0079]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4583 472 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 370: ep_len:472 episode reward: total was -28.000000. running mean: -64.986451\n",
      "startIDX:  754\n",
      "370 12 True\n",
      "x_t:  1 [0.24375    0.3875     0.190625   0.48333333]\n",
      "Q values:  tensor([[-4.8413, -4.4412, -4.4957, -4.7721, -4.7358, -3.4075]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10323 205 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 370: ep_len:205 episode reward: total was -11.100000. running mean: -64.447586\n",
      "startIDX:  2135\n",
      "370 15 True\n",
      "x_t:  2 [0.3125     0.4125     0.075      0.25833333]\n",
      "Q values:  tensor([[-5.4201, -5.7566, -5.5930, -5.7485, -5.3137, -4.7682]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15640 369 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 370: ep_len:369 episode reward: total was -82.900000. running mean: -64.632111\n",
      "startIDX:  556\n",
      "370 22 True\n",
      "x_t:  3 [0.490625   0.30416667 0.09375    0.30833333]\n",
      "Q values:  tensor([[-5.5345, -5.0744, -5.3856, -5.0072, -5.1368, -4.5068]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7114 234 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 370: ep_len:234 episode reward: total was -32.100000. running mean: -64.306789\n",
      "startIDX:  1243\n",
      "371 0 False\n",
      "x_t:  3 [0.121875   0.24583333 0.059375   0.28333333]\n",
      "Q values:  tensor([[-8.8423, -8.3360, -8.4710, -7.8552, -8.4608, -7.8595]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15175 1246 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  383\n",
      "371 1 True\n",
      "x_t:  1 [0.840625   0.275      0.1375     0.59583333]\n",
      "Q values:  tensor([[-5.1904, -5.5758, -4.9134, -4.9752, -5.2660, -4.4647]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28123 294 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1106\n",
      "371 5 False\n",
      "x_t:  3 [0.08125    0.22083333 0.05625    0.26666667]\n",
      "Q values:  tensor([[-0.2103, -0.2995,  0.1634,  0.8444, -0.4362, -0.2527]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10613 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  752\n",
      "371 10 True\n",
      "x_t:  0 [0.784375   0.3875     0.065625   0.32083333]\n",
      "Q values:  tensor([[-6.2063, -6.2909, -6.2536, -6.7703, -6.1964, -5.5053]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8126 733 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1018\n",
      "371 12 True\n",
      "x_t:  2 [0.78125 0.4125  0.05    0.2375 ]\n",
      "Q values:  tensor([[-4.9020, -4.7105, -4.7073, -4.6622, -4.6171, -3.9734]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13581 303 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  91\n",
      "371 15 True\n",
      "x_t:  3 [0.06875    0.24583333 0.0625     0.23333333]\n",
      "Q values:  tensor([[-5.1689, -4.9999, -5.3222, -4.8622, -5.2170, -4.1586]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 679 286 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371 22 True\n",
      "x_t:  1 [0.709375   0.30833333 0.096875   0.40416667]\n",
      "Q values:  tensor([[-6.5651, -6.5176, -6.6758, -6.6162, -6.1252, -5.7035]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1597 729 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2495\n",
      "ep 372: ep_len:43 episode reward: total was 13.000000. running mean: -63.253458\n",
      "startIDX:  1057\n",
      "372 1 True\n",
      "x_t:  3 [0.659375   0.29583333 0.13125    0.39583333]\n",
      "Q values:  tensor([[-4.9348, -5.0312, -5.3816, -5.4985, -5.4591, -4.3177]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35925 210 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 372: ep_len:210 episode reward: total was -10.100000. running mean: -62.721924\n",
      "startIDX:  2857\n",
      "ep 372: ep_len:110 episode reward: total was 72.000000. running mean: -61.374704\n",
      "startIDX:  2056\n",
      "372 10 True\n",
      "x_t:  1 [0.3875     0.30416667 0.078125   0.35      ]\n",
      "Q values:  tensor([[-6.5798, -6.2441, -6.5800, -5.8935, -6.0151, -5.3552]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18861 300 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 372: ep_len:300 episode reward: total was -39.300000. running mean: -61.153957\n",
      "startIDX:  1752\n",
      "372 12 True\n",
      "x_t:  0 [0.41875    0.42083333 0.1125     0.34166667]\n",
      "Q values:  tensor([[-6.6957, -6.7231, -5.7941, -6.3517, -6.7281, -5.5973]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21152 640 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 372: ep_len:640 episode reward: total was -101.600000. running mean: -61.558418\n",
      "startIDX:  1246\n",
      "372 15 True\n",
      "x_t:  3 [0.825      0.33333333 0.09375    0.38333333]\n",
      "Q values:  tensor([[-5.7212, -5.4723, -6.2397, -5.3965, -5.9742, -5.1628]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10345 261 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 372: ep_len:261 episode reward: total was 30.900000. running mean: -60.633834\n",
      "startIDX:  337\n",
      "372 22 True\n",
      "x_t:  3 [0.103125   0.24166667 0.06875    0.25416667]\n",
      "Q values:  tensor([[-9.1514, -7.9787, -8.6601, -8.5760, -9.3316, -7.4771]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4886 1270 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 372: ep_len:1270 episode reward: total was -150.900000. running mean: -61.536495\n",
      "startIDX:  919\n",
      "373 0 True\n",
      "x_t:  0 [0.6375     0.4125     0.09375    0.38333333]\n",
      "Q values:  tensor([[-6.3993, -6.9703, -7.3137, -6.2495, -7.1141, -5.8922]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10406 475 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  449\n",
      "373 1 False\n",
      "x_t:  1 [0.609375   0.275      0.184375   0.47916667]\n",
      "Q values:  tensor([[-7.0975, -6.4769, -6.9293, -7.6239, -6.7978, -6.5276]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30705 810 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1187\n",
      "373 5 False\n",
      "x_t:  2 [0.421875   0.39166667 0.09375    0.3       ]\n",
      "Q values:  tensor([[-7.1543, -6.4151, -6.3921, -7.0515, -6.7037, -6.4565]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12061 784 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  894\n",
      "373 10 False\n",
      "x_t:  1 [0.671875 0.2875   0.121875 0.3375  ]\n",
      "Q values:  tensor([[-11.9521,  -9.4639, -13.1697, -11.2647, -11.0582, -10.0215]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11353 1613 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  798\n",
      "373 12 True\n",
      "x_t:  0 [0.628125   0.41666667 0.071875   0.3       ]\n",
      "Q values:  tensor([[-7.0656, -6.8336, -7.7071, -7.8739, -6.9807, -6.3929]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11679 688 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  330\n",
      "373 15 True\n",
      "x_t:  1 [0.246875   0.36666667 0.18125    0.50416667]\n",
      "Q values:  tensor([[-5.4449, -5.5345, -6.3564, -5.3785, -5.9839, -5.3549]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2769 264 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  956\n",
      "373 22 True\n",
      "x_t:  0 [0.659375   0.4125     0.05625    0.30416667]\n",
      "Q values:  tensor([[-7.4756, -7.3115, -7.7051, -6.3122, -7.6477, -6.8160]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10444 492 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  706\n",
      "374 0 True\n",
      "x_t:  2 [0.03125  0.4125   0.109375 0.2625  ]\n",
      "Q values:  tensor([[-8.4336, -7.9102, -8.6358, -8.5963, -8.6393, -7.5468]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8878 867 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 374: ep_len:867 episode reward: total was -126.200000. running mean: -64.202658\n",
      "startIDX:  377\n",
      "374 1 True\n",
      "x_t:  1 [0.740625   0.28333333 0.16875    0.59166667]\n",
      "Q values:  tensor([[-8.3197, -7.2721, -8.0090, -7.8185, -8.2795, -6.4859]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28116 301 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 374: ep_len:301 episode reward: total was -37.900000. running mean: -63.939631\n",
      "startIDX:  2117\n",
      "374 5 True\n",
      "x_t:  4 [0.63125    0.35       0.090625   0.34583333]\n",
      "Q values:  tensor([[-7.5393, -7.3347, -7.9077, -7.1278, -6.8808, -6.5318]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19542 646 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 374: ep_len:646 episode reward: total was -71.000000. running mean: -64.010235\n",
      "startIDX:  462\n",
      "374 10 False\n",
      "x_t:  3 [0.25625    0.24583333 0.05625    0.28333333]\n",
      "Q values:  tensor([[ 0.8381, -0.7546,  0.3959,  1.9322,  0.0579,  0.3242]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5134 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 374: ep_len:200 episode reward: total was 14.000000. running mean: -63.230133\n",
      "startIDX:  830\n",
      "374 12 False\n",
      "x_t:  1 [0.284375   0.38333333 0.121875   0.4875    ]\n",
      "Q values:  tensor([[-9.3322, -7.9373, -9.4744, -9.7513, -9.8972, -8.9097]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12948 1320 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 374: ep_len:1320 episode reward: total was -262.600000. running mean: -65.223831\n",
      "startIDX:  1433\n",
      "374 15 False\n",
      "x_t:  3 [0.425      0.2875     0.084375   0.30833333]\n",
      "Q values:  tensor([[ 0.5323, -0.5591,  0.4579,  1.4868, -0.2731, -0.2826]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10416 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 374: ep_len:200 episode reward: total was -31.400000. running mean: -64.885593\n",
      "startIDX:  2299\n",
      "374 22 False\n",
      "x_t:  1 [0.584375   0.33333333 0.103125   0.44166667]\n",
      "Q values:  tensor([[-8.1760, -6.6170, -7.2136, -7.3491, -8.0528, -6.7925]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22961 1100 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 374: ep_len:1100 episode reward: total was -116.900000. running mean: -65.405737\n",
      "startIDX:  1221\n",
      "375 0 False\n",
      "x_t:  3 [0.09375    0.25       0.06875    0.26666667]\n",
      "Q values:  tensor([[-11.3039, -12.3701, -12.1008, -10.6903, -12.4527, -10.7144]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15169 1242 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1033\n",
      "375 1 False\n",
      "x_t:  3 [0.840625   0.30416667 0.153125   0.42916667]\n",
      "Q values:  tensor([[-5.1071, -4.8318, -6.1934, -4.6868, -5.8658, -4.7311]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35897 212 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2740\n",
      "375 5 True\n",
      "x_t:  0 [0.890625   0.39583333 0.078125   0.30833333]\n",
      "Q values:  tensor([[-7.8990, -8.2058, -8.6341, -9.3685, -8.4885, -7.6436]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23157 523 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2194\n",
      "375 10 True\n",
      "x_t:  0 [0.61875    0.4        0.059375   0.29583333]\n",
      "Q values:  tensor([[-9.0927, -8.3795, -7.7511, -8.3454, -8.1579, -7.6274]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20006 552 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1438\n",
      "375 12 False\n",
      "x_t:  3 [0.44375    0.3125     0.115625   0.35833333]\n",
      "Q values:  tensor([[0.7219, 1.0168, 0.5776, 2.7967, 0.6307, 0.2924]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 17898 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1676\n",
      "375 15 True\n",
      "x_t:  1 [0.471875   0.31666667 0.11875    0.3875    ]\n",
      "Q values:  tensor([[-6.4067, -6.2170, -5.8071, -6.8106, -6.0704, -5.1048]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12496 267 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2222\n",
      "375 22 False\n",
      "x_t:  1 [0.4625     0.34583333 0.165625   0.425     ]\n",
      "Q values:  tensor([[-9.4824, -7.7028, -8.2321, -9.2890, -8.5932, -7.9370]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22970 1130 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1625\n",
      "376 0 False\n",
      "x_t:  3 [0.69375    0.34166667 0.153125   0.39166667]\n",
      "Q values:  tensor([[2.4645, 0.9433, 1.6723, 3.4727, 0.9924, 1.5086]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 16831 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 376: ep_len:202 episode reward: total was -2.900000. running mean: -64.370403\n",
      "startIDX:  21\n",
      "376 1 True\n",
      "x_t:  3 [0.184375   0.2375     0.090625   0.29583333]\n",
      "Q values:  tensor([[-6.1827, -5.5531, -6.1715, -6.2200, -5.6161, -4.8978]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25756 242 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 376: ep_len:242 episode reward: total was -54.100000. running mean: -64.267699\n",
      "startIDX:  1146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376 5 True\n",
      "x_t:  2 [0.14375    0.39166667 0.06875    0.27916667]\n",
      "Q values:  tensor([[-7.4100, -7.3160, -7.1219, -6.8310, -6.9538, -6.2667]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12022 883 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 376: ep_len:883 episode reward: total was -79.100000. running mean: -64.416022\n",
      "startIDX:  2146\n",
      "376 10 True\n",
      "x_t:  0 [0.665625   0.39583333 0.10625    0.31666667]\n",
      "Q values:  tensor([[-6.3200, -5.6614, -6.1413, -6.0030, -6.5256, -5.3540]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20178 656 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 376: ep_len:656 episode reward: total was -209.000000. running mean: -65.861862\n",
      "startIDX:  1452\n",
      "376 12 True\n",
      "x_t:  3 [0.2875     0.27916667 0.0875     0.3125    ]\n",
      "Q values:  tensor([[-4.9669, -4.6024, -4.5314, -4.9197, -4.7266, -4.0185]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17935 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 376: ep_len:200 episode reward: total was -51.500000. running mean: -65.718243\n",
      "startIDX:  2971\n",
      "ep 376: ep_len:93 episode reward: total was 65.000000. running mean: -64.411061\n",
      "startIDX:  2659\n",
      "376 22 True\n",
      "x_t:  4 [0.253125 0.3875   0.0625   0.3125  ]\n",
      "Q values:  tensor([[-5.4149, -5.7738, -6.0739, -5.6534, -5.6912, -5.1326]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27299 535 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 376: ep_len:535 episode reward: total was -51.500000. running mean: -64.281950\n",
      "startIDX:  2365\n",
      "377 0 False\n",
      "x_t:  3 [0.078125   0.2375     0.075      0.24583333]\n",
      "Q values:  tensor([[-9.2684, -9.1233, -9.3938, -7.2620, -8.7599, -7.3337]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26097 1223 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  585\n",
      "377 1 True\n",
      "x_t:  2 [0.378125   0.38333333 0.096875   0.30833333]\n",
      "Q values:  tensor([[-8.6055, -7.5317, -8.1114, -7.7046, -8.1067, -6.8324]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31532 427 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2569\n",
      "377 5 False\n",
      "x_t:  2 [0.125      0.39583333 0.1        0.2625    ]\n",
      "Q values:  tensor([[-9.7707, -9.6880, -8.8514, -9.5101, -8.9112, -8.9575]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21569 786 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1248\n",
      "377 10 False\n",
      "x_t:  3 [0.075      0.23333333 0.065625   0.24166667]\n",
      "Q values:  tensor([[-12.0455, -11.4790, -11.8258, -10.3011, -11.3288, -10.7000]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14577 1223 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  403\n",
      "377 12 True\n",
      "x_t:  2 [0.003125   0.41666667 0.090625   0.24583333]\n",
      "Q values:  tensor([[-11.7286, -11.4117, -10.8376, -11.6810, -12.0339, -10.1154]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9826 1306 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2788\n",
      "377 15 True\n",
      "x_t:  1 [0.1      0.375    0.103125 0.5     ]\n",
      "Q values:  tensor([[-9.7001, -8.9975, -9.6765, -9.2995, -9.7945, -8.1509]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22044 266 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2250\n",
      "377 22 True\n",
      "x_t:  1 [0.71875 0.325   0.13125 0.4375 ]\n",
      "Q values:  tensor([[-14.0674, -13.0269, -14.3337, -12.2884, -14.0353, -12.0392]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22947 1106 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1992\n",
      "378 0 False\n",
      "x_t:  1 [0.003125 0.3875   0.18125  0.4     ]\n",
      "Q values:  tensor([[-7.9826, -6.9637, -7.6417, -7.5556, -7.7252, -7.0559]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18926 205 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 378: ep_len:205 episode reward: total was -36.600000. running mean: -68.921078\n",
      "startIDX:  526\n",
      "378 1 True\n",
      "x_t:  1 [0.590625   0.28333333 0.190625   0.46666667]\n",
      "Q values:  tensor([[-9.8404, -9.4053, -8.8718, -9.7572, -9.5683, -8.4648]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30707 747 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 378: ep_len:747 episode reward: total was -144.000000. running mean: -69.671867\n",
      "startIDX:  1374\n",
      "378 5 False\n",
      "x_t:  1 [0.34375    0.31666667 0.09375    0.375     ]\n",
      "Q values:  tensor([[-6.8881, -6.3281, -7.5199, -7.2648, -6.4615, -6.4160]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12540 243 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 378: ep_len:243 episode reward: total was -19.400000. running mean: -69.169149\n",
      "startIDX:  281\n",
      "378 10 True\n",
      "x_t:  3 [0.7        0.29583333 0.06875    0.37083333]\n",
      "Q values:  tensor([[-7.8133, -7.1187, -7.2583, -6.9996, -6.6419, -6.8965]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5056 253 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 378: ep_len:253 episode reward: total was -13.400000. running mean: -68.611457\n",
      "startIDX:  79\n",
      "378 12 False\n",
      "x_t:  1 [0.528125   0.3375     0.075      0.43333333]\n",
      "Q values:  tensor([[-8.1447, -7.0649, -8.1905, -8.6778, -9.3451, -7.3047]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2245 635 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 378: ep_len:635 episode reward: total was -110.500000. running mean: -69.030343\n",
      "startIDX:  2061\n",
      "378 15 True\n",
      "x_t:  1 [0.728125   0.3        0.09375    0.30833333]\n",
      "Q values:  tensor([[-9.2206, -9.4149, -9.8471, -9.0701, -9.9925, -8.4836]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14861 636 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 378: ep_len:636 episode reward: total was -130.600000. running mean: -69.646039\n",
      "startIDX:  887\n",
      "378 22 False\n",
      "x_t:  1 [0.1125   0.35     0.090625 0.4     ]\n",
      "Q values:  tensor([[-8.1669, -6.7982, -7.8939, -7.0796, -7.9273, -6.8501]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9494 256 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 378: ep_len:256 episode reward: total was -29.800000. running mean: -69.247579\n",
      "startIDX:  1603\n",
      "379 0 False\n",
      "x_t:  3 [0.696875   0.34166667 0.1625     0.4       ]\n",
      "Q values:  tensor([[ 1.3608, -0.3395,  0.6054,  1.7712, -0.0677, -0.5010]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16828 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  541\n",
      "379 1 False\n",
      "x_t:  1 [0.753125 0.275    0.165625 0.45    ]\n",
      "Q values:  tensor([[-8.1378, -7.4630, -8.5031, -8.7736, -8.5867, -7.4968]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30690 744 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  220\n",
      "379 5 False\n",
      "x_t:  1 [0.0625     0.37083333 0.20625    0.49583333]\n",
      "Q values:  tensor([[-7.8009, -6.8742, -8.0388, -7.4787, -7.7365, -7.0196]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2519 212 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1205\n",
      "379 10 False\n",
      "x_t:  3 [0.196875 0.2375   0.078125 0.2875  ]\n",
      "Q values:  tensor([[-11.7652, -10.1447, -11.2986,  -9.9911, -12.1485, -10.4058]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14620 1278 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1053\n",
      "379 12 False\n",
      "x_t:  3 [0.1        0.27083333 0.075      0.29583333]\n",
      "Q values:  tensor([[-10.2727, -10.5362, -11.1243, -10.0995, -10.7080, -10.1243]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16383 1445 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1358\n",
      "379 15 False\n",
      "x_t:  3 [0.7        0.32916667 0.103125   0.36666667]\n",
      "Q values:  tensor([[-6.6461, -6.1232, -5.9461, -5.6858, -7.1458, -5.6888]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10360 207 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2462\n",
      "379 22 True\n",
      "x_t:  2 [0.196875   0.41666667 0.0875     0.25416667]\n",
      "Q values:  tensor([[-7.5381, -7.8145, -7.6043, -7.5382, -7.6305, -7.0304]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23737 371 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  3241.6428594589233\n",
      "startIDX:  932\n",
      "380 0 True\n",
      "x_t:  0 [0.765625   0.40833333 0.125      0.34583333]\n",
      "Q values:  tensor([[-7.7263, -7.2668, -7.6669, -6.5874, -6.7137, -6.7820]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10348 435 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 380: ep_len:435 episode reward: total was -67.100000. running mean: -71.330535\n",
      "startIDX:  551\n",
      "380 1 False\n",
      "x_t:  1 [0.34375    0.3        0.196875   0.49583333]\n",
      "Q values:  tensor([[-7.7785, -7.0741, -7.7137, -7.8833, -7.3985, -7.1557]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30732 763 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 380: ep_len:763 episode reward: total was -115.600000. running mean: -71.773229\n",
      "startIDX:  1877\n",
      "380 5 True\n",
      "x_t:  2 [0.25625    0.39583333 0.084375   0.24166667]\n",
      "Q values:  tensor([[-8.4011, -8.2016, -7.6931, -8.8949, -8.1865, -7.4780]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15737 374 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 380: ep_len:374 episode reward: total was -98.200000. running mean: -72.037497\n",
      "startIDX:  1788\n",
      "380 10 True\n",
      "x_t:  2 [0.5      0.4      0.065625 0.25    ]\n",
      "Q values:  tensor([[-10.6248,  -9.7017,  -9.9974,  -9.3508, -10.0743,  -8.4150]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18232 888 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 380: ep_len:888 episode reward: total was -118.300000. running mean: -72.500122\n",
      "startIDX:  1963\n",
      "ep 380: ep_len:69 episode reward: total was -4.600000. running mean: -71.821121\n",
      "startIDX:  122\n",
      "380 15 True\n",
      "x_t:  2 [0.471875   0.40416667 0.065625   0.34583333]\n",
      "Q values:  tensor([[-7.7365, -7.3455, -7.7421, -8.0199, -8.2175, -7.2269]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2251 855 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 380: ep_len:855 episode reward: total was -98.700000. running mean: -72.089909\n",
      "startIDX:  2132\n",
      "380 22 True\n",
      "x_t:  0 [0.940625   0.39583333 0.05625    0.34583333]\n",
      "Q values:  tensor([[-8.8872, -8.4539, -8.6123, -9.2877, -8.3136, -8.2530]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20684 834 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 380: ep_len:834 episode reward: total was -137.200000. running mean: -72.741010\n",
      "startIDX:  1683\n",
      "381 0 False\n",
      "x_t:  3 [0.2375 0.275  0.1125 0.3   ]\n",
      "Q values:  tensor([[1.0346, 0.9289, 2.3116, 3.4347, 1.0371, 1.3218]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 16910 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  444\n",
      "381 1 False\n",
      "x_t:  1 [0.75       0.275      0.165625   0.45416667]\n",
      "Q values:  tensor([[-9.0976, -7.8608, -8.2412, -8.9823, -9.6144, -7.8612]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30692 793 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  42\n",
      "381 5 True\n",
      "x_t:  2 [0.015625   0.3875     0.19375    0.42083333]\n",
      "Q values:  tensor([[-12.0146, -11.0905, -11.7727, -10.7396, -10.3748,  -9.9833]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2058 920 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2551\n",
      "startIDX:  917\n",
      "381 12 False\n",
      "x_t:  1 [0.2125     0.3875     0.10625    0.48333333]\n",
      "Q values:  tensor([[-8.8148, -7.7211, -9.7546, -8.5133, -9.4089, -8.1148]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12955 634 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2159\n",
      "381 15 True\n",
      "x_t:  2 [0.578125   0.40416667 0.053125   0.25416667]\n",
      "Q values:  tensor([[-9.5655, -8.8774, -9.5703, -8.6043, -9.0414, -8.0233]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15602 341 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  476\n",
      "381 22 False\n",
      "x_t:  3 [0.875      0.33333333 0.078125   0.40416667]\n",
      "Q values:  tensor([[-12.2664, -11.5368, -11.1038, -10.4105, -11.2887, -10.6228]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7054 1031 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  195\n",
      "382 0 True\n",
      "x_t:  2 [0.7125     0.40416667 0.1        0.29166667]\n",
      "Q values:  tensor([[-8.9193, -8.6678, -9.7287, -8.6912, -9.0171, -8.3697]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2337 340 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 382: ep_len:340 episode reward: total was -78.700000. running mean: -74.136865\n",
      "startIDX:  466\n",
      "382 1 True\n",
      "x_t:  1 [0.84375    0.26666667 0.084375   0.45833333]\n",
      "Q values:  tensor([[-10.0316, -10.3286,  -9.8678,  -9.4143,  -9.4073,  -8.0849]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30686 770 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 382: ep_len:770 episode reward: total was -101.400000. running mean: -74.409496\n",
      "startIDX:  2341\n",
      "382 5 False\n",
      "x_t:  3 [0.084375   0.25833333 0.125      0.28333333]\n",
      "Q values:  tensor([[0.7992, 1.5036, 1.9600, 2.6006, 0.7411, 0.5608]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 20003 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 382: ep_len:201 episode reward: total was -25.700000. running mean: -73.922402\n",
      "startIDX:  2011\n",
      "382 10 True\n",
      "x_t:  1 [0.1        0.34166667 0.146875   0.375     ]\n",
      "Q values:  tensor([[-7.6756, -8.6876, -8.3266, -8.2704, -8.4090, -7.0880]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18823 303 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 382: ep_len:303 episode reward: total was -11.200000. running mean: -73.295178\n",
      "startIDX:  978\n",
      "382 12 False\n",
      "x_t:  2 [0.1375     0.42083333 0.103125   0.24166667]\n",
      "Q values:  tensor([[-9.0033, -8.8064, -7.9831, -8.6077, -8.6832, -8.2223]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13673 376 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 382: ep_len:376 episode reward: total was -117.300000. running mean: -73.735226\n",
      "startIDX:  2567\n",
      "382 15 False\n",
      "x_t:  3 [0.30625    0.25416667 0.0625     0.28333333]\n",
      "Q values:  tensor([[2.1646, 2.3426, 3.6164, 4.4443, 2.3022, 2.2694]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 19765 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 382: ep_len:200 episode reward: total was -40.200000. running mean: -73.399873\n",
      "startIDX:  1853\n",
      "382 22 False\n",
      "x_t:  2 [0.040625   0.4125     0.084375   0.25833333]\n",
      "Q values:  tensor([[-10.0579, -11.0208,  -9.2493, -10.4235, -11.9051,  -9.4220]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18462 791 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 382: ep_len:791 episode reward: total was -170.200000. running mean: -74.367875\n",
      "startIDX:  2433\n",
      "383 0 False\n",
      "x_t:  3 [0.1125     0.2375     0.05       0.25416667]\n",
      "Q values:  tensor([[-11.6727, -13.0705, -12.4492, -10.9874, -11.8983, -11.6421]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26106 1196 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  176\n",
      "383 1 False\n",
      "x_t:  2 [0.003125   0.375      0.09375    0.42916667]\n",
      "Q values:  tensor([[-13.8513, -14.0013, -11.0715, -12.5507, -13.1329, -11.7057]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27429 851 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2067\n",
      "383 5 True\n",
      "x_t:  3 [0.0625     0.25       0.08125    0.26666667]\n",
      "Q values:  tensor([[-13.5080, -13.8655, -12.9485, -14.4784, -13.6305, -13.0507]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18201 1221 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  363\n",
      "383 10 True\n",
      "x_t:  3 [0.815625   0.32916667 0.140625   0.36666667]\n",
      "Q values:  tensor([[-7.7163, -7.8129, -8.4664, -8.8576, -8.2609, -7.3200]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5040 214 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1215\n",
      "383 12 False\n",
      "x_t:  4 [0.1125     0.42083333 0.09375    0.36666667]\n",
      "Q values:  tensor([[-11.5973, -11.3596, -12.2159, -11.0343, -10.3850, -10.5376]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17401 485 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2370\n",
      "383 15 False\n",
      "x_t:  4 [0.075  0.4125 0.1125 0.3625]\n",
      "Q values:  tensor([[-12.7291, -11.6961, -13.2809, -11.5350, -10.9806, -11.1891]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19260 527 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2772\n",
      "383 22 True\n",
      "x_t:  4 [0.509375   0.37916667 0.059375   0.32083333]\n",
      "Q values:  tensor([[-14.9532, -13.7286, -14.6167, -14.9463, -15.6009, -13.2615]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27366 513 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  861\n",
      "384 0 False\n",
      "x_t:  0 [0.640625   0.40833333 0.0875     0.39166667]\n",
      "Q values:  tensor([[-14.7059, -15.3409, -15.3972, -15.4645, -16.1562, -14.7896]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10411 512 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 384: ep_len:512 episode reward: total was -184.900000. running mean: -84.283869\n",
      "startIDX:  535\n",
      "384 1 False\n",
      "x_t:  1 [0.85625    0.26666667 0.140625   0.4625    ]\n",
      "Q values:  tensor([[-15.1964, -14.9106, -16.6046, -15.7812, -15.0686, -15.5727]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30679 744 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 384: ep_len:744 episode reward: total was -226.000000. running mean: -85.701030\n",
      "startIDX:  287\n",
      "384 5 False\n",
      "x_t:  0 [0.66875    0.39583333 0.08125    0.37916667]\n",
      "Q values:  tensor([[-13.6919, -13.9509, -14.7263, -14.2156, -14.4760, -14.1298]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3587 523 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 384: ep_len:523 episode reward: total was -185.900000. running mean: -86.703020\n",
      "startIDX:  1363\n",
      "384 10 False\n",
      "x_t:  4 [0.003125   0.36666667 0.090625   0.27916667]\n",
      "Q values:  tensor([[-14.2117, -13.1835, -13.5911, -13.8381, -13.0549, -13.4137]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15703 538 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 384: ep_len:538 episode reward: total was -151.200000. running mean: -87.347990\n",
      "startIDX:  1081\n",
      "384 12 False\n",
      "x_t:  3 [0.140625   0.27916667 0.09375    0.30416667]\n",
      "Q values:  tensor([[-21.5006, -23.2074, -21.1965, -21.1579, -22.2869, -21.8126]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16392 1385 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 384: ep_len:1385 episode reward: total was -567.700000. running mean: -92.151510\n",
      "startIDX:  1428\n",
      "384 15 False\n",
      "x_t:  3 [0.375    0.275    0.096875 0.3     ]\n",
      "Q values:  tensor([[1.9251, 0.6943, 3.4866, 4.6953, 2.0526, 1.7942]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 10424 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 384: ep_len:201 episode reward: total was -38.600000. running mean: -91.615995\n",
      "startIDX:  905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384 22 True\n",
      "x_t:  1 [0.25625    0.3375     0.109375   0.40416667]\n",
      "Q values:  tensor([[-13.4819, -13.7961, -12.3346, -13.9746, -13.8020, -12.3975]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9509 245 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 384: ep_len:245 episode reward: total was -78.300000. running mean: -91.482835\n",
      "startIDX:  81\n",
      "385 0 False\n",
      "x_t:  2 [0.796875   0.39583333 0.046875   0.3       ]\n",
      "Q values:  tensor([[-22.0369, -21.7178, -21.7006, -23.2992, -23.3563, -21.7242]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2327 1063 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  855\n",
      "385 1 False\n",
      "x_t:  4 [0.06875    0.38333333 0.13125    0.42083333]\n",
      "Q values:  tensor([[-18.0899, -19.4050, -17.8287, -17.3397, -16.6870, -17.0032]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35432 536 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2862\n",
      "startIDX:  2040\n",
      "385 10 False\n",
      "x_t:  1 [0.1        0.34166667 0.146875   0.375     ]\n",
      "Q values:  tensor([[-15.0772, -14.3454, -14.7700, -16.4403, -14.5106, -14.6450]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18823 282 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2052\n",
      "startIDX:  2981\n",
      "startIDX:  87\n",
      "385 22 True\n",
      "x_t:  1 [0.8625     0.30416667 0.134375   0.40833333]\n",
      "Q values:  tensor([[-22.0870, -21.2358, -18.5239, -20.4104, -19.8752, -20.9732]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1578 694 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2061\n",
      "386 0 False\n",
      "x_t:  0 [0.840625   0.40416667 0.128125   0.34166667]\n",
      "Q values:  tensor([[-23.1744, -24.1514, -25.6546, -24.7420, -25.1936, -23.6614]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20634 823 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 386: ep_len:823 episode reward: total was -528.700000. running mean: -99.882442\n",
      "startIDX:  760\n",
      "386 1 False\n",
      "x_t:  3 [0.0875     0.23333333 0.08125    0.29583333]\n",
      "Q values:  tensor([[-26.0153, -23.9550, -24.6675, -22.7457, -25.6071, -24.8525]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34311 1383 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 386: ep_len:1383 episode reward: total was -913.300000. running mean: -108.016618\n",
      "startIDX:  2046\n",
      "386 5 True\n",
      "x_t:  3 [0.134375   0.24583333 0.103125   0.32916667]\n",
      "Q values:  tensor([[-25.5034, -29.0681, -27.7663, -29.4358, -27.1523, -26.6261]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18221 1223 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 386: ep_len:1223 episode reward: total was -869.200000. running mean: -115.628452\n",
      "startIDX:  2628\n",
      "ep 386: ep_len:3 episode reward: total was -3.000000. running mean: -114.502167\n",
      "startIDX:  76\n",
      "386 12 False\n",
      "x_t:  1 [0.68125    0.325      0.121875   0.42916667]\n",
      "Q values:  tensor([[-31.7352, -30.1804, -33.5265, -34.0354, -35.1866, -30.6783]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2232 626 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 386: ep_len:626 episode reward: total was -430.800000. running mean: -117.665146\n",
      "startIDX:  2127\n",
      "386 15 True\n",
      "x_t:  2 [0.596875   0.40833333 0.078125   0.26666667]\n",
      "Q values:  tensor([[-24.7825, -27.5226, -30.3011, -30.3767, -27.1908, -27.8582]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15598 344 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 386: ep_len:344 episode reward: total was -244.200000. running mean: -118.930494\n",
      "startIDX:  2965\n",
      "ep 386: ep_len:28 episode reward: total was 20.000000. running mean: -117.541189\n",
      "startIDX:  1488\n",
      "387 0 False\n",
      "x_t:  3 [0.68125    0.33333333 0.11875    0.375     ]\n",
      "Q values:  tensor([[-21.9851, -21.2226, -24.3712, -21.1233, -21.2748, -21.3117]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16834 269 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  443\n",
      "387 1 False\n",
      "x_t:  1 [0.821875   0.2625     0.1        0.45833333]\n",
      "Q values:  tensor([[-22.5812, -20.1916, -22.1621, -21.6003, -22.7455, -21.4956]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30687 781 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  412\n",
      "387 5 False\n",
      "x_t:  1 [0.68125    0.29166667 0.11875    0.35416667]\n",
      "Q values:  tensor([[-27.4971, -26.0218, -29.8528, -28.3119, -27.5491, -28.5027]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5050 692 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  552\n",
      "387 10 True\n",
      "x_t:  2 [0.3375     0.39583333 0.065625   0.26666667]\n",
      "Q values:  tensor([[-32.1554, -34.1429, -32.3987, -34.0128, -33.7464, -31.8474]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6636 774 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  661\n",
      "387 12 False\n",
      "x_t:  1 [0.05625    0.39583333 0.184375   0.47083333]\n",
      "Q values:  tensor([[-33.5628, -29.6743, -33.1832, -32.6187, -32.1055, -30.8724]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10309 248 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2310\n",
      "387 15 False\n",
      "x_t:  3 [0.071875   0.27083333 0.078125   0.3       ]\n",
      "Q values:  tensor([[-36.9961, -40.4500, -40.0628, -34.7262, -38.1984, -38.2620]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18176 1257 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2468\n",
      "387 22 False\n",
      "x_t:  2 [0.815625   0.40416667 0.05625    0.25416667]\n",
      "Q values:  tensor([[-32.2495, -32.3444, -31.6942, -32.5338, -33.2407, -32.2209]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23639 320 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1967\n",
      "388 0 False\n",
      "x_t:  1 [0.08125    0.35833333 0.103125   0.41666667]\n",
      "Q values:  tensor([[-37.0247, -31.6788, -36.1992, -35.8518, -35.0203, -33.5118]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18931 220 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 388: ep_len:220 episode reward: total was -134.900000. running mean: -138.212377\n",
      "startIDX:  831\n",
      "388 1 False\n",
      "x_t:  4 [0.13125    0.37916667 0.10625    0.4125    ]\n",
      "Q values:  tensor([[-28.8356, -28.7227, -30.2246, -27.6950, -27.3700, -30.0965]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35441 551 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 388: ep_len:551 episode reward: total was -280.500000. running mean: -139.635253\n",
      "startIDX:  2582\n",
      "388 5 False\n",
      "x_t:  2 [0.025      0.39583333 0.084375   0.27083333]\n",
      "Q values:  tensor([[-23.4065, -23.8796, -22.4112, -24.1852, -23.1765, -23.1640]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21550 783 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 388: ep_len:783 episode reward: total was -508.300000. running mean: -143.321900\n",
      "startIDX:  2113\n",
      "388 10 False\n",
      "x_t:  0 [0.88125    0.3875     0.10625    0.37916667]\n",
      "Q values:  tensor([[-25.3823, -29.2388, -29.1600, -28.2866, -27.6203, -27.0917]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19934 561 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 388: ep_len:561 episode reward: total was -339.500000. running mean: -145.283681\n",
      "startIDX:  1823\n",
      "388 12 True\n",
      "x_t:  0 [0.8125   0.4125   0.121875 0.35    ]\n",
      "Q values:  tensor([[-28.7480, -27.0063, -24.4152, -25.6077, -25.6949, -23.9076]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21102 585 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 388: ep_len:585 episode reward: total was -370.900000. running mean: -147.539845\n",
      "startIDX:  372\n",
      "388 15 False\n",
      "x_t:  1 [0.653125   0.3125     0.09375    0.51666667]\n",
      "Q values:  tensor([[-36.2522, -33.6734, -33.8377, -35.8665, -35.5381, -33.8004]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2801 258 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 388: ep_len:258 episode reward: total was -162.200000. running mean: -147.686446\n",
      "startIDX:  342\n",
      "388 22 False\n",
      "x_t:  3 [0.075      0.24583333 0.06875    0.24166667]\n",
      "Q values:  tensor([[-33.2938, -30.5404, -30.1032, -28.1197, -30.2902, -30.7004]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4876 1261 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 388: ep_len:1261 episode reward: total was -720.100000. running mean: -153.410582\n",
      "startIDX:  163\n",
      "389 0 False\n",
      "x_t:  2 [0.796875   0.40833333 0.1        0.2875    ]\n",
      "Q values:  tensor([[-31.4487, -33.7455, -30.0189, -32.3053, -34.6144, -30.6186]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2320 363 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  129\n",
      "389 1 False\n",
      "x_t:  2 [0.003125   0.36666667 0.10625    0.45833333]\n",
      "Q values:  tensor([[-23.2699, -25.3307, -21.3029, -23.7683, -23.9732, -22.1624]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27432 879 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1062\n",
      "389 5 False\n",
      "x_t:  3 [0.25625    0.24166667 0.125      0.30833333]\n",
      "Q values:  tensor([[ 3.2940, -0.0069,  1.7233,  4.8605,  1.1234,  0.6864]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10568 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  599\n",
      "389 10 True\n",
      "x_t:  2 [0.071875   0.4        0.065625   0.26666667]\n",
      "Q values:  tensor([[-19.7513, -20.4379, -19.4863, -21.0540, -18.9090, -18.0528]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6596 735 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  960\n",
      "389 12 False\n",
      "x_t:  1 [0.821875   0.35416667 0.1375     0.5125    ]\n",
      "Q values:  tensor([[-19.6052, -17.0607, -18.3806, -18.5113, -20.3019, -17.5038]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12916 584 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2623\n",
      "389 15 False\n",
      "x_t:  2 [0.003125   0.40833333 0.125      0.3375    ]\n",
      "Q values:  tensor([[-15.2678, -15.9797, -15.0421, -15.7336, -17.8004, -15.3775]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21476 880 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2758\n",
      "389 22 False\n",
      "x_t:  4 [0.00625    0.40833333 0.115625   0.3       ]\n",
      "Q values:  tensor([[-16.7552, -17.2815, -16.9468, -16.9177, -14.9830, -15.4061]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27265 482 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  3322.9199180603027\n",
      "startIDX:  1607\n",
      "390 0 False\n",
      "x_t:  3 [0.765625   0.32916667 0.10625    0.4125    ]\n",
      "Q values:  tensor([[1.9040, 0.5617, 1.5702, 3.4729, 1.6129, 0.9233]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 16825 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 390: ep_len:200 episode reward: total was -35.500000. running mean: -158.253735\n",
      "startIDX:  593\n",
      "390 1 False\n",
      "x_t:  2 [0.653125   0.37916667 0.115625   0.32083333]\n",
      "Q values:  tensor([[-19.4128, -18.8132, -16.6750, -18.3158, -18.0425, -16.9432]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31485 389 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 390: ep_len:389 episode reward: total was -174.400000. running mean: -158.415198\n",
      "startIDX:  1976\n",
      "390 5 False\n",
      "x_t:  3 [0.178125   0.25833333 0.084375   0.325     ]\n",
      "Q values:  tensor([[-20.8962, -18.4312, -19.7053, -17.4041, -17.4072, -18.4234]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18234 1256 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 390: ep_len:1256 episode reward: total was -559.100000. running mean: -162.422046\n",
      "startIDX:  2489\n",
      "390 10 False\n",
      "x_t:  1 [0.884375   0.2875     0.1125     0.34166667]\n",
      "Q values:  tensor([[-22.2519, -19.1810, -20.2151, -21.1135, -21.4843, -20.2412]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22467 1139 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 390: ep_len:1139 episode reward: total was -488.700000. running mean: -165.684825\n",
      "startIDX:  153\n",
      "390 12 False\n",
      "x_t:  2 [0.8125     0.40833333 0.084375   0.2375    ]\n",
      "Q values:  tensor([[-20.4184, -18.6737, -17.4539, -18.2352, -21.1602, -18.5885]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2805 289 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 390: ep_len:289 episode reward: total was -115.400000. running mean: -165.181977\n",
      "startIDX:  1747\n",
      "390 15 False\n",
      "x_t:  0 [0.78125    0.40416667 0.090625   0.325     ]\n",
      "Q values:  tensor([[-18.1473, -18.6651, -19.5170, -19.6870, -19.6815, -18.2541]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13381 467 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 390: ep_len:467 episode reward: total was -229.100000. running mean: -165.821157\n",
      "startIDX:  898\n",
      "390 22 True\n",
      "x_t:  1 [0.009375 0.3625   0.08125  0.4     ]\n",
      "Q values:  tensor([[-17.7620, -19.7100, -18.8728, -16.8013, -18.5095, -17.8636]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9481 240 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 390: ep_len:240 episode reward: total was -73.200000. running mean: -164.894946\n",
      "startIDX:  1189\n",
      "391 0 False\n",
      "x_t:  3 [0.078125   0.24583333 0.071875   0.2625    ]\n",
      "Q values:  tensor([[-19.4583, -20.9761, -18.4123, -18.0485, -20.4483, -18.7211]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15162 1257 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  520\n",
      "391 1 False\n",
      "x_t:  1 [0.73125    0.27916667 0.140625   0.45      ]\n",
      "Q values:  tensor([[-21.9612, -19.4273, -19.4898, -21.2056, -21.0541, -20.0341]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30696 763 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  441\n",
      "391 5 True\n",
      "x_t:  1 [0.86875    0.2875     0.125      0.37916667]\n",
      "Q values:  tensor([[-19.7231, -21.0398, -19.8604, -21.1380, -18.8533, -17.9818]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5027 660 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2231\n",
      "391 10 False\n",
      "x_t:  0 [0.871875   0.3875     0.078125   0.35416667]\n",
      "Q values:  tensor([[-17.4814, -19.6118, -19.7630, -17.7595, -18.5554, -17.6762]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19939 501 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  971\n",
      "391 12 False\n",
      "x_t:  2 [0.828125   0.40833333 0.08125    0.24166667]\n",
      "Q values:  tensor([[-16.6577, -17.7891, -16.3115, -18.3638, -17.0655, -16.5884]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13570 325 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  234\n",
      "391 15 False\n",
      "x_t:  2 [0.06875    0.4        0.075      0.33333333]\n",
      "Q values:  tensor([[-20.5306, -21.9695, -20.2997, -22.4354, -24.6846, -21.0790]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2202 776 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1964\n",
      "391 22 False\n",
      "x_t:  1 [0.203125   0.3375     0.125      0.39583333]\n",
      "Q values:  tensor([[-19.8689, -17.9561, -19.5664, -19.1181, -19.7907, -19.8869]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19011 273 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2549\n",
      "ep 392: ep_len:16 episode reward: total was 14.000000. running mean: -173.323783\n",
      "startIDX:  1106\n",
      "392 1 False\n",
      "x_t:  3 [0.54375    0.28333333 0.090625   0.35416667]\n",
      "Q values:  tensor([[-8.7577, -8.5277, -7.8952, -7.2686, -7.7468, -8.3405]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35951 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 392: ep_len:200 episode reward: total was -116.500000. running mean: -172.755545\n",
      "startIDX:  45\n",
      "392 5 False\n",
      "x_t:  2 [0.340625   0.39166667 0.1875     0.4375    ]\n",
      "Q values:  tensor([[-23.9480, -23.2534, -20.7513, -24.1925, -22.8080, -22.0031]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2086 916 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 392: ep_len:916 episode reward: total was -548.100000. running mean: -176.508990\n",
      "startIDX:  2420\n",
      "392 10 True\n",
      "x_t:  1 [0.76875    0.28333333 0.06875    0.32916667]\n",
      "Q values:  tensor([[-29.3516, -28.3849, -27.5685, -26.3409, -28.0202, -28.4636]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22484 1206 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 392: ep_len:1206 episode reward: total was -799.500000. running mean: -182.738900\n",
      "startIDX:  1424\n",
      "392 12 False\n",
      "x_t:  3 [0.39375    0.30416667 0.109375   0.34583333]\n",
      "Q values:  tensor([[-14.8937, -14.1159, -14.0868, -13.6225, -14.8087, -14.4792]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17906 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 392: ep_len:201 episode reward: total was -99.200000. running mean: -181.903511\n",
      "startIDX:  1289\n",
      "392 15 True\n",
      "x_t:  3 [0.86875    0.35416667 0.125      0.37916667]\n",
      "Q values:  tensor([[-22.2291, -22.2876, -21.8189, -20.6253, -19.7960, -21.1884]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10337 229 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 392: ep_len:229 episode reward: total was -57.400000. running mean: -180.658476\n",
      "startIDX:  883\n",
      "392 22 False\n",
      "x_t:  1 [0.003125   0.375      0.078125   0.38333333]\n",
      "Q values:  tensor([[-29.0006, -26.3945, -30.4560, -26.6132, -28.8457, -27.4598]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9479 249 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 392: ep_len:249 episode reward: total was -131.000000. running mean: -180.161891\n",
      "startIDX:  1200\n",
      "393 0 False\n",
      "x_t:  3 [0.0625     0.24166667 0.06875    0.2625    ]\n",
      "Q values:  tensor([[-31.9659, -34.8845, -33.1912, -31.0078, -34.5260, -31.2456]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15158 1254 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  801\n",
      "393 1 False\n",
      "x_t:  3 [0.078125   0.22916667 0.06875    0.29166667]\n",
      "Q values:  tensor([[-42.0088, -42.6641, -41.4403, -37.9775, -40.8443, -39.1354]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34307 1366 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2236\n",
      "393 5 False\n",
      "x_t:  3 [0.828125   0.33333333 0.11875    0.45      ]\n",
      "Q values:  tensor([[-25.2942, -26.3560, -25.1291, -24.9129, -25.8701, -25.4277]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19888 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  156\n",
      "393 10 True\n",
      "x_t:  4 [0.0375     0.35833333 0.053125   0.25416667]\n",
      "Q values:  tensor([[-33.2402, -35.1575, -32.8336, -34.6161, -33.5418, -34.0796]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4548 486 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1384\n",
      "393 12 False\n",
      "x_t:  3 [0.590625   0.325      0.103125   0.39166667]\n",
      "Q values:  tensor([[-30.7496, -31.6368, -31.9057, -29.2370, -30.1693, -29.3490]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17876 205 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2215\n",
      "393 15 False\n",
      "x_t:  3 [0.103125   0.27083333 0.090625   0.3125    ]\n",
      "Q values:  tensor([[-31.5350, -34.3778, -32.0978, -30.5776, -32.6674, -31.4032]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18183 1317 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  29\n",
      "393 22 False\n",
      "x_t:  1 [0.384375   0.34166667 0.140625   0.39583333]\n",
      "Q values:  tensor([[-32.3512, -31.6431, -32.7461, -31.6648, -35.6668, -33.6139]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1628 744 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2336\n",
      "394 0 False\n",
      "x_t:  3 [0.078125   0.2375     0.075      0.24583333]\n",
      "Q values:  tensor([[-25.0103, -25.8765, -25.8774, -23.7211, -26.3208, -24.1967]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26097 1255 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 394: ep_len:1255 episode reward: total was -765.900000. running mean: -210.231638\n",
      "startIDX:  198\n",
      "394 1 True\n",
      "x_t:  2 [0.21875    0.37083333 0.146875   0.425     ]\n",
      "Q values:  tensor([[-27.8587, -30.6804, -28.7513, -28.9729, -33.3502, -29.0542]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27467 873 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 394: ep_len:873 episode reward: total was -508.600000. running mean: -213.215322\n",
      "startIDX:  2686\n",
      "394 5 False\n",
      "x_t:  1 [0.071875 0.3625   0.196875 0.5     ]\n",
      "Q values:  tensor([[-31.1760, -30.2731, -31.2115, -30.9430, -34.1006, -30.2870]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22112 232 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 394: ep_len:232 episode reward: total was -116.500000. running mean: -212.248169\n",
      "startIDX:  869\n",
      "394 10 True\n",
      "x_t:  0 [0.81875    0.39166667 0.1125     0.32083333]\n",
      "Q values:  tensor([[-31.5505, -30.2496, -31.5096, -30.6410, -31.5781, -30.1472]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8115 472 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 394: ep_len:472 episode reward: total was -272.000000. running mean: -212.845687\n",
      "startIDX:  347\n",
      "394 12 False\n",
      "x_t:  4 [0.09375    0.425      0.096875   0.37916667]\n",
      "Q values:  tensor([[-25.5509, -27.2896, -26.3477, -27.6774, -25.3505, -25.3867]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7192 720 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 394: ep_len:720 episode reward: total was -357.900000. running mean: -214.296230\n",
      "startIDX:  743\n",
      "394 15 False\n",
      "x_t:  2 [0.290625   0.40416667 0.071875   0.29583333]\n",
      "Q values:  tensor([[-26.1410, -28.8802, -25.5272, -29.1862, -28.7903, -26.5448]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6046 408 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 394: ep_len:408 episode reward: total was -247.300000. running mean: -214.626268\n",
      "startIDX:  2432\n",
      "394 22 True\n",
      "x_t:  2 [0.88125 0.4     0.08125 0.2125 ]\n",
      "Q values:  tensor([[-31.2869, -29.9890, -31.6927, -30.6719, -29.7311, -28.8490]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23628 331 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 394: ep_len:331 episode reward: total was -150.100000. running mean: -213.981005\n",
      "startIDX:  2012\n",
      "395 0 False\n",
      "x_t:  0 [0.9375     0.4        0.059375   0.35416667]\n",
      "Q values:  tensor([[-20.8991, -20.9900, -24.0694, -23.2722, -22.7868, -21.0889]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20626 848 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  588\n",
      "395 1 False\n",
      "x_t:  3 [0.0625     0.22916667 0.059375   0.28333333]\n",
      "Q values:  tensor([[-18.8803, -18.7714, -19.9078, -18.2135, -18.7559, -18.4757]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34302 1794 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1727\n",
      "395 5 False\n",
      "x_t:  1 [0.896875   0.27083333 0.059375   0.32916667]\n",
      "Q values:  tensor([[-19.6034, -18.8775, -20.4215, -19.0184, -19.2865, -19.1059]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14922 591 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2236\n",
      "395 10 False\n",
      "x_t:  0 [0.7375     0.39166667 0.065625   0.32916667]\n",
      "Q values:  tensor([[-15.6128, -17.4290, -16.1934, -15.6766, -17.3550, -15.9018]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19972 516 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1804\n",
      "395 12 False\n",
      "x_t:  0 [0.471875   0.4125     0.075      0.34583333]\n",
      "Q values:  tensor([[-11.7180, -12.8376, -13.7791, -13.2386, -11.8642, -11.9448]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21146 611 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  564\n",
      "395 15 True\n",
      "x_t:  1 [0.95625    0.29166667 0.040625   0.2875    ]\n",
      "Q values:  tensor([[-11.7980, -11.7768, -12.2502, -11.5009, -12.0128, -10.2820]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5160 707 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1025\n",
      "395 22 True\n",
      "x_t:  0 [0.615625   0.4125     0.090625   0.31666667]\n",
      "Q values:  tensor([[-13.2430, -12.8087, -12.8428, -12.1337, -11.4315, -12.2136]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10451 447 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  520\n",
      "396 0 True\n",
      "x_t:  3 [0.65       0.35833333 0.134375   0.45416667]\n",
      "Q values:  tensor([[-6.9731, -7.6064, -7.8151, -7.8702, -7.8540, -7.0022]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7011 1022 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 396: ep_len:1022 episode reward: total was -192.500000. running mean: -216.852751\n",
      "startIDX:  987\n",
      "396 1 True\n",
      "x_t:  3 [0.790625   0.29583333 0.1125     0.42916667]\n",
      "Q values:  tensor([[ -9.5075, -10.0060,  -9.4749,  -9.5161, -10.2885,  -8.2551]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35908 242 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 396: ep_len:242 episode reward: total was 1.100000. running mean: -214.673223\n",
      "startIDX:  925\n",
      "396 5 True\n",
      "x_t:  3 [0.828125   0.3375     0.1625     0.40416667]\n",
      "Q values:  tensor([[-11.4381, -10.6796, -11.6383, -10.1159, -10.8449,  -9.9948]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10486 219 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 396: ep_len:219 episode reward: total was 47.700000. running mean: -212.049491\n",
      "startIDX:  2276\n",
      "396 10 False\n",
      "x_t:  1 [0.759375   0.2875     0.096875   0.32916667]\n",
      "Q values:  tensor([[-8.1839, -7.1005, -8.5656, -8.0175, -7.3536, -7.8240]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22483 1246 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 396: ep_len:1246 episode reward: total was -119.000000. running mean: -211.118996\n",
      "startIDX:  291\n",
      "396 12 True\n",
      "x_t:  4 [0.334375 0.3875   0.109375 0.275   ]\n",
      "Q values:  tensor([[-8.0264, -7.1730, -8.1085, -7.3570, -8.1809, -6.7548]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7261 788 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 396: ep_len:788 episode reward: total was -97.500000. running mean: -209.982806\n",
      "startIDX:  2797\n",
      "396 15 True\n",
      "x_t:  1 [0.5875     0.32916667 0.165625   0.47916667]\n",
      "Q values:  tensor([[-8.9979, -7.7642, -9.0295, -8.7767, -9.1162, -7.6184]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22087 282 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 396: ep_len:282 episode reward: total was -62.400000. running mean: -208.506978\n",
      "startIDX:  2455\n",
      "396 22 True\n",
      "x_t:  3 [0.14375    0.25       0.071875   0.26666667]\n",
      "Q values:  tensor([[-8.1567, -8.8464, -7.9759, -8.2876, -8.2689, -6.8394]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26202 1618 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 396: ep_len:1618 episode reward: total was -283.400000. running mean: -209.255908\n",
      "startIDX:  982\n",
      "397 0 True\n",
      "x_t:  2 [0.76875    0.40833333 0.096875   0.2875    ]\n",
      "Q values:  tensor([[-7.1405, -7.2243, -7.4280, -7.4637, -6.3963, -6.3526]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12635 1134 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  95\n",
      "397 1 True\n",
      "x_t:  2 [0.0625  0.3625  0.11875 0.4625 ]\n",
      "Q values:  tensor([[-7.4908, -7.7229, -7.4863, -7.7893, -7.0710, -6.6732]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27441 1032 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2679\n",
      "397 5 True\n",
      "x_t:  1 [0.5        0.3125     0.09375    0.52083333]\n",
      "Q values:  tensor([[-6.5260, -5.5939, -6.6618, -7.1753, -5.6634, -6.0577]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22146 258 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2571\n",
      "startIDX:  1207\n",
      "397 12 True\n",
      "x_t:  4 [0.39375    0.37916667 0.084375   0.30416667]\n",
      "Q values:  tensor([[-5.0001, -5.2727, -5.5107, -5.8004, -5.1813, -4.6013]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17445 526 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1296\n",
      "397 15 True\n",
      "x_t:  3 [0.8375     0.33333333 0.08125    0.3875    ]\n",
      "Q values:  tensor([[-4.8230, -5.2267, -5.3815, -5.4769, -5.0460, -4.1647]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10344 220 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2894\n",
      "startIDX:  2141\n",
      "398 0 True\n",
      "x_t:  1 [0.69375    0.33333333 0.225      0.50416667]\n",
      "Q values:  tensor([[-7.6024, -6.8007, -7.1898, -7.0621, -6.4810, -5.9920]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22929 1126 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 398: ep_len:1126 episode reward: total was -107.400000. running mean: -197.568621\n",
      "startIDX:  658\n",
      "398 1 True\n",
      "x_t:  2 [0.290625   0.375      0.071875   0.30416667]\n",
      "Q values:  tensor([[-5.0922, -4.6474, -5.1318, -4.8348, -5.1852, -4.5380]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31547 387 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 398: ep_len:387 episode reward: total was -86.400000. running mean: -196.456935\n",
      "startIDX:  1013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398 5 True\n",
      "x_t:  3 [0.528125   0.29166667 0.078125   0.32916667]\n",
      "Q values:  tensor([[-5.6990, -5.2559, -5.3900, -5.4333, -5.5919, -4.5315]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10527 217 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 398: ep_len:217 episode reward: total was 16.700000. running mean: -194.325366\n",
      "startIDX:  1438\n",
      "398 10 True\n",
      "x_t:  4 [0.00625    0.37083333 0.121875   0.26666667]\n",
      "Q values:  tensor([[-7.0880, -6.0004, -7.3027, -7.2126, -6.7460, -6.2358]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15706 515 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 398: ep_len:515 episode reward: total was -52.000000. running mean: -192.902112\n",
      "startIDX:  394\n",
      "398 12 True\n",
      "x_t:  3 [0.759375   0.34166667 0.090625   0.40833333]\n",
      "Q values:  tensor([[-6.1458, -5.9970, -6.5062, -6.1356, -5.7932, -5.2805]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7725 276 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 398: ep_len:276 episode reward: total was -6.500000. running mean: -191.038091\n",
      "startIDX:  1218\n",
      "398 15 True\n",
      "x_t:  4 [0.403125   0.36666667 0.0625     0.28333333]\n",
      "Q values:  tensor([[-6.3315, -6.8136, -6.9758, -7.1056, -7.0556, -5.5367]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9886 545 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 398: ep_len:545 episode reward: total was -105.200000. running mean: -190.179710\n",
      "startIDX:  2892\n",
      "ep 398: ep_len:65 episode reward: total was 43.000000. running mean: -187.847913\n",
      "startIDX:  1298\n",
      "399 0 True\n",
      "x_t:  3 [0.678125   0.325      0.13125    0.40416667]\n",
      "Q values:  tensor([[-6.2546, -6.6673, -7.3467, -6.7167, -6.6936, -5.5069]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15285 1278 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  745\n",
      "399 1 True\n",
      "x_t:  3 [0.8125     0.31666667 0.11875    0.49166667]\n",
      "Q values:  tensor([[-6.8662, -6.7098, -6.6965, -6.8251, -7.1102, -5.6046]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34458 1445 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2964\n",
      "startIDX:  950\n",
      "399 10 False\n",
      "x_t:  1 [0.65       0.29583333 0.1        0.33333333]\n",
      "Q values:  tensor([[-7.6712, -7.3849, -8.6458, -9.0218, -8.5466, -7.5476]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11359 1590 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  89\n",
      "399 12 True\n",
      "x_t:  1 [0.809375   0.30416667 0.096875   0.4375    ]\n",
      "Q values:  tensor([[-7.6569, -6.8316, -7.0463, -7.8826, -7.5554, -6.3679]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2224 607 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1291\n",
      "399 15 True\n",
      "x_t:  3 [0.425      0.2875     0.084375   0.30833333]\n",
      "Q values:  tensor([[-6.0903, -5.9582, -5.9993, -6.3535, -6.4188, -5.1951]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10416 267 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  79\n",
      "399 22 False\n",
      "x_t:  1 [0.90625  0.2875   0.090625 0.4125  ]\n",
      "Q values:  tensor([[-6.2350, -5.9788, -7.1082, -6.6797, -6.4212, -6.0724]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1576 680 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  3413.7240839004517\n",
      "startIDX:  1443\n",
      "400 0 False\n",
      "x_t:  4 [0.153125   0.3875     0.10625    0.27916667]\n",
      "Q values:  tensor([[-7.1950, -7.2394, -7.5903, -7.6091, -6.3729, -6.4317]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16308 532 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 400: ep_len:532 episode reward: total was -57.200000. running mean: -180.313996\n",
      "startIDX:  660\n",
      "400 1 True\n",
      "x_t:  2 [0.03125    0.3875     0.10625    0.30416667]\n",
      "Q values:  tensor([[-7.0358, -7.2890, -7.5867, -6.9999, -6.7086, -6.3820]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31586 404 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 400: ep_len:404 episode reward: total was -114.200000. running mean: -179.652856\n",
      "startIDX:  3035\n",
      "ep 400: ep_len:20 episode reward: total was 12.000000. running mean: -177.736328\n",
      "startIDX:  1052\n",
      "400 10 True\n",
      "x_t:  1 [0.534375   0.29583333 0.06875    0.35      ]\n",
      "Q values:  tensor([[ -9.8914,  -9.9075, -10.0787, -10.6766, -10.7586,  -8.8779]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11375 1523 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 400: ep_len:1523 episode reward: total was -193.900000. running mean: -177.897964\n",
      "startIDX:  1398\n",
      "400 12 True\n",
      "x_t:  3 [0.590625   0.32916667 0.084375   0.38333333]\n",
      "Q values:  tensor([[-6.0005, -6.1857, -6.2335, -6.2555, -6.2269, -5.5130]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17877 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 400: ep_len:201 episode reward: total was -1.200000. running mean: -176.130985\n",
      "startIDX:  2826\n",
      "400 15 True\n",
      "x_t:  1 [0.859375   0.30416667 0.13125    0.475     ]\n",
      "Q values:  tensor([[-5.6423, -5.9807, -5.9668, -6.5136, -6.1091, -5.3526]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22111 290 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 400: ep_len:290 episode reward: total was -36.600000. running mean: -174.735675\n",
      "startIDX:  2016\n",
      "400 22 False\n",
      "x_t:  1 [0.046875   0.3625     0.090625   0.39166667]\n",
      "Q values:  tensor([[-5.9227, -5.6724, -6.3708, -5.9830, -6.2599, -5.7307]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18993 243 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 400: ep_len:243 episode reward: total was -7.900000. running mean: -173.067318\n",
      "startIDX:  48\n",
      "401 0 False\n",
      "x_t:  1 [0.85       0.3        0.146875   0.42916667]\n",
      "Q values:  tensor([[-5.4628, -4.7447, -5.7570, -5.5151, -5.1375, -4.7636]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1609 740 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  915\n",
      "401 1 True\n",
      "x_t:  4 [0.065625   0.3875     0.115625   0.41666667]\n",
      "Q values:  tensor([[-6.5053, -6.4943, -6.4037, -6.6589, -6.5810, -5.9496]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35431 522 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1709\n",
      "401 5 True\n",
      "x_t:  2 [0.8375     0.4        0.071875   0.24583333]\n",
      "Q values:  tensor([[-7.3920, -6.4453, -5.6252, -6.5459, -6.4340, -5.2769]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15643 962 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2526\n",
      "401 10 True\n",
      "x_t:  1 [0.8875  0.2875  0.10625 0.3375 ]\n",
      "Q values:  tensor([[-6.8012, -6.9827, -6.7275, -7.3758, -7.4499, -6.0644]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22469 1140 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1865\n",
      "401 12 True\n",
      "x_t:  0 [0.45625    0.40833333 0.0875     0.37083333]\n",
      "Q values:  tensor([[-5.6900, -5.6253, -6.3671, -6.1693, -6.1329, -4.6974]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23026 945 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2861\n",
      "401 15 True\n",
      "x_t:  0 [0.253125 0.425    0.065625 0.275   ]\n",
      "Q values:  tensor([[-5.1464, -5.5527, -6.1051, -5.5970, -6.2472, -4.7124]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23168 791 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1500\n",
      "401 22 True\n",
      "x_t:  4 [0.21875    0.39166667 0.109375   0.2875    ]\n",
      "Q values:  tensor([[-5.3903, -4.9194, -5.2477, -5.2449, -5.0583, -4.2048]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16361 547 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2516\n",
      "ep 402: ep_len:35 episode reward: total was 25.000000. running mean: -164.277729\n",
      "startIDX:  1110\n",
      "ep 402: ep_len:208 episode reward: total was -64.300000. running mean: -163.277952\n",
      "startIDX:  2184\n",
      "402 5 True\n",
      "x_t:  4 [0.378125   0.39583333 0.1375     0.3875    ]\n",
      "Q values:  tensor([[-4.8066, -4.4191, -4.8598, -4.6920, -4.9429, -4.0639]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19497 577 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 402: ep_len:577 episode reward: total was -60.400000. running mean: -162.249172\n",
      "startIDX:  2319\n",
      "402 10 False\n",
      "x_t:  1 [0.65625    0.29166667 0.0875     0.325     ]\n",
      "Q values:  tensor([[-3.7371, -3.3188, -4.1178, -3.7472, -4.0160, -3.3841]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22495 1231 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 402: ep_len:1231 episode reward: total was -3.500000. running mean: -160.661680\n",
      "startIDX:  30\n",
      "402 12 False\n",
      "x_t:  1 [0.790625 0.3125   0.078125 0.425   ]\n",
      "Q values:  tensor([[-4.4271, -4.0282, -4.3456, -4.7007, -4.5987, -4.0599]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2226 655 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 402: ep_len:655 episode reward: total was -23.400000. running mean: -159.289063\n",
      "startIDX:  723\n",
      "402 15 True\n",
      "x_t:  2 [0.734375   0.40416667 0.08125    0.29166667]\n",
      "Q values:  tensor([[-4.2050, -3.9325, -3.8919, -4.0237, -4.0234, -3.3133]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5979 372 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 402: ep_len:372 episode reward: total was -38.800000. running mean: -158.084173\n",
      "startIDX:  72\n",
      "402 22 True\n",
      "x_t:  1 [0.90625  0.2875   0.090625 0.4125  ]\n",
      "Q values:  tensor([[-4.2447, -4.4009, -3.9912, -4.2948, -4.0801, -3.4071]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1576 693 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 402: ep_len:693 episode reward: total was -51.800000. running mean: -157.021331\n",
      "startIDX:  1149\n",
      "403 0 True\n",
      "x_t:  2 [0.778125   0.4125     0.103125   0.27083333]\n",
      "Q values:  tensor([[-4.1032, -4.0062, -4.6568, -4.0624, -4.6514, -3.6527]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12631 307 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  792\n",
      "403 1 True\n",
      "x_t:  3 [0.10625    0.2375     0.0875     0.30416667]\n",
      "Q values:  tensor([[-4.2661, -4.3142, -4.3169, -4.3415, -4.2611, -3.5912]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34323 1373 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  845\n",
      "403 5 True\n",
      "x_t:  4 [0.278125   0.39166667 0.090625   0.37916667]\n",
      "Q values:  tensor([[-5.2425, -4.9008, -4.8323, -5.0311, -4.7967, -3.8315]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10048 598 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1510\n",
      "403 10 True\n",
      "x_t:  3 [0.353125   0.26666667 0.09375    0.3125    ]\n",
      "Q values:  tensor([[-4.6916, -4.5281, -4.1503, -4.4000, -5.0262, -3.6283]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16481 366 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  67\n",
      "403 12 True\n",
      "x_t:  2 [0.4125     0.40833333 0.08125    0.25      ]\n",
      "Q values:  tensor([[-3.4746, -3.7272, -3.8416, -3.8766, -4.0099, -3.2475]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2868 956 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2340\n",
      "403 15 True\n",
      "x_t:  4 [0.15625    0.40833333 0.096875   0.34166667]\n",
      "Q values:  tensor([[-4.9994, -4.7732, -4.8733, -5.0677, -4.4170, -4.1867]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19270 537 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2234\n",
      "403 22 True\n",
      "x_t:  1 [0.121875   0.36666667 0.10625    0.49166667]\n",
      "Q values:  tensor([[-3.7802, -3.7860, -4.3015, -4.0808, -3.6855, -3.2451]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 23001 1154 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  28\n",
      "404 0 True\n",
      "x_t:  1 [0.309375   0.34166667 0.15       0.44166667]\n",
      "Q values:  tensor([[-4.1519, -3.8879, -4.2618, -4.1851, -4.2118, -3.4862]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1668 771 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 404: ep_len:771 episode reward: total was -47.700000. running mean: -147.828233\n",
      "startIDX:  589\n",
      "404 1 True\n",
      "x_t:  3 [0.403125   0.28333333 0.1125     0.375     ]\n",
      "Q values:  tensor([[-3.6595, -3.4988, -3.8473, -3.7780, -3.9212, -3.3636]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34397 1854 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 404: ep_len:1854 episode reward: total was -214.300000. running mean: -148.492951\n",
      "startIDX:  1619\n",
      "404 5 True\n",
      "x_t:  1 [0.896875   0.27083333 0.059375   0.32916667]\n",
      "Q values:  tensor([[-4.5496, -4.1445, -4.4456, -4.3863, -4.3557, -3.4587]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14922 666 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 404: ep_len:666 episode reward: total was -29.700000. running mean: -147.305022\n",
      "startIDX:  1692\n",
      "404 10 True\n",
      "x_t:  3 [0.75625    0.30833333 0.115625   0.39583333]\n",
      "Q values:  tensor([[-4.2416, -4.2032, -4.3394, -4.5498, -4.4769, -3.4855]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16415 243 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 404: ep_len:243 episode reward: total was 1.300000. running mean: -145.818971\n",
      "startIDX:  1602\n",
      "404 12 True\n",
      "x_t:  2 [0.0375     0.40833333 0.071875   0.2875    ]\n",
      "Q values:  tensor([[-4.5378, -4.1109, -4.0097, -3.9931, -4.4682, -3.3656]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19384 702 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 404: ep_len:702 episode reward: total was -31.800000. running mean: -144.678782\n",
      "startIDX:  2660\n",
      "404 15 True\n",
      "x_t:  2 [0.5        0.40416667 0.1        0.3125    ]\n",
      "Q values:  tensor([[-4.8452, -4.5927, -5.1903, -5.1018, -4.5912, -4.1814]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21541 898 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 404: ep_len:898 episode reward: total was -69.100000. running mean: -143.922994\n",
      "startIDX:  2409\n",
      "404 22 False\n",
      "x_t:  2 [0.609375   0.40833333 0.096875   0.25416667]\n",
      "Q values:  tensor([[-4.5746, -4.3142, -3.8068, -4.8705, -4.7518, -3.8818]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23668 364 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 404: ep_len:364 episode reward: total was -70.500000. running mean: -143.188764\n",
      "startIDX:  1016\n",
      "405 0 True\n",
      "x_t:  1 [0.734375   0.30416667 0.115625   0.45416667]\n",
      "Q values:  tensor([[-4.7748, -4.5302, -4.9320, -5.0500, -4.8787, -3.8556]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11961 788 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  469\n",
      "405 1 True\n",
      "x_t:  1 [0.084375   0.32083333 0.18125    0.53333333]\n",
      "Q values:  tensor([[-4.5059, -4.5230, -4.4122, -4.4376, -4.3401, -3.7986]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30757 812 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  721\n",
      "405 5 True\n",
      "x_t:  3 [0.278125   0.2875     0.11875    0.36666667]\n",
      "Q values:  tensor([[-5.4173, -5.3654, -6.0126, -5.5928, -5.8320, -4.8689]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8802 1333 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2361\n",
      "405 10 True\n",
      "x_t:  1 [0.08125    0.34583333 0.140625   0.37916667]\n",
      "Q values:  tensor([[-5.4828, -5.1461, -5.0445, -5.4740, -5.4661, -4.6113]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22554 1260 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  139\n",
      "405 12 True\n",
      "x_t:  3 [0.296875   0.27916667 0.0625     0.30416667]\n",
      "Q values:  tensor([[-6.5891, -6.4003, -6.6333, -6.1894, -7.2631, -5.5900]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5708 1757 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1670\n",
      "405 15 True\n",
      "x_t:  1 [0.6625     0.3125     0.065625   0.35416667]\n",
      "Q values:  tensor([[-4.3367, -4.4494, -4.2091, -4.9154, -4.5548, -3.6406]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12517 284 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  857\n",
      "405 22 True\n",
      "x_t:  0 [0.628125   0.4125     0.08125    0.30833333]\n",
      "Q values:  tensor([[-5.7585, -5.5633, -5.9293, -6.1597, -5.6767, -4.6613]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10449 757 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  345\n",
      "406 0 True\n",
      "x_t:  3 [0.40625    0.3        0.096875   0.32083333]\n",
      "Q values:  tensor([[-5.1306, -4.9772, -5.2538, -5.3319, -5.5759, -4.5049]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4938 1259 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 406: ep_len:1259 episode reward: total was -113.400000. running mean: -138.244846\n",
      "startIDX:  782\n",
      "406 1 True\n",
      "x_t:  3 [0.665625   0.30416667 0.1125     0.4625    ]\n",
      "Q values:  tensor([[-7.0855, -6.2633, -6.2443, -6.0137, -6.5355, -5.1226]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34440 1413 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 406: ep_len:1413 episode reward: total was -149.600000. running mean: -138.358397\n",
      "startIDX:  1204\n",
      "406 5 True\n",
      "x_t:  2 [0.75625    0.39166667 0.071875   0.29583333]\n",
      "Q values:  tensor([[-4.3484, -4.4569, -4.1621, -4.4812, -4.5252, -3.6933]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12103 789 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 406: ep_len:789 episode reward: total was -60.300000. running mean: -137.577813\n",
      "startIDX:  2238\n",
      "406 10 True\n",
      "x_t:  0 [0.803125   0.3875     0.06875    0.34166667]\n",
      "Q values:  tensor([[-5.3152, -4.4795, -5.3258, -5.0932, -5.1183, -4.3281]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19955 501 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 406: ep_len:501 episode reward: total was -50.200000. running mean: -136.704035\n",
      "startIDX:  1023\n",
      "406 12 True\n",
      "x_t:  2 [0.45       0.40833333 0.04375    0.25      ]\n",
      "Q values:  tensor([[-5.3589, -5.1357, -5.8138, -5.5661, -5.5757, -4.6332]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13631 329 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 406: ep_len:329 episode reward: total was -48.600000. running mean: -135.822995\n",
      "startIDX:  529\n",
      "406 15 False\n",
      "x_t:  2 [0.80625    0.40416667 0.075      0.29583333]\n",
      "Q values:  tensor([[-5.9653, -5.7903, -4.8133, -5.9544, -5.8997, -4.8329]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5966 1093 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 406: ep_len:1093 episode reward: total was -116.800000. running mean: -135.632765\n",
      "startIDX:  2869\n",
      "ep 406: ep_len:75 episode reward: total was 35.000000. running mean: -133.926437\n",
      "startIDX:  809\n",
      "407 0 True\n",
      "x_t:  1 [0.221875   0.34583333 0.121875   0.40416667]\n",
      "Q values:  tensor([[-5.8064, -5.0831, -5.5965, -5.9613, -5.8116, -4.5727]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9432 246 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  792\n",
      "407 1 True\n",
      "x_t:  3 [0.303125   0.2625     0.0875     0.34583333]\n",
      "Q values:  tensor([[-9.2477, -8.7819, -8.9597, -9.0827, -9.3589, -7.8513]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34371 1393 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  2305\n",
      "407 5 False\n",
      "x_t:  3 [0.3        0.2625     0.08125    0.33333333]\n",
      "Q values:  tensor([[1.8286, 0.0350, 1.4409, 2.8615, 1.2407, 1.0760]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 19959 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2084\n",
      "407 10 True\n",
      "x_t:  1 [0.48125    0.29583333 0.071875   0.34583333]\n",
      "Q values:  tensor([[-6.2657, -5.5630, -5.9919, -5.3750, -5.0989, -4.4727]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18876 299 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  417\n",
      "407 12 True\n",
      "x_t:  3 [0.265625   0.27916667 0.0875     0.29166667]\n",
      "Q values:  tensor([[-5.4425, -6.0218, -5.4742, -6.1734, -5.5016, -4.6033]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7795 286 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2463\n",
      "407 15 True\n",
      "x_t:  3 [0.6125     0.30833333 0.1        0.35      ]\n",
      "Q values:  tensor([[-5.1731, -4.9973, -4.9216, -4.6430, -5.2565, -3.9111]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19695 221 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  588\n",
      "407 22 False\n",
      "x_t:  3 [0.775      0.33333333 0.134375   0.39583333]\n",
      "Q values:  tensor([[3.8982, 3.6629, 3.3501, 4.1375, 3.6869, 3.8410]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 7063 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1053\n",
      "408 0 True\n",
      "x_t:  1 [0.15625    0.3625     0.109375   0.49166667]\n",
      "Q values:  tensor([[-6.2932, -6.2652, -6.6612, -6.7624, -7.1219, -5.1232]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12016 793 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 408: ep_len:793 episode reward: total was -77.200000. running mean: -126.407284\n",
      "startIDX:  442\n",
      "408 1 True\n",
      "x_t:  1 [0.484375   0.29583333 0.18125    0.47083333]\n",
      "Q values:  tensor([[-6.1471, -6.1382, -6.5581, -6.3481, -6.2508, -5.2052]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30720 805 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 408: ep_len:805 episode reward: total was -33.200000. running mean: -125.475211\n",
      "startIDX:  2320\n",
      "408 5 True\n",
      "x_t:  2 [0.28125    0.39583333 0.09375    0.27083333]\n",
      "Q values:  tensor([[-6.3128, -6.2579, -6.5363, -6.7804, -6.2517, -5.3752]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21595 998 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 408: ep_len:998 episode reward: total was -138.400000. running mean: -125.604459\n",
      "startIDX:  1302\n",
      "408 10 True\n",
      "x_t:  3 [0.475      0.27916667 0.109375   0.34583333]\n",
      "Q values:  tensor([[-7.5224, -6.9484, -7.0351, -7.1930, -6.9933, -5.7589]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14683 1241 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 408: ep_len:1241 episode reward: total was -128.600000. running mean: -125.634415\n",
      "startIDX:  1007\n",
      "408 12 True\n",
      "x_t:  2 [0.828125   0.40833333 0.08125    0.24166667]\n",
      "Q values:  tensor([[-5.0376, -4.9607, -5.5524, -5.1562, -5.3651, -4.1428]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13570 305 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 408: ep_len:305 episode reward: total was -38.300000. running mean: -124.761071\n",
      "startIDX:  60\n",
      "408 15 True\n",
      "x_t:  3 [0.50625    0.31666667 0.1125     0.35833333]\n",
      "Q values:  tensor([[-4.7375, -4.4613, -4.6892, -4.3008, -4.6775, -3.7964]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 569 256 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 408: ep_len:256 episode reward: total was -41.100000. running mean: -123.924460\n",
      "startIDX:  841\n",
      "408 22 True\n",
      "x_t:  1 [0.221875   0.34583333 0.090625   0.3875    ]\n",
      "Q values:  tensor([[-4.5451, -4.5764, -4.8238, -4.6920, -4.5613, -3.9380]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9505 278 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 408: ep_len:278 episode reward: total was 1.200000. running mean: -122.673215\n",
      "startIDX:  1044\n",
      "409 0 True\n",
      "x_t:  1 [0.396875   0.34166667 0.171875   0.45833333]\n",
      "Q values:  tensor([[-6.3300, -6.0360, -6.1754, -6.4632, -5.4128, -5.3504]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11991 796 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  630\n",
      "409 1 True\n",
      "x_t:  2 [0.46875 0.3875  0.075   0.3    ]\n",
      "Q values:  tensor([[-5.1905, -5.1893, -5.5460, -5.8000, -4.8012, -4.6087]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31519 397 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1857\n",
      "409 5 True\n",
      "x_t:  2 [0.84375    0.40416667 0.08125    0.2375    ]\n",
      "Q values:  tensor([[-5.6410, -5.7813, -5.5938, -5.5352, -5.5418, -4.5597]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15641 341 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1384\n",
      "409 10 True\n",
      "x_t:  4 [0.0625  0.3625  0.06875 0.275  ]\n",
      "Q values:  tensor([[-5.1969, -4.8419, -5.2769, -4.6001, -4.4740, -4.3022]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15712 542 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  896\n",
      "409 12 True\n",
      "x_t:  1 [0.053125 0.3875   0.146875 0.4875  ]\n",
      "Q values:  tensor([[-6.2014, -5.8757, -6.0402, -6.4713, -6.5364, -5.4104]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12972 651 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2822\n",
      "409 15 True\n",
      "x_t:  0 [0.584375   0.4125     0.128125   0.35833333]\n",
      "Q values:  tensor([[-6.7355, -5.8887, -6.1106, -5.8381, -6.6353, -5.1145]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23114 798 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  907\n",
      "409 22 True\n",
      "x_t:  1 [0.0125     0.37083333 0.175      0.39583333]\n",
      "Q values:  tensor([[-4.8184, -4.3650, -4.4774, -4.8603, -4.5066, -3.8892]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9486 238 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  3510.014646291733\n",
      "startIDX:  1009\n",
      "410 0 True\n",
      "x_t:  1 [0.525      0.33333333 0.178125   0.45      ]\n",
      "Q values:  tensor([[-6.8488, -6.3097, -6.4237, -6.7116, -6.3907, -5.1833]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11981 787 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 410: ep_len:787 episode reward: total was -34.100000. running mean: -116.107667\n",
      "startIDX:  293\n",
      "410 1 True\n",
      "x_t:  1 [0.578125   0.30833333 0.23125    0.56666667]\n",
      "Q values:  tensor([[-6.1564, -5.3249, -5.4800, -6.0003, -6.1762, -4.8735]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28103 338 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 410: ep_len:338 episode reward: total was 31.900000. running mean: -114.627590\n",
      "startIDX:  2617\n",
      "410 5 True\n",
      "x_t:  1 [0.003125   0.34583333 0.121875   0.51666667]\n",
      "Q values:  tensor([[-5.1931, -5.0442, -4.5564, -5.3845, -5.1845, -4.1890]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22105 269 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 410: ep_len:269 episode reward: total was 37.500000. running mean: -113.106314\n",
      "startIDX:  1577\n",
      "410 10 True\n",
      "x_t:  3 [0.065625   0.22916667 0.05625    0.24583333]\n",
      "Q values:  tensor([[-5.0883, -4.4396, -4.5633, -4.5485, -4.4142, -3.9066]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16566 387 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 410: ep_len:387 episode reward: total was -110.100000. running mean: -113.076251\n",
      "startIDX:  432\n",
      "410 12 True\n",
      "x_t:  3 [0.059375   0.24583333 0.05625    0.25      ]\n",
      "Q values:  tensor([[-4.5212, -4.2110, -3.8476, -3.6852, -4.3067, -3.5056]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7848 313 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 410: ep_len:313 episode reward: total was -67.300000. running mean: -112.618488\n",
      "startIDX:  1019\n",
      "410 15 True\n",
      "x_t:  4 [0.3875     0.35416667 0.06875    0.2375    ]\n",
      "Q values:  tensor([[-5.4832, -5.6639, -5.9130, -5.9832, -5.5442, -4.6988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9935 691 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 410: ep_len:691 episode reward: total was -28.300000. running mean: -111.775304\n",
      "startIDX:  1803\n",
      "410 22 True\n",
      "x_t:  2 [0.159375   0.40833333 0.0625     0.2625    ]\n",
      "Q values:  tensor([[-6.0502, -5.5135, -5.2223, -5.6485, -5.2567, -4.3968]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18477 822 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 410: ep_len:822 episode reward: total was -3.400000. running mean: -110.691551\n",
      "startIDX:  980\n",
      "411 0 True\n",
      "x_t:  1 [0.703125   0.3125     0.146875   0.44166667]\n",
      "Q values:  tensor([[-6.5872, -5.4925, -6.3936, -6.1609, -6.5934, -5.5180]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11962 787 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  640\n",
      "411 1 True\n",
      "x_t:  2 [0.8125     0.37916667 0.08125    0.3125    ]\n",
      "Q values:  tensor([[-6.1378, -5.4531, -6.2096, -6.2934, -6.1892, -4.8373]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31463 364 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1896\n",
      "411 5 True\n",
      "x_t:  2 [0.6375 0.4    0.0875 0.25  ]\n",
      "Q values:  tensor([[-5.8750, -5.4091, -5.7774, -6.0608, -5.8493, -4.6775]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15675 326 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  664\n",
      "411 10 True\n",
      "x_t:  2 [0.25625    0.40416667 0.103125   0.25833333]\n",
      "Q values:  tensor([[-5.1297, -5.0417, -5.0853, -5.5081, -5.0049, -4.0406]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6627 714 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  1835\n",
      "411 12 True\n",
      "x_t:  0 [0.421875   0.42083333 0.10625    0.3625    ]\n",
      "Q values:  tensor([[-9.9377, -8.7699, -8.9877, -8.9268, -9.2647, -7.5270]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23019 1532 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  282\n",
      "411 15 True\n",
      "x_t:  1 [0.25       0.36666667 0.184375   0.50416667]\n",
      "Q values:  tensor([[-5.8466, -5.8746, -6.3157, -6.0169, -5.8824, -4.9086]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2770 289 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1042\n",
      "411 22 True\n",
      "x_t:  0 [0.56875    0.40833333 0.071875   0.32083333]\n",
      "Q values:  tensor([[-4.2609, -4.1680, -4.3633, -3.9792, -4.4339, -3.3471]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10468 451 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1547\n",
      "412 0 True\n",
      "x_t:  3 [0.321875   0.275      0.084375   0.31666667]\n",
      "Q values:  tensor([[-5.2054, -5.1715, -5.0322, -5.3225, -5.1931, -4.1610]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16893 276 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 412: ep_len:276 episode reward: total was -99.200000. running mean: -106.785721\n",
      "startIDX:  617\n",
      "412 1 True\n",
      "x_t:  2 [0.078125   0.38333333 0.09375    0.31666667]\n",
      "Q values:  tensor([[-5.5585, -5.3044, -5.1901, -5.8503, -5.7004, -4.4680]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31579 432 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 412: ep_len:432 episode reward: total was -83.700000. running mean: -106.554864\n",
      "startIDX:  1636\n",
      "412 5 True\n",
      "x_t:  1 [0.753125   0.29166667 0.084375   0.3       ]\n",
      "Q values:  tensor([[-5.3335, -5.2372, -5.2912, -5.1858, -5.7424, -4.7166]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14939 666 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 412: ep_len:666 episode reward: total was -36.400000. running mean: -105.853315\n",
      "startIDX:  743\n",
      "412 10 True\n",
      "x_t:  1 [0.7625     0.2875     0.11875    0.34583333]\n",
      "Q values:  tensor([[-5.6927, -5.5283, -5.4247, -5.2078, -5.4625, -4.5922]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7193 268 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 412: ep_len:268 episode reward: total was -31.400000. running mean: -105.108782\n",
      "startIDX:  749\n",
      "412 12 True\n",
      "x_t:  1 [0.796875   0.3375     0.2        0.50833333]\n",
      "Q values:  tensor([[-3.6917, -4.1417, -4.2369, -3.8747, -4.3641, -3.3870]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10359 217 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 412: ep_len:217 episode reward: total was -25.700000. running mean: -104.314694\n",
      "startIDX:  715\n",
      "412 15 True\n",
      "x_t:  2 [0.7        0.40416667 0.109375   0.3       ]\n",
      "Q values:  tensor([[-4.6098, -4.2124, -4.6214, -4.8879, -4.3365, -4.0155]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5982 380 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 412: ep_len:380 episode reward: total was -59.100000. running mean: -103.862547\n",
      "startIDX:  2738\n",
      "412 22 True\n",
      "x_t:  4 [0.128125   0.39583333 0.1        0.30833333]\n",
      "Q values:  tensor([[-6.3629, -5.6514, -5.4950, -6.1638, -6.4319, -5.1573]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27283 501 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 412: ep_len:501 episode reward: total was -31.200000. running mean: -103.135922\n",
      "startIDX:  185\n",
      "413 0 True\n",
      "x_t:  2 [0.703125   0.40416667 0.059375   0.2875    ]\n",
      "Q values:  tensor([[-6.0026, -5.4529, -5.6797, -6.1086, -5.9074, -4.6883]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2341 355 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  148\n",
      "413 1 True\n",
      "x_t:  2 [0.6375     0.37083333 0.153125   0.44583333]\n",
      "Q values:  tensor([[-6.7143, -5.7615, -6.1138, -6.3837, -6.2357, -5.4727]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27522 924 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  748\n",
      "413 5 True\n",
      "x_t:  3 [0.190625   0.26666667 0.090625   0.34166667]\n",
      "Q values:  tensor([[-8.3312, -7.8965, -6.9173, -8.1116, -8.3431, -6.5435]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8782 1315 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2309\n",
      "startIDX:  305\n",
      "413 12 True\n",
      "x_t:  4 [0.29375    0.4125     0.140625   0.37083333]\n",
      "Q values:  tensor([[-5.3092, -4.7337, -4.8399, -4.9039, -5.2562, -4.3253]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7214 771 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1004\n",
      "413 15 True\n",
      "x_t:  3 [0.675    0.325    0.103125 0.3625  ]\n",
      "Q values:  tensor([[-6.8281, -6.4555, -6.4006, -5.9955, -6.9690, -5.0869]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10366 893 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1446\n",
      "413 22 True\n",
      "x_t:  4 [0.465625   0.37916667 0.08125    0.30416667]\n",
      "Q values:  tensor([[-6.9447, -5.8117, -6.2169, -6.6631, -6.4107, -5.0342]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16469 613 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2313\n",
      "414 0 True\n",
      "x_t:  3 [0.265625   0.2625     0.1        0.29583333]\n",
      "Q values:  tensor([[-7.8414, -7.4309, -6.7601, -7.0932, -8.0097, -6.1471]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26150 1271 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 414: ep_len:1271 episode reward: total was -92.600000. running mean: -100.754168\n",
      "startIDX:  359\n",
      "414 1 True\n",
      "x_t:  0 [0.46875    0.375      0.128125   0.46666667]\n",
      "Q values:  tensor([[-5.5075, -5.3553, -5.7632, -5.1456, -5.8556, -4.8459]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29179 833 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 414: ep_len:833 episode reward: total was -99.200000. running mean: -100.738626\n",
      "startIDX:  535\n",
      "414 5 True\n",
      "x_t:  2 [0.821875   0.3875     0.090625   0.25833333]\n",
      "Q values:  tensor([[-5.3282, -5.2080, -5.8291, -5.6222, -6.2699, -4.6572]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6032 487 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 414: ep_len:487 episode reward: total was -49.000000. running mean: -100.221240\n",
      "startIDX:  596\n",
      "414 10 True\n",
      "x_t:  2 [0.25       0.39166667 0.059375   0.27083333]\n",
      "Q values:  tensor([[-6.5204, -6.2894, -6.0649, -6.8354, -6.5679, -5.3274]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6622 752 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 414: ep_len:752 episode reward: total was -64.900000. running mean: -99.868028\n",
      "startIDX:  1923\n",
      "414 12 True\n",
      "x_t:  0 [0.45625    0.40833333 0.0875     0.37083333]\n",
      "Q values:  tensor([[-7.1844, -6.9323, -6.9840, -6.9744, -7.8132, -6.5751]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23026 928 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 414: ep_len:928 episode reward: total was -62.600000. running mean: -99.495347\n",
      "startIDX:  388\n",
      "414 15 True\n",
      "x_t:  0 [0.525      0.40833333 0.13125    0.4875    ]\n",
      "Q values:  tensor([[-5.8273, -6.0911, -6.0355, -5.7181, -6.1053, -4.7074]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3843 537 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 414: ep_len:537 episode reward: total was -141.100000. running mean: -99.911394\n",
      "startIDX:  1484\n",
      "414 22 True\n",
      "x_t:  4 [0.1125     0.38333333 0.065625   0.3125    ]\n",
      "Q values:  tensor([[-7.0154, -6.6037, -6.8389, -7.0446, -7.1716, -5.8201]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16340 537 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 414: ep_len:537 episode reward: total was -1.100000. running mean: -98.923280\n",
      "startIDX:  118\n",
      "415 0 False\n",
      "x_t:  1 [0.434375 0.325    0.10625  0.425   ]\n",
      "Q values:  tensor([[-6.3590, -4.9445, -5.6235, -6.3503, -5.9533, -5.0033]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1657 712 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  761\n",
      "415 1 True\n",
      "x_t:  3 [0.21875    0.25416667 0.1        0.325     ]\n",
      "Q values:  tensor([[-9.8644, -8.4794, -8.8852, -9.0626, -9.0624, -7.3012]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34355 1394 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  788\n",
      "415 5 True\n",
      "x_t:  4 [0.253125   0.39583333 0.11875    0.37083333]\n",
      "Q values:  tensor([[-5.7670, -5.4559, -5.7096, -5.9405, -5.7868, -4.3831]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10046 642 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2198\n",
      "415 10 True\n",
      "x_t:  0 [0.709375   0.4        0.078125   0.32083333]\n",
      "Q values:  tensor([[-7.1527, -6.8512, -7.1221, -7.1063, -6.3974, -5.4463]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19977 525 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  967\n",
      "415 12 False\n",
      "x_t:  1 [0.240625   0.39166667 0.140625   0.47916667]\n",
      "Q values:  tensor([[-5.7266, -4.8134, -6.0721, -5.5814, -5.8098, -5.1090]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12951 598 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1686\n",
      "415 15 False\n",
      "x_t:  1 [0.38125    0.32916667 0.125      0.36666667]\n",
      "Q values:  tensor([[-4.5136, -4.0997, -4.6748, -4.7078, -4.4331, -4.1408]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12489 260 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  81\n",
      "415 22 True\n",
      "x_t:  1 [0.74375    0.30833333 0.140625   0.39583333]\n",
      "Q values:  tensor([[-4.9364, -4.9220, -4.9153, -5.0517, -4.9709, -4.3874]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1591 676 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  2213\n",
      "416 0 True\n",
      "x_t:  1 [0.61875    0.31666667 0.121875   0.52083333]\n",
      "Q values:  tensor([[-5.1850, -5.0484, -5.3015, -5.6482, -5.6836, -4.3717]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22938 1097 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 416: ep_len:1097 episode reward: total was -82.000000. running mean: -95.032219\n",
      "startIDX:  740\n",
      "416 1 True\n",
      "x_t:  3 [0.0625     0.22916667 0.059375   0.28333333]\n",
      "Q values:  tensor([[-5.8502, -5.6923, -5.8372, -6.3972, -6.1831, -4.9850]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34302 1368 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 416: ep_len:1368 episode reward: total was -73.000000. running mean: -94.811897\n",
      "startIDX:  2979\n",
      "ep 416: ep_len:46 episode reward: total was 36.000000. running mean: -93.503778\n",
      "startIDX:  241\n",
      "416 10 True\n",
      "x_t:  4 [0.04375    0.35833333 0.071875   0.25833333]\n",
      "Q values:  tensor([[-4.5754, -3.8735, -4.1313, -4.8264, -4.7714, -3.8725]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4550 443 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 416: ep_len:443 episode reward: total was -22.900000. running mean: -92.797740\n",
      "startIDX:  198\n",
      "416 12 True\n",
      "x_t:  3 [0.15       0.2625     0.0625     0.28333333]\n",
      "Q values:  tensor([[-4.1830, -3.8726, -4.2635, -4.5666, -4.4721, -3.5706]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5682 1392 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 416: ep_len:1392 episode reward: total was -64.600000. running mean: -92.515763\n",
      "startIDX:  1940\n",
      "416 15 True\n",
      "x_t:  1 [0.703125   0.29583333 0.084375   0.31666667]\n",
      "Q values:  tensor([[-4.1600, -4.3334, -4.2869, -4.3773, -4.3934, -3.4313]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14868 710 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 416: ep_len:710 episode reward: total was 5.500000. running mean: -91.535605\n",
      "startIDX:  1375\n",
      "416 22 True\n",
      "x_t:  3 [0.178125   0.2625     0.071875   0.30416667]\n",
      "Q values:  tensor([[-3.7682, -3.8574, -3.6982, -3.8527, -3.8025, -2.9963]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15228 1292 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 416: ep_len:1292 episode reward: total was -50.500000. running mean: -91.125249\n",
      "startIDX:  643\n",
      "417 0 True\n",
      "x_t:  2 [0.409375   0.4        0.084375   0.25833333]\n",
      "Q values:  tensor([[-3.3424, -3.2586, -3.2575, -3.2832, -3.4022, -2.6216]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8931 938 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  94\n",
      "417 1 False\n",
      "x_t:  3 [0.11875    0.225      0.06875    0.28333333]\n",
      "Q values:  tensor([[3.5175, 1.5795, 3.7461, 4.5969, 1.8628, 2.8541]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 25776 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1347\n",
      "417 5 True\n",
      "x_t:  1 [0.128125   0.33333333 0.078125   0.3875    ]\n",
      "Q values:  tensor([[-2.3622, -2.5766, -2.4535, -2.4778, -2.3220, -1.8799]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12517 245 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  578\n",
      "417 10 True\n",
      "x_t:  1 [0.6        0.29166667 0.075      0.325     ]\n",
      "Q values:  tensor([[-2.6608, -2.4967, -2.5373, -2.5767, -2.9762, -2.2060]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7173 1022 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1326\n",
      "417 12 True\n",
      "x_t:  3 [0.4375     0.30416667 0.09375    0.35      ]\n",
      "Q values:  tensor([[-2.7209, -2.4121, -2.5834, -2.6235, -2.7269, -2.1668]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17901 248 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1166\n",
      "417 15 True\n",
      "x_t:  4 [0.03125    0.3875     0.075      0.30416667]\n",
      "Q values:  tensor([[-3.0731, -2.9975, -2.9512, -2.8623, -2.8539, -2.4201]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9816 535 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1429\n",
      "417 22 True\n",
      "x_t:  4 [0.35       0.37083333 0.06875    0.3125    ]\n",
      "Q values:  tensor([[-2.5081, -2.5966, -2.4928, -2.5354, -2.5474, -1.9264]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16383 585 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1601\n",
      "418 0 False\n",
      "x_t:  3 [0.80625    0.33333333 0.090625   0.42083333]\n",
      "Q values:  tensor([[-2.3968, -2.1720, -2.3962, -2.0121, -2.4439, -2.0524]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16822 205 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 418: ep_len:205 episode reward: total was 21.400000. running mean: -85.163584\n",
      "startIDX:  398\n",
      "418 1 False\n",
      "x_t:  0 [0.484375   0.375      0.121875   0.46666667]\n",
      "Q values:  tensor([[-1.8841, -2.3001, -2.2719, -2.5319, -2.4127, -1.8889]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29175 544 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 418: ep_len:544 episode reward: total was -71.800000. running mean: -85.029948\n",
      "startIDX:  1271\n",
      "418 5 True\n",
      "x_t:  0 [0.725      0.3875     0.08125    0.33333333]\n",
      "Q values:  tensor([[-3.0197, -3.1360, -3.2536, -3.2714, -3.6099, -2.5924]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13530 1485 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 418: ep_len:1485 episode reward: total was -160.100000. running mean: -85.780649\n",
      "startIDX:  2557\n",
      "ep 418: ep_len:37 episode reward: total was -21.900000. running mean: -85.141842\n",
      "startIDX:  1099\n",
      "418 12 True\n",
      "x_t:  3 [0.659375   0.34166667 0.08125    0.42083333]\n",
      "Q values:  tensor([[-3.7436, -4.0009, -3.0624, -3.7593, -3.6076, -2.7815]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16476 1434 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 418: ep_len:1434 episode reward: total was -133.900000. running mean: -85.629424\n",
      "startIDX:  2883\n",
      "418 15 True\n",
      "x_t:  0 [0.3125     0.42083333 0.06875    0.27083333]\n",
      "Q values:  tensor([[-3.1464, -3.3061, -3.2916, -3.4584, -3.3831, -2.6989]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23210 579 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 418: ep_len:579 episode reward: total was -111.700000. running mean: -85.890130\n",
      "startIDX:  250\n",
      "418 22 True\n",
      "x_t:  3 [0.1875   0.25     0.053125 0.275   ]\n",
      "Q values:  tensor([[-6.1795, -5.7793, -5.6284, -6.0167, -5.8582, -4.8997]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4907 1328 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 418: ep_len:1328 episode reward: total was -70.600000. running mean: -85.737228\n",
      "startIDX:  669\n",
      "419 0 True\n",
      "x_t:  2 [0.1375     0.4125     0.1        0.26666667]\n",
      "Q values:  tensor([[-4.9349, -4.6754, -4.9690, -5.1699, -4.7479, -3.9942]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8892 885 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  798\n",
      "419 1 True\n",
      "x_t:  3 [0.084375   0.23333333 0.0875     0.29583333]\n",
      "Q values:  tensor([[-5.2632, -5.7913, -5.2673, -5.6209, -5.7630, -4.0313]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34310 1338 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  16\n",
      "419 5 True\n",
      "x_t:  2 [0.225      0.3875     0.15       0.43333333]\n",
      "Q values:  tensor([[-5.0286, -4.7109, -5.0284, -4.8915, -5.1220, -3.9910]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2076 945 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2554\n",
      "startIDX:  1985\n",
      "startIDX:  1742\n",
      "419 15 True\n",
      "x_t:  1 [0.009375   0.37083333 0.14375    0.40416667]\n",
      "Q values:  tensor([[-5.4680, -5.0105, -5.1302, -5.0179, -5.2581, -4.2524]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12448 211 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2608\n",
      "419 22 True\n",
      "x_t:  4 [0.075      0.39583333 0.11875    0.3125    ]\n",
      "Q values:  tensor([[-10.0809,  -9.2129,  -9.8382,  -8.8429, -10.9086,  -7.5241]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27276 1772 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  3607.846012353897\n",
      "startIDX:  1601\n",
      "420 0 True\n",
      "x_t:  2 [0.31875    0.40416667 0.06875    0.25      ]\n",
      "Q values:  tensor([[-4.8311, -4.9417, -4.6238, -5.0337, -4.7155, -4.0055]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18440 989 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 420: ep_len:989 episode reward: total was -131.200000. running mean: -84.425527\n",
      "startIDX:  258\n",
      "420 1 True\n",
      "x_t:  2 [0.003125 0.3625   0.1      0.45    ]\n",
      "Q values:  tensor([[-5.5043, -5.3104, -5.2842, -5.7099, -5.1914, -4.6215]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27431 829 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 420: ep_len:829 episode reward: total was -40.300000. running mean: -83.984272\n",
      "startIDX:  2684\n",
      "420 5 True\n",
      "x_t:  0 [0.884375   0.39166667 0.071875   0.3       ]\n",
      "Q values:  tensor([[-5.3418, -4.9230, -5.3255, -5.4359, -5.0208, -4.3875]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23161 752 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 420: ep_len:752 episode reward: total was -92.100000. running mean: -84.065429\n",
      "startIDX:  1903\n",
      "420 10 True\n",
      "x_t:  2 [0.2        0.40416667 0.103125   0.24583333]\n",
      "Q values:  tensor([[-5.3487, -4.7139, -6.0776, -5.0554, -5.4953, -4.6971]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18181 822 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 420: ep_len:822 episode reward: total was -63.700000. running mean: -83.861775\n",
      "startIDX:  1901\n",
      "420 12 True\n",
      "x_t:  0 [0.209375   0.425      0.08125    0.35833333]\n",
      "Q values:  tensor([[-5.0617, -5.2465, -5.0855, -5.5502, -5.2765, -4.3373]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 22990 920 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 420: ep_len:920 episode reward: total was -53.600000. running mean: -83.559157\n",
      "startIDX:  345\n",
      "420 15 True\n",
      "x_t:  0 [0.2125     0.42083333 0.078125   0.31666667]\n",
      "Q values:  tensor([[-5.4166, -5.5637, -5.7928, -6.1232, -5.9464, -4.7873]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3764 757 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 420: ep_len:757 episode reward: total was -136.100000. running mean: -84.084566\n",
      "startIDX:  2990\n",
      "ep 420: ep_len:12 episode reward: total was 4.000000. running mean: -83.203720\n",
      "startIDX:  385\n",
      "421 0 True\n",
      "x_t:  3 [0.43125  0.325    0.109375 0.4125  ]\n",
      "Q values:  tensor([[-5.1709, -5.3894, -5.3390, -5.4174, -4.9429, -4.6356]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7042 1117 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  713\n",
      "421 1 True\n",
      "x_t:  3 [0.459375   0.29583333 0.125      0.40416667]\n",
      "Q values:  tensor([[-6.6728, -6.4874, -6.7895, -6.7065, -7.2168, -5.9877]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34411 1447 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  387\n",
      "421 5 True\n",
      "x_t:  1 [0.546875   0.29583333 0.071875   0.3625    ]\n",
      "Q values:  tensor([[-5.0582, -5.4412, -5.1434, -4.9789, -5.3729, -4.0868]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5071 730 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2329\n",
      "421 10 True\n",
      "x_t:  1 [0.121875   0.3375     0.13125    0.37083333]\n",
      "Q values:  tensor([[-4.6177, -4.8374, -4.3667, -4.6055, -4.6817, -3.8633]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22549 1270 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  169\n",
      "421 12 True\n",
      "x_t:  4 [0.09375    0.425      0.096875   0.37916667]\n",
      "Q values:  tensor([[-10.5654,  -9.1672,  -9.8694, -11.2040, -10.7292,  -8.9834]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7192 2183 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  773\n",
      "421 15 True\n",
      "x_t:  2 [0.615625   0.40833333 0.053125   0.29166667]\n",
      "Q values:  tensor([[-4.9370, -4.6855, -4.6321, -4.5544, -4.2689, -4.0279]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6000 377 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  597\n",
      "421 22 False\n",
      "x_t:  3 [0.678125   0.31666667 0.075      0.3625    ]\n",
      "Q values:  tensor([[4.8817, 2.8905, 3.8533, 6.1248, 4.6202, 4.7040]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 7080 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2017\n",
      "422 0 True\n",
      "x_t:  0 [0.9125     0.39583333 0.08125    0.4       ]\n",
      "Q values:  tensor([[-4.7991, -4.4185, -4.9800, -4.9500, -5.2578, -3.6797]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20746 897 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 422: ep_len:897 episode reward: total was -118.200000. running mean: -82.853017\n",
      "startIDX:  514\n",
      "422 1 True\n",
      "x_t:  2 [0.734375   0.37916667 0.1125     0.31666667]\n",
      "Q values:  tensor([[-5.4544, -5.3254, -5.5021, -4.9965, -5.8488, -4.5482]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31472 1152 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 422: ep_len:1152 episode reward: total was -94.000000. running mean: -82.964487\n",
      "startIDX:  2266\n",
      "422 5 True\n",
      "x_t:  2 [0.653125   0.39166667 0.065625   0.27916667]\n",
      "Q values:  tensor([[-4.5358, -4.3847, -4.2484, -4.5971, -4.2736, -3.5137]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21653 1064 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 422: ep_len:1064 episode reward: total was -133.300000. running mean: -83.467842\n",
      "startIDX:  126\n",
      "422 10 True\n",
      "x_t:  4 [0.121875   0.35416667 0.096875   0.24583333]\n",
      "Q values:  tensor([[-5.9092, -5.7805, -5.5218, -6.2680, -6.0584, -4.7208]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4565 1566 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 422: ep_len:1566 episode reward: total was -189.200000. running mean: -84.525164\n",
      "startIDX:  1161\n",
      "422 12 True\n",
      "x_t:  3 [0.13125    0.27083333 0.08125    0.3       ]\n",
      "Q values:  tensor([[-5.7450, -5.9363, -5.6306, -6.1769, -5.9577, -4.8988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16389 1341 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 422: ep_len:1341 episode reward: total was -92.800000. running mean: -84.607912\n",
      "startIDX:  2498\n",
      "422 15 True\n",
      "x_t:  0 [0.321875   0.425      0.084375   0.25416667]\n",
      "Q values:  tensor([[-9.0316, -8.5879, -9.4045, -9.2433, -8.9704, -7.4652]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23155 1927 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 422: ep_len:1927 episode reward: total was -302.900000. running mean: -86.790833\n",
      "startIDX:  1183\n",
      "422 22 True\n",
      "x_t:  1 [0.29375    0.35833333 0.209375   0.5       ]\n",
      "Q values:  tensor([[-5.1687, -5.0807, -5.6593, -4.8135, -5.3465, -4.2693]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11960 714 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 422: ep_len:714 episode reward: total was -58.200000. running mean: -86.504925\n",
      "startIDX:  1366\n",
      "423 0 True\n",
      "x_t:  4 [0.0375     0.38333333 0.1        0.3       ]\n",
      "Q values:  tensor([[-4.9030, -4.7543, -4.4155, -4.6125, -4.3714, -3.5260]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16292 546 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  422\n",
      "423 1 True\n",
      "x_t:  0 [0.503125   0.375      0.109375   0.45833333]\n",
      "Q values:  tensor([[-3.8554, -4.3877, -4.7325, -4.3264, -4.0984, -3.3941]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29168 510 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1897\n",
      "423 5 False\n",
      "x_t:  3 [0.428125   0.31666667 0.140625   0.4125    ]\n",
      "Q values:  tensor([[-6.5538, -6.7755, -7.2056, -6.4710, -6.7566, -6.5318]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18288 1634 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  903\n",
      "423 10 True\n",
      "x_t:  2 [0.546875   0.39166667 0.1        0.25833333]\n",
      "Q values:  tensor([[-8.9296, -8.1849, -8.6538, -8.4868, -8.0770, -7.3232]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12102 1987 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  772\n",
      "423 12 True\n",
      "x_t:  0 [0.790625 0.4125   0.128125 0.3     ]\n",
      "Q values:  tensor([[-5.2782, -4.7909, -5.2100, -4.8971, -5.1449, -4.1588]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11649 860 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1869\n",
      "423 15 True\n",
      "x_t:  1 [0.78125    0.30416667 0.103125   0.30416667]\n",
      "Q values:  tensor([[-5.6120, -5.1742, -5.3528, -5.6661, -5.5221, -4.3997]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14855 725 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  651\n",
      "423 22 True\n",
      "x_t:  2 [0.68125    0.40833333 0.11875    0.25416667]\n",
      "Q values:  tensor([[-6.0210, -6.2707, -6.1497, -6.6038, -6.2455, -4.8211]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9031 965 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1608\n",
      "424 0 True\n",
      "x_t:  2 [0.61875    0.4        0.103125   0.24166667]\n",
      "Q values:  tensor([[-7.2702, -6.8155, -6.9099, -7.3865, -6.9757, -5.5719]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18490 1030 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 424: ep_len:1030 episode reward: total was -142.000000. running mean: -86.500441\n",
      "startIDX:  35\n",
      "424 1 False\n",
      "x_t:  3 [0.359375   0.25416667 0.09375    0.33333333]\n",
      "Q values:  tensor([[2.0100, 1.5684, 2.8269, 3.2397, 1.5870, 2.1609]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 25714 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 424: ep_len:200 episode reward: total was 6.400000. running mean: -85.571436\n",
      "startIDX:  2742\n",
      "424 5 True\n",
      "x_t:  0 [0.209375   0.40833333 0.103125   0.35833333]\n",
      "Q values:  tensor([[-5.2345, -5.8168, -5.7627, -5.8099, -5.5570, -4.8087]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23293 592 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 424: ep_len:592 episode reward: total was -102.900000. running mean: -85.744722\n",
      "startIDX:  602\n",
      "424 10 True\n",
      "x_t:  2 [0.428125   0.40416667 0.09375    0.25416667]\n",
      "Q values:  tensor([[-6.4882, -5.0489, -5.6612, -6.2361, -5.6702, -5.1740]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6655 755 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 424: ep_len:755 episode reward: total was -51.600000. running mean: -85.403275\n",
      "startIDX:  954\n",
      "424 12 True\n",
      "x_t:  1 [0.06875    0.38333333 0.159375   0.4875    ]\n",
      "Q values:  tensor([[-6.3589, -6.5115, -6.1172, -6.6927, -6.1454, -5.2479]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12970 609 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 424: ep_len:609 episode reward: total was -70.100000. running mean: -85.250242\n",
      "startIDX:  2762\n",
      "424 15 True\n",
      "x_t:  1 [0.1625     0.37083333 0.18125    0.5       ]\n",
      "Q values:  tensor([[-5.3126, -4.8704, -5.8239, -5.2763, -5.3784, -4.9368]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22049 283 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 424: ep_len:283 episode reward: total was 5.100000. running mean: -84.346739\n",
      "startIDX:  1343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424 22 True\n",
      "x_t:  4 [0.4375     0.37083333 0.065625   0.31666667]\n",
      "Q values:  tensor([[-13.5281, -13.1972, -12.3083, -13.9497, -12.8459, -10.9072]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16398 1888 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 424: ep_len:1888 episode reward: total was -209.700000. running mean: -85.600272\n",
      "startIDX:  2149\n",
      "425 0 True\n",
      "x_t:  1 [0.68125    0.32083333 0.159375   0.50416667]\n",
      "Q values:  tensor([[-10.1063,  -9.1747,  -9.6528, -10.4261, -10.2300,  -8.2052]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22933 1135 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  66\n",
      "425 1 False\n",
      "x_t:  3 [0.184375   0.2375     0.096875   0.29583333]\n",
      "Q values:  tensor([[2.0929, 0.9684, 1.9572, 3.3880, 1.4749, 1.7413]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 25752 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1931\n",
      "425 5 True\n",
      "x_t:  3 [0.21875    0.27083333 0.08125    0.3375    ]\n",
      "Q values:  tensor([[-9.2583, -8.8697, -9.9026, -9.8187, -9.5389, -8.4553]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18244 1299 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  40\n",
      "425 10 True\n",
      "x_t:  3 [0.165625   0.25416667 0.09375    0.28333333]\n",
      "Q values:  tensor([[-7.1909, -8.0743, -7.9539, -8.3795, -8.5579, -6.3946]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3613 1110 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  872\n",
      "425 12 False\n",
      "x_t:  1 [0.015625 0.3875   0.165625 0.4875  ]\n",
      "Q values:  tensor([[-5.4299, -4.7042, -5.4930, -5.8952, -5.4466, -4.7227]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12976 669 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2805\n",
      "425 15 True\n",
      "x_t:  1 [0.171875   0.375      0.196875   0.49583333]\n",
      "Q values:  tensor([[-5.4092, -4.9106, -4.9695, -5.0453, -5.1307, -3.9746]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22051 267 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2515\n",
      "425 22 True\n",
      "x_t:  3 [0.215625   0.25416667 0.075      0.2875    ]\n",
      "Q values:  tensor([[-8.7221, -7.0859, -7.1108, -8.5213, -7.4975, -6.8177]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26220 1297 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  785\n",
      "426 0 True\n",
      "x_t:  1 [0.2125     0.34583333 0.121875   0.40833333]\n",
      "Q values:  tensor([[-4.5427, -4.4685, -4.7256, -4.8589, -4.5872, -4.0018]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9431 239 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 426: ep_len:239 episode reward: total was -8.500000. running mean: -82.093872\n",
      "startIDX:  829\n",
      "426 1 True\n",
      "x_t:  4 [0.13125    0.37916667 0.109375   0.35833333]\n",
      "Q values:  tensor([[-4.6626, -5.2183, -4.6141, -5.4094, -4.8226, -4.0793]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35542 621 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 426: ep_len:621 episode reward: total was -64.300000. running mean: -81.915933\n",
      "startIDX:  2488\n",
      "426 5 True\n",
      "x_t:  2 [0.203125   0.39583333 0.103125   0.275     ]\n",
      "Q values:  tensor([[-5.0361, -5.3536, -5.2828, -4.8861, -5.0562, -4.2540]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21581 820 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 426: ep_len:820 episode reward: total was -32.500000. running mean: -81.421774\n",
      "startIDX:  387\n",
      "426 10 False\n",
      "x_t:  3 [0.703125   0.3        0.134375   0.37916667]\n",
      "Q values:  tensor([[3.2500, 2.6125, 2.6499, 3.8459, 3.1134, 2.9576]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 5052 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 426: ep_len:201 episode reward: total was -6.100000. running mean: -80.668556\n",
      "startIDX:  759\n",
      "426 12 True\n",
      "x_t:  0 [0.640625   0.40833333 0.078125   0.38333333]\n",
      "Q values:  tensor([[-5.0365, -5.0748, -4.5778, -5.1530, -4.8153, -4.0442]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11713 895 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 426: ep_len:895 episode reward: total was -130.000000. running mean: -81.161870\n",
      "startIDX:  1257\n",
      "426 15 True\n",
      "x_t:  3 [0.209375 0.25     0.0625   0.2625  ]\n",
      "Q values:  tensor([[-3.7271, -3.2913, -3.7029, -3.5480, -3.0635, -3.0232]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10467 308 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 426: ep_len:308 episode reward: total was -42.700000. running mean: -80.777252\n",
      "startIDX:  1099\n",
      "426 22 True\n",
      "x_t:  1 [0.74375    0.3125     0.075      0.47916667]\n",
      "Q values:  tensor([[-4.1996, -4.0790, -4.4836, -4.5691, -4.3000, -3.7053]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11930 748 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 426: ep_len:748 episode reward: total was -17.900000. running mean: -80.148479\n",
      "startIDX:  1748\n",
      "427 0 True\n",
      "x_t:  2 [0.21875    0.40416667 0.08125    0.24166667]\n",
      "Q values:  tensor([[-5.1042, -4.8380, -4.9932, -5.0880, -4.9545, -4.1735]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18425 795 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  617\n",
      "427 1 True\n",
      "x_t:  2 [0.640625   0.38333333 0.13125    0.31666667]\n",
      "Q values:  tensor([[-3.2725, -2.9480, -3.2947, -3.2103, -3.0543, -2.6682]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31488 381 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  634\n",
      "427 5 True\n",
      "x_t:  3 [0.09375    0.26666667 0.084375   0.31666667]\n",
      "Q values:  tensor([[-7.3514, -6.7805, -6.7293, -7.0851, -6.4599, -5.6614]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8758 1363 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2147\n",
      "427 10 True\n",
      "x_t:  0 [0.634375   0.40833333 0.096875   0.3       ]\n",
      "Q values:  tensor([[-4.2734, -4.0643, -4.0944, -4.2362, -4.1258, -3.5882]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19995 572 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1356\n",
      "427 12 True\n",
      "x_t:  3 [0.284375   0.27083333 0.0625     0.29166667]\n",
      "Q values:  tensor([[-3.7537, -3.3747, -3.3851, -3.5060, -3.5481, -2.8820]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17940 256 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  633\n",
      "427 15 True\n",
      "x_t:  1 [0.375    0.325    0.059375 0.3125  ]\n",
      "Q values:  tensor([[-4.6761, -4.1984, -4.7227, -4.2753, -4.6225, -3.6660]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5244 693 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  788\n",
      "427 22 True\n",
      "x_t:  2 [0.09375    0.41666667 0.08125    0.25      ]\n",
      "Q values:  tensor([[-4.4016, -4.2836, -4.2960, -3.8830, -4.2156, -3.6380]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8932 854 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2456\n",
      "ep 428: ep_len:68 episode reward: total was 34.000000. running mean: -77.916503\n",
      "startIDX:  19\n",
      "428 1 False\n",
      "x_t:  3 [0.534375   0.26666667 0.10625    0.37916667]\n",
      "Q values:  tensor([[3.4234, 3.4128, 3.9542, 4.3979, 3.8374, 4.0798]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 25680 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 428: ep_len:201 episode reward: total was -2.600000. running mean: -77.163338\n",
      "startIDX:  2254\n",
      "428 5 True\n",
      "x_t:  3 [0.140625   0.24583333 0.1        0.30416667]\n",
      "Q values:  tensor([[-3.5173, -3.7495, -3.8255, -3.5528, -3.8389, -3.2722]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19993 245 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 428: ep_len:245 episode reward: total was -36.900000. running mean: -76.760705\n",
      "startIDX:  2042\n",
      "428 10 True\n",
      "x_t:  1 [0.303125   0.32083333 0.121875   0.34166667]\n",
      "Q values:  tensor([[-4.6824, -4.5105, -4.8332, -4.7118, -4.7207, -3.9671]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18850 308 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 428: ep_len:308 episode reward: total was -36.000000. running mean: -76.353098\n",
      "startIDX:  42\n",
      "428 12 True\n",
      "x_t:  2 [0.771875   0.40416667 0.04375    0.25      ]\n",
      "Q values:  tensor([[-6.4673, -6.1111, -5.6396, -6.1370, -5.6410, -5.2373]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2816 943 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 428: ep_len:943 episode reward: total was -102.400000. running mean: -76.613567\n",
      "startIDX:  1750\n",
      "428 15 True\n",
      "x_t:  0 [0.334375   0.4125     0.071875   0.27083333]\n",
      "Q values:  tensor([[-5.6247, -5.3216, -5.4480, -5.3926, -4.9658, -4.6457]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13517 521 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 428: ep_len:521 episode reward: total was -129.800000. running mean: -77.145431\n",
      "startIDX:  2274\n",
      "428 22 True\n",
      "x_t:  1 [0.7375     0.31666667 0.159375   0.44583333]\n",
      "Q values:  tensor([[-6.5140, -6.8988, -7.1074, -6.5732, -6.9071, -5.9858]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22942 1085 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 428: ep_len:1085 episode reward: total was -90.600000. running mean: -77.279977\n",
      "startIDX:  308\n",
      "429 0 True\n",
      "x_t:  3 [0.278125   0.25416667 0.075      0.29166667]\n",
      "Q values:  tensor([[-8.3272, -7.6995, -7.7421, -7.5793, -8.1598, -6.8364]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4904 1279 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  616\n",
      "429 1 False\n",
      "x_t:  2 [0.809375   0.38333333 0.071875   0.30833333]\n",
      "Q values:  tensor([[-4.8754, -4.3350, -4.2079, -4.3043, -5.0556, -4.2351]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31465 374 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  1969\n",
      "429 5 False\n",
      "x_t:  3 [0.303125   0.29166667 0.109375   0.37916667]\n",
      "Q values:  tensor([[-8.2139, -7.6250, -8.4403, -7.1428, -8.0089, -7.2430]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18265 1285 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  216\n",
      "429 10 True\n",
      "x_t:  4 [0.028125   0.35416667 0.05625    0.2625    ]\n",
      "Q values:  tensor([[-6.0046, -5.0382, -5.8817, -6.0862, -5.5876, -4.8666]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4547 445 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1765\n",
      "429 12 False\n",
      "x_t:  0 [0.74375 0.4125  0.1125  0.3375 ]\n",
      "Q values:  tensor([[-5.8665, -6.9737, -6.6050, -6.5512, -5.8760, -6.0178]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21112 616 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  77\n",
      "429 15 True\n",
      "x_t:  3 [0.7375     0.33333333 0.075      0.4125    ]\n",
      "Q values:  tensor([[-5.4206, -5.8010, -5.4406, -5.6933, -5.2159, -4.7401]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 538 221 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  821\n",
      "429 22 False\n",
      "x_t:  1 [0.653125   0.32083333 0.1625     0.40416667]\n",
      "Q values:  tensor([[-5.2783, -5.0863, -5.4420, -6.2731, -6.0779, -5.0875]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9552 315 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  3721.6395485401154\n",
      "startIDX:  1620\n",
      "430 0 False\n",
      "x_t:  3 [0.540625   0.30833333 0.10625    0.37916667]\n",
      "Q values:  tensor([[-6.2163, -5.3164, -5.9295, -5.0956, -5.4174, -5.2397]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16853 218 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 430: ep_len:218 episode reward: total was -17.100000. running mean: -76.433325\n",
      "startIDX:  680\n",
      "430 1 True\n",
      "x_t:  3 [0.859375   0.34583333 0.13125    0.45      ]\n",
      "Q values:  tensor([[-13.1498, -13.5160, -13.9151, -14.4100, -13.9834, -12.8622]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34467 1493 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 430: ep_len:1493 episode reward: total was -226.700000. running mean: -77.935992\n",
      "startIDX:  2528\n",
      "430 5 False\n",
      "x_t:  2 [0.1625     0.3875     0.065625   0.27083333]\n",
      "Q values:  tensor([[-9.3827, -8.8875, -8.0805, -9.3188, -9.2869, -8.1432]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21573 818 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 430: ep_len:818 episode reward: total was -89.900000. running mean: -78.055632\n",
      "startIDX:  2304\n",
      "430 10 False\n",
      "x_t:  1 [0.86875    0.275      0.053125   0.34583333]\n",
      "Q values:  tensor([[ -9.9849,  -9.2297,  -9.2326,  -9.9843, -11.3688,  -9.2624]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22473 1238 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 430: ep_len:1238 episode reward: total was -107.300000. running mean: -78.348076\n",
      "startIDX:  423\n",
      "430 12 True\n",
      "x_t:  3 [0.6        0.32083333 0.1375     0.38333333]\n",
      "Q values:  tensor([[-6.5562, -6.7918, -6.6110, -5.9387, -6.6983, -5.3846]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7742 259 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 430: ep_len:259 episode reward: total was -23.000000. running mean: -77.794595\n",
      "startIDX:  1366\n",
      "430 15 True\n",
      "x_t:  3 [0.540625   0.29166667 0.075      0.325     ]\n",
      "Q values:  tensor([[-6.5555, -6.8091, -6.6365, -6.0409, -6.2029, -5.2673]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10393 215 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 430: ep_len:215 episode reward: total was -30.100000. running mean: -77.317649\n",
      "startIDX:  962\n",
      "430 22 False\n",
      "x_t:  0 [0.575      0.40833333 0.071875   0.34166667]\n",
      "Q values:  tensor([[-6.4139, -7.0909, -6.8713, -7.5288, -7.5406, -6.5324]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10493 502 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 430: ep_len:502 episode reward: total was -103.700000. running mean: -77.581473\n",
      "startIDX:  421\n",
      "431 0 True\n",
      "x_t:  3 [0.584375   0.35416667 0.159375   0.45833333]\n",
      "Q values:  tensor([[-9.4472, -8.7430, -7.5013, -8.2338, -8.4663, -7.2407]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7018 1085 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  316\n",
      "431 1 True\n",
      "x_t:  1 [0.578125   0.30833333 0.23125    0.56666667]\n",
      "Q values:  tensor([[-7.5796, -7.4264, -7.4083, -7.7598, -7.8091, -6.9826]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28103 321 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2994\n",
      "startIDX:  38\n",
      "431 10 True\n",
      "x_t:  3 [0.834375   0.3125     0.09375    0.40833333]\n",
      "Q values:  tensor([[ -8.8702,  -9.2340,  -9.8089, -10.3088,  -9.2999,  -9.0955]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3708 1153 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1279\n",
      "431 12 True\n",
      "x_t:  4 [0.128125   0.42083333 0.084375   0.37083333]\n",
      "Q values:  tensor([[-7.0964, -6.4658, -6.9326, -5.9786, -7.0967, -5.8166]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17402 469 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  960\n",
      "431 15 True\n",
      "x_t:  4 [0.15       0.39166667 0.09375    0.29166667]\n",
      "Q values:  tensor([[-6.2676, -6.5742, -6.8153, -6.5815, -6.6737, -6.2037]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9838 652 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1135\n",
      "431 22 False\n",
      "x_t:  2 [0.778125   0.40833333 0.090625   0.25      ]\n",
      "Q values:  tensor([[-12.0843, -10.3587, -10.2314, -11.6387, -11.3348, -10.5045]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12591 1066 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2138\n",
      "432 0 True\n",
      "x_t:  1 [0.846875   0.30416667 0.146875   0.5375    ]\n",
      "Q values:  tensor([[-9.6247, -9.2972, -8.7399, -9.4641, -9.7071, -8.8396]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22919 1125 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 432: ep_len:1125 episode reward: total was -160.900000. running mean: -78.285905\n",
      "startIDX:  352\n",
      "432 1 False\n",
      "x_t:  1 [0.7875     0.275      0.165625   0.59583333]\n",
      "Q values:  tensor([[-6.7037, -5.4358, -5.9025, -6.1024, -6.4489, -5.5929]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28121 321 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 432: ep_len:321 episode reward: total was -36.800000. running mean: -77.871046\n",
      "startIDX:  2318\n",
      "432 5 False\n",
      "x_t:  3 [0.25625    0.25833333 0.1125     0.34583333]\n",
      "Q values:  tensor([[ 0.4242, -0.7726,  1.3287,  1.5571,  0.3391, -0.1857]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19965 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 432: ep_len:202 episode reward: total was -2.300000. running mean: -77.115336\n",
      "startIDX:  929\n",
      "432 10 True\n",
      "x_t:  1 [0.875      0.2875     0.11875    0.34166667]\n",
      "Q values:  tensor([[-13.6752, -12.9567, -14.3592, -12.3512, -12.1424, -12.4926]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11327 1600 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 432: ep_len:1600 episode reward: total was -324.300000. running mean: -79.587182\n",
      "startIDX:  590\n",
      "432 12 False\n",
      "x_t:  2 [0.0875     0.4125     0.0875     0.25416667]\n",
      "Q values:  tensor([[-13.2394, -12.1064, -10.9304, -13.5752, -12.6079, -11.5433]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9840 1029 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 432: ep_len:1029 episode reward: total was -215.600000. running mean: -80.947311\n",
      "startIDX:  585\n",
      "432 15 False\n",
      "x_t:  1 [0.821875   0.29583333 0.084375   0.27916667]\n",
      "Q values:  tensor([[-8.9767, -8.1017, -8.9379, -9.2414, -8.6326, -8.1812]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5175 696 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 432: ep_len:696 episode reward: total was -132.200000. running mean: -81.459837\n",
      "startIDX:  362\n",
      "432 22 True\n",
      "x_t:  3 [0.0625  0.2375  0.05625 0.2375 ]\n",
      "Q values:  tensor([[-13.2770, -12.3940, -13.4730, -11.7961, -12.9964, -11.4655]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4871 1245 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 432: ep_len:1245 episode reward: total was -312.200000. running mean: -83.767239\n",
      "startIDX:  1183\n",
      "433 0 False\n",
      "x_t:  3 [0.0625     0.24583333 0.0625     0.25833333]\n",
      "Q values:  tensor([[-13.7689, -13.0899, -14.2733, -12.6295, -14.2605, -13.3491]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15156 1273 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  646\n",
      "433 1 False\n",
      "x_t:  2 [0.028125   0.37916667 0.09375    0.3125    ]\n",
      "Q values:  tensor([[-9.8997, -9.3818, -7.8906, -9.2479, -9.3710, -7.9646]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31587 425 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2845\n",
      "startIDX:  493\n",
      "433 10 False\n",
      "x_t:  3 [0.09375    0.22083333 0.078125   0.25833333]\n",
      "Q values:  tensor([[2.8414, 1.0961, 2.9953, 4.9163, 2.2808, 2.7102]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 5176 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1414\n",
      "433 12 False\n",
      "x_t:  3 [0.36875    0.30833333 0.125      0.34166667]\n",
      "Q values:  tensor([[ 0.9480, -0.2007,  0.5410,  3.2526,  0.3769,  0.3608]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17909 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433 15 False\n",
      "x_t:  4 [0.175      0.37916667 0.059375   0.2375    ]\n",
      "Q values:  tensor([[-14.5210, -12.9790, -13.6208, -12.7723, -12.3308, -12.5928]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19338 543 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2973\n",
      "startIDX:  1461\n",
      "434 0 True\n",
      "x_t:  4 [0.55625    0.35416667 0.065625   0.26666667]\n",
      "Q values:  tensor([[-15.9948, -15.6736, -15.5865, -15.5246, -15.7174, -15.5823]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16399 539 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 434: ep_len:539 episode reward: total was -263.200000. running mean: -86.353032\n",
      "startIDX:  1106\n",
      "ep 434: ep_len:209 episode reward: total was -113.600000. running mean: -86.625502\n",
      "startIDX:  1940\n",
      "434 5 False\n",
      "x_t:  3 [0.1        0.25416667 0.1        0.30833333]\n",
      "Q values:  tensor([[-20.6291, -20.7802, -20.8748, -18.9047, -21.6044, -20.1695]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18213 1260 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 434: ep_len:1260 episode reward: total was -564.300000. running mean: -91.402247\n",
      "startIDX:  2129\n",
      "434 10 False\n",
      "x_t:  0 [0.909375   0.39166667 0.08125    0.35416667]\n",
      "Q values:  tensor([[-13.9871, -13.9956, -14.0012, -14.2723, -15.1076, -14.7084]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19928 544 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 434: ep_len:544 episode reward: total was -219.600000. running mean: -92.684224\n",
      "startIDX:  1166\n",
      "434 12 False\n",
      "x_t:  3 [0.075      0.26666667 0.078125   0.2875    ]\n",
      "Q values:  tensor([[-30.9048, -29.9121, -30.7384, -28.2577, -30.0861, -29.1722]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16376 1337 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 434: ep_len:1337 episode reward: total was -690.100000. running mean: -98.658382\n",
      "startIDX:  466\n",
      "434 15 False\n",
      "x_t:  1 [0.478125   0.31666667 0.1        0.3       ]\n",
      "Q values:  tensor([[-25.7325, -22.3246, -26.1187, -22.6587, -24.5708, -22.6871]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5227 779 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 434: ep_len:779 episode reward: total was -319.800000. running mean: -100.869798\n",
      "startIDX:  2968\n",
      "ep 434: ep_len:25 episode reward: total was 9.000000. running mean: -99.771100\n",
      "startIDX:  273\n",
      "435 0 False\n",
      "x_t:  3 [0.059375   0.23333333 0.065625   0.22916667]\n",
      "Q values:  tensor([[-32.5296, -30.6451, -31.5352, -29.7216, -33.8280, -31.2267]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4833 1255 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1166\n",
      "startIDX:  2341\n",
      "435 5 False\n",
      "x_t:  3 [0.1        0.25       0.103125   0.29166667]\n",
      "Q values:  tensor([[-17.4047, -17.4549, -18.3754, -17.0205, -17.1148, -17.1435]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 20000 211 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2613\n",
      "startIDX:  143\n",
      "435 12 True\n",
      "x_t:  2 [0.825      0.40833333 0.084375   0.24583333]\n",
      "Q values:  tensor([[-17.2193, -18.8318, -18.1629, -20.9464, -18.8065, -17.5148]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2804 293 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2264\n",
      "435 15 False\n",
      "x_t:  3 [0.096875   0.27083333 0.075      0.30833333]\n",
      "Q values:  tensor([[-25.1157, -23.5942, -23.7729, -23.3631, -24.0629, -24.9317]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18181 1255 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1419\n",
      "435 22 False\n",
      "x_t:  3 [0.19375    0.2625     0.065625   0.29583333]\n",
      "Q values:  tensor([[-20.6511, -21.4068, -20.6761, -20.4249, -21.8164, -22.3765]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15231 1272 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1681\n",
      "436 0 False\n",
      "x_t:  3 [0.20625    0.26666667 0.06875    0.2875    ]\n",
      "Q values:  tensor([[-18.8539, -17.9687, -19.8369, -17.8436, -18.3048, -18.5432]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16919 205 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 436: ep_len:205 episode reward: total was -144.700000. running mean: -122.896100\n",
      "startIDX:  521\n",
      "436 1 False\n",
      "x_t:  1 [0.79375    0.275      0.125      0.45416667]\n",
      "Q values:  tensor([[-33.7094, -31.2574, -33.3073, -33.9151, -31.3494, -32.2501]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30688 738 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 436: ep_len:738 episode reward: total was -500.000000. running mean: -126.667139\n",
      "startIDX:  1098\n",
      "436 5 False\n",
      "x_t:  3 [0.084375   0.225      0.0625     0.25833333]\n",
      "Q values:  tensor([[-26.3581, -25.3879, -25.5965, -25.1821, -26.6626, -26.1936]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10612 210 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 436: ep_len:210 episode reward: total was -90.000000. running mean: -126.300468\n",
      "startIDX:  1512\n",
      "436 10 False\n",
      "x_t:  3 [0.825      0.325      0.146875   0.39166667]\n",
      "Q values:  tensor([[-30.6596, -29.5750, -32.0060, -29.3412, -34.1770, -30.7768]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16407 334 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 436: ep_len:334 episode reward: total was -139.900000. running mean: -126.436463\n",
      "startIDX:  1754\n",
      "436 12 False\n",
      "x_t:  0 [0.90625    0.40416667 0.0875     0.3625    ]\n",
      "Q values:  tensor([[-34.4844, -37.3611, -38.8442, -34.7845, -39.9155, -35.2611]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21091 606 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 436: ep_len:606 episode reward: total was -381.900000. running mean: -128.991098\n",
      "startIDX:  579\n",
      "436 15 False\n",
      "x_t:  1 [0.884375   0.29583333 0.08125    0.275     ]\n",
      "Q values:  tensor([[-30.0497, -26.8202, -27.9579, -27.5694, -27.7673, -29.8093]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5168 690 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 436: ep_len:690 episode reward: total was -419.300000. running mean: -131.894187\n",
      "startIDX:  2459\n",
      "436 22 True\n",
      "x_t:  2 [0.671875   0.40416667 0.0625     0.25833333]\n",
      "Q values:  tensor([[-25.1737, -25.3770, -24.7696, -23.1292, -23.5027, -23.8966]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23662 323 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 436: ep_len:323 episode reward: total was -239.800000. running mean: -132.973245\n",
      "startIDX:  1640\n",
      "437 0 False\n",
      "x_t:  3 [0.321875   0.275      0.084375   0.31666667]\n",
      "Q values:  tensor([[-28.1169, -26.9337, -28.6314, -25.7980, -26.7725, -26.8173]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16893 220 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  615\n",
      "437 1 False\n",
      "x_t:  2 [0.796875   0.37916667 0.075      0.30416667]\n",
      "Q values:  tensor([[-27.6079, -28.2237, -24.7028, -27.2491, -27.9124, -25.0405]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31467 379 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2183\n",
      "437 5 True\n",
      "x_t:  4 [0.01875    0.42916667 0.1125     0.4       ]\n",
      "Q values:  tensor([[-22.8464, -23.4037, -20.9379, -22.1757, -20.4063, -22.1513]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19467 570 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  796\n",
      "437 10 False\n",
      "x_t:  1 [0.003125   0.35416667 0.134375   0.37916667]\n",
      "Q values:  tensor([[-28.4048, -27.1950, -29.6364, -28.5640, -28.0723, -28.2669]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7107 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  375\n",
      "437 12 False\n",
      "x_t:  4 [0.140625   0.42916667 0.13125    0.375     ]\n",
      "Q values:  tensor([[-26.0027, -26.9136, -24.4271, -26.8001, -23.0531, -24.0559]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7196 704 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1222\n",
      "437 15 False\n",
      "x_t:  3 [0.88125    0.34583333 0.115625   0.39166667]\n",
      "Q values:  tensor([[-29.2088, -29.2162, -29.5171, -27.3254, -28.6513, -28.3846]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10336 264 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2553\n",
      "437 22 False\n",
      "x_t:  3 [0.0625     0.24166667 0.071875   0.24583333]\n",
      "Q values:  tensor([[-29.1541, -28.6874, -27.8494, -26.9895, -30.5933, -29.0737]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26174 1231 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1014\n",
      "438 0 False\n",
      "x_t:  1 [0.878125   0.3        0.109375   0.42916667]\n",
      "Q values:  tensor([[-31.0866, -29.5784, -30.7687, -30.1599, -30.4913, -30.6021]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11946 780 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 438: ep_len:780 episode reward: total was -575.800000. running mean: -153.085071\n",
      "startIDX:  185\n",
      "438 1 False\n",
      "x_t:  2 [0.1        0.35833333 0.103125   0.45416667]\n",
      "Q values:  tensor([[-31.1278, -30.8349, -29.3034, -31.9329, -30.5003, -31.1766]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27445 873 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 438: ep_len:873 episode reward: total was -636.400000. running mean: -157.918220\n",
      "startIDX:  2845\n",
      "ep 438: ep_len:118 episode reward: total was -20.000000. running mean: -156.539038\n",
      "startIDX:  2587\n",
      "ep 438: ep_len:23 episode reward: total was 4.100000. running mean: -154.932648\n",
      "startIDX:  190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438 12 False\n",
      "x_t:  3 [0.159375 0.275    0.10625  0.275   ]\n",
      "Q values:  tensor([[-38.2629, -40.1707, -38.4166, -35.4917, -39.3279, -38.2624]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5686 1413 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 438: ep_len:1413 episode reward: total was -1118.000000. running mean: -164.563321\n",
      "startIDX:  633\n",
      "438 15 True\n",
      "x_t:  1 [0.953125   0.29166667 0.040625   0.27916667]\n",
      "Q values:  tensor([[-33.6203, -33.4009, -32.5071, -34.7594, -33.4066, -32.5668]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5161 660 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 438: ep_len:660 episode reward: total was -493.200000. running mean: -167.849688\n",
      "startIDX:  2693\n",
      "438 22 False\n",
      "x_t:  4 [0.128125   0.39583333 0.1        0.30833333]\n",
      "Q values:  tensor([[-34.2071, -32.4244, -34.7688, -33.1446, -30.7263, -32.6225]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27283 531 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 438: ep_len:531 episode reward: total was -416.300000. running mean: -170.334191\n",
      "startIDX:  208\n",
      "439 0 False\n",
      "x_t:  2 [0.796875   0.40833333 0.1        0.2875    ]\n",
      "Q values:  tensor([[-30.4624, -29.7489, -29.0654, -29.5648, -29.2046, -29.2525]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2320 335 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  884\n",
      "439 1 False\n",
      "x_t:  4 [0.003125   0.39583333 0.11875    0.4       ]\n",
      "Q values:  tensor([[-32.3152, -31.7103, -30.5167, -31.5063, -29.9896, -31.1954]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35422 521 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2379\n",
      "439 5 False\n",
      "x_t:  3 [0.078125   0.2375     0.06875    0.27083333]\n",
      "Q values:  tensor([[-29.5975, -32.7041, -31.2383, -27.3949, -30.7436, -30.5378]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 20012 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  236\n",
      "439 10 False\n",
      "x_t:  4 [0.04375    0.35833333 0.071875   0.25833333]\n",
      "Q values:  tensor([[-36.9737, -35.7013, -36.8194, -38.9174, -35.2183, -35.5665]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4550 441 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2017\n",
      "startIDX:  1837\n",
      "439 15 False\n",
      "x_t:  0 [0.671875   0.40416667 0.11875    0.3375    ]\n",
      "Q values:  tensor([[-32.6724, -35.8176, -33.4853, -33.7488, -33.0036, -33.1376]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13399 436 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  130\n",
      "439 22 False\n",
      "x_t:  1 [0.90625  0.2875   0.090625 0.4125  ]\n",
      "Q values:  tensor([[-38.3437, -37.7606, -41.1252, -38.4237, -38.8750, -37.9028]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1576 668 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  3807.8010058403015\n",
      "startIDX:  1510\n",
      "440 0 False\n",
      "x_t:  3 [0.8        0.34583333 0.1875     0.41666667]\n",
      "Q values:  tensor([[-30.9363, -29.9654, -30.6909, -28.8328, -30.5428, -30.3610]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16817 249 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 440: ep_len:249 episode reward: total was -44.800000. running mean: -174.303153\n",
      "startIDX:  612\n",
      "440 1 False\n",
      "x_t:  2 [0.809375   0.38333333 0.10625    0.30833333]\n",
      "Q values:  tensor([[-30.5327, -30.6991, -28.9554, -30.7156, -29.8182, -29.5887]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31461 369 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 440: ep_len:369 episode reward: total was -214.800000. running mean: -174.708121\n",
      "startIDX:  197\n",
      "440 5 False\n",
      "x_t:  1 [0.15625    0.3375     0.13125    0.52916667]\n",
      "Q values:  tensor([[-32.8457, -30.6100, -32.7376, -30.8156, -30.8528, -32.4345]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2524 230 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 440: ep_len:230 episode reward: total was -122.100000. running mean: -174.182040\n",
      "startIDX:  1794\n",
      "440 10 False\n",
      "x_t:  2 [0.040625   0.39583333 0.071875   0.25      ]\n",
      "Q values:  tensor([[-19.1418, -20.7721, -18.7491, -20.2017, -20.7517, -19.2570]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18149 870 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 440: ep_len:870 episode reward: total was -422.900000. running mean: -176.669219\n",
      "startIDX:  1028\n",
      "440 12 True\n",
      "x_t:  2 [0.878125   0.40416667 0.046875   0.20416667]\n",
      "Q values:  tensor([[-25.2319, -24.7745, -27.3138, -24.7428, -28.5911, -24.7312]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13566 296 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 440: ep_len:296 episode reward: total was -169.000000. running mean: -176.592527\n",
      "startIDX:  1812\n",
      "440 15 True\n",
      "x_t:  0 [0.53125    0.40833333 0.1        0.34583333]\n",
      "Q values:  tensor([[-21.0240, -19.9730, -21.3716, -19.5374, -21.9197, -20.2145]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13422 450 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 440: ep_len:450 episode reward: total was -269.200000. running mean: -177.518602\n",
      "startIDX:  995\n",
      "440 22 False\n",
      "x_t:  0 [0.834375   0.40416667 0.10625    0.34166667]\n",
      "Q values:  tensor([[-17.9883, -18.4629, -20.4180, -18.3647, -19.3541, -19.1311]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10411 447 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 440: ep_len:447 episode reward: total was -267.100000. running mean: -178.414416\n",
      "startIDX:  2031\n",
      "441 0 True\n",
      "x_t:  0 [0.853125   0.40416667 0.121875   0.35      ]\n",
      "Q values:  tensor([[-18.4749, -16.9793, -15.8902, -16.5000, -18.5887, -16.4241]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20631 864 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  450\n",
      "441 1 True\n",
      "x_t:  1 [0.603125   0.27916667 0.190625   0.47083333]\n",
      "Q values:  tensor([[-18.1347, -18.3711, -17.5010, -17.4367, -21.5047, -18.1020]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30706 786 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  748\n",
      "441 5 False\n",
      "x_t:  3 [0.084375   0.25833333 0.0875     0.32083333]\n",
      "Q values:  tensor([[-19.2355, -17.8742, -19.2306, -17.2556, -19.4092, -18.0289]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8756 1314 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  683\n",
      "441 10 False\n",
      "x_t:  1 [0.103125 0.35     0.1125   0.375   ]\n",
      "Q values:  tensor([[-27.6814, -25.0713, -27.2115, -28.8310, -27.7924, -26.3316]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7114 264 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  991\n",
      "441 12 False\n",
      "x_t:  2 [0.79375    0.4125     0.096875   0.24583333]\n",
      "Q values:  tensor([[-26.1109, -27.0258, -25.1108, -26.4085, -27.7488, -25.3581]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13574 318 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3034\n",
      "startIDX:  2180\n",
      "441 22 False\n",
      "x_t:  0 [0.940625   0.39583333 0.05625    0.35      ]\n",
      "Q values:  tensor([[-36.2970, -37.7028, -37.9977, -36.4548, -40.6825, -37.0719]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20682 809 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1133\n",
      "442 0 True\n",
      "x_t:  2 [0.771875   0.40833333 0.084375   0.2875    ]\n",
      "Q values:  tensor([[-38.7630, -34.9537, -33.3633, -34.4559, -38.3732, -34.9754]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12636 332 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 442: ep_len:332 episode reward: total was -219.100000. running mean: -195.063953\n",
      "startIDX:  645\n",
      "442 1 False\n",
      "x_t:  2 [0.809375   0.38333333 0.10625    0.30833333]\n",
      "Q values:  tensor([[-28.8761, -27.1636, -26.3590, -30.8024, -27.1295, -27.8916]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31461 358 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 442: ep_len:358 episode reward: total was -238.000000. running mean: -195.493314\n",
      "startIDX:  1231\n",
      "442 5 False\n",
      "x_t:  2 [0.25       0.39583333 0.09375    0.27916667]\n",
      "Q values:  tensor([[-25.9687, -27.4217, -24.7728, -26.0962, -27.2901, -26.3627]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12037 757 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 442: ep_len:757 episode reward: total was -449.500000. running mean: -198.033381\n",
      "startIDX:  1216\n",
      "442 10 False\n",
      "x_t:  3 [0.084375   0.22083333 0.059375   0.24583333]\n",
      "Q values:  tensor([[-27.1631, -27.4318, -29.5445, -26.5690, -28.5171, -28.6909]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14581 1225 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 442: ep_len:1225 episode reward: total was -888.300000. running mean: -204.936047\n",
      "startIDX:  449\n",
      "442 12 True\n",
      "x_t:  3 [0.7875     0.3625     0.165625   0.41666667]\n",
      "Q values:  tensor([[-20.9995, -19.9558, -24.2971, -20.7094, -23.6617, -21.6418]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7718 240 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 442: ep_len:240 episode reward: total was -167.700000. running mean: -204.563686\n",
      "startIDX:  1287\n",
      "442 15 False\n",
      "x_t:  3 [0.896875   0.34583333 0.1        0.39166667]\n",
      "Q values:  tensor([[-27.6019, -26.1915, -28.9627, -25.5460, -27.2321, -26.2393]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10335 235 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 442: ep_len:235 episode reward: total was -159.500000. running mean: -204.113050\n",
      "startIDX:  2679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442 22 False\n",
      "x_t:  4 [0.0875     0.40416667 0.125      0.3       ]\n",
      "Q values:  tensor([[-28.5068, -29.5425, -28.7796, -29.3463, -27.2837, -27.8579]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27279 524 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 442: ep_len:524 episode reward: total was -270.900000. running mean: -204.780919\n",
      "startIDX:  1084\n",
      "443 0 True\n",
      "x_t:  1 [0.203125   0.35833333 0.175      0.4875    ]\n",
      "Q values:  tensor([[-30.2395, -32.6889, -31.3041, -32.3534, -33.1316, -31.8162]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12010 779 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  962\n",
      "443 1 True\n",
      "x_t:  4 [0.003125   0.39583333 0.11875    0.40833333]\n",
      "Q values:  tensor([[-38.7724, -35.8678, -36.8378, -37.2206, -35.9896, -35.5973]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35421 475 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1545\n",
      "443 5 False\n",
      "x_t:  1 [0.528125   0.29583333 0.115625   0.28333333]\n",
      "Q values:  tensor([[-30.2890, -27.4696, -31.6691, -27.5091, -29.0041, -29.0367]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14971 710 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2254\n",
      "443 10 False\n",
      "x_t:  1 [0.88125    0.28333333 0.103125   0.35      ]\n",
      "Q values:  tensor([[-37.4709, -34.7296, -36.4145, -37.0511, -37.4345, -36.1292]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22470 1249 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  757\n",
      "443 12 False\n",
      "x_t:  1 [0.4875     0.34166667 0.159375   0.52083333]\n",
      "Q values:  tensor([[-30.4082, -29.8953, -30.5061, -30.9652, -33.3708, -30.8342]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10336 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  357\n",
      "443 15 False\n",
      "x_t:  1 [0.003125   0.38333333 0.128125   0.48333333]\n",
      "Q values:  tensor([[-33.5010, -32.9922, -35.8494, -34.3564, -33.4112, -33.0093]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2752 239 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1410\n",
      "443 22 True\n",
      "x_t:  3 [0.290625   0.29583333 0.103125   0.32083333]\n",
      "Q values:  tensor([[-17.9233, -20.9489, -20.0554, -20.8743, -20.2255, -19.3409]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15258 1292 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  914\n",
      "444 0 False\n",
      "x_t:  0 [0.88125    0.40416667 0.109375   0.35833333]\n",
      "Q values:  tensor([[-22.9885, -25.9028, -24.4657, -25.8701, -24.5833, -23.6496]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10330 445 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 444: ep_len:445 episode reward: total was -300.100000. running mean: -222.616392\n",
      "startIDX:  925\n",
      "444 1 False\n",
      "x_t:  4 [0.003125   0.39583333 0.11875    0.4       ]\n",
      "Q values:  tensor([[-23.4066, -23.7690, -25.1248, -23.7814, -23.2669, -23.3583]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35422 505 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 444: ep_len:505 episode reward: total was -357.900000. running mean: -223.969228\n",
      "startIDX:  2508\n",
      "444 5 False\n",
      "x_t:  2 [0.003125   0.4        0.075      0.25833333]\n",
      "Q values:  tensor([[-23.8306, -26.7552, -23.6518, -25.4455, -27.3912, -25.4590]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21545 798 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 444: ep_len:798 episode reward: total was -561.900000. running mean: -227.348536\n",
      "startIDX:  1263\n",
      "444 10 False\n",
      "x_t:  3 [0.06875    0.22083333 0.065625   0.25      ]\n",
      "Q values:  tensor([[-31.3525, -33.6212, -31.8468, -30.9480, -31.7581, -31.5978]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14575 1214 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 444: ep_len:1214 episode reward: total was -895.000000. running mean: -234.025051\n",
      "startIDX:  220\n",
      "444 12 False\n",
      "x_t:  3 [0.071875   0.25833333 0.0625     0.26666667]\n",
      "Q values:  tensor([[-34.5621, -35.7818, -38.4016, -33.7408, -35.6800, -35.5736]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5668 1374 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 444: ep_len:1374 episode reward: total was -1028.900000. running mean: -241.973800\n",
      "startIDX:  1533\n",
      "444 15 True\n",
      "x_t:  2 [0.0625     0.4125     0.103125   0.25833333]\n",
      "Q values:  tensor([[-30.9029, -32.9706, -31.9778, -30.7675, -30.5711, -32.5236]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 11921 757 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 444: ep_len:757 episode reward: total was -559.400000. running mean: -245.148062\n",
      "startIDX:  1768\n",
      "444 22 True\n",
      "x_t:  3 [0.409375   0.29583333 0.0875     0.32083333]\n",
      "Q values:  tensor([[-24.7267, -27.9450, -28.2220, -28.1718, -29.1819, -27.8802]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16914 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 444: ep_len:204 episode reward: total was -148.200000. running mean: -244.178582\n",
      "startIDX:  104\n",
      "445 0 False\n",
      "x_t:  1 [0.86875    0.3        0.128125   0.42916667]\n",
      "Q values:  tensor([[-30.5777, -28.2031, -30.6545, -32.5969, -28.5039, -28.3708]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1607 710 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  778\n",
      "445 1 False\n",
      "x_t:  3 [0.0625     0.23333333 0.059375   0.275     ]\n",
      "Q values:  tensor([[-31.4452, -32.7381, -32.9905, -30.5687, -31.5155, -31.0293]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34301 1356 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  705\n",
      "445 5 False\n",
      "x_t:  3 [0.0625     0.25833333 0.078125   0.31666667]\n",
      "Q values:  tensor([[-25.8630, -24.5799, -25.5636, -23.7618, -24.1603, -24.2252]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8747 1299 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1093\n",
      "445 10 True\n",
      "x_t:  2 [0.859375   0.38333333 0.075      0.26666667]\n",
      "Q values:  tensor([[-25.2602, -26.0219, -25.6520, -27.1477, -25.8696, -25.0641]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12054 349 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1517\n",
      "445 12 False\n",
      "x_t:  2 [0.2875     0.40833333 0.090625   0.3       ]\n",
      "Q values:  tensor([[-23.0287, -22.8892, -20.4335, -22.6390, -23.5957, -21.3721]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19420 795 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  362\n",
      "445 15 False\n",
      "x_t:  1 [0.234375   0.36666667 0.18125    0.50833333]\n",
      "Q values:  tensor([[-28.2636, -25.6617, -26.9506, -26.7918, -26.2872, -25.8647]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2768 248 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  829\n",
      "445 22 False\n",
      "x_t:  1 [0.153125   0.35416667 0.15625    0.40416667]\n",
      "Q values:  tensor([[-27.8613, -25.6014, -25.7089, -27.4569, -26.4257, -25.9611]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9499 289 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1531\n",
      "446 0 False\n",
      "x_t:  3 [0.703125   0.35       0.153125   0.39166667]\n",
      "Q values:  tensor([[-28.4964, -29.3055, -29.0593, -27.6187, -28.9095, -27.8112]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16829 251 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 446: ep_len:251 episode reward: total was -125.200000. running mean: -254.899324\n",
      "startIDX:  669\n",
      "446 1 False\n",
      "x_t:  3 [0.065625   0.22916667 0.0625     0.28333333]\n",
      "Q values:  tensor([[-23.4915, -24.5151, -23.8560, -22.1533, -25.1379, -23.7379]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34303 1417 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 446: ep_len:1417 episode reward: total was -612.000000. running mean: -258.470331\n",
      "startIDX:  2840\n",
      "ep 446: ep_len:118 episode reward: total was 82.000000. running mean: -255.065628\n",
      "startIDX:  52\n",
      "446 10 True\n",
      "x_t:  3 [0.0625     0.23333333 0.0625     0.25416667]\n",
      "Q values:  tensor([[-25.6529, -25.7259, -24.0928, -23.4996, -25.4406, -23.3031]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3581 1076 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 446: ep_len:1076 episode reward: total was -426.500000. running mean: -256.779971\n",
      "startIDX:  1332\n",
      "446 12 False\n",
      "x_t:  3 [0.80625    0.35416667 0.109375   0.45      ]\n",
      "Q values:  tensor([[-22.9382, -22.8916, -21.9807, -21.0139, -22.7376, -21.5514]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17851 230 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 446: ep_len:230 episode reward: total was -105.900000. running mean: -255.271172\n",
      "startIDX:  1702\n",
      "446 15 False\n",
      "x_t:  1 [0.259375   0.35       0.13125    0.37083333]\n",
      "Q values:  tensor([[-23.2908, -18.6953, -20.0735, -21.1135, -19.6874, -18.9386]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12473 239 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 446: ep_len:239 episode reward: total was -78.300000. running mean: -253.501460\n",
      "startIDX:  2495\n",
      "446 22 False\n",
      "x_t:  3 [0.0625     0.2375     0.0625     0.24166667]\n",
      "Q values:  tensor([[-16.4920, -15.0127, -16.7721, -12.9041, -15.6689, -13.6952]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26173 1264 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 446: ep_len:1264 episode reward: total was -397.200000. running mean: -254.938445\n",
      "startIDX:  1005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447 0 False\n",
      "x_t:  1 [0.675      0.31666667 0.165625   0.44166667]\n",
      "Q values:  tensor([[-14.8796, -12.4546, -14.8962, -13.7960, -13.9885, -13.1194]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11966 822 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  701\n",
      "447 1 False\n",
      "x_t:  3 [0.178125   0.24166667 0.0875     0.31666667]\n",
      "Q values:  tensor([[-13.3894, -13.6720, -13.3115, -11.7436, -13.4909, -12.3467]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34337 1424 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2687\n",
      "447 5 True\n",
      "x_t:  0 [0.328125   0.40833333 0.096875   0.28333333]\n",
      "Q values:  tensor([[-11.7606, -10.6124, -10.8252, -10.7125, -10.4831,  -9.9428]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23272 818 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2632\n",
      "startIDX:  1091\n",
      "447 12 True\n",
      "x_t:  3 [0.190625   0.28333333 0.09375    0.31666667]\n",
      "Q values:  tensor([[-8.1740, -7.8663, -7.9704, -7.5273, -7.2468, -7.1803]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16403 1390 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  399\n",
      "447 15 True\n",
      "x_t:  0 [0.503125   0.40833333 0.075      0.35      ]\n",
      "Q values:  tensor([[-8.5868, -8.0782, -8.3015, -8.4521, -9.0289, -7.9321]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3718 466 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  263\n",
      "447 22 True\n",
      "x_t:  3 [0.078125   0.24583333 0.071875   0.24166667]\n",
      "Q values:  tensor([[-8.6963, -7.7004, -7.9570, -7.3180, -7.6992, -6.8523]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4879 1271 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  105\n",
      "448 0 False\n",
      "x_t:  1 [0.85       0.3        0.146875   0.42916667]\n",
      "Q values:  tensor([[-7.6754, -6.2259, -6.9580, -6.8983, -7.0653, -6.3756]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1609 712 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 448: ep_len:712 episode reward: total was -84.700000. running mean: -248.123946\n",
      "startIDX:  528\n",
      "448 1 True\n",
      "x_t:  1 [0.65625    0.27083333 0.140625   0.4625    ]\n",
      "Q values:  tensor([[-6.0673, -5.8384, -5.7143, -6.1084, -5.8260, -5.1034]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30701 752 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 448: ep_len:752 episode reward: total was -87.200000. running mean: -246.514707\n",
      "startIDX:  939\n",
      "448 5 False\n",
      "x_t:  3 [0.490625   0.2875     0.096875   0.32916667]\n",
      "Q values:  tensor([[-9.3220, -8.0732, -8.0673, -7.5872, -7.9751, -7.6241]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10531 237 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 448: ep_len:237 episode reward: total was -150.400000. running mean: -245.553560\n",
      "startIDX:  466\n",
      "448 10 False\n",
      "x_t:  3 [0.25625    0.24583333 0.05625    0.28333333]\n",
      "Q values:  tensor([[ 0.6475, -1.6031, -1.1212,  1.4201, -1.2861, -0.9131]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5134 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 448: ep_len:200 episode reward: total was -40.600000. running mean: -243.504024\n",
      "startIDX:  1037\n",
      "448 12 True\n",
      "x_t:  2 [0.36875    0.4125     0.078125   0.25416667]\n",
      "Q values:  tensor([[-8.0055, -6.4557, -6.4080, -6.3413, -6.4866, -6.1554]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13641 335 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 448: ep_len:335 episode reward: total was -92.100000. running mean: -241.989984\n",
      "startIDX:  3035\n",
      "ep 448: ep_len:67 episode reward: total was 39.000000. running mean: -239.180084\n",
      "startIDX:  2042\n",
      "448 22 False\n",
      "x_t:  1 [0.08125    0.35416667 0.125      0.39583333]\n",
      "Q values:  tensor([[-8.6518, -7.1267, -8.5831, -7.7493, -7.5492, -7.1535]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18998 238 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 448: ep_len:238 episode reward: total was -32.400000. running mean: -237.112283\n",
      "startIDX:  867\n",
      "449 0 True\n",
      "x_t:  0 [0.81875    0.4        0.084375   0.35833333]\n",
      "Q values:  tensor([[-7.5981, -6.4741, -6.7438, -7.0074, -6.5780, -5.9954]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10343 449 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  651\n",
      "449 1 False\n",
      "x_t:  3 [0.0875     0.23333333 0.08125    0.29583333]\n",
      "Q values:  tensor([[-7.8371, -7.5069, -7.5674, -6.4993, -7.1632, -6.6402]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34311 1775 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  331\n",
      "449 5 True\n",
      "x_t:  1 [0.75       0.28333333 0.0875     0.36666667]\n",
      "Q values:  tensor([[-7.6268, -7.1993, -8.1056, -7.5603, -7.7600, -7.4149]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5044 731 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  924\n",
      "449 10 True\n",
      "x_t:  1 [0.74375    0.28333333 0.059375   0.33333333]\n",
      "Q values:  tensor([[-6.9127, -6.6704, -6.7589, -6.6545, -6.3716, -5.7126]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11348 1588 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1094\n",
      "449 12 False\n",
      "x_t:  3 [0.075      0.26666667 0.078125   0.2875    ]\n",
      "Q values:  tensor([[-10.3136,  -8.4039,  -8.3707,  -7.6575,  -8.8101,  -7.8584]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16376 1412 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1420\n",
      "449 15 False\n",
      "x_t:  3 [0.425      0.2875     0.109375   0.30833333]\n",
      "Q values:  tensor([[-2.3027, -2.4910, -2.3650, -0.4785, -2.5892, -2.6997]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10413 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2894\n",
      "Time elapsed:  3903.036534547806\n",
      "startIDX:  2257\n",
      "450 0 True\n",
      "x_t:  2 [0.359375 0.4125   0.109375 0.25    ]\n",
      "Q values:  tensor([[-9.9374, -9.9206, -8.8918, -8.9497, -9.0556, -8.0018]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23659 357 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 450: ep_len:357 episode reward: total was -126.400000. running mean: -231.281077\n",
      "startIDX:  733\n",
      "450 1 False\n",
      "x_t:  3 [0.071875   0.22916667 0.065625   0.29166667]\n",
      "Q values:  tensor([[-15.4452, -12.9851, -13.8998, -12.8858, -13.9306, -12.9208]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34306 1389 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 450: ep_len:1389 episode reward: total was -438.700000. running mean: -233.355266\n",
      "startIDX:  454\n",
      "450 5 False\n",
      "x_t:  1 [0.825      0.27916667 0.084375   0.38333333]\n",
      "Q values:  tensor([[-10.3370,  -9.0825, -10.1025, -10.1297, -10.1555,  -9.7453]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5035 650 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 450: ep_len:650 episode reward: total was -201.400000. running mean: -233.035713\n",
      "startIDX:  2443\n",
      "450 10 False\n",
      "x_t:  1 [0.803125   0.27916667 0.11875    0.34166667]\n",
      "Q values:  tensor([[-13.0290, -11.0010, -11.5374, -12.1418, -12.1841, -11.2104]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22476 1175 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 450: ep_len:1175 episode reward: total was -401.600000. running mean: -234.721356\n",
      "startIDX:  1671\n",
      "450 12 False\n",
      "x_t:  1 [0.046875   0.37083333 0.140625   0.35833333]\n",
      "Q values:  tensor([[-11.6427,  -9.7567, -10.5146, -10.5602, -10.4898,  -9.8919]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19877 238 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 450: ep_len:238 episode reward: total was -59.100000. running mean: -232.965143\n",
      "startIDX:  191\n",
      "450 15 True\n",
      "x_t:  2 [0.028125   0.40416667 0.11875    0.3375    ]\n",
      "Q values:  tensor([[-18.3041, -17.0167, -15.8327, -17.8925, -17.6993, -15.6333]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2199 794 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 450: ep_len:794 episode reward: total was -314.700000. running mean: -233.782491\n",
      "startIDX:  1792\n",
      "450 22 False\n",
      "x_t:  3 [0.26875 0.275   0.08125 0.3    ]\n",
      "Q values:  tensor([[-10.7702,  -9.6601,  -9.5038,  -9.3043,  -9.7502,  -9.4937]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16944 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 450: ep_len:201 episode reward: total was -92.900000. running mean: -232.373666\n",
      "startIDX:  1640\n",
      "451 0 False\n",
      "x_t:  3 [0.4        0.29166667 0.0875     0.34166667]\n",
      "Q values:  tensor([[-12.3679, -11.9598, -11.5714, -11.0692, -11.6618, -12.0956]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16878 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1039\n",
      "451 1 False\n",
      "x_t:  3 [0.60625    0.29583333 0.1125     0.36666667]\n",
      "Q values:  tensor([[-17.0798, -15.4255, -15.3911, -14.7778, -15.1093, -15.2816]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35939 226 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  191\n",
      "451 5 True\n",
      "x_t:  1 [0.4        0.325      0.1375     0.54583333]\n",
      "Q values:  tensor([[-16.0852, -14.8516, -15.1535, -16.6226, -14.5201, -15.0824]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2538 232 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  909\n",
      "451 10 False\n",
      "x_t:  1 [0.85       0.2875     0.128125   0.33333333]\n",
      "Q values:  tensor([[-35.2040, -31.1060, -31.1926, -33.0166, -32.5779, -31.5339]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11331 1596 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  1097\n",
      "451 12 False\n",
      "x_t:  3 [0.065625   0.2625     0.0625     0.24583333]\n",
      "Q values:  tensor([[-31.5850, -26.0985, -29.1845, -25.4325, -26.6820, -27.4156]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16373 1353 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  71\n",
      "451 15 True\n",
      "x_t:  3 [0.678125   0.32916667 0.115625   0.40416667]\n",
      "Q values:  tensor([[-17.9786, -17.2202, -15.9189, -16.7662, -15.5270, -16.0725]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 542 224 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1712\n",
      "451 22 False\n",
      "x_t:  3 [0.525      0.3125     0.115625   0.34583333]\n",
      "Q values:  tensor([[-18.7548, -18.3962, -21.1611, -16.6048, -19.4835, -17.6797]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16894 214 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  900\n",
      "452 0 False\n",
      "x_t:  1 [0.8        0.31666667 0.178125   0.42083333]\n",
      "Q values:  tensor([[-37.5170, -36.0282, -37.0916, -36.9002, -36.8786, -36.8066]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11951 1258 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 452: ep_len:1258 episode reward: total was -927.600000. running mean: -249.593972\n",
      "startIDX:  572\n",
      "452 1 False\n",
      "x_t:  2 [0.796875   0.37916667 0.075      0.30416667]\n",
      "Q values:  tensor([[-26.4991, -28.2084, -26.0362, -28.7820, -29.9930, -26.1979]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31467 401 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 452: ep_len:401 episode reward: total was -281.000000. running mean: -249.908032\n",
      "startIDX:  37\n",
      "452 5 False\n",
      "x_t:  2 [0.015625   0.3875     0.19375    0.42083333]\n",
      "Q values:  tensor([[-40.2534, -40.6294, -36.7786, -41.5162, -38.0229, -38.2493]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2058 901 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 452: ep_len:901 episode reward: total was -592.900000. running mean: -253.337952\n",
      "startIDX:  458\n",
      "452 10 False\n",
      "x_t:  3 [0.253125   0.24583333 0.071875   0.27916667]\n",
      "Q values:  tensor([[-20.8918, -19.1249, -22.2306, -19.0922, -20.7691, -19.4267]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5133 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 452: ep_len:202 episode reward: total was -131.700000. running mean: -252.121572\n",
      "startIDX:  1075\n",
      "452 12 False\n",
      "x_t:  3 [0.128125   0.275      0.09375    0.30833333]\n",
      "Q values:  tensor([[-42.0024, -47.2039, -42.9522, -38.5526, -42.3954, -43.1194]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16390 1404 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 452: ep_len:1404 episode reward: total was -992.400000. running mean: -259.524356\n",
      "startIDX:  1398\n",
      "452 15 True\n",
      "x_t:  3 [0.5375     0.29583333 0.115625   0.34166667]\n",
      "Q values:  tensor([[-23.4385, -21.9020, -23.1156, -23.1443, -22.7984, -23.0130]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10390 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 452: ep_len:203 episode reward: total was -154.100000. running mean: -258.470113\n",
      "startIDX:  1391\n",
      "452 22 True\n",
      "x_t:  3 [0.096875   0.25416667 0.075      0.2875    ]\n",
      "Q values:  tensor([[-32.5225, -34.7684, -33.5944, -34.4166, -36.7664, -33.6908]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15209 1274 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 452: ep_len:1274 episode reward: total was -836.500000. running mean: -264.250412\n",
      "startIDX:  2042\n",
      "453 0 False\n",
      "x_t:  0 [0.66875    0.39583333 0.09375    0.37083333]\n",
      "Q values:  tensor([[-26.8634, -26.9640, -27.7867, -29.4959, -28.5945, -27.5059]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20697 874 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  589\n",
      "453 1 False\n",
      "x_t:  2 [0.809375   0.37916667 0.09375    0.31666667]\n",
      "Q values:  tensor([[-22.9743, -23.4071, -22.8753, -24.9852, -24.0376, -23.9524]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31462 389 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1700\n",
      "453 5 False\n",
      "x_t:  1 [0.784375   0.28333333 0.059375   0.30416667]\n",
      "Q values:  tensor([[-29.9842, -29.4129, -30.3430, -30.6881, -33.7324, -29.5099]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14937 626 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2048\n",
      "453 10 False\n",
      "x_t:  1 [0.1        0.3375     0.10625    0.38333333]\n",
      "Q values:  tensor([[-19.6800, -18.8600, -18.9120, -18.9478, -19.4548, -19.3566]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18820 278 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1128\n",
      "453 12 False\n",
      "x_t:  3 [0.06875 0.2625  0.06875 0.25   ]\n",
      "Q values:  tensor([[-29.0943, -29.2220, -30.6458, -27.2707, -30.3572, -27.5898]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16374 1344 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2733\n",
      "453 15 True\n",
      "x_t:  2 [0.084375   0.4125     0.125      0.32916667]\n",
      "Q values:  tensor([[-27.2417, -26.7931, -27.5949, -27.9061, -27.6834, -26.0194]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21486 831 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2313\n",
      "453 22 False\n",
      "x_t:  1 [0.86875    0.3        0.128125   0.44583333]\n",
      "Q values:  tensor([[-23.2162, -22.4455, -23.4868, -25.0844, -24.4528, -23.6985]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22930 1068 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1184\n",
      "454 0 False\n",
      "x_t:  3 [0.0625     0.24583333 0.05625    0.25416667]\n",
      "Q values:  tensor([[-23.5111, -22.6849, -24.5470, -20.2181, -22.0139, -21.6619]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15155 1263 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 454: ep_len:1263 episode reward: total was -586.000000. running mean: -278.240205\n",
      "startIDX:  599\n",
      "454 1 True\n",
      "x_t:  2 [0.646875   0.38333333 0.125      0.30833333]\n",
      "Q values:  tensor([[-26.1657, -25.8364, -26.7734, -25.0142, -24.3297, -23.8312]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31486 388 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 454: ep_len:388 episode reward: total was -189.400000. running mean: -277.351803\n",
      "startIDX:  1952\n",
      "454 5 False\n",
      "x_t:  3 [0.06875  0.25     0.078125 0.2625  ]\n",
      "Q values:  tensor([[-15.5653, -17.6221, -17.1626, -15.0694, -17.9794, -16.3818]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18206 1258 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 454: ep_len:1258 episode reward: total was -449.100000. running mean: -279.069284\n",
      "startIDX:  2112\n",
      "454 10 False\n",
      "x_t:  0 [0.871875   0.39166667 0.10625    0.34583333]\n",
      "Q values:  tensor([[-21.2587, -22.4756, -23.5882, -21.7889, -23.3757, -21.8927]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19936 555 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 454: ep_len:555 episode reward: total was -206.900000. running mean: -278.347592\n",
      "startIDX:  692\n",
      "454 12 False\n",
      "x_t:  1 [0.190625 0.375    0.15     0.5     ]\n",
      "Q values:  tensor([[-22.0984, -19.8964, -24.1893, -21.7807, -22.8394, -20.5585]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10317 236 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 454: ep_len:236 episode reward: total was -49.400000. running mean: -276.058116\n",
      "startIDX:  2991\n",
      "ep 454: ep_len:89 episode reward: total was -41.000000. running mean: -273.707535\n",
      "startIDX:  524\n",
      "454 22 True\n",
      "x_t:  4 [0.025      0.41666667 0.0875     0.36666667]\n",
      "Q values:  tensor([[-13.3712, -13.9846, -13.9052, -14.1604, -13.9814, -13.1288]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 6638 829 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 454: ep_len:829 episode reward: total was -210.500000. running mean: -273.075459\n",
      "startIDX:  7\n",
      "455 0 False\n",
      "x_t:  1 [0.86875    0.3        0.128125   0.42916667]\n",
      "Q values:  tensor([[-13.3631, -12.8861, -13.7018, -13.8675, -13.5066, -12.9834]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1607 755 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  418\n",
      "455 1 False\n",
      "x_t:  0 [0.8375     0.37083333 0.13125    0.40416667]\n",
      "Q values:  tensor([[-12.4590, -12.6917, -14.1533, -13.2223, -14.0312, -12.7638]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29096 493 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  181\n",
      "455 5 False\n",
      "x_t:  1 [0.003125   0.37083333 0.190625   0.49583333]\n",
      "Q values:  tensor([[ -9.9010,  -8.6330,  -9.7743,  -9.7816, -10.5232,  -8.8627]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2516 1062 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1233\n",
      "455 10 True\n",
      "x_t:  3 [0.184375   0.2375     0.075      0.28333333]\n",
      "Q values:  tensor([[-8.8394, -8.4723, -9.1047, -8.4936, -8.7403, -8.5434]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14615 1240 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  543\n",
      "455 12 True\n",
      "x_t:  2 [0.15625    0.4125     0.090625   0.25416667]\n",
      "Q values:  tensor([[-8.6148, -8.7266, -9.1176, -8.7678, -8.2750, -7.6450]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9851 1065 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1836\n",
      "455 15 True\n",
      "x_t:  0 [0.828125   0.4        0.096875   0.32916667]\n",
      "Q values:  tensor([[-10.6719, -10.6749, -10.8971, -11.1810, -11.3718,  -9.7602]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13376 419 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455 22 True\n",
      "x_t:  1 [0.86875    0.3        0.128125   0.44583333]\n",
      "Q values:  tensor([[-5.6381, -5.3213, -5.3660, -5.0855, -5.2843, -4.9494]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22930 1027 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2158\n",
      "456 0 True\n",
      "x_t:  1 [0.3125     0.35416667 0.240625   0.5       ]\n",
      "Q values:  tensor([[-4.5078, -4.5978, -5.1352, -4.3660, -4.2429, -3.9272]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22958 1124 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 456: ep_len:1124 episode reward: total was -84.500000. running mean: -262.043835\n",
      "startIDX:  61\n",
      "456 1 True\n",
      "x_t:  3 [0.25       0.2375     0.090625   0.32083333]\n",
      "Q values:  tensor([[-8.1775, -8.4142, -7.9527, -8.3577, -8.4496, -7.0272]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25736 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 456: ep_len:201 episode reward: total was -89.000000. running mean: -260.313397\n",
      "startIDX:  923\n",
      "456 5 True\n",
      "x_t:  1 [0.375      0.30416667 0.06875    0.37916667]\n",
      "Q values:  tensor([[-2.7872, -2.7970, -3.0214, -3.0118, -2.9245, -2.5470]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12542 1244 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 456: ep_len:1244 episode reward: total was -325.400000. running mean: -260.964263\n",
      "startIDX:  780\n",
      "456 10 True\n",
      "x_t:  1 [0.64375    0.2875     0.053125   0.34166667]\n",
      "Q values:  tensor([[-7.8168, -7.8756, -7.7416, -7.6104, -7.7568, -6.1564]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7175 235 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 456: ep_len:235 episode reward: total was -38.300000. running mean: -258.737620\n",
      "startIDX:  1762\n",
      "456 12 True\n",
      "x_t:  0 [0.2        0.425      0.075      0.34583333]\n",
      "Q values:  tensor([[-4.1395, -3.8992, -3.6853, -4.4091, -3.9068, -3.3964]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21189 657 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 456: ep_len:657 episode reward: total was -110.700000. running mean: -257.257244\n",
      "startIDX:  87\n",
      "456 15 True\n",
      "x_t:  3 [0.415625   0.30833333 0.06875    0.32916667]\n",
      "Q values:  tensor([[-4.7997, -5.0175, -4.3115, -4.4631, -4.7862, -3.9207]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 589 237 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 456: ep_len:237 episode reward: total was -65.600000. running mean: -255.340671\n",
      "startIDX:  1034\n",
      "456 22 True\n",
      "x_t:  0 [0.76875    0.40833333 0.075      0.3125    ]\n",
      "Q values:  tensor([[-3.9216, -3.6815, -3.7390, -3.6489, -3.7783, -3.0176]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10426 433 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 456: ep_len:433 episode reward: total was -38.200000. running mean: -253.169265\n",
      "startIDX:  1260\n",
      "457 0 True\n",
      "x_t:  3 [0.29375    0.27916667 0.090625   0.325     ]\n",
      "Q values:  tensor([[-2.5437, -3.0660, -2.9701, -2.7389, -3.1187, -2.3863]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15223 1260 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  620\n",
      "457 1 True\n",
      "x_t:  2 [0.653125   0.37916667 0.115625   0.32083333]\n",
      "Q values:  tensor([[-4.0459, -3.8613, -3.7008, -4.4980, -3.9038, -3.1403]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31485 381 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2438\n",
      "457 5 True\n",
      "x_t:  1 [0.046875   0.34583333 0.175      0.52083333]\n",
      "Q values:  tensor([[-2.9793, -2.8694, -2.9701, -2.9102, -3.1283, -2.4428]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22109 1211 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2307\n",
      "457 10 False\n",
      "x_t:  1 [0.86875    0.275      0.053125   0.34583333]\n",
      "Q values:  tensor([[-3.2216, -2.6835, -3.0743, -3.1427, -3.0282, -2.7282]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22473 1232 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1040\n",
      "457 12 True\n",
      "x_t:  2 [0.41875    0.40833333 0.071875   0.25416667]\n",
      "Q values:  tensor([[-5.1287, -5.0673, -5.0953, -5.6104, -5.0172, -4.2748]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13633 328 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1878\n",
      "457 15 True\n",
      "x_t:  1 [0.8875     0.29583333 0.078125   0.3125    ]\n",
      "Q values:  tensor([[-3.8164, -3.4918, -3.4203, -3.8023, -3.6858, -3.0411]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14843 734 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  180\n",
      "457 22 True\n",
      "x_t:  3 [0.078125   0.24583333 0.071875   0.24166667]\n",
      "Q values:  tensor([[-3.8182, -4.4696, -4.0101, -4.7423, -4.1175, -3.6488]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4877 1666 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2219\n",
      "458 0 True\n",
      "x_t:  3 [0.596875   0.3125     0.115625   0.35833333]\n",
      "Q values:  tensor([[-8.0971, -8.3304, -9.4299, -8.0350, -8.4938, -7.5229]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26206 2773 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 458: ep_len:2773 episode reward: total was -324.800000. running mean: -244.897821\n",
      "startIDX:  832\n",
      "458 1 True\n",
      "x_t:  4 [0.328125 0.375    0.09375  0.3875  ]\n",
      "Q values:  tensor([[-4.5231, -3.9842, -4.6684, -4.3558, -4.4146, -3.7624]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35503 584 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 458: ep_len:584 episode reward: total was -28.400000. running mean: -242.732843\n",
      "startIDX:  959\n",
      "458 5 True\n",
      "x_t:  3 [0.30625    0.25416667 0.090625   0.29583333]\n",
      "Q values:  tensor([[-5.4553, -5.1403, -5.2693, -5.5627, -4.8636, -4.1038]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10563 251 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 458: ep_len:251 episode reward: total was -150.800000. running mean: -241.813514\n",
      "startIDX:  987\n",
      "458 10 False\n",
      "x_t:  1 [0.075      0.34166667 0.09375    0.4125    ]\n",
      "Q values:  tensor([[-6.5926, -5.5536, -5.6680, -6.6115, -5.7627, -5.5828]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11427 1608 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 458: ep_len:1608 episode reward: total was -162.700000. running mean: -241.022379\n",
      "startIDX:  1324\n",
      "458 12 True\n",
      "x_t:  3 [0.609375   0.34166667 0.140625   0.40416667]\n",
      "Q values:  tensor([[-5.2143, -5.2730, -5.4529, -5.9893, -5.2653, -4.6774]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17869 233 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 458: ep_len:233 episode reward: total was -88.500000. running mean: -239.497155\n",
      "startIDX:  3147\n",
      "ep 458: ep_len:9 episode reward: total was -1.000000. running mean: -237.112184\n",
      "startIDX:  1046\n",
      "458 22 True\n",
      "x_t:  1 [0.753125   0.32083333 0.140625   0.475     ]\n",
      "Q values:  tensor([[-5.8899, -5.9008, -5.6553, -6.1958, -6.0773, -5.0292]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11926 1165 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 458: ep_len:1165 episode reward: total was -171.000000. running mean: -236.451062\n",
      "startIDX:  808\n",
      "459 0 False\n",
      "x_t:  0 [0.625      0.40833333 0.08125    0.35416667]\n",
      "Q values:  tensor([[-4.9689, -5.3549, -5.4888, -5.4005, -5.3236, -5.1844]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10392 716 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  131\n",
      "459 1 True\n",
      "x_t:  2 [0.346875   0.37083333 0.140625   0.42916667]\n",
      "Q values:  tensor([[-7.3710, -7.0094, -7.3845, -7.0020, -7.3936, -6.3070]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27484 932 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  822\n",
      "459 5 True\n",
      "x_t:  4 [0.228125   0.40416667 0.115625   0.38333333]\n",
      "Q values:  tensor([[-6.3478, -6.1855, -6.3522, -6.4587, -6.2853, -5.7868]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10040 607 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  923\n",
      "459 10 False\n",
      "x_t:  1 [0.453125   0.30833333 0.1375     0.35416667]\n",
      "Q values:  tensor([[-7.5546, -7.2712, -7.6207, -8.4713, -7.6477, -7.6537]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11383 1628 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  922\n",
      "459 12 True\n",
      "x_t:  2 [0.70625    0.40416667 0.05       0.25416667]\n",
      "Q values:  tensor([[-9.3418, -8.3295, -9.9141, -8.6867, -8.8385, -8.0721]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13592 923 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  980\n",
      "459 15 False\n",
      "x_t:  4 [0.0875     0.3875     0.09375    0.29166667]\n",
      "Q values:  tensor([[-8.7845, -8.6383, -8.6303, -8.3500, -7.8915, -7.8927]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9828 634 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  44\n",
      "459 22 False\n",
      "x_t:  1 [0.85       0.30833333 0.14375    0.40833333]\n",
      "Q values:  tensor([[-8.5375, -7.6883, -8.9750, -8.0512, -8.3593, -7.8928]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1581 709 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  4013.2898848056793\n",
      "startIDX:  1246\n",
      "460 0 True\n",
      "x_t:  3 [0.11875    0.24583333 0.05625    0.275     ]\n",
      "Q values:  tensor([[-10.9046, -11.1694, -11.7762, -10.1431,  -9.5739,  -9.9690]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15174 1251 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 460: ep_len:1251 episode reward: total was -272.200000. running mean: -229.017199\n",
      "startIDX:  1047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460 1 True\n",
      "x_t:  3 [0.815625   0.3        0.09375    0.41666667]\n",
      "Q values:  tensor([[-8.1646, -8.1484, -8.4019, -8.2906, -7.9310, -7.4268]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35906 207 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 460: ep_len:207 episode reward: total was -56.900000. running mean: -227.296027\n",
      "startIDX:  1560\n",
      "460 5 False\n",
      "x_t:  1 [0.903125 0.275    0.065625 0.325   ]\n",
      "Q values:  tensor([[-7.7818, -7.2430, -8.0193, -8.0238, -8.3158, -7.5218]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14921 699 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 460: ep_len:699 episode reward: total was -209.800000. running mean: -227.121067\n",
      "startIDX:  73\n",
      "460 10 True\n",
      "x_t:  3 [0.078125   0.24166667 0.075      0.25833333]\n",
      "Q values:  tensor([[-11.9854, -12.2005, -12.2010, -10.9086, -12.0369, -10.0994]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3588 1095 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 460: ep_len:1095 episode reward: total was -294.300000. running mean: -227.792856\n",
      "startIDX:  103\n",
      "460 12 False\n",
      "x_t:  1 [0.825      0.30833333 0.16875    0.43333333]\n",
      "Q values:  tensor([[-10.0563,  -9.4761, -10.3610, -10.1903,  -9.9791,  -9.5077]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2219 603 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 460: ep_len:603 episode reward: total was -167.000000. running mean: -227.184928\n",
      "startIDX:  1879\n",
      "460 15 False\n",
      "x_t:  1 [0.878125   0.29583333 0.05625    0.30833333]\n",
      "Q values:  tensor([[-13.1152, -12.6307, -13.0606, -13.5538, -12.7185, -13.0013]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14845 738 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 460: ep_len:738 episode reward: total was -221.300000. running mean: -227.126078\n",
      "startIDX:  534\n",
      "460 22 False\n",
      "x_t:  4 [0.01875    0.42083333 0.09375    0.37083333]\n",
      "Q values:  tensor([[-15.7176, -13.5594, -13.9315, -14.3365, -13.1605, -14.2545]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 6635 801 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 460: ep_len:801 episode reward: total was -271.300000. running mean: -227.567818\n",
      "startIDX:  447\n",
      "461 0 True\n",
      "x_t:  3 [0.415625   0.32916667 0.125      0.39166667]\n",
      "Q values:  tensor([[-21.6599, -19.5007, -20.4746, -21.8044, -21.2493, -19.6813]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7046 1080 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  612\n",
      "461 1 False\n",
      "x_t:  2 [0.809375   0.38333333 0.06875    0.30833333]\n",
      "Q values:  tensor([[-14.9185, -13.9603, -13.1950, -14.0653, -13.6417, -13.7165]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31466 383 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2317\n",
      "461 5 False\n",
      "x_t:  3 [0.18125    0.25416667 0.071875   0.3       ]\n",
      "Q values:  tensor([[-14.0293, -13.5869, -15.0236, -12.8681, -15.4197, -13.3241]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19986 209 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1787\n",
      "461 10 False\n",
      "x_t:  2 [0.0125     0.39583333 0.0625     0.25416667]\n",
      "Q values:  tensor([[-18.5079, -17.4320, -16.4201, -19.5570, -17.7221, -17.4090]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18144 860 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  509\n",
      "461 12 False\n",
      "x_t:  3 [0.7875     0.3375     0.128125   0.42083333]\n",
      "Q values:  tensor([[-16.6490, -16.1220, -15.0187, -14.1375, -15.3446, -15.2837]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7720 209 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  77\n",
      "461 15 True\n",
      "x_t:  3 [0.840625   0.35833333 0.15625    0.43333333]\n",
      "Q values:  tensor([[-18.3217, -16.9608, -17.0746, -16.1532, -18.8776, -17.1220]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 520 216 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1538\n",
      "461 22 False\n",
      "x_t:  4 [0.028125   0.39166667 0.078125   0.30833333]\n",
      "Q values:  tensor([[-26.6905, -28.2500, -28.4746, -31.6002, -25.9602, -28.1644]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16327 516 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  80\n",
      "462 0 False\n",
      "x_t:  1 [0.853125   0.3        0.1        0.43333333]\n",
      "Q values:  tensor([[-22.2280, -21.7507, -25.7913, -22.4971, -22.2216, -22.7054]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1614 721 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 462: ep_len:721 episode reward: total was -300.400000. running mean: -227.350746\n",
      "startIDX:  89\n",
      "462 1 False\n",
      "x_t:  3 [0.1375 0.225  0.0625 0.275 ]\n",
      "Q values:  tensor([[-10.0696, -10.6280, -10.6140,  -9.3079, -10.8201, -10.2569]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25772 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 462: ep_len:200 episode reward: total was -69.400000. running mean: -225.771239\n",
      "startIDX:  241\n",
      "462 5 True\n",
      "x_t:  1 [0.440625 0.325    0.18125  0.55    ]\n",
      "Q values:  tensor([[-18.8515, -17.4869, -17.8187, -16.4855, -17.9109, -14.8445]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2541 219 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 462: ep_len:219 episode reward: total was -73.900000. running mean: -224.252526\n",
      "startIDX:  1140\n",
      "462 10 False\n",
      "x_t:  2 [0.859375   0.38333333 0.075      0.26666667]\n",
      "Q values:  tensor([[-18.1087, -19.4325, -16.7989, -18.7749, -18.3663, -17.0221]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12054 319 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 462: ep_len:319 episode reward: total was -95.200000. running mean: -222.962001\n",
      "startIDX:  1822\n",
      "462 12 False\n",
      "x_t:  0 [0.809375   0.40833333 0.096875   0.34583333]\n",
      "Q values:  tensor([[-23.1917, -25.5970, -26.2319, -25.8989, -25.7142, -24.0671]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21107 574 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 462: ep_len:574 episode reward: total was -155.700000. running mean: -222.289381\n",
      "startIDX:  2927\n",
      "462 15 True\n",
      "x_t:  0 [0.921875   0.40416667 0.075      0.35416667]\n",
      "Q values:  tensor([[-19.4762, -18.6337, -20.8558, -18.6091, -21.7633, -17.1998]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23065 486 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 462: ep_len:486 episode reward: total was -130.000000. running mean: -221.366487\n",
      "startIDX:  3001\n",
      "ep 462: ep_len:8 episode reward: total was -6.900000. running mean: -219.221822\n",
      "startIDX:  1264\n",
      "463 0 False\n",
      "x_t:  3 [0.06875    0.24166667 0.071875   0.2625    ]\n",
      "Q values:  tensor([[-28.3895, -26.9997, -28.6110, -25.1267, -28.9973, -25.6085]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15161 1205 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1031\n",
      "463 1 False\n",
      "x_t:  3 [0.5125     0.2875     0.096875   0.33333333]\n",
      "Q values:  tensor([[-19.2745, -18.4155, -18.6966, -16.4824, -20.0750, -16.9788]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35956 233 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  538\n",
      "463 5 True\n",
      "x_t:  2 [0.753125   0.39583333 0.10625    0.29583333]\n",
      "Q values:  tensor([[-14.9639, -15.6342, -14.7587, -15.1065, -16.4651, -13.6264]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6044 496 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2409\n",
      "463 10 True\n",
      "x_t:  1 [0.759375   0.2875     0.096875   0.32916667]\n",
      "Q values:  tensor([[-24.3831, -25.3095, -24.4676, -24.6272, -23.9322, -20.9574]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22483 1200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1793\n",
      "463 12 True\n",
      "x_t:  0 [0.64375    0.41666667 0.10625    0.3375    ]\n",
      "Q values:  tensor([[-14.9994, -15.5638, -16.3644, -15.3744, -16.5923, -13.6018]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21125 590 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  763\n",
      "463 15 True\n",
      "x_t:  2 [0.59375    0.40833333 0.053125   0.29583333]\n",
      "Q values:  tensor([[ -9.6451, -10.1277, -11.0060,  -9.9427,  -9.1905,  -8.5594]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6002 378 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1758\n",
      "463 22 False\n",
      "x_t:  3 [0.471875   0.3        0.1125     0.34583333]\n",
      "Q values:  tensor([[0.8308, 0.5451, 1.0984, 4.5132, 0.6043, 1.4060]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 16903 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2023\n",
      "464 0 True\n",
      "x_t:  0 [0.909375   0.40833333 0.06875    0.3375    ]\n",
      "Q values:  tensor([[-8.0943, -8.3387, -8.3264, -7.7228, -8.6920, -6.7488]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20629 838 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 464: ep_len:838 episode reward: total was -90.600000. running mean: -209.978668\n",
      "startIDX:  528\n",
      "464 1 True\n",
      "x_t:  1 [0.846875 0.2625   0.08125  0.4625  ]\n",
      "Q values:  tensor([[-5.5846, -6.8899, -6.2215, -6.4431, -6.7764, -5.1960]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30685 736 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 464: ep_len:736 episode reward: total was -35.900000. running mean: -208.237881\n",
      "startIDX:  817\n",
      "464 5 True\n",
      "x_t:  4 [0.121875   0.40416667 0.14375    0.3875    ]\n",
      "Q values:  tensor([[-5.5462, -6.2520, -6.3916, -5.5487, -5.5664, -4.8966]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10027 602 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 464: ep_len:602 episode reward: total was -31.800000. running mean: -206.473503\n",
      "startIDX:  1053\n",
      "464 10 True\n",
      "x_t:  1 [0.521875   0.3        0.071875   0.34166667]\n",
      "Q values:  tensor([[-6.2710, -6.3104, -7.2756, -6.3742, -6.7084, -5.4464]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11376 1528 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 464: ep_len:1528 episode reward: total was -118.600000. running mean: -205.594768\n",
      "startIDX:  360\n",
      "464 12 True\n",
      "x_t:  4 [0.009375   0.45       0.14375    0.35833333]\n",
      "Q values:  tensor([[-3.9976, -4.2970, -3.9383, -4.0548, -4.2775, -3.2435]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7185 712 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 464: ep_len:712 episode reward: total was -39.000000. running mean: -203.928820\n",
      "startIDX:  51\n",
      "464 15 True\n",
      "x_t:  2 [0.00625    0.40416667 0.109375   0.33333333]\n",
      "Q values:  tensor([[-3.3965, -3.7417, -3.4990, -3.4621, -3.3743, -2.8177]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2194 1066 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 464: ep_len:1066 episode reward: total was -155.400000. running mean: -203.443532\n",
      "startIDX:  2155\n",
      "464 22 True\n",
      "x_t:  0 [0.65625    0.40833333 0.090625   0.32916667]\n",
      "Q values:  tensor([[-2.2829, -2.3170, -2.4134, -2.1174, -2.5594, -1.9295]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20799 867 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 464: ep_len:867 episode reward: total was -122.500000. running mean: -202.634096\n",
      "startIDX:  2344\n",
      "465 0 True\n",
      "x_t:  3 [0.378125 0.275    0.075    0.3125  ]\n",
      "Q values:  tensor([[-2.7036, -2.6477, -2.8294, -2.2603, -2.3136, -1.9223]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26171 1284 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  251\n",
      "465 1 True\n",
      "x_t:  2 [0.54375    0.37916667 0.14375    0.42916667]\n",
      "Q values:  tensor([[-2.0216, -2.2014, -2.0857, -1.9137, -2.0392, -1.6619]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27511 855 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  616\n",
      "465 5 True\n",
      "x_t:  2 [0.475  0.3875 0.0625 0.3125]\n",
      "Q values:  tensor([[-2.5854, -2.6961, -2.6621, -2.7728, -2.6494, -2.1198]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6086 470 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1159\n",
      "465 10 True\n",
      "x_t:  2 [0.784375   0.4        0.090625   0.24583333]\n",
      "Q values:  tensor([[-2.2525, -2.5016, -2.5368, -2.1790, -2.2292, -1.8023]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12064 326 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1807\n",
      "465 12 True\n",
      "x_t:  0 [0.225      0.42916667 0.0875     0.34166667]\n",
      "Q values:  tensor([[-1.4173, -1.6816, -1.7570, -1.4999, -1.5325, -1.2187]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21181 639 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3130\n",
      "startIDX:  2185\n",
      "465 22 True\n",
      "x_t:  0 [0.646875 0.4      0.065625 0.3375  ]\n",
      "Q values:  tensor([[-1.2938, -1.5613, -1.5521, -1.2722, -1.2747, -1.0850]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20791 877 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  207\n",
      "466 0 True\n",
      "x_t:  2 [0.009375   0.40833333 0.071875   0.3       ]\n",
      "Q values:  tensor([[-1.8560, -2.0290, -2.1194, -1.7976, -2.0535, -1.3995]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2439 388 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 466: ep_len:388 episode reward: total was -95.600000. running mean: -191.766903\n",
      "startIDX:  641\n",
      "466 1 True\n",
      "x_t:  2 [0.640625   0.37916667 0.1        0.32083333]\n",
      "Q values:  tensor([[-2.2099, -2.4522, -2.3712, -2.2012, -2.2850, -1.7580]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31490 393 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 466: ep_len:393 episode reward: total was -42.300000. running mean: -190.272234\n",
      "startIDX:  611\n",
      "466 5 True\n",
      "x_t:  2 [0.7375     0.39166667 0.059375   0.30416667]\n",
      "Q values:  tensor([[-1.6005, -1.8556, -1.7966, -1.5996, -1.5291, -1.2820]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6051 459 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 466: ep_len:459 episode reward: total was -27.100000. running mean: -188.640511\n",
      "startIDX:  991\n",
      "466 10 True\n",
      "x_t:  3 [0.078125 0.225    0.059375 0.25    ]\n",
      "Q values:  tensor([[-3.2944, -3.4851, -3.6793, -3.4196, -3.3792, -2.8080]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14578 3171 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 466: ep_len:3171 episode reward: total was -284.900000. running mean: -189.603106\n",
      "startIDX:  584\n",
      "466 12 True\n",
      "x_t:  1 [0.828125   0.32083333 0.16875    0.5125    ]\n",
      "Q values:  tensor([[-1.8395, -2.1306, -1.9893, -1.7671, -2.0647, -1.5115]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10360 1276 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 466: ep_len:1276 episode reward: total was -125.700000. running mean: -188.964075\n",
      "startIDX:  1295\n",
      "466 15 True\n",
      "x_t:  3 [0.634375   0.3125     0.09375    0.35416667]\n",
      "Q values:  tensor([[-2.1788, -2.2763, -2.3577, -2.0914, -2.3018, -1.5961]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10372 245 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 466: ep_len:245 episode reward: total was -95.800000. running mean: -188.032435\n",
      "startIDX:  1553\n",
      "466 22 True\n",
      "x_t:  4 [0.053125   0.39583333 0.121875   0.29166667]\n",
      "Q values:  tensor([[-2.1792, -2.4379, -2.5899, -2.1238, -2.0365, -1.8460]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16335 510 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 466: ep_len:510 episode reward: total was -21.600000. running mean: -186.368110\n",
      "startIDX:  1917\n",
      "467 0 True\n",
      "x_t:  1 [0.265625   0.34166667 0.121875   0.3875    ]\n",
      "Q values:  tensor([[-2.9278, -2.8211, -3.0558, -2.2767, -2.7832, -2.0743]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18948 251 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  821\n",
      "467 1 True\n",
      "x_t:  4 [0.36875    0.37916667 0.1        0.39583333]\n",
      "Q values:  tensor([[-2.6484, -2.7930, -2.9339, -2.3540, -2.5848, -2.1531]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35482 569 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1856\n",
      "467 5 True\n",
      "x_t:  2 [0.8375     0.4        0.071875   0.24583333]\n",
      "Q values:  tensor([[-2.7780, -3.1043, -3.0912, -2.9240, -2.8758, -2.2355]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15643 344 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1177\n",
      "467 10 True\n",
      "x_t:  3 [0.240625   0.25416667 0.078125   0.2875    ]\n",
      "Q values:  tensor([[-4.1289, -4.6089, -4.6172, -4.2669, -4.5854, -3.6464]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14631 1298 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1684\n",
      "467 12 True\n",
      "x_t:  0 [0.396875 0.425    0.109375 0.3375  ]\n",
      "Q values:  tensor([[-3.4145, -3.6156, -3.7139, -3.4671, -3.5925, -2.9639]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21158 874 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1203\n",
      "467 15 True\n",
      "x_t:  4 [0.30625    0.37916667 0.084375   0.29166667]\n",
      "Q values:  tensor([[-3.7364, -4.3487, -4.0187, -3.9295, -3.5137, -3.3466]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9868 545 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1014\n",
      "467 22 True\n",
      "x_t:  0 [0.678125 0.4125   0.065625 0.3     ]\n",
      "Q values:  tensor([[-3.7922, -3.7893, -4.3550, -3.2777, -3.6319, -2.9454]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10441 456 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1491\n",
      "468 0 True\n",
      "x_t:  3 [0.684375   0.33333333 0.15       0.40416667]\n",
      "Q values:  tensor([[-4.2992, -4.3413, -4.5075, -3.8210, -4.2851, -3.2267]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16832 260 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 468: ep_len:260 episode reward: total was -114.300000. running mean: -176.994800\n",
      "startIDX:  460\n",
      "468 1 True\n",
      "x_t:  1 [0.846875 0.2625   0.08125  0.4625  ]\n",
      "Q values:  tensor([[-3.7320, -4.2170, -4.6511, -4.0296, -4.2780, -3.4506]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30685 782 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 468: ep_len:782 episode reward: total was -33.500000. running mean: -175.559852\n",
      "startIDX:  2342\n",
      "468 5 False\n",
      "x_t:  3 [0.153125 0.25     0.09375  0.3     ]\n",
      "Q values:  tensor([[1.2599, 0.8733, 1.6364, 2.8529, 0.7002, 1.3868]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 19989 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 468: ep_len:200 episode reward: total was -77.700000. running mean: -174.581253\n",
      "startIDX:  2188\n",
      "468 10 False\n",
      "x_t:  0 [0.690625 0.4      0.078125 0.3125  ]\n",
      "Q values:  tensor([[-5.3130, -5.8169, -6.4752, -6.0014, -5.6490, -5.4247]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19983 545 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 468: ep_len:545 episode reward: total was -100.300000. running mean: -173.838441\n",
      "startIDX:  753\n",
      "468 12 False\n",
      "x_t:  0 [0.9125  0.4125  0.08125 0.3    ]\n",
      "Q values:  tensor([[-7.0088, -7.8686, -8.4216, -7.5738, -8.1915, -7.0906]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11628 859 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 468: ep_len:859 episode reward: total was -172.800000. running mean: -173.828056\n",
      "startIDX:  105\n",
      "468 15 False\n",
      "x_t:  3 [0.5625     0.3125     0.090625   0.37916667]\n",
      "Q values:  tensor([[-7.3721, -7.3393, -8.1256, -6.1386, -7.8552, -6.4653]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 562 223 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 468: ep_len:223 episode reward: total was -40.600000. running mean: -172.495776\n",
      "startIDX:  2588\n",
      "468 22 False\n",
      "x_t:  3 [0.14375    0.25       0.071875   0.26666667]\n",
      "Q values:  tensor([[-8.8730, -9.5526, -9.9390, -8.0645, -9.2128, -8.1517]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26202 1225 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 468: ep_len:1225 episode reward: total was -311.700000. running mean: -173.887818\n",
      "startIDX:  820\n",
      "469 0 True\n",
      "x_t:  1 [0.003125   0.36666667 0.125      0.39166667]\n",
      "Q values:  tensor([[-7.5981, -9.1662, -9.1091, -8.0480, -7.5553, -7.0772]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9406 210 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  419\n",
      "469 1 False\n",
      "x_t:  0 [0.7375     0.375      0.11875    0.40416667]\n",
      "Q values:  tensor([[-8.3981, -8.6665, -9.7808, -9.1221, -8.6582, -8.9482]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29116 502 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1983\n",
      "469 5 True\n",
      "x_t:  3 [0.06875  0.25     0.078125 0.2625  ]\n",
      "Q values:  tensor([[-12.2984, -12.2502, -13.5041, -12.2150, -13.0513, -11.8492]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18206 1274 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1546\n",
      "469 10 True\n",
      "x_t:  3 [0.63125    0.30416667 0.1375     0.35833333]\n",
      "Q values:  tensor([[ -9.1802,  -9.1834, -10.5947, -10.3686,  -9.7933,  -8.1525]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16432 334 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1452\n",
      "469 12 False\n",
      "x_t:  3 [0.2875     0.28333333 0.096875   0.30416667]\n",
      "Q values:  tensor([[-0.0922,  0.6991,  1.8439,  3.3116,  0.1319, -0.3094]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17932 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1937\n",
      "469 15 False\n",
      "x_t:  1 [0.890625   0.3        0.103125   0.30416667]\n",
      "Q values:  tensor([[-16.0155, -14.7529, -17.1115, -17.0031, -16.0273, -16.0095]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14840 694 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  74\n",
      "469 22 False\n",
      "x_t:  1 [0.815625 0.3      0.075    0.4     ]\n",
      "Q values:  tensor([[-16.7234, -15.3714, -18.7555, -17.6120, -16.5544, -16.2115]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1587 689 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  4106.96270442009\n",
      "startIDX:  2278\n",
      "470 0 True\n",
      "x_t:  2 [0.16875 0.4125  0.125   0.2625 ]\n",
      "Q values:  tensor([[-15.2986, -13.9228, -15.8289, -14.7095, -15.2598, -15.8368]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23684 361 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 470: ep_len:361 episode reward: total was -193.700000. running mean: -176.648122\n",
      "startIDX:  803\n",
      "470 1 False\n",
      "x_t:  4 [0.171875   0.3875     0.115625   0.40416667]\n",
      "Q values:  tensor([[-24.2791, -22.2656, -23.2795, -23.3215, -20.8201, -22.3287]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35446 583 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 470: ep_len:583 episode reward: total was -234.300000. running mean: -177.224640\n",
      "startIDX:  1269\n",
      "470 5 False\n",
      "x_t:  2 [0.225      0.39166667 0.053125   0.275     ]\n",
      "Q values:  tensor([[-22.3360, -23.1004, -19.9669, -23.5756, -25.1391, -21.6345]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12032 729 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 470: ep_len:729 episode reward: total was -411.100000. running mean: -179.563394\n",
      "startIDX:  989\n",
      "470 10 False\n",
      "x_t:  1 [0.875      0.2875     0.11875    0.34166667]\n",
      "Q values:  tensor([[-44.9121, -41.3055, -46.6949, -46.4543, -42.7798, -42.8844]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11327 1543 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 470: ep_len:1543 episode reward: total was -958.600000. running mean: -187.353760\n",
      "startIDX:  1056\n",
      "470 12 False\n",
      "x_t:  3 [0.0625     0.2625     0.06875    0.25833333]\n",
      "Q values:  tensor([[-31.3389, -33.0291, -33.0368, -29.8460, -33.1544, -30.2424]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16372 1395 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 470: ep_len:1395 episode reward: total was -798.400000. running mean: -193.464222\n",
      "startIDX:  401\n",
      "470 15 False\n",
      "x_t:  0 [0.678125   0.41666667 0.06875    0.32916667]\n",
      "Q values:  tensor([[-18.0040, -18.0054, -19.6818, -21.1984, -19.7284, -18.7772]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3694 460 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 470: ep_len:460 episode reward: total was -250.900000. running mean: -194.038580\n",
      "startIDX:  2116\n",
      "470 22 False\n",
      "x_t:  0 [0.85       0.40416667 0.078125   0.32083333]\n",
      "Q values:  tensor([[-20.0754, -21.2424, -22.1097, -21.0261, -22.1223, -20.6493]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20705 845 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 470: ep_len:845 episode reward: total was -493.500000. running mean: -197.033194\n",
      "startIDX:  1484\n",
      "471 0 False\n",
      "x_t:  3 [0.803125   0.34166667 0.175      0.425     ]\n",
      "Q values:  tensor([[-18.4274, -17.8095, -19.3898, -16.7286, -18.5819, -18.0500]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16818 256 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  437\n",
      "471 1 False\n",
      "x_t:  1 [0.859375   0.25833333 0.1375     0.47083333]\n",
      "Q values:  tensor([[-29.0414, -26.5622, -30.3863, -30.0645, -29.8152, -30.1611]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30678 787 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1881\n",
      "471 5 True\n",
      "x_t:  2 [0.75       0.39166667 0.053125   0.25833333]\n",
      "Q values:  tensor([[-19.4538, -17.6810, -17.8898, -18.3900, -17.1306, -15.7392]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15660 330 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  918\n",
      "471 10 False\n",
      "x_t:  1 [0.753125   0.28333333 0.128125   0.34166667]\n",
      "Q values:  tensor([[-32.4487, -30.5613, -34.1373, -33.5328, -35.3067, -34.1243]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11342 1608 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  333\n",
      "471 12 False\n",
      "x_t:  4 [0.08125 0.425   0.1125  0.3875 ]\n",
      "Q values:  tensor([[-23.9689, -21.1929, -21.7304, -22.1350, -21.1285, -22.3607]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7191 729 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2492\n",
      "471 15 False\n",
      "x_t:  3 [0.728125   0.32083333 0.06875    0.37083333]\n",
      "Q values:  tensor([[-16.8381, -15.7805, -18.3526, -12.8611, -16.0218, -16.9344]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19679 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1265\n",
      "471 22 False\n",
      "x_t:  2 [0.871875   0.40416667 0.0625     0.18333333]\n",
      "Q values:  tensor([[-25.1087, -28.9458, -23.1119, -27.4798, -26.9393, -25.1068]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12579 309 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  222\n",
      "472 0 False\n",
      "x_t:  2 [0.615625   0.40833333 0.08125    0.29583333]\n",
      "Q values:  tensor([[-31.6985, -30.5876, -30.3976, -31.4116, -31.0895, -31.2298]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2353 340 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 472: ep_len:340 episode reward: total was -220.800000. running mean: -207.287276\n",
      "startIDX:  596\n",
      "472 1 False\n",
      "x_t:  2 [0.8125     0.38333333 0.1125     0.30833333]\n",
      "Q values:  tensor([[-27.4186, -26.1838, -24.5459, -26.8131, -26.6712, -27.8966]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31459 382 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 472: ep_len:382 episode reward: total was -228.700000. running mean: -207.501403\n",
      "startIDX:  904\n",
      "472 5 True\n",
      "x_t:  4 [0.334375   0.39166667 0.13125    0.3625    ]\n",
      "Q values:  tensor([[-31.7554, -30.1830, -30.1798, -29.5157, -31.3820, -29.5711]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10056 570 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 472: ep_len:570 episode reward: total was -395.300000. running mean: -209.379389\n",
      "startIDX:  1069\n",
      "472 10 False\n",
      "x_t:  2 [0.79375    0.4        0.09375    0.24166667]\n",
      "Q values:  tensor([[-27.8379, -28.1811, -27.0328, -30.4265, -29.3876, -27.1591]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12061 375 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 472: ep_len:375 episode reward: total was -224.600000. running mean: -209.531595\n",
      "startIDX:  1351\n",
      "472 12 False\n",
      "x_t:  3 [0.796875   0.34583333 0.075      0.45416667]\n",
      "Q values:  tensor([[-29.1529, -26.2503, -29.1357, -25.9360, -27.1012, -25.9834]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17853 209 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 472: ep_len:209 episode reward: total was -120.800000. running mean: -208.644279\n",
      "startIDX:  292\n",
      "472 15 False\n",
      "x_t:  1 [0.25       0.36666667 0.184375   0.50416667]\n",
      "Q values:  tensor([[-28.1586, -23.4056, -26.1034, -24.9147, -27.3335, -23.9922]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2770 279 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 472: ep_len:279 episode reward: total was -97.000000. running mean: -207.527836\n",
      "startIDX:  2862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 472: ep_len:75 episode reward: total was -61.000000. running mean: -206.062558\n",
      "startIDX:  1587\n",
      "473 0 True\n",
      "x_t:  3 [0.703125   0.35       0.153125   0.39166667]\n",
      "Q values:  tensor([[-23.8750, -21.7891, -23.2904, -22.3666, -23.0054, -22.0728]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16829 219 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  646\n",
      "473 1 False\n",
      "x_t:  2 [0.796875   0.37916667 0.075      0.30416667]\n",
      "Q values:  tensor([[-21.2800, -21.0345, -19.1072, -20.9506, -20.3896, -19.7321]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31467 344 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2649\n",
      "473 5 True\n",
      "x_t:  1 [0.65625    0.29583333 0.190625   0.52916667]\n",
      "Q values:  tensor([[-24.2206, -23.6539, -24.3245, -25.1524, -24.3523, -23.3989]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22166 279 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2494\n",
      "473 10 False\n",
      "x_t:  1 [0.8875  0.2875  0.10625 0.3375 ]\n",
      "Q values:  tensor([[-23.3061, -21.1375, -22.6365, -22.2758, -23.1475, -22.2128]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22469 1134 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1357\n",
      "473 12 False\n",
      "x_t:  3 [0.36875    0.29583333 0.1        0.32083333]\n",
      "Q values:  tensor([[-21.2157, -22.0199, -22.6263, -19.3940, -21.1274, -19.7169]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17913 246 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2900\n",
      "473 15 False\n",
      "x_t:  0 [0.925      0.4        0.06875    0.35416667]\n",
      "Q values:  tensor([[-29.1294, -29.4511, -31.5743, -29.6572, -30.2689, -29.4075]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23064 493 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2889\n",
      "startIDX:  1099\n",
      "474 0 False\n",
      "x_t:  2 [0.621875   0.40416667 0.090625   0.29166667]\n",
      "Q values:  tensor([[-26.6108, -27.2198, -24.5409, -29.5425, -27.1765, -25.1398]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12656 355 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 474: ep_len:355 episode reward: total was -189.300000. running mean: -208.432571\n",
      "startIDX:  398\n",
      "474 1 False\n",
      "x_t:  0 [0.934375   0.37083333 0.059375   0.40416667]\n",
      "Q values:  tensor([[-23.0074, -23.4019, -23.5602, -27.0322, -23.3001, -24.4605]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29087 492 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 474: ep_len:492 episode reward: total was -304.100000. running mean: -209.389246\n",
      "startIDX:  1176\n",
      "474 5 False\n",
      "x_t:  2 [0.109375   0.39583333 0.0875     0.275     ]\n",
      "Q values:  tensor([[-30.4607, -33.5454, -28.1614, -36.1788, -31.1084, -29.3652]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12018 886 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 474: ep_len:886 episode reward: total was -589.000000. running mean: -213.185353\n",
      "startIDX:  2220\n",
      "474 10 False\n",
      "x_t:  0 [0.903125   0.39166667 0.084375   0.35416667]\n",
      "Q values:  tensor([[-22.5353, -23.6362, -22.9998, -25.4099, -24.8138, -23.1400]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19930 506 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 474: ep_len:506 episode reward: total was -288.900000. running mean: -213.942500\n",
      "startIDX:  1821\n",
      "474 12 False\n",
      "x_t:  0 [0.809375 0.4125   0.09375  0.35    ]\n",
      "Q values:  tensor([[-28.2946, -29.3257, -29.3907, -31.1018, -28.7105, -28.3244]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21104 582 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 474: ep_len:582 episode reward: total was -342.700000. running mean: -215.230075\n",
      "startIDX:  2484\n",
      "474 15 False\n",
      "x_t:  3 [0.659375   0.31666667 0.115625   0.3625    ]\n",
      "Q values:  tensor([[-13.7799, -13.0440, -13.1164, -12.1957, -12.5272, -12.6823]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19684 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 474: ep_len:200 episode reward: total was -90.000000. running mean: -213.977774\n",
      "startIDX:  106\n",
      "474 22 False\n",
      "x_t:  1 [0.725      0.30416667 0.15       0.4       ]\n",
      "Q values:  tensor([[-27.4028, -24.4729, -28.7447, -24.5738, -27.3174, -24.8008]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1593 682 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 474: ep_len:682 episode reward: total was -334.000000. running mean: -215.177996\n",
      "startIDX:  1789\n",
      "475 0 False\n",
      "x_t:  2 [0.0875     0.4        0.059375   0.25833333]\n",
      "Q values:  tensor([[-24.7236, -23.2911, -21.3034, -26.2253, -24.7173, -22.9562]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18402 745 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  624\n",
      "475 1 False\n",
      "x_t:  2 [0.8125     0.37916667 0.071875   0.31666667]\n",
      "Q values:  tensor([[-24.8988, -24.0791, -23.1404, -24.7953, -25.3754, -23.4429]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31464 360 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1374\n",
      "475 5 False\n",
      "x_t:  1 [0.046875   0.34583333 0.15       0.40833333]\n",
      "Q values:  tensor([[-23.6599, -21.8174, -24.0726, -24.3311, -25.0123, -22.3647]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12511 235 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1736\n",
      "475 10 True\n",
      "x_t:  3 [0.6375     0.3        0.125      0.36666667]\n",
      "Q values:  tensor([[-26.0611, -23.8208, -24.4566, -25.9104, -26.3382, -23.2142]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16434 248 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  152\n",
      "475 12 False\n",
      "x_t:  2 [0.51875    0.40833333 0.059375   0.25      ]\n",
      "Q values:  tensor([[-27.4020, -23.8918, -23.3247, -24.2793, -24.7083, -24.6447]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2854 320 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1262\n",
      "475 15 False\n",
      "x_t:  3 [0.734375   0.325      0.078125   0.36666667]\n",
      "Q values:  tensor([[-25.1244, -22.0268, -22.8761, -21.7748, -23.6414, -22.3782]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10358 258 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1803\n",
      "475 22 False\n",
      "x_t:  2 [0.003125   0.40833333 0.053125   0.25833333]\n",
      "Q values:  tensor([[-19.4026, -18.1436, -17.7489, -18.0218, -19.0799, -18.4521]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18452 805 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  682\n",
      "476 0 True\n",
      "x_t:  2 [0.03125  0.4125   0.109375 0.2625  ]\n",
      "Q values:  tensor([[-20.2248, -21.7830, -20.8885, -22.1537, -19.9929, -17.7590]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8878 869 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 476: ep_len:869 episode reward: total was -249.600000. running mean: -211.241847\n",
      "startIDX:  1198\n",
      "ep 476: ep_len:5 episode reward: total was 3.000000. running mean: -209.099428\n",
      "startIDX:  592\n",
      "476 5 False\n",
      "x_t:  2 [0.64375    0.3875     0.065625   0.30833333]\n",
      "Q values:  tensor([[-16.6655, -17.1931, -15.3527, -16.0641, -16.2870, -15.4881]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6062 467 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 476: ep_len:467 episode reward: total was -120.300000. running mean: -208.211434\n",
      "startIDX:  446\n",
      "476 10 False\n",
      "x_t:  3 [0.340625   0.25833333 0.078125   0.3125    ]\n",
      "Q values:  tensor([[4.0995, 1.1633, 3.7198, 5.7671, 1.4061, 2.2522]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 5110 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 476: ep_len:200 episode reward: total was -25.000000. running mean: -206.379320\n",
      "startIDX:  336\n",
      "476 12 True\n",
      "x_t:  4 [0.04375    0.44583333 0.146875   0.3625    ]\n",
      "Q values:  tensor([[-11.2274, -11.3822, -11.6575, -10.9433, -11.4766,  -9.9517]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7188 708 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 476: ep_len:708 episode reward: total was -106.300000. running mean: -205.378527\n",
      "startIDX:  2724\n",
      "476 15 True\n",
      "x_t:  2 [0.190625   0.41666667 0.13125    0.32083333]\n",
      "Q values:  tensor([[-10.8582, -11.4363, -10.3797, -10.9030, -11.1309,  -9.2383]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21499 865 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 476: ep_len:865 episode reward: total was -130.600000. running mean: -204.630741\n",
      "startIDX:  225\n",
      "476 22 True\n",
      "x_t:  3 [0.1625     0.25416667 0.0625     0.2625    ]\n",
      "Q values:  tensor([[-10.0710, -10.0134,  -8.8223,  -9.0724,  -8.9270,  -8.7783]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4900 1610 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 476: ep_len:1610 episode reward: total was -312.100000. running mean: -205.705434\n",
      "startIDX:  1618\n",
      "477 0 False\n",
      "x_t:  3 [0.696875   0.34166667 0.1625     0.4       ]\n",
      "Q values:  tensor([[2.9935, 1.9286, 3.7344, 4.4093, 1.0498, 2.8778]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 16828 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  168\n",
      "477 1 True\n",
      "x_t:  2 [0.13125    0.3625     0.153125   0.45833333]\n",
      "Q values:  tensor([[-5.9509, -5.9336, -5.9677, -5.1971, -5.7816, -4.9079]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27452 870 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2508\n",
      "477 5 True\n",
      "x_t:  2 [0.190625   0.39583333 0.075      0.27083333]\n",
      "Q values:  tensor([[-6.1583, -6.4594, -5.7217, -5.9992, -5.9772, -5.1384]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21576 834 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  2404\n",
      "477 10 True\n",
      "x_t:  1 [0.803125   0.27916667 0.11875    0.34166667]\n",
      "Q values:  tensor([[-5.0174, -5.1491, -5.0239, -4.8007, -5.0892, -4.2424]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22476 1200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  830\n",
      "477 12 True\n",
      "x_t:  0 [0.89375    0.40833333 0.075      0.3       ]\n",
      "Q values:  tensor([[-4.8620, -4.8958, -4.4408, -4.2220, -4.8458, -3.8903]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11637 645 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2145\n",
      "477 15 True\n",
      "x_t:  2 [0.7625     0.40833333 0.0875     0.25833333]\n",
      "Q values:  tensor([[-5.4115, -5.0502, -5.0075, -4.6097, -5.3463, -4.2924]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15572 334 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2053\n",
      "477 22 True\n",
      "x_t:  1 [0.16875    0.35       0.084375   0.38333333]\n",
      "Q values:  tensor([[-4.5790, -4.7720, -4.3357, -4.2567, -4.5489, -3.2855]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19007 227 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1971\n",
      "478 0 True\n",
      "x_t:  0 [0.8375     0.39583333 0.103125   0.34166667]\n",
      "Q values:  tensor([[-2.3422, -2.5890, -2.5147, -2.4196, -2.6248, -1.9392]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20638 1058 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 478: ep_len:1058 episode reward: total was -113.900000. running mean: -193.657515\n",
      "startIDX:  650\n",
      "478 1 True\n",
      "x_t:  2 [0.384375   0.3875     0.121875   0.31666667]\n",
      "Q values:  tensor([[-3.7466, -3.7840, -3.7401, -3.5597, -2.9462, -2.8269]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31528 388 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 478: ep_len:388 episode reward: total was -61.200000. running mean: -192.332940\n",
      "startIDX:  2939\n",
      "ep 478: ep_len:71 episode reward: total was 47.000000. running mean: -189.939610\n",
      "startIDX:  95\n",
      "478 10 True\n",
      "x_t:  3 [0.140625   0.24583333 0.06875    0.275     ]\n",
      "Q values:  tensor([[-1.6207, -1.9024, -1.9885, -1.6694, -1.7353, -1.6423]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3606 1062 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 478: ep_len:1062 episode reward: total was -91.000000. running mean: -188.950214\n",
      "startIDX:  1358\n",
      "478 12 True\n",
      "x_t:  3 [0.8        0.37083333 0.140625   0.42916667]\n",
      "Q values:  tensor([[-4.0511, -4.5142, -4.4005, -3.8401, -4.1428, -3.1822]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17850 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 478: ep_len:202 episode reward: total was -69.700000. running mean: -187.757712\n",
      "startIDX:  2521\n",
      "478 15 True\n",
      "x_t:  3 [0.25       0.25833333 0.090625   0.27083333]\n",
      "Q values:  tensor([[-3.2036, -3.3498, -3.4800, -3.1280, -3.1666, -2.2104]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19774 220 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 478: ep_len:220 episode reward: total was -85.300000. running mean: -186.733135\n",
      "startIDX:  1471\n",
      "478 22 False\n",
      "x_t:  4 [0.428125   0.37083333 0.059375   0.30833333]\n",
      "Q values:  tensor([[-2.3052, -2.8539, -2.8115, -2.6899, -2.1781, -2.2487]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16396 568 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 478: ep_len:568 episode reward: total was -39.900000. running mean: -185.264804\n",
      "startIDX:  1679\n",
      "479 0 False\n",
      "x_t:  3 [0.21875    0.25833333 0.065625   0.29583333]\n",
      "Q values:  tensor([[3.3586, 3.7401, 3.9296, 6.1609, 1.4425, 3.5352]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 16917 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  549\n",
      "479 1 True\n",
      "x_t:  1 [0.01875    0.32916667 0.134375   0.5375    ]\n",
      "Q values:  tensor([[-3.0373, -3.2640, -3.2176, -3.0239, -2.9231, -2.5556]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30766 763 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  251\n",
      "479 5 True\n",
      "x_t:  1 [0.778125   0.2875     0.109375   0.58333333]\n",
      "Q values:  tensor([[-6.9192, -7.2299, -6.3612, -6.4629, -6.4176, -5.5892]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2561 212 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1504\n",
      "479 10 True\n",
      "x_t:  3 [0.221875   0.25       0.090625   0.29166667]\n",
      "Q values:  tensor([[-2.8328, -3.1941, -3.2006, -3.1835, -3.0258, -2.3697]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16513 394 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1566\n",
      "479 12 True\n",
      "x_t:  2 [0.153125   0.41666667 0.11875    0.28333333]\n",
      "Q values:  tensor([[-2.9807, -3.5127, -3.2550, -3.0747, -3.1793, -2.5666]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19402 754 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1785\n",
      "479 15 True\n",
      "x_t:  1 [0.146875   0.35       0.103125   0.33333333]\n",
      "Q values:  tensor([[-3.5444, -4.1059, -3.3335, -3.6787, -3.2098, -2.9427]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14937 1231 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2961\n",
      "Time elapsed:  4187.403501033783\n",
      "startIDX:  1851\n",
      "480 0 True\n",
      "x_t:  2 [0.1125     0.40416667 0.103125   0.24583333]\n",
      "Q values:  tensor([[-4.3392, -4.4576, -4.4618, -4.0979, -4.1671, -3.6629]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18410 722 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 480: ep_len:722 episode reward: total was -51.400000. running mean: -177.633432\n",
      "startIDX:  1\n",
      "480 1 True\n",
      "x_t:  3 [0.240625 0.2375   0.078125 0.3125  ]\n",
      "Q values:  tensor([[-4.5247, -4.5912, -5.0351, -4.4734, -4.1437, -3.7127]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25741 232 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 480: ep_len:232 episode reward: total was -100.000000. running mean: -176.857097\n",
      "startIDX:  2121\n",
      "480 5 True\n",
      "x_t:  4 [0.559375   0.34166667 0.05       0.26666667]\n",
      "Q values:  tensor([[-5.2559, -5.4690, -5.3611, -5.2304, -5.2343, -4.4713]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19588 654 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 480: ep_len:654 episode reward: total was -76.400000. running mean: -175.852526\n",
      "startIDX:  2495\n",
      "480 10 True\n",
      "x_t:  1 [0.78125  0.2875   0.140625 0.3375  ]\n",
      "Q values:  tensor([[-6.1907, -6.9628, -6.6318, -6.2802, -6.6420, -5.7043]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22478 1154 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 480: ep_len:1154 episode reward: total was -75.700000. running mean: -174.851001\n",
      "startIDX:  1381\n",
      "480 12 True\n",
      "x_t:  3 [0.33125    0.28333333 0.08125    0.31666667]\n",
      "Q values:  tensor([[-4.7198, -5.4047, -5.1422, -5.0066, -4.7944, -4.0713]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17926 228 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 480: ep_len:228 episode reward: total was -84.900000. running mean: -173.951491\n",
      "startIDX:  730\n",
      "480 15 False\n",
      "x_t:  2 [0.19375    0.40416667 0.121875   0.3       ]\n",
      "Q values:  tensor([[-6.5340, -6.5832, -5.1199, -6.8078, -5.9622, -5.2470]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6054 423 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 480: ep_len:423 episode reward: total was -75.200000. running mean: -172.963976\n",
      "startIDX:  2207\n",
      "480 22 True\n",
      "x_t:  2 [0.88125 0.4     0.08125 0.2125 ]\n",
      "Q values:  tensor([[-8.0513, -8.9641, -8.0081, -8.1886, -8.1513, -7.2495]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23628 1459 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 480: ep_len:1459 episode reward: total was -151.800000. running mean: -172.752336\n",
      "startIDX:  1682\n",
      "481 0 False\n",
      "x_t:  3 [0.2875     0.275      0.10625    0.31666667]\n",
      "Q values:  tensor([[1.3218, 2.7901, 2.9774, 4.6503, 0.1886, 2.1204]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 16898 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  641\n",
      "481 1 True\n",
      "x_t:  2 [0.44375    0.3875     0.06875    0.30416667]\n",
      "Q values:  tensor([[-7.2329, -6.8007, -6.2553, -6.6705, -7.1114, -6.0422]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31523 368 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1177\n",
      "481 5 True\n",
      "x_t:  2 [0.003125   0.40416667 0.090625   0.25416667]\n",
      "Q values:  tensor([[-8.2219, -9.2697, -8.2916, -8.3557, -8.3542, -7.3982]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12002 864 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  467\n",
      "481 10 False\n",
      "x_t:  2 [0.575      0.4        0.071875   0.25833333]\n",
      "Q values:  tensor([[-8.3664, -8.3592, -7.2633, -8.9006, -8.5614, -7.4472]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6676 980 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1481\n",
      "481 12 False\n",
      "x_t:  3 [0.16875    0.25416667 0.059375   0.27916667]\n",
      "Q values:  tensor([[-4.0064, -3.6941, -4.8053, -2.0396, -4.0152, -4.1095]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17967 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2003\n",
      "481 15 True\n",
      "x_t:  1 [0.24375    0.34166667 0.109375   0.3125    ]\n",
      "Q values:  tensor([[-10.9954, -10.8714, -11.2194, -10.5140, -10.3685,  -9.5751]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14925 707 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2310\n",
      "481 22 True\n",
      "x_t:  2 [0.88125 0.4     0.08125 0.2125 ]\n",
      "Q values:  tensor([[ -9.4367, -10.8477,  -9.0523, -10.1683, -10.0818,  -9.0838]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23628 1443 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  1801\n",
      "482 0 True\n",
      "x_t:  2 [0.003125   0.40416667 0.053125   0.25416667]\n",
      "Q values:  tensor([[-9.2909, -8.9230, -9.1290, -8.9254, -8.9628, -8.3437]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18390 741 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 482: ep_len:741 episode reward: total was -99.900000. running mean: -168.605599\n",
      "startIDX:  402\n",
      "482 1 True\n",
      "x_t:  0 [0.840625   0.37916667 0.13125    0.4       ]\n",
      "Q values:  tensor([[-7.9228, -8.4787, -8.2045, -6.8638, -8.0113, -6.6145]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29099 505 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 482: ep_len:505 episode reward: total was -80.500000. running mean: -167.724543\n",
      "startIDX:  2628\n",
      "482 5 True\n",
      "x_t:  1 [0.490625   0.30416667 0.08125    0.52083333]\n",
      "Q values:  tensor([[-8.0652, -8.1801, -7.5095, -8.0294, -7.1692, -6.5988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22145 287 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 482: ep_len:287 episode reward: total was -40.400000. running mean: -166.451298\n",
      "startIDX:  615\n",
      "482 10 True\n",
      "x_t:  2 [0.003125   0.40833333 0.115625   0.25416667]\n",
      "Q values:  tensor([[-12.4347, -12.9676, -11.8169, -12.0818, -10.7401, -10.7274]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6588 730 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 482: ep_len:730 episode reward: total was -126.400000. running mean: -166.050785\n",
      "startIDX:  1362\n",
      "482 12 False\n",
      "x_t:  3 [0.690625 0.35     0.15     0.4375  ]\n",
      "Q values:  tensor([[-6.2678, -6.2063, -5.9051, -5.0773, -6.1657, -5.3723]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17860 214 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 482: ep_len:214 episode reward: total was -51.500000. running mean: -164.905277\n",
      "startIDX:  2448\n",
      "482 15 True\n",
      "x_t:  3 [0.428125   0.27916667 0.078125   0.3       ]\n",
      "Q values:  tensor([[-10.5882, -11.0232, -11.0076,  -8.9657, -10.3090,  -8.9824]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19737 242 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 482: ep_len:242 episode reward: total was -111.000000. running mean: -164.366224\n",
      "startIDX:  985\n",
      "482 22 True\n",
      "x_t:  0 [0.7625     0.4125     0.1125     0.32083333]\n",
      "Q values:  tensor([[-10.4806, -10.1366,  -9.0143,  -9.8801,  -9.3161,  -9.0329]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10418 449 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 482: ep_len:449 episode reward: total was -101.100000. running mean: -163.733562\n",
      "startIDX:  1754\n",
      "483 0 True\n",
      "x_t:  0 [0.71875    0.40416667 0.1125     0.34166667]\n",
      "Q values:  tensor([[-17.1618, -18.7840, -17.8645, -18.0738, -17.7489, -16.0701]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20664 1884 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1105\n",
      "483 1 False\n",
      "x_t:  3 [0.553125   0.27916667 0.0875     0.35833333]\n",
      "Q values:  tensor([[2.3882, 1.9584, 2.4573, 3.2684, 1.0508, 1.3864]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 35950 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2327\n",
      "483 5 False\n",
      "x_t:  3 [0.175      0.24583333 0.090625   0.30416667]\n",
      "Q values:  tensor([[2.1104, 2.0324, 2.7582, 3.7032, 1.8477, 1.5315]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 19984 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2265\n",
      "483 10 True\n",
      "x_t:  1 [0.39375    0.30833333 0.090625   0.34166667]\n",
      "Q values:  tensor([[-17.6240, -18.5245, -18.6282, -17.6163, -17.0151, -15.6805]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22523 1297 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1723\n",
      "startIDX:  2079\n",
      "483 15 False\n",
      "x_t:  2 [0.378125   0.4125     0.09375    0.25416667]\n",
      "Q values:  tensor([[-7.5757, -7.7686, -6.6661, -7.9740, -7.1940, -7.1621]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15629 395 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2502\n",
      "483 22 False\n",
      "x_t:  3 [0.3        0.275      0.084375   0.29166667]\n",
      "Q values:  tensor([[-11.4256, -13.2022, -12.1269, -10.6870, -11.1038, -10.8805]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26239 1297 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1533\n",
      "484 0 True\n",
      "x_t:  3 [0.6875     0.32916667 0.090625   0.3875    ]\n",
      "Q values:  tensor([[ -9.3395, -10.4494, -10.3980,  -9.8457,  -9.3059,  -8.4274]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16835 244 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 484: ep_len:244 episode reward: total was -96.200000. running mean: -166.956131\n",
      "startIDX:  244\n",
      "484 1 True\n",
      "x_t:  2 [0.003125   0.36666667 0.1125     0.44583333]\n",
      "Q values:  tensor([[-12.4027, -12.8868, -12.4650, -11.9795, -12.2387, -10.6864]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27433 828 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 484: ep_len:828 episode reward: total was -105.700000. running mean: -166.343570\n",
      "startIDX:  2273\n",
      "484 5 False\n",
      "x_t:  3 [0.43125    0.2875     0.078125   0.35833333]\n",
      "Q values:  tensor([[2.1170, 1.7397, 3.0856, 4.4722, 1.9819, 1.9489]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 19938 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 484: ep_len:200 episode reward: total was -67.500000. running mean: -165.355134\n",
      "startIDX:  650\n",
      "484 10 True\n",
      "x_t:  2 [0.06875    0.40416667 0.05625    0.25416667]\n",
      "Q values:  tensor([[-10.6893, -11.7609, -10.7579, -10.7974, -10.4582,  -9.6390]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6595 706 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 484: ep_len:706 episode reward: total was -103.300000. running mean: -164.734583\n",
      "startIDX:  145\n",
      "484 12 True\n",
      "x_t:  3 [0.4625   0.3      0.121875 0.3375  ]\n",
      "Q values:  tensor([[-18.5832, -21.1328, -19.0131, -19.2053, -17.2167, -16.9258]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5736 1744 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 484: ep_len:1744 episode reward: total was -371.300000. running mean: -166.800237\n",
      "startIDX:  664\n",
      "484 15 True\n",
      "x_t:  1 [0.55       0.32083333 0.084375   0.275     ]\n",
      "Q values:  tensor([[ -9.8673, -11.3025,  -9.4971,  -9.8276,  -9.0924,  -8.7483]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5217 678 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 484: ep_len:678 episode reward: total was -117.200000. running mean: -166.304234\n",
      "startIDX:  1437\n",
      "484 22 False\n",
      "x_t:  4 [0.009375   0.39166667 0.084375   0.3       ]\n",
      "Q values:  tensor([[-9.2041, -9.9928, -8.8723, -9.1357, -7.8302, -7.8897]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16325 577 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 484: ep_len:577 episode reward: total was -98.100000. running mean: -165.622192\n",
      "startIDX:  1166\n",
      "485 0 True\n",
      "x_t:  2 [0.653125   0.40416667 0.0625     0.29583333]\n",
      "Q values:  tensor([[-8.7685, -9.0025, -9.0625, -8.5441, -8.0999, -7.4866]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12655 327 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  525\n",
      "485 1 True\n",
      "x_t:  1 [0.640625   0.275      0.153125   0.46666667]\n",
      "Q values:  tensor([[-9.0171, -8.4799, -8.6067, -8.2851, -8.2194, -7.1035]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30702 755 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1921\n",
      "485 5 True\n",
      "x_t:  2 [0.846875   0.40416667 0.084375   0.2375    ]\n",
      "Q values:  tensor([[-7.4778, -6.7172, -7.0272, -6.2577, -6.8534, -5.6750]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15640 304 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2306\n",
      "485 10 True\n",
      "x_t:  1 [0.296875   0.32083333 0.06875    0.34583333]\n",
      "Q values:  tensor([[ -9.5293, -10.0298,  -8.9322,  -9.0130,  -8.6472,  -8.4530]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22534 1256 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1125\n",
      "485 12 True\n",
      "x_t:  3 [0.246875 0.2875   0.096875 0.3375  ]\n",
      "Q values:  tensor([[ -9.4112, -10.7256,  -8.6462, -10.0373, -10.0462,  -8.3249]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16416 1376 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3141\n",
      "startIDX:  652\n",
      "485 22 True\n",
      "x_t:  2 [0.7625     0.4125     0.1        0.25833333]\n",
      "Q values:  tensor([[-7.1270, -7.9433, -7.8611, -7.1452, -7.0267, -6.5082]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9043 982 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1599\n",
      "486 0 True\n",
      "x_t:  3 [0.83125    0.35       0.165625   0.41666667]\n",
      "Q values:  tensor([[-6.1439, -6.0236, -5.8772, -5.9040, -5.5949, -4.7224]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16813 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 486: ep_len:204 episode reward: total was -45.800000. running mean: -157.121614\n",
      "startIDX:  412\n",
      "486 1 True\n",
      "x_t:  0 [0.8375     0.37083333 0.13125    0.40416667]\n",
      "Q values:  tensor([[-5.2860, -5.0697, -4.5845, -5.0278, -4.8313, -4.0692]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29098 503 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 486: ep_len:503 episode reward: total was -38.300000. running mean: -155.933397\n",
      "startIDX:  1066\n",
      "486 5 True\n",
      "x_t:  2 [0.253125   0.4        0.1        0.29166667]\n",
      "Q values:  tensor([[-7.6241, -7.3985, -6.5419, -7.1546, -7.0779, -5.9986]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12039 916 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 486: ep_len:916 episode reward: total was -151.300000. running mean: -155.887063\n",
      "startIDX:  1132\n",
      "486 10 True\n",
      "x_t:  2 [0.7875   0.4      0.065625 0.25    ]\n",
      "Q values:  tensor([[-5.7862, -5.8316, -5.3354, -5.6312, -5.3738, -4.6753]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12067 338 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 486: ep_len:338 episode reward: total was -30.300000. running mean: -154.631193\n",
      "startIDX:  1919\n",
      "486 12 True\n",
      "x_t:  0 [0.39375    0.41666667 0.128125   0.375     ]\n",
      "Q values:  tensor([[-4.3781, -4.7530, -4.5538, -4.4368, -4.3604, -3.7845]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23016 927 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 486: ep_len:927 episode reward: total was -62.900000. running mean: -153.713881\n",
      "startIDX:  2589\n",
      "486 15 True\n",
      "x_t:  2 [0.28125    0.39583333 0.06875    0.34583333]\n",
      "Q values:  tensor([[-6.0136, -6.0296, -5.9842, -5.0284, -5.5000, -4.7919]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21509 925 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 486: ep_len:925 episode reward: total was -68.500000. running mean: -152.861742\n",
      "startIDX:  2937\n",
      "ep 486: ep_len:44 episode reward: total was -20.900000. running mean: -151.542125\n",
      "startIDX:  945\n",
      "487 0 True\n",
      "x_t:  0 [0.6875     0.4        0.09375    0.35416667]\n",
      "Q values:  tensor([[-3.9563, -3.9671, -3.5866, -3.8737, -3.4903, -3.3248]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10366 443 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1193\n",
      "startIDX:  2742\n",
      "487 5 True\n",
      "x_t:  0 [0.565625   0.40416667 0.06875    0.3       ]\n",
      "Q values:  tensor([[-3.8327, -3.7910, -3.8845, -3.5041, -3.6168, -3.0091]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23226 567 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1630\n",
      "487 10 True\n",
      "x_t:  3 [0.55       0.29583333 0.103125   0.35416667]\n",
      "Q values:  tensor([[-3.7310, -4.1476, -3.9983, -4.0398, -3.8758, -3.3643]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16448 285 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1160\n",
      "487 12 False\n",
      "x_t:  3 [0.40625    0.325      0.11875    0.37083333]\n",
      "Q values:  tensor([[-3.1519, -3.2823, -3.2172, -2.7784, -3.1789, -2.7950]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16445 1369 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  352\n",
      "487 15 True\n",
      "x_t:  1 [0.284375   0.36666667 0.15625    0.50833333]\n",
      "Q values:  tensor([[-3.3872, -3.7511, -3.3223, -3.3891, -2.9014, -2.8484]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2772 253 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2495\n",
      "487 22 True\n",
      "x_t:  3 [0.115625   0.24583333 0.05625    0.25416667]\n",
      "Q values:  tensor([[-3.7706, -4.3557, -3.6761, -4.0528, -4.0733, -3.3764]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26191 1273 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1695\n",
      "488 0 False\n",
      "x_t:  3 [0.20625    0.26666667 0.06875    0.2875    ]\n",
      "Q values:  tensor([[-2.7181, -2.8025, -2.6536, -2.4138, -2.9232, -2.9528]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16919 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 488: ep_len:203 episode reward: total was -47.500000. running mean: -144.220315\n",
      "startIDX:  498\n",
      "488 1 True\n",
      "x_t:  1 [0.334375   0.30833333 0.203125   0.4875    ]\n",
      "Q values:  tensor([[-3.2847, -3.6625, -3.3858, -3.5601, -3.3854, -2.8993]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30733 786 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 488: ep_len:786 episode reward: total was -35.500000. running mean: -143.133111\n",
      "startIDX:  1382\n",
      "488 5 True\n",
      "x_t:  1 [0.16875    0.3375     0.14375    0.38333333]\n",
      "Q values:  tensor([[-3.6648, -3.8265, -3.2842, -3.4800, -3.2205, -2.8926]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12523 226 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 488: ep_len:226 episode reward: total was 0.000000. running mean: -141.701780\n",
      "startIDX:  1112\n",
      "488 10 True\n",
      "x_t:  2 [0.475      0.40416667 0.096875   0.24166667]\n",
      "Q values:  tensor([[-3.9069, -3.9414, -3.9014, -3.7519, -3.7176, -3.0025]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12113 368 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 488: ep_len:368 episode reward: total was -49.100000. running mean: -140.775763\n",
      "startIDX:  276\n",
      "488 12 True\n",
      "x_t:  4 [0.271875 0.425    0.14375  0.375   ]\n",
      "Q values:  tensor([[-3.3263, -3.4253, -3.2643, -3.2646, -3.1825, -2.7463]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7210 762 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 488: ep_len:762 episode reward: total was -71.000000. running mean: -140.078005\n",
      "startIDX:  2648\n",
      "488 15 True\n",
      "x_t:  2 [0.43125    0.40416667 0.078125   0.32083333]\n",
      "Q values:  tensor([[-2.7587, -2.8885, -2.8987, -2.6707, -2.9520, -2.3681]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21530 891 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 488: ep_len:891 episode reward: total was -120.400000. running mean: -139.881225\n",
      "startIDX:  2333\n",
      "488 22 True\n",
      "x_t:  2 [0.83125    0.40416667 0.078125   0.25833333]\n",
      "Q values:  tensor([[-4.5723, -4.9010, -4.5303, -4.6599, -4.4634, -3.8173]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23636 1418 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 488: ep_len:1418 episode reward: total was -108.500000. running mean: -139.567413\n",
      "startIDX:  699\n",
      "489 0 True\n",
      "x_t:  2 [0.390625   0.40416667 0.065625   0.25833333]\n",
      "Q values:  tensor([[-3.4571, -3.4915, -3.2329, -3.2220, -3.2250, -2.7115]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8924 891 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  867\n",
      "489 1 True\n",
      "x_t:  4 [0.35625    0.37083333 0.103125   0.38333333]\n",
      "Q values:  tensor([[-3.9215, -4.3238, -3.8152, -3.9737, -3.6947, -3.1753]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35498 568 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2885\n",
      "startIDX:  2468\n",
      "489 10 True\n",
      "x_t:  1 [0.653125   0.29583333 0.075      0.31666667]\n",
      "Q values:  tensor([[-4.0521, -4.1884, -4.1008, -3.9779, -3.6947, -3.4644]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22496 1160 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  759\n",
      "489 12 True\n",
      "x_t:  0 [0.790625   0.40833333 0.053125   0.29583333]\n",
      "Q values:  tensor([[-4.2963, -4.5433, -4.1047, -4.3698, -4.0557, -3.8267]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11654 883 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1974\n",
      "489 15 True\n",
      "x_t:  1 [0.68125    0.29583333 0.0625     0.3125    ]\n",
      "Q values:  tensor([[-3.9235, -4.0286, -3.5495, -4.0178, -3.9686, -3.2858]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14871 692 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  805\n",
      "489 22 True\n",
      "x_t:  2 [0.528125   0.40833333 0.08125    0.2625    ]\n",
      "Q values:  tensor([[-4.6415, -4.8646, -4.2542, -4.4897, -4.4398, -3.8140]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9002 885 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  4285.156346082687\n",
      "startIDX:  1897\n",
      "490 0 True\n",
      "x_t:  1 [0.659375 0.3125   0.121875 0.375   ]\n",
      "Q values:  tensor([[-3.0407, -3.2772, -3.1569, -2.9412, -3.0515, -2.5275]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18989 275 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 490: ep_len:275 episode reward: total was -16.400000. running mean: -132.421537\n",
      "startIDX:  464\n",
      "490 1 True\n",
      "x_t:  2 [0.728125   0.37916667 0.0625     0.31666667]\n",
      "Q values:  tensor([[-4.7739, -4.7202, -4.9747, -4.3594, -4.8103, -3.9765]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31479 1172 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 490: ep_len:1172 episode reward: total was -78.600000. running mean: -131.883322\n",
      "startIDX:  1914\n",
      "490 5 True\n",
      "x_t:  2 [0.596875   0.39583333 0.05       0.25416667]\n",
      "Q values:  tensor([[-4.1338, -4.5924, -4.4227, -4.5096, -4.4689, -3.7547]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15684 314 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 490: ep_len:314 episode reward: total was -31.000000. running mean: -130.874488\n",
      "startIDX:  2605\n",
      "ep 490: ep_len:14 episode reward: total was 0.000000. running mean: -129.565743\n",
      "startIDX:  1415\n",
      "490 12 True\n",
      "x_t:  2 [0.65       0.4125     0.125      0.29166667]\n",
      "Q values:  tensor([[-3.9626, -3.8989, -4.0743, -3.7173, -3.8939, -3.3729]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19466 980 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 490: ep_len:980 episode reward: total was -179.600000. running mean: -130.066086\n",
      "startIDX:  2861\n",
      "490 15 True\n",
      "x_t:  1 [0.8625     0.30833333 0.134375   0.47083333]\n",
      "Q values:  tensor([[-2.9932, -3.2597, -3.0992, -3.1416, -3.0134, -2.5904]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22114 266 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 490: ep_len:266 episode reward: total was -52.100000. running mean: -129.286425\n",
      "startIDX:  1953\n",
      "490 22 True\n",
      "x_t:  2 [0.265625   0.40416667 0.084375   0.27083333]\n",
      "Q values:  tensor([[-5.2498, -5.4925, -4.9777, -5.4831, -5.2091, -4.4474]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18493 753 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 490: ep_len:753 episode reward: total was -65.000000. running mean: -128.643561\n",
      "startIDX:  1658\n",
      "491 0 True\n",
      "x_t:  2 [0.359375 0.4      0.059375 0.2625  ]\n",
      "Q values:  tensor([[-4.5726, -4.9668, -5.0439, -4.8371, -4.6439, -4.0605]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18443 989 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1173\n",
      "startIDX:  773\n",
      "491 5 True\n",
      "x_t:  4 [0.165625   0.4        0.115625   0.38333333]\n",
      "Q values:  tensor([[-6.7238, -6.8563, -6.6420, -6.4899, -6.5886, -5.6166]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10033 626 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2452\n",
      "491 10 True\n",
      "x_t:  1 [0.89375    0.27916667 0.103125   0.34166667]\n",
      "Q values:  tensor([[-7.4686, -8.8890, -7.7977, -7.8025, -8.6278, -6.6570]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22466 1183 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1087\n",
      "491 12 True\n",
      "x_t:  3 [0.19375    0.2875     0.1        0.32083333]\n",
      "Q values:  tensor([[-11.0719, -10.4554, -10.8664, -10.4101, -10.7040,  -8.8619]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16407 1388 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  340\n",
      "491 15 True\n",
      "x_t:  1 [0.603125   0.32916667 0.121875   0.50833333]\n",
      "Q values:  tensor([[-4.7586, -5.0424, -4.5104, -4.3299, -4.5268, -3.6507]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2799 274 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1358\n",
      "491 22 True\n",
      "x_t:  3 [0.546875 0.3375   0.109375 0.3625  ]\n",
      "Q values:  tensor([[-10.0683,  -9.5461,  -8.8652, -10.4371,  -8.9697,  -7.5040]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15303 1323 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2331\n",
      "492 0 True\n",
      "x_t:  3 [0.6875     0.325      0.134375   0.37083333]\n",
      "Q values:  tensor([[ -9.8133, -10.1878,  -9.5627, -10.2142,  -8.8452,  -7.4979]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26218 1299 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 492: ep_len:1299 episode reward: total was -86.800000. running mean: -123.962526\n",
      "startIDX:  888\n",
      "492 1 True\n",
      "x_t:  4 [0.3375     0.36666667 0.115625   0.39166667]\n",
      "Q values:  tensor([[-6.1472, -6.5157, -6.3520, -5.7708, -5.8047, -5.0910]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35499 570 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 492: ep_len:570 episode reward: total was -73.100000. running mean: -123.453901\n",
      "startIDX:  617\n",
      "492 5 True\n",
      "x_t:  2 [0.64375    0.3875     0.065625   0.30833333]\n",
      "Q values:  tensor([[-5.9214, -6.4367, -5.6904, -5.8892, -5.9482, -4.9390]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6062 473 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 492: ep_len:473 episode reward: total was -36.700000. running mean: -122.586362\n",
      "startIDX:  1145\n",
      "492 10 True\n",
      "x_t:  2 [0.509375   0.39583333 0.0625     0.25      ]\n",
      "Q values:  tensor([[-4.8543, -4.2833, -3.9863, -4.2189, -4.4978, -3.4213]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12110 359 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 492: ep_len:359 episode reward: total was -39.200000. running mean: -121.752498\n",
      "startIDX:  286\n",
      "492 12 True\n",
      "x_t:  3 [0.6875   0.3375   0.109375 0.3875  ]\n",
      "Q values:  tensor([[-5.6182, -5.6628, -4.8485, -4.8934, -5.8106, -4.5641]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7732 1015 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 492: ep_len:1015 episode reward: total was -124.500000. running mean: -121.779973\n",
      "startIDX:  1863\n",
      "492 15 True\n",
      "x_t:  1 [0.896875   0.29583333 0.08125    0.30833333]\n",
      "Q values:  tensor([[-6.3640, -6.6937, -6.1886, -5.9267, -5.9523, -4.9826]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14842 746 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 492: ep_len:746 episode reward: total was 17.900000. running mean: -120.383173\n",
      "startIDX:  1123\n",
      "492 22 True\n",
      "x_t:  1 [0.446875   0.34166667 0.146875   0.49583333]\n",
      "Q values:  tensor([[-6.3312, -6.4465, -5.7256, -5.6710, -6.1746, -5.1390]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11952 747 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 492: ep_len:747 episode reward: total was -27.400000. running mean: -119.453342\n",
      "startIDX:  1967\n",
      "493 0 True\n",
      "x_t:  1 [0.11875    0.35416667 0.09375    0.41666667]\n",
      "Q values:  tensor([[-4.3457, -4.8010, -4.5433, -4.5191, -3.9369, -3.6308]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18934 219 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  512\n",
      "493 1 True\n",
      "x_t:  2 [0.459375   0.38333333 0.059375   0.30833333]\n",
      "Q values:  tensor([[-8.5959, -8.9424, -8.1136, -7.9846, -7.4239, -6.8373]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31521 1168 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1766\n",
      "493 5 True\n",
      "x_t:  1 [0.515625   0.29583333 0.065625   0.2875    ]\n",
      "Q values:  tensor([[-5.4879, -5.5492, -5.1163, -5.0331, -4.9723, -4.3475]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14977 609 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2525\n",
      "493 10 True\n",
      "x_t:  1 [0.528125 0.3      0.05     0.325   ]\n",
      "Q values:  tensor([[-8.7806, -9.0265, -9.0615, -8.3158, -7.7865, -6.8433]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22510 1139 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  837\n",
      "493 12 True\n",
      "x_t:  0 [0.7      0.4125   0.059375 0.2875  ]\n",
      "Q values:  tensor([[-7.8709, -7.8343, -6.7754, -7.4558, -7.2810, -6.2888]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11668 648 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2557\n",
      "493 15 True\n",
      "x_t:  3 [0.3125     0.27083333 0.084375   0.27083333]\n",
      "Q values:  tensor([[-3.3899, -3.7227, -3.3262, -3.3726, -3.2773, -2.8869]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19760 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  789\n",
      "493 22 True\n",
      "x_t:  2 [0.29375    0.40416667 0.04375    0.25833333]\n",
      "Q values:  tensor([[-6.9448, -7.2334, -6.3089, -5.9942, -6.9763, -5.5364]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8960 854 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  645\n",
      "494 0 True\n",
      "x_t:  2 [0.84375    0.40416667 0.053125   0.2375    ]\n",
      "Q values:  tensor([[-7.5115, -8.2456, -7.0674, -6.9713, -7.3076, -6.1282]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8999 965 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 494: ep_len:965 episode reward: total was -98.900000. running mean: -115.490917\n",
      "startIDX:  959\n",
      "494 1 True\n",
      "x_t:  4 [0.353125   0.36666667 0.103125   0.4125    ]\n",
      "Q values:  tensor([[-4.8454, -4.6402, -4.2035, -4.4312, -4.3986, -3.9192]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35476 511 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 494: ep_len:511 episode reward: total was -51.100000. running mean: -114.847008\n",
      "startIDX:  2448\n",
      "494 5 True\n",
      "x_t:  2 [0.503125   0.39583333 0.0875     0.275     ]\n",
      "Q values:  tensor([[-7.2665, -6.9560, -6.9085, -7.4454, -7.5913, -6.0820]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21629 972 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 494: ep_len:972 episode reward: total was -128.500000. running mean: -114.983537\n",
      "startIDX:  1952\n",
      "494 10 True\n",
      "x_t:  1 [0.51875    0.3        0.1        0.33333333]\n",
      "Q values:  tensor([[-5.0083, -4.9220, -4.9009, -4.6063, -4.6225, -3.9916]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18884 365 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 494: ep_len:365 episode reward: total was -24.300000. running mean: -114.076702\n",
      "startIDX:  10\n",
      "494 12 True\n",
      "x_t:  3 [0.0875     0.25833333 0.071875   0.275     ]\n",
      "Q values:  tensor([[-13.9791, -12.0730, -11.6849, -11.5215, -11.9353, -10.4060]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5671 2378 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 494: ep_len:2378 episode reward: total was -187.900000. running mean: -114.814935\n",
      "startIDX:  2063\n",
      "494 15 True\n",
      "x_t:  2 [0.684375   0.40833333 0.103125   0.2625    ]\n",
      "Q values:  tensor([[-6.6093, -6.9545, -6.5739, -6.3722, -6.6979, -5.4303]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15582 1006 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 494: ep_len:1006 episode reward: total was -116.700000. running mean: -114.833786\n",
      "startIDX:  1377\n",
      "494 22 True\n",
      "x_t:  3 [0.090625   0.25       0.059375   0.27916667]\n",
      "Q values:  tensor([[-5.4869, -6.1641, -6.0902, -5.6076, -5.9945, -4.5786]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15205 1259 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 494: ep_len:1259 episode reward: total was -52.700000. running mean: -114.212448\n",
      "startIDX:  1640\n",
      "495 0 False\n",
      "x_t:  3 [0.434375   0.30833333 0.103125   0.34166667]\n",
      "Q values:  tensor([[ 0.5727,  0.3254,  0.6184,  1.4837, -0.2992,  0.1301]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16871 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  552\n",
      "495 1 True\n",
      "x_t:  1 [0.85625    0.26666667 0.140625   0.45833333]\n",
      "Q values:  tensor([[-5.1960, -5.5714, -5.7181, -5.2401, -5.3746, -4.5369]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30680 718 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  989\n",
      "495 5 True\n",
      "x_t:  3 [0.309375   0.25833333 0.11875    0.31666667]\n",
      "Q values:  tensor([[-3.7016, -4.0814, -3.5585, -3.5891, -3.4990, -2.9309]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10560 238 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  517\n",
      "495 10 True\n",
      "x_t:  2 [0.575      0.4        0.071875   0.25833333]\n",
      "Q values:  tensor([[-4.3162, -4.5952, -4.4085, -4.0884, -4.4090, -3.6386]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6676 823 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1507\n",
      "495 12 True\n",
      "x_t:  2 [0.740625   0.40416667 0.071875   0.30416667]\n",
      "Q values:  tensor([[-4.6613, -4.6412, -4.1702, -4.3838, -4.6527, -3.5456]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19473 800 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3105\n",
      "startIDX:  2810\n",
      "startIDX:  1822\n",
      "496 0 True\n",
      "x_t:  2 [0.778125   0.40416667 0.1        0.23333333]\n",
      "Q values:  tensor([[-3.1680, -3.4338, -3.1387, -3.1473, -3.3298, -2.5523]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18517 779 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 496: ep_len:779 episode reward: total was -96.600000. running mean: -110.838625\n",
      "startIDX:  530\n",
      "496 1 True\n",
      "x_t:  2 [0.46875 0.3875  0.075   0.3    ]\n",
      "Q values:  tensor([[-3.7098, -3.7518, -3.2778, -3.7767, -3.5710, -3.0236]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31519 1157 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 496: ep_len:1157 episode reward: total was -122.400000. running mean: -110.954239\n",
      "startIDX:  714\n",
      "496 5 False\n",
      "x_t:  4 [0.121875   0.40416667 0.134375   0.3875    ]\n",
      "Q values:  tensor([[-4.1060, -4.2788, -4.4848, -4.0265, -3.6992, -3.9092]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10026 1968 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 496: ep_len:1968 episode reward: total was -152.900000. running mean: -111.373696\n",
      "startIDX:  80\n",
      "496 10 True\n",
      "x_t:  3 [0.709375   0.31666667 0.140625   0.38333333]\n",
      "Q values:  tensor([[-3.6307, -3.9437, -3.6137, -3.5799, -3.5252, -2.9194]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3698 1137 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 496: ep_len:1137 episode reward: total was -83.600000. running mean: -111.095959\n",
      "startIDX:  495\n",
      "496 12 True\n",
      "x_t:  3 [0.58125    0.3125     0.065625   0.36666667]\n",
      "Q values:  tensor([[-3.1913, -3.0437, -3.0011, -2.5323, -3.0000, -2.3776]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7748 231 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 496: ep_len:231 episode reward: total was -35.600000. running mean: -110.341000\n",
      "startIDX:  2900\n",
      "496 15 True\n",
      "x_t:  0 [0.840625   0.40416667 0.05625    0.35833333]\n",
      "Q values:  tensor([[-2.7041, -3.0056, -2.7708, -2.8043, -3.0073, -2.2093]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23084 502 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 496: ep_len:502 episode reward: total was -43.900000. running mean: -109.676590\n",
      "startIDX:  213\n",
      "496 22 True\n",
      "x_t:  2 [0.490625   0.40416667 0.065625   0.25833333]\n",
      "Q values:  tensor([[-3.4728, -3.6458, -3.5539, -3.6273, -3.2472, -2.8211]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2335 341 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 496: ep_len:341 episode reward: total was -41.100000. running mean: -108.990824\n",
      "startIDX:  839\n",
      "497 0 True\n",
      "x_t:  0 [0.65625    0.4125     0.128125   0.39166667]\n",
      "Q values:  tensor([[-2.9886, -3.1640, -3.2192, -2.9015, -2.9117, -2.4840]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10424 714 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  718\n",
      "497 1 True\n",
      "x_t:  3 [0.709375   0.31666667 0.10625    0.45833333]\n",
      "Q values:  tensor([[-4.7750, -4.7987, -4.0824, -5.3470, -4.5711, -3.8073]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34445 1476 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2047\n",
      "497 5 True\n",
      "x_t:  3 [0.190625   0.27083333 0.1        0.32916667]\n",
      "Q values:  tensor([[-5.3996, -5.7025, -5.0281, -5.5118, -5.4767, -4.3627]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18238 1250 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  140\n",
      "497 10 True\n",
      "x_t:  4 [0.278125   0.34166667 0.059375   0.2375    ]\n",
      "Q values:  tensor([[-4.0346, -3.7302, -3.5720, -3.6119, -4.0499, -3.3248]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4590 503 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1584\n",
      "497 12 True\n",
      "x_t:  1 [0.109375   0.35833333 0.078125   0.36666667]\n",
      "Q values:  tensor([[-4.5929, -4.2359, -3.9923, -4.1556, -3.9323, -3.1460]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19881 956 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1378\n",
      "497 15 False\n",
      "x_t:  3 [0.74375    0.32916667 0.09375    0.37083333]\n",
      "Q values:  tensor([[ 0.1753, -0.0771,  0.1793,  0.6916, -0.6544, -0.0874]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10356 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2948\n",
      "startIDX:  590\n",
      "498 0 True\n",
      "x_t:  2 [0.3375     0.40416667 0.08125    0.2625    ]\n",
      "Q values:  tensor([[-5.1893, -5.1841, -5.4609, -5.4149, -5.7994, -4.5885]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8919 959 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 498: ep_len:959 episode reward: total was -31.400000. running mean: -105.203907\n",
      "startIDX:  1173\n",
      "ep 498: ep_len:19 episode reward: total was -1.000000. running mean: -104.161868\n",
      "startIDX:  1312\n",
      "498 5 True\n",
      "x_t:  2 [0.190625   0.39583333 0.0875     0.27916667]\n",
      "Q values:  tensor([[-5.4902, -5.5941, -5.2261, -5.3755, -5.1125, -4.6055]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12030 697 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 498: ep_len:697 episode reward: total was -57.400000. running mean: -103.694249\n",
      "startIDX:  401\n",
      "498 10 True\n",
      "x_t:  3 [0.3625     0.26666667 0.11875    0.32083333]\n",
      "Q values:  tensor([[-4.1701, -4.6022, -4.1463, -4.0826, -4.3557, -3.3932]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5102 217 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 498: ep_len:217 episode reward: total was -88.700000. running mean: -103.544307\n",
      "startIDX:  1431\n",
      "498 12 False\n",
      "x_t:  3 [0.365625 0.3      0.1125   0.3375  ]\n",
      "Q values:  tensor([[1.0062, 1.0892, 1.6178, 1.8202, 0.3709, 1.4629]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 17911 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 498: ep_len:200 episode reward: total was -33.600000. running mean: -102.844864\n",
      "startIDX:  261\n",
      "498 15 True\n",
      "x_t:  2 [0.00625    0.40416667 0.109375   0.33333333]\n",
      "Q values:  tensor([[-6.6068, -6.2545, -6.1080, -5.9772, -6.8049, -4.9166]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2194 771 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 498: ep_len:771 episode reward: total was -45.500000. running mean: -102.271415\n",
      "startIDX:  1734\n",
      "498 22 False\n",
      "x_t:  3 [0.521875   0.3125     0.121875   0.34583333]\n",
      "Q values:  tensor([[ 0.8310,  0.5970,  0.9366,  1.5442, -0.0275,  0.4607]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16893 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 498: ep_len:202 episode reward: total was -41.100000. running mean: -101.659701\n",
      "startIDX:  1837\n",
      "499 0 True\n",
      "x_t:  2 [0.365625   0.4125     0.09375    0.24583333]\n",
      "Q values:  tensor([[-7.0787, -6.6323, -7.2240, -6.8644, -7.1154, -5.8803]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18446 759 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1017\n",
      "499 1 True\n",
      "x_t:  3 [0.740625   0.29166667 0.0875     0.40416667]\n",
      "Q values:  tensor([[-4.3963, -4.4177, -4.4388, -4.1065, -4.4257, -3.5467]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35918 232 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2219\n",
      "499 5 True\n",
      "x_t:  3 [0.8625     0.33333333 0.096875   0.45833333]\n",
      "Q values:  tensor([[-4.0046, -4.0813, -4.4718, -4.0670, -4.2779, -3.2256]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19886 208 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1369\n",
      "499 10 True\n",
      "x_t:  4 [0.003125   0.37083333 0.05625    0.27916667]\n",
      "Q values:  tensor([[-5.2583, -5.0398, -5.0918, -4.8173, -5.0252, -4.2006]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15701 541 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1634\n",
      "499 12 True\n",
      "x_t:  2 [0.25       0.40833333 0.115625   0.3       ]\n",
      "Q values:  tensor([[-7.3601, -7.8858, -7.7077, -7.1837, -6.8925, -5.8249]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19416 690 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  835\n",
      "499 15 True\n",
      "x_t:  3 [0.06875    0.23333333 0.0625     0.2375    ]\n",
      "Q values:  tensor([[-9.0602, -8.9285, -8.4932, -9.1842, -8.2710, -7.0426]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8500 1253 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  146\n",
      "499 22 True\n",
      "x_t:  1 [0.8375     0.29583333 0.075      0.40416667]\n",
      "Q values:  tensor([[-6.2405, -6.7090, -6.0901, -5.9141, -5.7640, -5.0549]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1585 662 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  4384.242830514908\n",
      "startIDX:  200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 0 True\n",
      "x_t:  2 [0.71875    0.40416667 0.103125   0.29166667]\n",
      "Q values:  tensor([[-5.8809, -6.1279, -5.8123, -5.9947, -5.5817, -4.9675]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2335 342 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 500: ep_len:342 episode reward: total was -23.500000. running mean: -98.035020\n",
      "startIDX:  660\n",
      "500 1 True\n",
      "x_t:  3 [0.10625    0.22916667 0.0875     0.3125    ]\n",
      "Q values:  tensor([[-10.5327, -10.1175, -10.3508,  -9.5314, -10.6204,  -8.5347]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34321 1771 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 500: ep_len:1771 episode reward: total was -159.000000. running mean: -98.644669\n",
      "startIDX:  477\n",
      "500 5 True\n",
      "x_t:  1 [0.15       0.3375     0.078125   0.32916667]\n",
      "Q values:  tensor([[-5.9121, -6.7205, -6.1516, -6.3923, -6.0278, -5.3319]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5125 696 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 500: ep_len:696 episode reward: total was -86.200000. running mean: -98.520223\n",
      "startIDX:  143\n",
      "500 10 True\n",
      "x_t:  4 [0.003125   0.3625     0.078125   0.25416667]\n",
      "Q values:  tensor([[-4.1060, -4.3957, -4.4339, -4.0474, -4.3453, -3.6896]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4544 477 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 500: ep_len:477 episode reward: total was 23.100000. running mean: -97.304020\n",
      "startIDX:  1984\n",
      "ep 500: ep_len:57 episode reward: total was -15.100000. running mean: -96.481980\n",
      "startIDX:  543\n",
      "500 15 True\n",
      "x_t:  1 [0.25625    0.34583333 0.065625   0.3125    ]\n",
      "Q values:  tensor([[-6.0821, -5.9335, -5.6385, -5.5498, -5.7603, -4.7190]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5259 742 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 500: ep_len:742 episode reward: total was -112.500000. running mean: -96.642160\n",
      "startIDX:  30\n",
      "500 22 True\n",
      "x_t:  1 [0.128125   0.37083333 0.15625    0.40833333]\n",
      "Q values:  tensor([[-5.0597, -5.5851, -5.1472, -5.1526, -5.0654, -4.1820]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1653 758 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 500: ep_len:758 episode reward: total was -57.600000. running mean: -96.251739\n",
      "startIDX:  2059\n",
      "501 0 True\n",
      "x_t:  0 [0.66875    0.4        0.08125    0.36666667]\n",
      "Q values:  tensor([[-5.1179, -5.4343, -4.7176, -4.6341, -4.7561, -4.1551]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20690 857 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  291\n",
      "501 1 True\n",
      "x_t:  0 [0.934375   0.37083333 0.059375   0.40416667]\n",
      "Q values:  tensor([[-4.3131, -4.7684, -4.9555, -4.4304, -4.6212, -3.7618]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29087 821 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1890\n",
      "501 5 True\n",
      "x_t:  2 [0.76875    0.39583333 0.078125   0.25416667]\n",
      "Q values:  tensor([[-3.8387, -3.9639, -3.6941, -3.9041, -3.8223, -3.0053]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15656 321 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1106\n",
      "501 10 True\n",
      "x_t:  2 [0.428125   0.4        0.0625     0.24583333]\n",
      "Q values:  tensor([[-3.4849, -3.6555, -3.9909, -3.2468, -3.3318, -2.8248]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12123 382 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  440\n",
      "501 12 True\n",
      "x_t:  3 [0.78125    0.3375     0.06875    0.41666667]\n",
      "Q values:  tensor([[-3.0436, -3.2447, -3.0296, -3.2431, -3.2458, -2.5727]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7724 254 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1886\n",
      "501 15 True\n",
      "x_t:  1 [0.6125     0.3        0.10625    0.30833333]\n",
      "Q values:  tensor([[-4.4195, -4.2770, -3.7245, -4.5602, -4.2272, -3.3238]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14878 742 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1469\n",
      "501 22 True\n",
      "x_t:  4 [0.29375    0.38333333 0.08125    0.30416667]\n",
      "Q values:  tensor([[-4.9120, -5.2823, -5.1432, -4.4774, -5.0033, -4.2067]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16371 560 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  895\n",
      "502 0 True\n",
      "x_t:  1 [0.809375   0.30416667 0.134375   0.44166667]\n",
      "Q values:  tensor([[-5.3388, -5.4716, -5.2861, -5.4231, -5.4879, -4.3259]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11954 1270 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 502: ep_len:1270 episode reward: total was -119.700000. running mean: -92.298066\n",
      "startIDX:  637\n",
      "502 1 True\n",
      "x_t:  2 [0.36875 0.375   0.06875 0.3125 ]\n",
      "Q values:  tensor([[-4.0242, -4.3189, -4.5952, -3.8089, -4.1181, -3.7094]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31534 389 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 502: ep_len:389 episode reward: total was -45.600000. running mean: -91.831086\n",
      "startIDX:  2773\n",
      "502 5 True\n",
      "x_t:  0 [0.85       0.38333333 0.078125   0.32083333]\n",
      "Q values:  tensor([[-3.7757, -3.8769, -3.8953, -3.5118, -3.6366, -2.9894]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23166 519 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 502: ep_len:519 episode reward: total was -37.600000. running mean: -91.288775\n",
      "startIDX:  497\n",
      "502 10 False\n",
      "x_t:  3 [0.084375   0.225      0.078125   0.25833333]\n",
      "Q values:  tensor([[0.3198, 1.1610, 2.2485, 3.7760, 0.7781, 1.0947]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 5179 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 502: ep_len:200 episode reward: total was -27.000000. running mean: -90.645887\n",
      "startIDX:  134\n",
      "502 12 True\n",
      "x_t:  2 [0.734375   0.41666667 0.065625   0.22916667]\n",
      "Q values:  tensor([[-3.6708, -3.6286, -3.2330, -3.6672, -3.3899, -2.8729]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2818 299 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 502: ep_len:299 episode reward: total was -9.200000. running mean: -89.831428\n",
      "startIDX:  2436\n",
      "502 15 True\n",
      "x_t:  4 [0.053125   0.42083333 0.134375   0.37083333]\n",
      "Q values:  tensor([[-3.7964, -3.7850, -4.0140, -3.8971, -3.5572, -3.0557]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19256 478 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 502: ep_len:478 episode reward: total was -28.000000. running mean: -89.213114\n",
      "startIDX:  1693\n",
      "502 22 True\n",
      "x_t:  3 [0.86875    0.3625     0.125      0.40416667]\n",
      "Q values:  tensor([[-3.8714, -3.7767, -3.7540, -3.5736, -3.5461, -3.1757]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16843 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 502: ep_len:202 episode reward: total was -40.700000. running mean: -88.727983\n",
      "startIDX:  1888\n",
      "503 0 True\n",
      "x_t:  2 [0.740625   0.40416667 0.078125   0.2375    ]\n",
      "Q values:  tensor([[-8.9033, -9.1352, -9.2455, -8.1701, -8.3968, -6.9390]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23600 2610 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  415\n",
      "503 1 True\n",
      "x_t:  0 [0.734375 0.375    0.0875   0.4     ]\n",
      "Q values:  tensor([[-4.2854, -4.0925, -4.2505, -4.1114, -4.0113, -3.2895]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29121 501 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2386\n",
      "503 5 True\n",
      "x_t:  1 [0.2125     0.34583333 0.171875   0.5       ]\n",
      "Q values:  tensor([[-7.3916, -6.8860, -6.5438, -6.5110, -6.3560, -5.4667]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22123 1244 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2532\n",
      "503 10 True\n",
      "x_t:  1 [0.684375 0.2875   0.128125 0.325   ]\n",
      "Q values:  tensor([[-5.9431, -5.1646, -4.9600, -5.2748, -5.5088, -4.3828]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22489 1137 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  201\n",
      "503 12 True\n",
      "x_t:  4 [0.028125   0.40833333 0.078125   0.29166667]\n",
      "Q values:  tensor([[-8.2185, -8.2572, -7.8868, -7.8227, -8.9430, -6.5563]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7304 2218 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1093\n",
      "503 15 True\n",
      "x_t:  4 [0.2625     0.3625     0.05625    0.21666667]\n",
      "Q values:  tensor([[-4.0238, -3.7380, -4.0222, -3.8806, -3.6053, -3.0828]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9970 655 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  612\n",
      "503 22 True\n",
      "x_t:  2 [0.071875   0.40833333 0.1        0.2625    ]\n",
      "Q values:  tensor([[-4.4058, -4.2044, -4.0963, -4.2390, -4.1008, -3.4500]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8930 930 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2157\n",
      "504 0 True\n",
      "x_t:  1 [0.040625   0.37916667 0.1625     0.49166667]\n",
      "Q values:  tensor([[-4.6061, -4.7811, -4.3414, -4.9368, -4.5953, -3.8206]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22980 1154 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 504: ep_len:1154 episode reward: total was -68.200000. running mean: -89.691387\n",
      "startIDX:  754\n",
      "504 1 True\n",
      "x_t:  3 [0.675      0.30416667 0.11875    0.4625    ]\n",
      "Q values:  tensor([[-5.7737, -6.0253, -5.5873, -5.6561, -5.6571, -4.7003]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34441 1424 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 504: ep_len:1424 episode reward: total was -110.200000. running mean: -89.896473\n",
      "startIDX:  2029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504 5 True\n",
      "x_t:  3 [0.375      0.30833333 0.13125    0.40416667]\n",
      "Q values:  tensor([[-4.9476, -4.3052, -5.0482, -4.5745, -4.7313, -3.8307]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18277 1261 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 504: ep_len:1261 episode reward: total was -73.300000. running mean: -89.730509\n",
      "startIDX:  249\n",
      "504 10 True\n",
      "x_t:  4 [0.26875    0.34166667 0.046875   0.24166667]\n",
      "Q values:  tensor([[-4.7059, -4.5827, -4.0529, -4.6252, -4.3173, -3.6954]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4587 451 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 504: ep_len:451 episode reward: total was -45.300000. running mean: -89.286204\n",
      "startIDX:  1771\n",
      "504 12 True\n",
      "x_t:  0 [0.590625 0.4125   0.10625  0.3375  ]\n",
      "Q values:  tensor([[-4.3589, -4.2229, -4.1213, -3.8997, -4.4993, -3.4314]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21131 614 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 504: ep_len:614 episode reward: total was -33.000000. running mean: -88.723341\n",
      "startIDX:  321\n",
      "504 15 True\n",
      "x_t:  1 [0.290625   0.3625     0.153125   0.50833333]\n",
      "Q values:  tensor([[-4.3844, -4.2237, -4.5502, -4.0857, -3.8515, -3.5109]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2773 278 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 504: ep_len:278 episode reward: total was -11.900000. running mean: -87.955108\n",
      "startIDX:  1214\n",
      "504 22 True\n",
      "x_t:  2 [0.703125 0.4125   0.096875 0.25    ]\n",
      "Q values:  tensor([[-3.8766, -3.6833, -3.9781, -3.6214, -3.7091, -3.1433]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12603 344 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 504: ep_len:344 episode reward: total was -22.500000. running mean: -87.300557\n",
      "startIDX:  1607\n",
      "505 0 True\n",
      "x_t:  3 [0.146875   0.25       0.084375   0.27916667]\n",
      "Q values:  tensor([[-3.7400, -3.7890, -4.0363, -3.7433, -3.8423, -3.2372]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16934 254 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  406\n",
      "505 1 True\n",
      "x_t:  0 [0.740625   0.375      0.121875   0.39583333]\n",
      "Q values:  tensor([[-3.9180, -3.8611, -3.8364, -3.5825, -4.0645, -3.3091]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29118 492 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2010\n",
      "505 5 True\n",
      "x_t:  3 [0.21875    0.26666667 0.103125   0.34166667]\n",
      "Q values:  tensor([[-6.5996, -6.7987, -6.4673, -6.9483, -6.7734, -5.3728]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18246 1262 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2536\n",
      "startIDX:  1401\n",
      "505 12 False\n",
      "x_t:  3 [0.496875   0.3125     0.103125   0.36666667]\n",
      "Q values:  tensor([[ 0.2571,  0.4800,  1.1577,  2.3780, -0.0399,  0.2856]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17888 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1255\n",
      "505 15 True\n",
      "x_t:  3 [0.675      0.32083333 0.109375   0.37083333]\n",
      "Q values:  tensor([[-4.2668, -4.6578, -4.9190, -3.9079, -4.7198, -3.8654]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10365 253 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2821\n",
      "startIDX:  1098\n",
      "506 0 True\n",
      "x_t:  2 [0.671875   0.40416667 0.065625   0.3       ]\n",
      "Q values:  tensor([[-3.2217, -2.7246, -3.2189, -2.5245, -3.0468, -2.6561]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12652 354 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 506: ep_len:354 episode reward: total was -21.100000. running mean: -84.310945\n",
      "startIDX:  989\n",
      "506 1 True\n",
      "x_t:  3 [0.840625   0.30833333 0.15       0.42083333]\n",
      "Q values:  tensor([[-2.9284, -3.2049, -2.8431, -3.1486, -3.0812, -2.6331]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35898 238 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 506: ep_len:238 episode reward: total was -58.800000. running mean: -84.055836\n",
      "startIDX:  1035\n",
      "506 5 False\n",
      "x_t:  3 [0.409375   0.27083333 0.121875   0.32083333]\n",
      "Q values:  tensor([[2.1680, 1.4590, 2.7818, 2.8711, 1.5970, 2.2127]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 10543 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 506: ep_len:200 episode reward: total was -47.000000. running mean: -83.685278\n",
      "startIDX:  1170\n",
      "506 10 True\n",
      "x_t:  3 [0.146875   0.23333333 0.075      0.26666667]\n",
      "Q values:  tensor([[-8.9845, -8.5690, -8.4539, -8.2628, -8.1246, -7.1451]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14602 1562 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 506: ep_len:1562 episode reward: total was -192.900000. running mean: -84.777425\n",
      "startIDX:  573\n",
      "506 12 True\n",
      "x_t:  2 [0.003125   0.41666667 0.090625   0.24583333]\n",
      "Q values:  tensor([[-5.6488, -5.7456, -5.4576, -5.5502, -5.3481, -4.4168]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9826 1026 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 506: ep_len:1026 episode reward: total was -31.200000. running mean: -84.241651\n",
      "startIDX:  2169\n",
      "506 15 True\n",
      "x_t:  3 [0.209375   0.28333333 0.078125   0.325     ]\n",
      "Q values:  tensor([[-7.4684, -7.1780, -6.6131, -7.0299, -7.2733, -5.8652]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18204 1635 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 506: ep_len:1635 episode reward: total was -193.400000. running mean: -85.333234\n",
      "startIDX:  905\n",
      "506 22 True\n",
      "x_t:  1 [0.646875   0.32083333 0.165625   0.40416667]\n",
      "Q values:  tensor([[-4.3131, -4.0344, -4.6292, -4.0927, -4.3306, -3.6682]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9551 266 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 506: ep_len:266 episode reward: total was -21.300000. running mean: -84.692902\n",
      "startIDX:  439\n",
      "507 0 True\n",
      "x_t:  3 [0.571875   0.35833333 0.1625     0.44583333]\n",
      "Q values:  tensor([[-7.4086, -7.7443, -6.9186, -7.0756, -7.0706, -5.8917]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7019 1074 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  78\n",
      "507 1 False\n",
      "x_t:  3 [0.246875   0.2375     0.090625   0.31666667]\n",
      "Q values:  tensor([[-0.7001, -0.5551, -0.7367,  0.1287, -1.1031, -0.9443]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25738 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  627\n",
      "507 5 False\n",
      "x_t:  3 [0.196875   0.26666667 0.09375    0.35      ]\n",
      "Q values:  tensor([[-7.0236, -6.3898, -7.1024, -5.4044, -6.5988, -5.5209]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8783 1387 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  849\n",
      "507 10 True\n",
      "x_t:  0 [0.784375   0.3875     0.065625   0.32083333]\n",
      "Q values:  tensor([[-4.2362, -4.4055, -4.1052, -3.9136, -4.4519, -3.6118]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8124 466 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1186\n",
      "507 12 False\n",
      "x_t:  4 [0.1125     0.42083333 0.09375    0.36666667]\n",
      "Q values:  tensor([[-3.2003, -2.9665, -3.4125, -3.1150, -2.7989, -2.9379]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17401 508 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2266\n",
      "507 15 True\n",
      "x_t:  3 [0.528125   0.32916667 0.08125    0.37916667]\n",
      "Q values:  tensor([[-4.7806, -5.0125, -4.4754, -4.6534, -5.1954, -4.0387]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18253 1314 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2945\n",
      "startIDX:  2038\n",
      "508 0 True\n",
      "x_t:  0 [0.7125     0.39583333 0.11875    0.34583333]\n",
      "Q values:  tensor([[-4.3487, -4.2653, -4.8755, -4.4051, -4.4964, -3.7176]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20665 852 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 508: ep_len:852 episode reward: total was -49.800000. running mean: -81.521910\n",
      "startIDX:  1089\n",
      "508 1 False\n",
      "x_t:  3 [0.653125   0.3        0.1375     0.37916667]\n",
      "Q values:  tensor([[-0.1497, -0.3058,  0.0332,  0.6788, -0.5388, -0.1926]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35927 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 508: ep_len:200 episode reward: total was -18.900000. running mean: -80.895690\n",
      "startIDX:  1772\n",
      "508 5 True\n",
      "x_t:  1 [0.728125   0.29166667 0.109375   0.29583333]\n",
      "Q values:  tensor([[-3.4506, -3.5744, -3.6141, -3.3747, -3.7929, -2.8877]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14941 571 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 508: ep_len:571 episode reward: total was -32.700000. running mean: -80.413734\n",
      "startIDX:  1677\n",
      "508 10 True\n",
      "x_t:  3 [0.15625    0.23333333 0.078125   0.27916667]\n",
      "Q values:  tensor([[-3.9894, -3.9393, -4.3165, -4.0140, -3.7279, -3.2607]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16529 311 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 508: ep_len:311 episode reward: total was -84.400000. running mean: -80.453596\n",
      "startIDX:  1477\n",
      "508 12 True\n",
      "x_t:  2 [0.003125   0.41666667 0.096875   0.27916667]\n",
      "Q values:  tensor([[-4.6066, -3.7654, -3.8829, -3.8635, -4.3377, -3.4998]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19377 914 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 508: ep_len:914 episode reward: total was -120.000000. running mean: -80.849060\n",
      "startIDX:  2041\n",
      "508 15 True\n",
      "x_t:  1 [0.71875    0.29583333 0.1        0.3       ]\n",
      "Q values:  tensor([[-3.9503, -3.9152, -4.0931, -3.9089, -4.2691, -3.5189]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14863 658 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 508: ep_len:658 episode reward: total was -40.000000. running mean: -80.440570\n",
      "startIDX:  760\n",
      "508 22 True\n",
      "x_t:  2 [0.00625    0.40833333 0.084375   0.2625    ]\n",
      "Q values:  tensor([[-4.4986, -4.3621, -4.1646, -4.4181, -4.3392, -3.5091]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8918 850 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 508: ep_len:850 episode reward: total was -31.400000. running mean: -79.950164\n",
      "startIDX:  1549\n",
      "509 0 True\n",
      "x_t:  3 [0.08125    0.25       0.075      0.26666667]\n",
      "Q values:  tensor([[-3.9091, -3.9223, -4.0700, -3.9438, -3.6186, -3.3151]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16949 288 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1131\n",
      "startIDX:  2009\n",
      "509 5 True\n",
      "x_t:  3 [0.0625     0.25416667 0.08125    0.25833333]\n",
      "Q values:  tensor([[-3.9787, -4.3048, -3.7975, -4.1909, -3.6733, -3.4528]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18202 1246 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2608\n",
      "startIDX:  1405\n",
      "509 12 True\n",
      "x_t:  3 [0.3875   0.3      0.109375 0.35    ]\n",
      "Q values:  tensor([[-4.2919, -4.3061, -4.3604, -4.0862, -4.0475, -3.4512]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17907 215 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1815\n",
      "509 15 True\n",
      "x_t:  0 [0.5        0.4125     0.10625    0.34583333]\n",
      "Q values:  tensor([[-3.7427, -3.4821, -3.6960, -3.6188, -4.0181, -3.2201]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13427 457 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1139\n",
      "509 22 True\n",
      "x_t:  1 [0.428125   0.3375     0.0875     0.50416667]\n",
      "Q values:  tensor([[-4.3655, -4.2477, -3.6297, -4.1302, -4.0401, -3.0932]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11954 718 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  4480.080170631409\n",
      "startIDX:  2275\n",
      "510 0 True\n",
      "x_t:  2 [0.5375     0.40416667 0.090625   0.2625    ]\n",
      "Q values:  tensor([[-4.1936, -4.9708, -4.4716, -4.4932, -4.3470, -3.8020]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23634 338 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 510: ep_len:338 episode reward: total was -64.200000. running mean: -77.492011\n",
      "startIDX:  866\n",
      "510 1 True\n",
      "x_t:  4 [0.36875    0.37916667 0.103125   0.3875    ]\n",
      "Q values:  tensor([[-4.1738, -4.3504, -4.2764, -3.8718, -4.0338, -3.4635]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35486 564 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 510: ep_len:564 episode reward: total was -41.200000. running mean: -77.129090\n",
      "startIDX:  1853\n",
      "510 5 True\n",
      "x_t:  2 [0.4625     0.4        0.1        0.24166667]\n",
      "Q values:  tensor([[-3.8999, -3.7698, -3.4821, -3.8181, -3.7153, -3.1264]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15701 371 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 510: ep_len:371 episode reward: total was -50.400000. running mean: -76.861800\n",
      "startIDX:  1589\n",
      "510 10 False\n",
      "x_t:  3 [0.703125   0.29583333 0.08125    0.37083333]\n",
      "Q values:  tensor([[-3.4942, -3.5640, -4.0374, -3.0123, -3.3194, -3.0335]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16425 306 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 510: ep_len:306 episode reward: total was -35.700000. running mean: -76.450182\n",
      "startIDX:  1078\n",
      "510 12 True\n",
      "x_t:  3 [0.15       0.27083333 0.090625   0.3125    ]\n",
      "Q values:  tensor([[-4.8580, -4.6077, -4.9862, -4.9553, -4.4090, -4.0894]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16395 1386 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 510: ep_len:1386 episode reward: total was -59.500000. running mean: -76.280680\n",
      "startIDX:  2420\n",
      "510 15 True\n",
      "x_t:  4 [0.246875   0.38333333 0.084375   0.29583333]\n",
      "Q values:  tensor([[-4.3690, -5.0210, -4.8273, -4.5076, -4.4544, -4.0371]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19292 494 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 510: ep_len:494 episode reward: total was -48.300000. running mean: -76.000873\n",
      "startIDX:  759\n",
      "510 22 True\n",
      "x_t:  2 [0.228125   0.4125     0.096875   0.25416667]\n",
      "Q values:  tensor([[-4.0845, -4.0589, -4.2130, -4.0687, -3.9459, -3.4314]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8955 876 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 510: ep_len:876 episode reward: total was -63.200000. running mean: -75.872864\n",
      "startIDX:  349\n",
      "511 0 True\n",
      "x_t:  3 [0.3125     0.27083333 0.090625   0.30416667]\n",
      "Q values:  tensor([[-5.3113, -4.7500, -4.9644, -4.5325, -5.0865, -4.1760]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4915 1236 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  641\n",
      "511 1 True\n",
      "x_t:  2 [0.640625   0.38333333 0.13125    0.31666667]\n",
      "Q values:  tensor([[-5.4570, -5.1088, -5.1956, -4.8970, -5.0221, -4.2299]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31488 361 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2694\n",
      "511 5 True\n",
      "x_t:  0 [0.690625   0.40416667 0.09375    0.3       ]\n",
      "Q values:  tensor([[-4.5241, -3.9912, -4.1538, -4.2746, -3.5178, -3.4931]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23202 777 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  49\n",
      "511 10 False\n",
      "x_t:  3 [0.11875    0.25       0.075      0.27916667]\n",
      "Q values:  tensor([[-3.8226, -4.3448, -4.3672, -3.6844, -3.8901, -3.7073]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3601 1101 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1287\n",
      "511 12 True\n",
      "x_t:  4 [0.4125   0.375    0.071875 0.2875  ]\n",
      "Q values:  tensor([[-6.5894, -6.3020, -5.9422, -6.1034, -5.7232, -5.2243]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17452 484 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  361\n",
      "511 15 True\n",
      "x_t:  1 [0.734375   0.325      0.14375    0.49583333]\n",
      "Q values:  tensor([[-4.9574, -4.8536, -5.0269, -4.4810, -4.3322, -4.1643]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2810 256 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1657\n",
      "511 22 True\n",
      "x_t:  3 [0.521875   0.3125     0.121875   0.34583333]\n",
      "Q values:  tensor([[-7.0895, -6.5279, -7.1235, -6.6111, -5.7667, -5.3227]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16893 245 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  737\n",
      "512 0 True\n",
      "x_t:  1 [0.61875    0.30833333 0.128125   0.425     ]\n",
      "Q values:  tensor([[-5.3427, -5.4526, -4.7840, -5.3312, -4.7561, -4.0371]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9477 291 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 512: ep_len:291 episode reward: total was -11.300000. running mean: -74.428758\n",
      "startIDX:  677\n",
      "512 1 True\n",
      "x_t:  3 [0.171875   0.24166667 0.0875     0.31666667]\n",
      "Q values:  tensor([[-6.7352, -6.4540, -6.0618, -6.9668, -6.4551, -5.2022]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34336 1436 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 512: ep_len:1436 episode reward: total was -89.500000. running mean: -74.579470\n",
      "startIDX:  2790\n",
      "512 5 True\n",
      "x_t:  0 [0.59375    0.40833333 0.065625   0.3       ]\n",
      "Q values:  tensor([[-5.5100, -5.9687, -5.1875, -5.6435, -5.5895, -5.0185]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23222 534 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 512: ep_len:534 episode reward: total was -111.100000. running mean: -74.944675\n",
      "startIDX:  1763\n",
      "512 10 True\n",
      "x_t:  2 [0.046875 0.4      0.10625  0.25    ]\n",
      "Q values:  tensor([[-5.5856, -5.4725, -5.5934, -5.5882, -5.0299, -4.6010]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18155 870 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 512: ep_len:870 episode reward: total was -58.900000. running mean: -74.784229\n",
      "startIDX:  1703\n",
      "512 12 True\n",
      "x_t:  1 [0.79375    0.30416667 0.171875   0.40833333]\n",
      "Q values:  tensor([[-7.0490, -7.1448, -6.3685, -6.2964, -6.6821, -5.3133]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19951 254 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 512: ep_len:254 episode reward: total was -47.700000. running mean: -74.513386\n",
      "startIDX:  68\n",
      "512 15 True\n",
      "x_t:  3 [0.303125   0.28333333 0.078125   0.3125    ]\n",
      "Q values:  tensor([[-6.1358, -6.4688, -5.3126, -5.4871, -5.3960, -4.9039]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 612 260 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 512: ep_len:260 episode reward: total was -118.400000. running mean: -74.952252\n",
      "startIDX:  2983\n",
      "ep 512: ep_len:20 episode reward: total was 10.000000. running mean: -74.102730\n",
      "startIDX:  2006\n",
      "513 0 True\n",
      "x_t:  1 [0.678125   0.31666667 0.14375    0.51666667]\n",
      "Q values:  tensor([[-9.5599, -9.7517, -9.7514, -9.4116, -9.1801, -7.8388]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22934 1999 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  577\n",
      "513 1 True\n",
      "x_t:  2 [0.14375    0.38333333 0.115625   0.3125    ]\n",
      "Q values:  tensor([[-6.9691, -6.9202, -7.4207, -6.0376, -6.4511, -5.8104]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31568 439 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3042\n",
      "startIDX:  1095\n",
      "513 10 True\n",
      "x_t:  2 [0.546875   0.39166667 0.1        0.25833333]\n",
      "Q values:  tensor([[-6.9595, -6.4092, -6.3315, -6.2356, -5.8966, -5.4984]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12102 384 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513 12 True\n",
      "x_t:  0 [0.478125   0.40833333 0.071875   0.35833333]\n",
      "Q values:  tensor([[-7.9256, -8.0088, -7.6331, -8.0569, -6.9031, -6.4213]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21148 615 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2021\n",
      "513 15 True\n",
      "x_t:  1 [0.41875    0.32083333 0.09375    0.30833333]\n",
      "Q values:  tensor([[-7.2301, -7.4848, -7.2782, -6.9756, -7.2701, -5.9402]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14903 685 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1738\n",
      "513 22 True\n",
      "x_t:  3 [0.2        0.2625     0.115625   0.29583333]\n",
      "Q values:  tensor([[-8.8823, -9.3323, -9.1157, -9.0090, -8.3362, -7.9366]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16957 244 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  762\n",
      "514 0 True\n",
      "x_t:  1 [0.70625    0.30833333 0.178125   0.42916667]\n",
      "Q values:  tensor([[-8.4693, -8.3481, -9.5208, -8.9395, -7.6848, -7.5856]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9487 283 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 514: ep_len:283 episode reward: total was -43.300000. running mean: -80.870152\n",
      "startIDX:  545\n",
      "514 1 True\n",
      "x_t:  2 [0.1875     0.37916667 0.078125   0.3125    ]\n",
      "Q values:  tensor([[-13.2105, -13.5045, -13.2267, -12.7475, -12.7120, -11.5493]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31563 1182 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 514: ep_len:1182 episode reward: total was -195.900000. running mean: -82.020451\n",
      "startIDX:  1497\n",
      "514 5 True\n",
      "x_t:  0 [0.934375 0.3875   0.05625  0.35    ]\n",
      "Q values:  tensor([[-9.6580, -9.5353, -9.8029, -9.9462, -9.0642, -8.1640]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13497 466 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 514: ep_len:466 episode reward: total was -46.400000. running mean: -81.664246\n",
      "startIDX:  1242\n",
      "514 10 True\n",
      "x_t:  3 [0.1        0.23333333 0.06875    0.25      ]\n",
      "Q values:  tensor([[-13.4069, -13.5538, -13.1363, -12.5310, -12.7951, -11.4207]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14589 1239 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 514: ep_len:1239 episode reward: total was -70.800000. running mean: -81.555604\n",
      "startIDX:  1532\n",
      "514 12 True\n",
      "x_t:  2 [0.440625   0.40833333 0.084375   0.30416667]\n",
      "Q values:  tensor([[-13.7757, -14.6368, -14.1101, -13.4628, -13.5389, -11.9517]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19437 791 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 514: ep_len:791 episode reward: total was -103.200000. running mean: -81.772048\n",
      "startIDX:  2202\n",
      "514 15 False\n",
      "x_t:  3 [0.6875     0.35833333 0.0875     0.41666667]\n",
      "Q values:  tensor([[-17.4603, -15.7732, -16.6911, -14.0331, -15.9668, -14.3994]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18275 1360 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 514: ep_len:1360 episode reward: total was -105.600000. running mean: -82.010327\n",
      "startIDX:  1459\n",
      "514 22 True\n",
      "x_t:  4 [0.01875  0.3875   0.078125 0.3125  ]\n",
      "Q values:  tensor([[-11.5750, -12.2150, -10.7575, -12.3337, -11.6942, -10.0613]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16326 549 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 514: ep_len:549 episode reward: total was -6.400000. running mean: -81.254224\n",
      "startIDX:  2031\n",
      "515 0 True\n",
      "x_t:  0 [0.671875   0.39166667 0.1        0.37916667]\n",
      "Q values:  tensor([[-10.3779, -11.3624, -11.9736, -12.5197, -11.4284, -10.1374]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20706 864 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  104\n",
      "515 1 False\n",
      "x_t:  3 [0.1625     0.22916667 0.08125    0.29583333]\n",
      "Q values:  tensor([[1.3821, 1.8543, 2.6505, 5.0869, 1.6864, 1.7235]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 25762 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  234\n",
      "515 5 True\n",
      "x_t:  0 [0.48125    0.39583333 0.146875   0.39166667]\n",
      "Q values:  tensor([[-7.3759, -6.5478, -7.0053, -6.8479, -6.5997, -5.7433]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3601 745 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  693\n",
      "515 10 True\n",
      "x_t:  1 [0.6625     0.29583333 0.096875   0.33333333]\n",
      "Q values:  tensor([[-8.6742, -8.1906, -8.3315, -8.1689, -8.4679, -6.8887]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7181 292 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  67\n",
      "515 12 True\n",
      "x_t:  1 [0.740625   0.3125     0.109375   0.43333333]\n",
      "Q values:  tensor([[-6.6268, -6.4939, -6.1951, -6.0915, -7.3977, -5.6733]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2228 622 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  588\n",
      "515 15 True\n",
      "x_t:  1 [0.8   0.3   0.1   0.275]\n",
      "Q values:  tensor([[-6.2953, -5.8456, -6.1660, -5.6957, -6.3181, -5.0827]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5178 699 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1544\n",
      "515 22 True\n",
      "x_t:  4 [0.225      0.3875     0.10625    0.29583333]\n",
      "Q values:  tensor([[-4.3910, -4.8446, -4.2968, -4.2375, -4.8911, -3.5624]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16363 518 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  660\n",
      "516 0 True\n",
      "x_t:  2 [0.471875   0.40416667 0.071875   0.25416667]\n",
      "Q values:  tensor([[-4.1797, -4.2216, -4.3821, -4.2801, -4.3955, -3.4515]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8938 940 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 516: ep_len:940 episode reward: total was -53.600000. running mean: -77.604935\n",
      "startIDX:  427\n",
      "516 1 True\n",
      "x_t:  2 [0.8125     0.38333333 0.1125     0.30833333]\n",
      "Q values:  tensor([[-3.2177, -3.1777, -3.2305, -3.1767, -3.5859, -2.7120]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31459 1178 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 516: ep_len:1178 episode reward: total was -39.400000. running mean: -77.222886\n",
      "startIDX:  112\n",
      "516 5 True\n",
      "x_t:  2 [0.61875    0.37916667 0.165625   0.46666667]\n",
      "Q values:  tensor([[-2.9739, -3.2284, -3.2713, -3.2252, -3.3608, -2.4987]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2108 914 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 516: ep_len:914 episode reward: total was -45.600000. running mean: -76.906657\n",
      "startIDX:  991\n",
      "516 10 True\n",
      "x_t:  1 [0.8125     0.27916667 0.08125    0.34166667]\n",
      "Q values:  tensor([[-3.4360, -3.5938, -3.5555, -3.4772, -3.7316, -2.8355]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11337 1574 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 516: ep_len:1574 episode reward: total was -63.700000. running mean: -76.774590\n",
      "startIDX:  489\n",
      "516 12 True\n",
      "x_t:  3 [0.503125   0.31666667 0.121875   0.35      ]\n",
      "Q values:  tensor([[-3.3107, -3.5142, -3.6314, -3.1101, -3.3032, -2.6444]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7755 235 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 516: ep_len:235 episode reward: total was -44.900000. running mean: -76.455844\n",
      "startIDX:  355\n",
      "516 15 True\n",
      "x_t:  0 [0.83125    0.40416667 0.071875   0.34166667]\n",
      "Q values:  tensor([[-2.6968, -2.4337, -2.4203, -2.4537, -2.6296, -2.0317]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3667 692 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 516: ep_len:692 episode reward: total was -84.200000. running mean: -76.533286\n",
      "startIDX:  984\n",
      "516 22 True\n",
      "x_t:  1 [0.6        0.32916667 0.178125   0.50416667]\n",
      "Q values:  tensor([[-2.0469, -2.1279, -2.2715, -2.0170, -2.4599, -1.6831]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11938 1222 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 516: ep_len:1222 episode reward: total was -128.000000. running mean: -77.047953\n",
      "startIDX:  163\n",
      "517 0 True\n",
      "x_t:  2 [0.209375   0.40416667 0.075      0.3       ]\n",
      "Q values:  tensor([[-2.8101, -2.7296, -2.7558, -2.8065, -2.8056, -2.2132]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2410 404 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  844\n",
      "517 1 True\n",
      "x_t:  4 [0.003125   0.39583333 0.11875    0.40833333]\n",
      "Q values:  tensor([[-2.7549, -2.5600, -2.8049, -2.7240, -2.8756, -2.1041]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35421 542 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  149\n",
      "517 5 True\n",
      "x_t:  2 [0.596875   0.37083333 0.084375   0.46666667]\n",
      "Q values:  tensor([[-2.0242, -2.1014, -2.0884, -2.1702, -2.4075, -1.7493]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2104 889 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2178\n",
      "517 10 True\n",
      "x_t:  0 [0.5625     0.3875     0.065625   0.30833333]\n",
      "Q values:  tensor([[-2.3762, -2.3039, -2.1979, -2.1821, -2.6416, -1.7234]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20022 575 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1471\n",
      "517 12 True\n",
      "x_t:  3 [0.08125    0.24583333 0.0625     0.25833333]\n",
      "Q values:  tensor([[-3.2503, -2.9167, -3.3695, -2.8285, -3.2941, -2.4948]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17991 228 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  302\n",
      "517 15 True\n",
      "x_t:  1 [0.4375     0.34583333 0.1625     0.52083333]\n",
      "Q values:  tensor([[-2.3960, -2.5232, -2.5111, -2.4560, -2.6153, -1.9696]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2785 290 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517 22 True\n",
      "x_t:  3 [0.153125   0.25       0.065625   0.26666667]\n",
      "Q values:  tensor([[-3.0838, -2.5981, -2.5879, -2.7881, -3.1500, -2.2711]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4898 1649 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1371\n",
      "518 0 True\n",
      "x_t:  4 [0.446875   0.35       0.071875   0.23333333]\n",
      "Q values:  tensor([[-2.1889, -2.2232, -2.1725, -2.1997, -2.4299, -1.7511]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16433 606 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 518: ep_len:606 episode reward: total was -77.300000. running mean: -75.965449\n",
      "startIDX:  442\n",
      "518 1 True\n",
      "x_t:  1 [0.175      0.31666667 0.121875   0.50416667]\n",
      "Q values:  tensor([[-2.2006, -2.4338, -2.2768, -2.1425, -2.6230, -1.7279]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30753 815 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 518: ep_len:815 episode reward: total was -43.500000. running mean: -75.640795\n",
      "startIDX:  1108\n",
      "518 5 True\n",
      "x_t:  2 [0.303125   0.38333333 0.065625   0.2875    ]\n",
      "Q values:  tensor([[-2.6594, -2.7875, -2.6041, -2.6118, -3.0152, -2.1378]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12044 915 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 518: ep_len:915 episode reward: total was -108.800000. running mean: -75.972387\n",
      "startIDX:  1835\n",
      "518 10 True\n",
      "x_t:  2 [0.421875 0.4      0.071875 0.25    ]\n",
      "Q values:  tensor([[-2.6653, -2.5839, -2.7165, -2.7544, -2.8661, -1.9696]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18219 869 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 518: ep_len:869 episode reward: total was -57.000000. running mean: -75.782663\n",
      "startIDX:  728\n",
      "518 12 True\n",
      "x_t:  0 [0.821875   0.40416667 0.1        0.30833333]\n",
      "Q values:  tensor([[-3.0864, -3.0221, -3.1592, -3.0708, -3.5271, -2.4275]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11644 873 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 518: ep_len:873 episode reward: total was -47.000000. running mean: -75.494836\n",
      "startIDX:  193\n",
      "518 15 True\n",
      "x_t:  2 [0.196875   0.40416667 0.096875   0.33333333]\n",
      "Q values:  tensor([[-4.1030, -4.1449, -4.1277, -3.7727, -4.4833, -3.2158]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2217 805 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 518: ep_len:805 episode reward: total was -45.300000. running mean: -75.192888\n",
      "startIDX:  2262\n",
      "518 22 True\n",
      "x_t:  2 [0.609375   0.40833333 0.096875   0.25416667]\n",
      "Q values:  tensor([[-3.8639, -3.8161, -3.6605, -3.9235, -4.2620, -2.8128]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23668 1450 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 518: ep_len:1450 episode reward: total was -85.000000. running mean: -75.290959\n",
      "startIDX:  1613\n",
      "519 0 False\n",
      "x_t:  3 [0.696875 0.35     0.15625  0.3875  ]\n",
      "Q values:  tensor([[1.0635, 0.8790, 0.6968, 1.2686, 0.7269, 1.0547]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 16830 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1076\n",
      "519 1 True\n",
      "x_t:  3 [0.63125    0.29166667 0.10625    0.37083333]\n",
      "Q values:  tensor([[-3.6005, -3.0842, -3.1813, -3.4441, -3.7618, -2.5786]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35935 208 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1036\n",
      "519 5 False\n",
      "x_t:  3 [0.36875    0.2625     0.134375   0.32916667]\n",
      "Q values:  tensor([[-1.2005, -1.2600, -0.9398, -0.4075, -1.6388, -0.9167]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10548 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1931\n",
      "519 10 True\n",
      "x_t:  2 [0.11875 0.4     0.08125 0.25   ]\n",
      "Q values:  tensor([[-3.3791, -3.8352, -3.5587, -3.4706, -4.2302, -2.9878]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18164 808 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1274\n",
      "519 12 True\n",
      "x_t:  4 [0.3875     0.3625     0.059375   0.24166667]\n",
      "Q values:  tensor([[-3.4735, -3.3479, -4.0339, -3.3042, -3.9254, -2.8328]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17484 516 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  686\n",
      "519 15 True\n",
      "x_t:  2 [0.75       0.40416667 0.065625   0.29583333]\n",
      "Q values:  tensor([[-3.9606, -4.0048, -3.9647, -4.0969, -4.5303, -3.1985]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5977 397 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  132\n",
      "519 22 True\n",
      "x_t:  2 [0.734375   0.40833333 0.05       0.24166667]\n",
      "Q values:  tensor([[-4.7020, -4.7953, -5.3002, -4.6676, -5.5534, -4.0079]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2295 1009 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  4577.0190782547\n",
      "startIDX:  681\n",
      "520 0 True\n",
      "x_t:  2 [0.4625   0.4      0.046875 0.2625  ]\n",
      "Q values:  tensor([[-4.9037, -5.3616, -5.2295, -4.6083, -5.1948, -3.8649]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8935 893 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 520: ep_len:893 episode reward: total was -84.500000. running mean: -74.733538\n",
      "startIDX:  668\n",
      "520 1 True\n",
      "x_t:  3 [0.19375    0.24166667 0.08125    0.325     ]\n",
      "Q values:  tensor([[-6.6199, -6.9890, -7.4442, -6.6601, -7.8519, -5.2993]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34343 1454 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 520: ep_len:1454 episode reward: total was -45.100000. running mean: -74.437203\n",
      "startIDX:  1967\n",
      "520 5 True\n",
      "x_t:  4 [0.225      0.40416667 0.096875   0.41666667]\n",
      "Q values:  tensor([[-12.1294, -10.9322, -11.8538, -11.0119, -13.8515,  -9.4112]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19483 1911 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 520: ep_len:1911 episode reward: total was -108.700000. running mean: -74.779831\n",
      "startIDX:  1324\n",
      "520 10 True\n",
      "x_t:  4 [0.003125   0.36666667 0.075      0.2875    ]\n",
      "Q values:  tensor([[-5.0301, -4.5152, -4.8993, -5.0192, -5.4698, -3.9126]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15702 565 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 520: ep_len:565 episode reward: total was 9.000000. running mean: -73.942032\n",
      "startIDX:  1341\n",
      "520 12 True\n",
      "x_t:  3 [0.0625 0.25   0.0625 0.25  ]\n",
      "Q values:  tensor([[-3.9569, -4.0401, -4.0122, -3.5493, -4.3953, -3.0514]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17999 291 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 520: ep_len:291 episode reward: total was -142.200000. running mean: -74.624612\n",
      "startIDX:  2154\n",
      "520 15 True\n",
      "x_t:  2 [0.725      0.40416667 0.06875    0.2625    ]\n",
      "Q values:  tensor([[-4.6722, -4.2552, -4.6250, -3.8796, -5.2860, -3.3926]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15578 329 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 520: ep_len:329 episode reward: total was -30.100000. running mean: -74.179366\n",
      "startIDX:  1139\n",
      "520 22 True\n",
      "x_t:  1 [0.275  0.3625 0.2125 0.5125]\n",
      "Q values:  tensor([[-7.3127, -7.3409, -7.2661, -6.9997, -7.4558, -5.4678]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11962 727 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 520: ep_len:727 episode reward: total was -26.400000. running mean: -73.701572\n",
      "startIDX:  1547\n",
      "521 0 True\n",
      "x_t:  3 [0.571875   0.30416667 0.071875   0.37916667]\n",
      "Q values:  tensor([[-3.6889, -3.4932, -3.8313, -3.2748, -3.9373, -2.8643]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16851 252 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  985\n",
      "startIDX:  281\n",
      "521 5 True\n",
      "x_t:  0 [0.546875 0.3875   0.084375 0.3875  ]\n",
      "Q values:  tensor([[-4.7208, -4.9281, -5.0148, -4.5754, -5.6251, -4.0865]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3597 531 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  782\n",
      "521 10 True\n",
      "x_t:  0 [0.6        0.4        0.08125    0.29583333]\n",
      "Q values:  tensor([[-5.0596, -4.5922, -5.7133, -5.0852, -5.2877, -4.1335]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8162 732 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  59\n",
      "521 12 True\n",
      "x_t:  2 [0.090625   0.40833333 0.084375   0.25      ]\n",
      "Q values:  tensor([[-6.5761, -6.4022, -6.3970, -5.8332, -6.6737, -4.9515]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2914 974 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2487\n",
      "521 15 True\n",
      "x_t:  3 [0.625      0.30833333 0.0875     0.34583333]\n",
      "Q values:  tensor([[-4.8624, -4.9110, -5.3230, -4.7379, -5.2845, -3.9479]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19694 209 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2854\n",
      "startIDX:  49\n",
      "522 0 True\n",
      "x_t:  3 [0.084375   0.23333333 0.06875    0.24166667]\n",
      "Q values:  tensor([[-11.1409, -10.6097, -10.7522, -11.1797, -11.8135,  -8.9751]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4843 2354 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 522: ep_len:2354 episode reward: total was -176.400000. running mean: -75.207141\n",
      "startIDX:  470\n",
      "522 1 True\n",
      "x_t:  1 [0.328125   0.30416667 0.1625     0.49166667]\n",
      "Q values:  tensor([[-6.1969, -6.1423, -6.5486, -5.9132, -6.5367, -5.1329]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30736 806 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 522: ep_len:806 episode reward: total was -34.300000. running mean: -74.798070\n",
      "startIDX:  2870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 522: ep_len:108 episode reward: total was 80.000000. running mean: -73.250089\n",
      "startIDX:  934\n",
      "522 10 True\n",
      "x_t:  2 [0.390625   0.4        0.1        0.24583333]\n",
      "Q values:  tensor([[-7.9798, -8.0878, -8.8920, -7.9413, -9.0803, -6.5411]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12127 1984 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 522: ep_len:1984 episode reward: total was -174.200000. running mean: -74.259588\n",
      "startIDX:  1999\n",
      "ep 522: ep_len:49 episode reward: total was -27.300000. running mean: -73.789993\n",
      "startIDX:  712\n",
      "522 15 True\n",
      "x_t:  2 [0.7625     0.40833333 0.06875    0.29583333]\n",
      "Q values:  tensor([[-3.9492, -3.9998, -4.4118, -3.5297, -4.4193, -3.3975]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5975 387 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 522: ep_len:387 episode reward: total was -26.100000. running mean: -73.313093\n",
      "startIDX:  1668\n",
      "522 22 True\n",
      "x_t:  2 [0.075      0.40833333 0.05       0.27083333]\n",
      "Q values:  tensor([[-4.8809, -4.2338, -4.8431, -4.3010, -5.0092, -3.6850]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18464 1035 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 522: ep_len:1035 episode reward: total was -201.600000. running mean: -74.595962\n",
      "startIDX:  1583\n",
      "523 0 True\n",
      "x_t:  3 [0.621875   0.32916667 0.121875   0.38333333]\n",
      "Q values:  tensor([[-4.4483, -4.7420, -4.8986, -4.5014, -4.9720, -3.5341]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16839 229 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  665\n",
      "523 1 True\n",
      "x_t:  3 [0.503125   0.29166667 0.1        0.40416667]\n",
      "Q values:  tensor([[-4.8908, -4.5357, -4.7403, -4.6284, -5.1900, -3.7079]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34414 1460 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2776\n",
      "523 5 True\n",
      "x_t:  0 [0.903125   0.4        0.078125   0.29583333]\n",
      "Q values:  tensor([[-3.9686, -4.1196, -3.9849, -4.1762, -4.3666, -3.2048]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23152 509 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2613\n",
      "startIDX:  1839\n",
      "523 12 True\n",
      "x_t:  0 [0.203125   0.43333333 0.06875    0.31666667]\n",
      "Q values:  tensor([[-3.6351, -3.6971, -3.6217, -3.8391, -4.0575, -2.9645]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 22987 944 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  55\n",
      "523 15 True\n",
      "x_t:  3 [0.740625   0.34166667 0.121875   0.41666667]\n",
      "Q values:  tensor([[-4.7611, -4.7199, -4.9126, -4.5641, -5.2602, -3.9088]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 534 229 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2517\n",
      "523 22 True\n",
      "x_t:  3 [0.4625     0.29166667 0.121875   0.3375    ]\n",
      "Q values:  tensor([[-4.7600, -4.9663, -5.1774, -4.9023, -5.0064, -3.9242]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26275 1317 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1123\n",
      "524 0 True\n",
      "x_t:  2 [0.15    0.4     0.10625 0.3125 ]\n",
      "Q values:  tensor([[-5.0388, -4.6298, -5.0491, -4.7728, -5.0828, -3.7296]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12735 389 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 524: ep_len:389 episode reward: total was -59.800000. running mean: -72.578832\n",
      "startIDX:  428\n",
      "524 1 True\n",
      "x_t:  1 [0.396875   0.29583333 0.14375    0.47916667]\n",
      "Q values:  tensor([[-3.6956, -3.5420, -3.6362, -3.7430, -3.7091, -2.9842]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30729 829 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 524: ep_len:829 episode reward: total was -26.700000. running mean: -72.120043\n",
      "startIDX:  1467\n",
      "524 5 True\n",
      "x_t:  0 [0.51875    0.39166667 0.10625    0.32916667]\n",
      "Q values:  tensor([[-3.7703, -3.8955, -4.2136, -3.6087, -4.4474, -3.1190]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13564 518 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 524: ep_len:518 episode reward: total was -45.400000. running mean: -71.852843\n",
      "startIDX:  876\n",
      "524 10 True\n",
      "x_t:  1 [0.46875    0.3125     0.11875    0.34166667]\n",
      "Q values:  tensor([[-6.3325, -5.9204, -6.1794, -6.4811, -6.4622, -5.1119]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11380 2051 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 524: ep_len:2051 episode reward: total was -223.200000. running mean: -73.366314\n",
      "startIDX:  1170\n",
      "524 12 True\n",
      "x_t:  3 [0.31875    0.30833333 0.11875    0.34166667]\n",
      "Q values:  tensor([[-5.8878, -5.3139, -5.7293, -5.9296, -6.3476, -4.6933]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16430 1356 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 524: ep_len:1356 episode reward: total was -79.500000. running mean: -73.427651\n",
      "startIDX:  3022\n",
      "ep 524: ep_len:68 episode reward: total was 52.000000. running mean: -72.173375\n",
      "startIDX:  2296\n",
      "524 22 True\n",
      "x_t:  2 [0.815625   0.40416667 0.05625    0.25416667]\n",
      "Q values:  tensor([[-4.8854, -4.8476, -5.6503, -4.8417, -5.8107, -4.4170]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23639 1443 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 524: ep_len:1443 episode reward: total was -76.400000. running mean: -72.215641\n",
      "startIDX:  959\n",
      "525 0 True\n",
      "x_t:  1 [0.915625   0.29166667 0.08125    0.4375    ]\n",
      "Q values:  tensor([[-4.3375, -3.8573, -3.9904, -4.2956, -4.3615, -3.3893]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11944 813 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  185\n",
      "525 1 True\n",
      "x_t:  2 [0.30625    0.36666667 0.0875     0.42916667]\n",
      "Q values:  tensor([[-3.8326, -3.9074, -4.0903, -3.4682, -4.1525, -3.0998]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27474 884 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2870\n",
      "startIDX:  1509\n",
      "525 10 True\n",
      "x_t:  2 [0.046875 0.4      0.10625  0.25    ]\n",
      "Q values:  tensor([[-4.1582, -4.3604, -4.3354, -4.1290, -4.5021, -3.3920]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18155 1210 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1674\n",
      "525 12 True\n",
      "x_t:  1 [0.28125    0.34166667 0.140625   0.35833333]\n",
      "Q values:  tensor([[-5.6967, -5.4834, -5.1088, -5.3748, -6.0078, -4.3362]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19900 246 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2043\n",
      "525 15 True\n",
      "x_t:  1 [0.4125     0.32083333 0.059375   0.30833333]\n",
      "Q values:  tensor([[-3.6531, -3.5393, -3.3623, -3.4864, -3.9999, -2.7921]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14905 693 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  41\n",
      "525 22 True\n",
      "x_t:  1 [0.590625   0.31666667 0.06875    0.39166667]\n",
      "Q values:  tensor([[-4.1219, -3.8990, -3.9694, -3.6858, -4.4062, -3.0651]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1610 729 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2506\n",
      "ep 526: ep_len:37 episode reward: total was 3.000000. running mean: -70.326919\n",
      "startIDX:  599\n",
      "526 1 True\n",
      "x_t:  2 [0.646875   0.38333333 0.125      0.30833333]\n",
      "Q values:  tensor([[-3.6211, -4.1386, -4.2521, -3.6568, -4.0753, -3.1049]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31486 388 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 526: ep_len:388 episode reward: total was -12.100000. running mean: -69.744650\n",
      "startIDX:  1599\n",
      "526 5 True\n",
      "x_t:  1 [0.575      0.3        0.0875     0.28333333]\n",
      "Q values:  tensor([[-5.4622, -5.1961, -5.1266, -5.1950, -5.6098, -4.2204]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14966 714 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 526: ep_len:714 episode reward: total was -84.900000. running mean: -69.896203\n",
      "startIDX:  1032\n",
      "526 10 True\n",
      "x_t:  1 [0.853125   0.2875     0.109375   0.32916667]\n",
      "Q values:  tensor([[-5.1318, -4.4947, -5.2605, -4.9572, -6.1130, -4.0698]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11332 1541 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 526: ep_len:1541 episode reward: total was -88.300000. running mean: -70.080241\n",
      "startIDX:  543\n",
      "526 12 True\n",
      "x_t:  0 [0.84375    0.40833333 0.075      0.3875    ]\n",
      "Q values:  tensor([[-4.1860, -4.6033, -3.9946, -4.1861, -4.6511, -3.3805]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11738 2000 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 526: ep_len:2000 episode reward: total was -231.000000. running mean: -71.689439\n",
      "startIDX:  2198\n",
      "526 15 True\n",
      "x_t:  3 [0.715625   0.35833333 0.078125   0.43333333]\n",
      "Q values:  tensor([[-4.9023, -4.9116, -4.8209, -5.0198, -5.2415, -3.9883]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18277 1341 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 526: ep_len:1341 episode reward: total was -71.000000. running mean: -71.682544\n",
      "startIDX:  517\n",
      "526 22 True\n",
      "x_t:  4 [0.021875   0.42083333 0.09375    0.375     ]\n",
      "Q values:  tensor([[-5.1982, -5.1217, -4.9319, -5.0252, -5.5220, -3.9918]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 6643 810 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 526: ep_len:810 episode reward: total was -40.900000. running mean: -71.374719\n",
      "startIDX:  2109\n",
      "527 0 True\n",
      "x_t:  1 [0.521875   0.33333333 0.215625   0.50416667]\n",
      "Q values:  tensor([[-5.8781, -6.1709, -6.1299, -5.9388, -6.7116, -4.9626]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22941 1151 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  440\n",
      "527 1 True\n",
      "x_t:  1 [0.46875    0.29166667 0.109375   0.475     ]\n",
      "Q values:  tensor([[-5.7235, -5.2501, -5.2330, -5.2954, -6.3544, -4.3898]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30725 828 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  820\n",
      "527 5 True\n",
      "x_t:  4 [0.003125   0.41666667 0.10625    0.37083333]\n",
      "Q values:  tensor([[-4.7056, -4.4764, -4.8622, -4.3334, -4.8906, -3.8377]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10011 592 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2179\n",
      "527 10 True\n",
      "x_t:  0 [0.809375 0.3875   0.090625 0.35    ]\n",
      "Q values:  tensor([[-4.0041, -4.1613, -4.5006, -3.9169, -4.6893, -3.5249]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19951 540 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  72\n",
      "527 12 True\n",
      "x_t:  2 [0.346875   0.40833333 0.06875    0.25      ]\n",
      "Q values:  tensor([[-6.2908, -5.5873, -5.5291, -5.3747, -5.9848, -4.4278]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2878 959 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3123\n",
      "startIDX:  2525\n",
      "527 22 True\n",
      "x_t:  3 [0.128125   0.2375     0.0625     0.26666667]\n",
      "Q values:  tensor([[-6.6279, -6.9587, -6.7573, -6.0961, -7.3144, -5.3790]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26195 1274 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1468\n",
      "528 0 True\n",
      "x_t:  1 [0.003125 0.3875   0.18125  0.4     ]\n",
      "Q values:  tensor([[-7.5016, -6.8335, -7.6133, -7.1716, -8.0991, -6.1636]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18926 1849 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 528: ep_len:1849 episode reward: total was -378.500000. running mean: -71.266549\n",
      "startIDX:  321\n",
      "528 1 True\n",
      "x_t:  0 [0.9375     0.37083333 0.05625    0.4       ]\n",
      "Q values:  tensor([[-4.8004, -5.3406, -5.4769, -5.0632, -6.0246, -4.2758]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29089 820 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 528: ep_len:820 episode reward: total was -35.700000. running mean: -70.910883\n",
      "startIDX:  441\n",
      "528 5 True\n",
      "x_t:  1 [0.465625   0.30833333 0.075      0.36666667]\n",
      "Q values:  tensor([[-5.3304, -5.4756, -5.6901, -5.4303, -6.0489, -4.5445]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5081 708 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 528: ep_len:708 episode reward: total was -40.000000. running mean: -70.601775\n",
      "startIDX:  1523\n",
      "528 10 True\n",
      "x_t:  3 [0.734375   0.31666667 0.1375     0.3875    ]\n",
      "Q values:  tensor([[-4.2930, -4.0292, -4.3767, -4.1962, -4.8541, -3.4778]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16417 338 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 528: ep_len:338 episode reward: total was -135.300000. running mean: -71.248757\n",
      "startIDX:  206\n",
      "528 12 True\n",
      "x_t:  3 [0.30625    0.29583333 0.11875    0.30416667]\n",
      "Q values:  tensor([[-6.6973, -6.1268, -6.5025, -6.2428, -7.7725, -5.4639]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5714 1423 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 528: ep_len:1423 episode reward: total was -64.300000. running mean: -71.179269\n",
      "startIDX:  2265\n",
      "528 15 True\n",
      "x_t:  3 [0.4375     0.3125     0.071875   0.36666667]\n",
      "Q values:  tensor([[-6.0869, -6.2875, -5.4880, -5.6466, -5.9891, -4.7645]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18240 1308 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 528: ep_len:1308 episode reward: total was -99.500000. running mean: -71.462477\n",
      "startIDX:  14\n",
      "528 22 True\n",
      "x_t:  1 [0.85       0.30416667 0.13125    0.40416667]\n",
      "Q values:  tensor([[-4.9927, -4.7178, -4.9355, -4.9017, -5.4032, -4.3003]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1582 731 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 528: ep_len:731 episode reward: total was 3.800000. running mean: -70.709852\n",
      "startIDX:  235\n",
      "529 0 True\n",
      "x_t:  2 [0.540625   0.40833333 0.1125     0.29166667]\n",
      "Q values:  tensor([[-5.2092, -5.0745, -5.3505, -5.1828, -6.0199, -4.0461]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2360 335 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  641\n",
      "529 1 True\n",
      "x_t:  3 [0.140625   0.24166667 0.08125    0.3125    ]\n",
      "Q values:  tensor([[-6.6487, -7.3760, -6.6119, -7.3203, -7.4999, -5.3767]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34330 1760 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  36\n",
      "529 5 True\n",
      "x_t:  1 [0.290625   0.34583333 0.159375   0.52916667]\n",
      "Q values:  tensor([[-5.7354, -5.9220, -6.0579, -5.8009, -6.3987, -4.7443]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2533 1146 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1530\n",
      "529 10 True\n",
      "x_t:  3 [0.771875   0.30833333 0.109375   0.39166667]\n",
      "Q values:  tensor([[-5.2151, -4.8535, -5.2277, -4.1570, -5.0852, -3.8867]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16413 328 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  15\n",
      "529 12 True\n",
      "x_t:  1 [0.80625  0.3125   0.153125 0.4125  ]\n",
      "Q values:  tensor([[-5.1144, -5.0726, -5.3209, -5.1613, -5.2276, -4.2216]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2221 654 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2280\n",
      "529 15 True\n",
      "x_t:  3 [0.3        0.30416667 0.1125     0.34166667]\n",
      "Q values:  tensor([[-5.8870, -5.9451, -6.3716, -5.6336, -6.6348, -4.8929]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18221 1299 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2906\n",
      "Time elapsed:  4690.928026199341\n",
      "startIDX:  2157\n",
      "530 0 True\n",
      "x_t:  1 [0.665625 0.3125   0.115625 0.5125  ]\n",
      "Q values:  tensor([[-5.7497, -5.0954, -5.4228, -5.2735, -5.6289, -4.3694]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22935 1117 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 530: ep_len:1117 episode reward: total was -36.200000. running mean: -70.648954\n",
      "startIDX:  555\n",
      "530 1 True\n",
      "x_t:  2 [0.78125    0.37083333 0.084375   0.33333333]\n",
      "Q values:  tensor([[-4.8625, -5.2037, -5.3198, -4.8060, -5.4039, -4.1284]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31468 1124 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 530: ep_len:1124 episode reward: total was -97.300000. running mean: -70.915465\n",
      "startIDX:  21\n",
      "530 5 True\n",
      "x_t:  2 [0.46875    0.38333333 0.153125   0.45      ]\n",
      "Q values:  tensor([[-4.3381, -4.4572, -4.4764, -4.2891, -4.9727, -3.5628]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2095 931 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 530: ep_len:931 episode reward: total was -25.700000. running mean: -70.463310\n",
      "startIDX:  87\n",
      "530 10 True\n",
      "x_t:  3 [0.146875   0.24166667 0.065625   0.27916667]\n",
      "Q values:  tensor([[-5.2642, -5.1445, -5.2413, -4.3720, -5.5573, -3.9819]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3607 1074 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 530: ep_len:1074 episode reward: total was -55.700000. running mean: -70.315677\n",
      "startIDX:  2022\n",
      "ep 530: ep_len:26 episode reward: total was 10.000000. running mean: -69.512520\n",
      "startIDX:  73\n",
      "530 15 True\n",
      "x_t:  3 [0.45625 0.3125  0.0875  0.35   ]\n",
      "Q values:  tensor([[-4.4813, -4.2887, -4.2822, -4.0536, -4.7161, -3.3501]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 580 249 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 530: ep_len:249 episode reward: total was -51.200000. running mean: -69.329395\n",
      "startIDX:  1345\n",
      "530 22 True\n",
      "x_t:  3 [0.065625   0.26666667 0.078125   0.2625    ]\n",
      "Q values:  tensor([[-4.7158, -4.3092, -4.3894, -4.2040, -4.9612, -3.7256]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15202 1278 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 530: ep_len:1278 episode reward: total was -26.400000. running mean: -68.900101\n",
      "startIDX:  1590\n",
      "531 0 True\n",
      "x_t:  2 [0.671875   0.39583333 0.053125   0.25      ]\n",
      "Q values:  tensor([[-4.2113, -3.8338, -3.7689, -3.7970, -4.3907, -3.1132]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18495 1043 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  427\n",
      "531 1 True\n",
      "x_t:  1 [0.596875   0.28333333 0.09375    0.47083333]\n",
      "Q values:  tensor([[-4.0283, -4.1392, -4.4020, -3.7105, -4.4568, -3.2585]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30712 820 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2959\n",
      "startIDX:  1148\n",
      "531 10 True\n",
      "x_t:  2 [0.709375   0.4        0.090625   0.24583333]\n",
      "Q values:  tensor([[-3.3235, -3.2843, -3.3964, -3.3028, -3.7494, -2.7464]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12077 327 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1948\n",
      "startIDX:  2494\n",
      "531 15 True\n",
      "x_t:  3 [0.58125    0.3        0.08125    0.33333333]\n",
      "Q values:  tensor([[-3.7204, -3.5903, -3.5281, -3.0007, -4.1941, -2.8277]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19703 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3013\n",
      "startIDX:  1550\n",
      "532 0 True\n",
      "x_t:  3 [0.4        0.29166667 0.0875     0.34166667]\n",
      "Q values:  tensor([[-4.4686, -4.6833, -4.6142, -4.5600, -4.9729, -3.6920]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16878 260 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 532: ep_len:260 episode reward: total was -109.000000. running mean: -67.092358\n",
      "startIDX:  866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532 1 True\n",
      "x_t:  4 [0.075      0.38333333 0.15625    0.41666667]\n",
      "Q values:  tensor([[-3.4202, -3.2797, -3.2850, -3.1282, -3.2110, -2.5833]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35434 535 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 532: ep_len:535 episode reward: total was -46.700000. running mean: -66.888434\n",
      "startIDX:  602\n",
      "532 5 True\n",
      "x_t:  2 [0.21875    0.39166667 0.10625    0.3       ]\n",
      "Q values:  tensor([[-3.9245, -3.8135, -3.9359, -3.5769, -3.8167, -3.0117]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6116 489 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 532: ep_len:489 episode reward: total was -84.500000. running mean: -67.064550\n",
      "startIDX:  2504\n",
      "532 10 True\n",
      "x_t:  1 [0.765625   0.29166667 0.109375   0.325     ]\n",
      "Q values:  tensor([[-3.2674, -3.5238, -3.5912, -3.4862, -3.9437, -2.6995]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22482 1142 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 532: ep_len:1142 episode reward: total was -78.500000. running mean: -67.178904\n",
      "startIDX:  1294\n",
      "532 12 True\n",
      "x_t:  4 [0.41875    0.37083333 0.065625   0.275     ]\n",
      "Q values:  tensor([[-4.3390, -3.9993, -4.2196, -3.9984, -4.6541, -3.4994]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17458 488 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 532: ep_len:488 episode reward: total was -65.900000. running mean: -67.166115\n",
      "startIDX:  847\n",
      "532 15 True\n",
      "x_t:  3 [0.234375   0.24583333 0.065625   0.25416667]\n",
      "Q values:  tensor([[-4.7831, -4.5447, -5.0952, -4.6720, -4.8269, -3.9024]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8605 1290 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 532: ep_len:1290 episode reward: total was -66.700000. running mean: -67.161454\n",
      "startIDX:  834\n",
      "532 22 True\n",
      "x_t:  1 [0.253125   0.33333333 0.084375   0.4125    ]\n",
      "Q values:  tensor([[-3.5308, -4.2473, -4.6245, -3.8981, -4.5316, -3.2113]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9508 290 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 532: ep_len:290 episode reward: total was 26.400000. running mean: -66.225839\n",
      "startIDX:  2334\n",
      "533 0 True\n",
      "x_t:  3 [0.215625   0.25416667 0.08125    0.28333333]\n",
      "Q values:  tensor([[-5.5161, -5.7263, -5.4844, -5.4567, -5.8187, -4.4607]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26135 1277 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  409\n",
      "533 1 True\n",
      "x_t:  0 [0.575      0.37916667 0.134375   0.40416667]\n",
      "Q values:  tensor([[-3.8028, -3.7218, -4.1282, -3.6771, -4.1782, -3.1370]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29142 525 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  693\n",
      "533 5 True\n",
      "x_t:  3 [0.08125    0.2625     0.090625   0.31666667]\n",
      "Q values:  tensor([[-4.9887, -5.5023, -4.9766, -4.8965, -5.4967, -4.3672]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8754 1341 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2395\n",
      "startIDX:  1463\n",
      "533 12 False\n",
      "x_t:  3 [0.20625    0.2625     0.075      0.28333333]\n",
      "Q values:  tensor([[1.0570, 0.8159, 0.9912, 1.4880, 0.1059, 0.8873]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 17956 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  889\n",
      "533 15 True\n",
      "x_t:  3 [0.228125   0.24583333 0.06875    0.25833333]\n",
      "Q values:  tensor([[-5.7726, -6.4796, -6.5480, -5.9559, -7.1849, -5.1117]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8601 1263 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1094\n",
      "533 22 True\n",
      "x_t:  1 [0.4125     0.32916667 0.096875   0.50833333]\n",
      "Q values:  tensor([[-4.4905, -4.7301, -4.7560, -4.3408, -5.1438, -3.6530]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11955 748 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2314\n",
      "534 0 True\n",
      "x_t:  3 [0.084375   0.24166667 0.071875   0.25      ]\n",
      "Q values:  tensor([[-5.7052, -5.4919, -5.7813, -5.2568, -6.0571, -4.2911]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26099 1263 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 534: ep_len:1263 episode reward: total was -36.100000. running mean: -64.470939\n",
      "startIDX:  1150\n",
      "ep 534: ep_len:32 episode reward: total was 2.000000. running mean: -63.806230\n",
      "startIDX:  423\n",
      "534 5 True\n",
      "x_t:  3 [0.590625   0.32916667 0.1375     0.4375    ]\n",
      "Q values:  tensor([[-10.2543,  -9.8435, -10.5287,  -9.3333, -10.3002,  -7.7646]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8860 2584 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 534: ep_len:2584 episode reward: total was -265.500000. running mean: -65.823167\n",
      "startIDX:  1995\n",
      "534 10 True\n",
      "x_t:  1 [0.771875   0.28333333 0.10625    0.325     ]\n",
      "Q values:  tensor([[-4.3707, -4.7107, -4.5563, -4.6011, -5.0389, -3.6876]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18923 363 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 534: ep_len:363 episode reward: total was -44.800000. running mean: -65.612936\n",
      "startIDX:  1094\n",
      "534 12 True\n",
      "x_t:  3 [0.3      0.3      0.071875 0.3375  ]\n",
      "Q values:  tensor([[-6.2336, -6.5691, -6.5976, -5.9632, -7.4674, -5.2645]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16424 1393 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 534: ep_len:1393 episode reward: total was -75.200000. running mean: -65.708806\n",
      "startIDX:  2545\n",
      "534 15 False\n",
      "x_t:  3 [0.396875   0.27083333 0.08125    0.29583333]\n",
      "Q values:  tensor([[4.3077, 2.1351, 3.5028, 4.4584, 0.9244, 2.7715]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 19742 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 534: ep_len:200 episode reward: total was -19.100000. running mean: -65.242718\n",
      "startIDX:  2821\n",
      "ep 534: ep_len:97 episode reward: total was -91.900000. running mean: -65.509291\n",
      "startIDX:  864\n",
      "535 0 True\n",
      "x_t:  0 [0.65       0.40833333 0.128125   0.39583333]\n",
      "Q values:  tensor([[-4.8813, -4.6431, -4.5343, -4.8820, -5.1916, -3.5942]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10419 507 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  590\n",
      "535 1 True\n",
      "x_t:  3 [0.2        0.25416667 0.1125     0.31666667]\n",
      "Q values:  tensor([[-5.8802, -6.3539, -6.4442, -5.7292, -6.4440, -4.9580]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34352 1825 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2078\n",
      "535 5 True\n",
      "x_t:  4 [0.628125 0.35     0.065625 0.3     ]\n",
      "Q values:  tensor([[-3.4460, -3.7150, -3.8050, -3.5190, -3.9867, -2.9605]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19558 673 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2538\n",
      "startIDX:  1148\n",
      "535 12 True\n",
      "x_t:  3 [0.140625   0.27916667 0.09375    0.30416667]\n",
      "Q values:  tensor([[-4.4978, -5.0856, -4.8720, -4.4906, -5.0142, -3.7663]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16392 1373 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3077\n",
      "startIDX:  1201\n",
      "535 22 True\n",
      "x_t:  1 [0.315625   0.35       0.19375    0.50833333]\n",
      "Q values:  tensor([[-4.5207, -4.4275, -4.6753, -4.7937, -4.6884, -3.6888]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11959 694 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2047\n",
      "536 0 True\n",
      "x_t:  0 [0.853125   0.40416667 0.121875   0.34583333]\n",
      "Q values:  tensor([[-4.7655, -4.3252, -4.5493, -4.3375, -5.0429, -3.4648]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20632 825 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 536: ep_len:825 episode reward: total was -39.800000. running mean: -64.144327\n",
      "startIDX:  502\n",
      "536 1 True\n",
      "x_t:  2 [0.190625   0.37916667 0.0875     0.30833333]\n",
      "Q values:  tensor([[-4.3184, -5.1337, -5.0392, -4.8955, -5.2342, -3.8822]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31562 1192 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 536: ep_len:1192 episode reward: total was -152.400000. running mean: -65.026884\n",
      "startIDX:  1910\n",
      "536 5 True\n",
      "x_t:  2 [0.534375   0.40416667 0.103125   0.24583333]\n",
      "Q values:  tensor([[-4.5105, -4.8206, -4.7170, -4.7062, -5.0839, -3.6817]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15690 325 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 536: ep_len:325 episode reward: total was -38.000000. running mean: -64.756615\n",
      "startIDX:  1835\n",
      "536 10 True\n",
      "x_t:  2 [0.1875     0.39583333 0.05       0.25416667]\n",
      "Q values:  tensor([[-3.9647, -3.7364, -3.5920, -4.0094, -3.9255, -3.2287]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18175 852 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 536: ep_len:852 episode reward: total was -54.200000. running mean: -64.651049\n",
      "startIDX:  451\n",
      "536 12 True\n",
      "x_t:  3 [0.7875     0.3375     0.128125   0.42083333]\n",
      "Q values:  tensor([[-4.0286, -4.0327, -4.0206, -3.9201, -4.7076, -3.1356]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7720 243 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 536: ep_len:243 episode reward: total was -43.000000. running mean: -64.434538\n",
      "startIDX:  550\n",
      "536 15 True\n",
      "x_t:  3 [0.084375   0.2375     0.05       0.23333333]\n",
      "Q values:  tensor([[-6.7206, -6.9875, -7.0289, -6.4305, -7.1474, -5.5755]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8504 2354 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 536: ep_len:2354 episode reward: total was -202.600000. running mean: -65.816193\n",
      "startIDX:  1167\n",
      "536 22 True\n",
      "x_t:  1 [0.3875     0.3375     0.121875   0.50833333]\n",
      "Q values:  tensor([[-3.8479, -3.8965, -3.9861, -3.8801, -4.2654, -3.0998]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11956 716 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 536: ep_len:716 episode reward: total was -41.800000. running mean: -65.576031\n",
      "startIDX:  1463\n",
      "537 0 True\n",
      "x_t:  4 [0.534375   0.35416667 0.075      0.275     ]\n",
      "Q values:  tensor([[-3.7270, -3.6152, -3.7398, -3.9412, -3.9526, -3.2093]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16381 543 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  591\n",
      "537 1 True\n",
      "x_t:  3 [0.20625    0.25       0.1125     0.32916667]\n",
      "Q values:  tensor([[-4.6781, -4.0338, -4.6265, -4.6761, -4.5331, -3.5720]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34353 1836 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2684\n",
      "537 5 True\n",
      "x_t:  1 [0.321875   0.32916667 0.103125   0.525     ]\n",
      "Q values:  tensor([[-2.9831, -2.8836, -2.9213, -2.7799, -3.1125, -2.1488]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22132 246 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1051\n",
      "537 10 True\n",
      "x_t:  1 [0.3625     0.3125     0.11875    0.35833333]\n",
      "Q values:  tensor([[-6.3558, -6.1531, -5.9547, -5.7640, -6.0569, -4.6215]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11393 1580 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  363\n",
      "537 12 True\n",
      "x_t:  4 [0.10625    0.425      0.0875     0.39166667]\n",
      "Q values:  tensor([[-4.5346, -4.1052, -4.2076, -4.6430, -4.8015, -3.6121]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7193 718 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1817\n",
      "537 15 True\n",
      "x_t:  0 [0.20625    0.425      0.075      0.35416667]\n",
      "Q values:  tensor([[-4.6556, -4.3812, -4.6013, -4.4608, -4.9852, -3.6070]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13494 485 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2365\n",
      "537 22 True\n",
      "x_t:  2 [0.671875 0.4125   0.084375 0.25    ]\n",
      "Q values:  tensor([[-5.5812, -4.8427, -5.2081, -4.4377, -5.4547, -4.0881]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23661 1383 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  406\n",
      "538 0 True\n",
      "x_t:  2 [0.7875     0.40416667 0.053125   0.25416667]\n",
      "Q values:  tensor([[-5.9635, -5.1303, -5.5544, -4.9652, -5.8205, -4.4638]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8988 2050 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 538: ep_len:2050 episode reward: total was -191.200000. running mean: -68.372893\n",
      "startIDX:  1085\n",
      "ep 538: ep_len:233 episode reward: total was -70.200000. running mean: -68.391164\n",
      "startIDX:  963\n",
      "538 5 True\n",
      "x_t:  3 [0.696875   0.3125     0.175      0.39583333]\n",
      "Q values:  tensor([[-3.2499, -3.0078, -3.2853, -3.1353, -3.2389, -2.4416]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10500 218 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 538: ep_len:218 episode reward: total was -107.900000. running mean: -68.786253\n",
      "startIDX:  2141\n",
      "538 10 True\n",
      "x_t:  0 [0.621875 0.4      0.075    0.3125  ]\n",
      "Q values:  tensor([[-4.0986, -4.0609, -4.2539, -3.7518, -4.7506, -3.3657]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20001 578 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 538: ep_len:578 episode reward: total was -47.100000. running mean: -68.569390\n",
      "startIDX:  1547\n",
      "538 12 True\n",
      "x_t:  2 [0.50625    0.4        0.06875    0.30833333]\n",
      "Q values:  tensor([[-5.0085, -5.2968, -5.5380, -4.6414, -5.5131, -4.0730]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19446 765 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 538: ep_len:765 episode reward: total was -94.700000. running mean: -68.830696\n",
      "startIDX:  353\n",
      "538 15 True\n",
      "x_t:  1 [0.25       0.36666667 0.184375   0.50416667]\n",
      "Q values:  tensor([[-3.4398, -3.6815, -3.7127, -3.4395, -3.7748, -3.0309]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2770 250 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 538: ep_len:250 episode reward: total was -26.700000. running mean: -68.409389\n",
      "startIDX:  1705\n",
      "538 22 True\n",
      "x_t:  3 [0.334375   0.27916667 0.10625    0.31666667]\n",
      "Q values:  tensor([[-4.1618, -4.0990, -3.8619, -3.9520, -4.1427, -3.1811]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16928 234 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 538: ep_len:234 episode reward: total was -87.000000. running mean: -68.595295\n",
      "startIDX:  1545\n",
      "539 0 True\n",
      "x_t:  3 [0.590625   0.32916667 0.146875   0.38333333]\n",
      "Q values:  tensor([[-3.4026, -3.6139, -3.4585, -3.1186, -3.7060, -2.7420]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16842 237 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  955\n",
      "539 1 True\n",
      "x_t:  4 [0.209375   0.37916667 0.1        0.3625    ]\n",
      "Q values:  tensor([[-4.2290, -4.1274, -4.0201, -4.2374, -4.2183, -3.4914]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35529 552 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  309\n",
      "539 5 True\n",
      "x_t:  0 [0.79375    0.38333333 0.059375   0.38333333]\n",
      "Q values:  tensor([[-4.4543, -4.5937, -4.7565, -4.4739, -4.9462, -3.7324]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3572 499 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1066\n",
      "539 10 True\n",
      "x_t:  3 [0.70625    0.29166667 0.075      0.375     ]\n",
      "Q values:  tensor([[-7.4049, -6.9301, -7.8859, -6.1897, -7.8088, -5.8556]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14714 1693 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  358\n",
      "539 12 True\n",
      "x_t:  3 [0.8875     0.35833333 0.103125   0.42916667]\n",
      "Q values:  tensor([[-8.5396, -7.5370, -7.9281, -7.4639, -8.3399, -6.6248]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7710 975 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1971\n",
      "539 15 True\n",
      "x_t:  1 [0.596875   0.30833333 0.046875   0.30833333]\n",
      "Q values:  tensor([[-5.8449, -6.0263, -5.5729, -6.1073, -6.1311, -4.9031]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14883 685 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1385\n",
      "539 22 True\n",
      "x_t:  3 [0.1        0.25416667 0.0625     0.27916667]\n",
      "Q values:  tensor([[-11.0762, -11.2787, -11.0686,  -9.7648, -11.6813,  -9.1167]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15207 1256 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  4800.3887004852295\n",
      "startIDX:  1639\n",
      "540 0 True\n",
      "x_t:  3 [0.365625   0.29166667 0.1125     0.31666667]\n",
      "Q values:  tensor([[-6.0183, -5.9382, -6.3503, -5.9691, -6.9673, -4.8928]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16883 213 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 540: ep_len:213 episode reward: total was -71.500000. running mean: -70.328359\n",
      "startIDX:  235\n",
      "540 1 True\n",
      "x_t:  2 [0.325      0.36666667 0.115625   0.43333333]\n",
      "Q values:  tensor([[-8.1701, -7.8926, -7.9151, -7.8648, -8.9659, -6.7094]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27477 859 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 540: ep_len:859 episode reward: total was -63.600000. running mean: -70.261076\n",
      "startIDX:  2567\n",
      "540 5 True\n",
      "x_t:  2 [0.146875   0.39166667 0.08125    0.27083333]\n",
      "Q values:  tensor([[-9.1951, -9.0371, -9.0086, -8.3649, -9.8716, -7.2031]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21571 796 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 540: ep_len:796 episode reward: total was -66.300000. running mean: -70.221465\n",
      "startIDX:  1587\n",
      "540 10 True\n",
      "x_t:  3 [0.721875   0.3        0.09375    0.37916667]\n",
      "Q values:  tensor([[-7.1981, -6.3827, -6.2940, -6.0477, -7.1644, -5.1663]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16422 311 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 540: ep_len:311 episode reward: total was -91.300000. running mean: -70.432250\n",
      "startIDX:  1415\n",
      "540 12 False\n",
      "x_t:  3 [0.446875   0.30833333 0.11875    0.3625    ]\n",
      "Q values:  tensor([[0.5754, 0.9045, 0.7854, 2.5245, 0.1097, 0.5549]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 17896 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 540: ep_len:200 episode reward: total was -47.300000. running mean: -70.200928\n",
      "startIDX:  1337\n",
      "540 15 True\n",
      "x_t:  3 [0.190625   0.25       0.059375   0.26666667]\n",
      "Q values:  tensor([[-4.9118, -5.0602, -5.1415, -4.3648, -5.3248, -4.2964]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10471 271 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 540: ep_len:271 episode reward: total was -116.900000. running mean: -70.667918\n",
      "startIDX:  1762\n",
      "540 22 True\n",
      "x_t:  3 [0.2        0.27083333 0.090625   0.27916667]\n",
      "Q values:  tensor([[-6.8145, -6.5045, -6.2870, -6.2810, -7.6053, -5.2177]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16959 226 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 540: ep_len:226 episode reward: total was -73.300000. running mean: -70.694239\n",
      "startIDX:  1583\n",
      "541 0 False\n",
      "x_t:  3 [0.7875     0.32916667 0.0875     0.4125    ]\n",
      "Q values:  tensor([[-4.5462, -4.9068, -4.8750, -4.0182, -5.9891, -4.0627]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16824 222 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541 1 True\n",
      "x_t:  3 [0.59375    0.30416667 0.13125    0.44583333]\n",
      "Q values:  tensor([[-7.4974, -6.8005, -6.9671, -6.5709, -7.8535, -5.6809]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34432 1474 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  444\n",
      "541 5 True\n",
      "x_t:  1 [0.76875    0.28333333 0.13125    0.37916667]\n",
      "Q values:  tensor([[-7.1420, -6.3503, -6.7830, -6.8784, -7.6244, -5.5842]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5038 679 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1084\n",
      "541 10 True\n",
      "x_t:  2 [0.54375  0.4      0.090625 0.25    ]\n",
      "Q values:  tensor([[-5.6667, -4.8085, -4.6790, -4.9685, -5.4675, -4.1798]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12103 376 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  516\n",
      "541 12 True\n",
      "x_t:  2 [0.003125   0.41666667 0.10625    0.24583333]\n",
      "Q values:  tensor([[-6.9861, -6.9515, -7.2237, -6.6015, -8.1081, -5.9064]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9830 1062 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  605\n",
      "541 15 True\n",
      "x_t:  1 [0.534375   0.3125     0.065625   0.29583333]\n",
      "Q values:  tensor([[-6.4255, -6.3859, -6.6181, -5.9212, -6.7848, -5.0793]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5221 694 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1162\n",
      "541 22 True\n",
      "x_t:  1 [0.74375    0.3125     0.075      0.47916667]\n",
      "Q values:  tensor([[-5.4705, -5.1727, -5.3134, -5.2000, -5.5605, -4.3594]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11930 699 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  992\n",
      "542 0 True\n",
      "x_t:  3 [0.140625   0.25416667 0.071875   0.28333333]\n",
      "Q values:  tensor([[-13.9418, -13.4984, -14.0691, -13.2683, -14.2651, -11.2382]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15182 2409 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 542: ep_len:2409 episode reward: total was -215.200000. running mean: -70.886244\n",
      "startIDX:  209\n",
      "542 1 True\n",
      "x_t:  2 [0.43125    0.375      0.13125    0.42916667]\n",
      "Q values:  tensor([[-5.4150, -6.0842, -5.4677, -5.5222, -5.8733, -4.8133]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27492 879 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 542: ep_len:879 episode reward: total was -76.200000. running mean: -70.939382\n",
      "startIDX:  519\n",
      "542 5 True\n",
      "x_t:  2 [0.853125   0.375      0.0625     0.28333333]\n",
      "Q values:  tensor([[-5.6782, -5.2494, -5.4065, -4.8229, -5.6150, -4.3773]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6028 497 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 542: ep_len:497 episode reward: total was -12.700000. running mean: -70.356988\n",
      "startIDX:  939\n",
      "542 10 True\n",
      "x_t:  2 [0.7875     0.40416667 0.1        0.24166667]\n",
      "Q values:  tensor([[-9.8832, -9.8185, -9.3907, -9.0749, -9.7355, -7.8920]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12062 1946 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 542: ep_len:1946 episode reward: total was -159.800000. running mean: -71.251418\n",
      "startIDX:  1025\n",
      "542 12 True\n",
      "x_t:  2 [0.78125 0.4125  0.05    0.2375 ]\n",
      "Q values:  tensor([[-4.3570, -4.4052, -4.1386, -3.9575, -4.7308, -3.5116]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13581 314 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 542: ep_len:314 episode reward: total was -25.000000. running mean: -70.788904\n",
      "startIDX:  334\n",
      "542 15 True\n",
      "x_t:  0 [0.340625   0.41666667 0.078125   0.26666667]\n",
      "Q values:  tensor([[-4.4958, -4.2474, -4.4271, -4.0737, -4.5602, -3.5364]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3819 789 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 542: ep_len:789 episode reward: total was -136.300000. running mean: -71.444015\n",
      "startIDX:  64\n",
      "542 22 True\n",
      "x_t:  1 [0.478125   0.33333333 0.15625    0.39166667]\n",
      "Q values:  tensor([[-4.9198, -4.3653, -4.8451, -4.4985, -4.8669, -3.8154]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1618 721 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 542: ep_len:721 episode reward: total was -120.600000. running mean: -71.935575\n",
      "startIDX:  1315\n",
      "543 0 True\n",
      "x_t:  4 [0.146875 0.3875   0.1      0.275   ]\n",
      "Q values:  tensor([[-6.4413, -6.0823, -5.5951, -5.7976, -6.0323, -4.6578]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16307 1797 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  354\n",
      "543 1 True\n",
      "x_t:  0 [0.8        0.35       0.10625    0.56666667]\n",
      "Q values:  tensor([[-4.4781, -4.3272, -5.1548, -4.3901, -5.4158, -3.9905]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29227 847 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  598\n",
      "543 5 False\n",
      "x_t:  2 [0.66875    0.39166667 0.075      0.30416667]\n",
      "Q values:  tensor([[-4.4545, -3.8480, -3.4852, -4.1143, -4.2155, -3.5804]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6060 472 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2111\n",
      "543 10 True\n",
      "x_t:  0 [0.746875   0.39583333 0.096875   0.32916667]\n",
      "Q values:  tensor([[-5.7707, -5.3946, -5.2911, -5.6041, -5.8375, -4.3664]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19961 569 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  760\n",
      "543 12 True\n",
      "x_t:  0 [0.671875   0.40833333 0.10625    0.3875    ]\n",
      "Q values:  tensor([[-4.9374, -4.2391, -4.3955, -4.4570, -4.8501, -3.4377]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11719 911 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1623\n",
      "543 15 True\n",
      "x_t:  1 [0.09375    0.35416667 0.08125    0.3875    ]\n",
      "Q values:  tensor([[-4.2319, -4.1440, -3.8578, -4.0496, -4.2330, -3.3257]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12455 268 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  666\n",
      "543 22 True\n",
      "x_t:  2 [0.7625     0.40833333 0.084375   0.25833333]\n",
      "Q values:  tensor([[-5.4030, -5.6210, -5.2008, -5.2212, -5.4996, -4.5277]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9040 981 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  391\n",
      "544 0 True\n",
      "x_t:  3 [0.5875  0.3625  0.15625 0.45   ]\n",
      "Q values:  tensor([[-4.6371, -4.7763, -4.7092, -4.7378, -5.2401, -4.1637]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7017 1106 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 544: ep_len:1106 episode reward: total was -45.400000. running mean: -71.705569\n",
      "startIDX:  1098\n",
      "ep 544: ep_len:226 episode reward: total was -67.600000. running mean: -71.664514\n",
      "startIDX:  631\n",
      "544 5 True\n",
      "x_t:  3 [0.134375   0.2625     0.078125   0.32916667]\n",
      "Q values:  tensor([[-5.6015, -6.0872, -6.2326, -5.9059, -6.1866, -5.2413]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8769 1388 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 544: ep_len:1388 episode reward: total was -49.400000. running mean: -71.441869\n",
      "startIDX:  946\n",
      "544 10 True\n",
      "x_t:  1 [0.4375     0.3125     0.11875    0.35416667]\n",
      "Q values:  tensor([[-7.2773, -6.7117, -6.9792, -6.9859, -7.5884, -6.1243]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11386 1610 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 544: ep_len:1610 episode reward: total was -88.200000. running mean: -71.609450\n",
      "startIDX:  655\n",
      "544 12 True\n",
      "x_t:  1 [0.1625     0.375      0.11875    0.49583333]\n",
      "Q values:  tensor([[-6.8619, -6.9242, -7.1173, -6.3363, -7.4399, -5.9143]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10314 1221 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 544: ep_len:1221 episode reward: total was -141.000000. running mean: -72.303355\n",
      "startIDX:  2233\n",
      "544 15 True\n",
      "x_t:  3 [0.303125   0.30833333 0.1125     0.34166667]\n",
      "Q values:  tensor([[-7.2579, -6.9995, -6.3906, -7.1896, -6.8587, -6.1197]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18223 1306 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 544: ep_len:1306 episode reward: total was -53.900000. running mean: -72.119322\n",
      "startIDX:  1459\n",
      "544 22 True\n",
      "x_t:  4 [0.1375     0.39166667 0.1125     0.29166667]\n",
      "Q values:  tensor([[-5.1204, -4.8348, -4.9904, -4.9561, -5.3293, -4.1911]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16347 553 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 544: ep_len:553 episode reward: total was -25.100000. running mean: -71.649129\n",
      "startIDX:  1550\n",
      "545 0 True\n",
      "x_t:  3 [0.578125   0.30833333 0.075      0.375     ]\n",
      "Q values:  tensor([[-4.6031, -4.7768, -5.2563, -4.2483, -5.2464, -4.0521]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16850 251 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  76\n",
      "545 1 False\n",
      "x_t:  3 [0.178125   0.22916667 0.078125   0.3       ]\n",
      "Q values:  tensor([[1.9869, 1.3554, 1.1008, 2.6122, 0.7245, 0.5363]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 25759 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  728\n",
      "545 5 True\n",
      "x_t:  3 [0.115625   0.27083333 0.06875    0.3125    ]\n",
      "Q values:  tensor([[-6.7583, -6.6951, -6.5662, -7.2476, -7.2816, -5.8604]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8764 1309 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2380\n",
      "545 10 True\n",
      "x_t:  1 [0.565625 0.3      0.134375 0.325   ]\n",
      "Q values:  tensor([[-7.6059, -7.6885, -7.6065, -7.1747, -7.6156, -6.3846]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22502 1216 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  729\n",
      "545 12 True\n",
      "x_t:  0 [0.9125     0.40833333 0.08125    0.30833333]\n",
      "Q values:  tensor([[-5.3601, -4.9469, -4.9572, -4.5117, -5.2880, -4.1652]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11632 861 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2251\n",
      "545 15 True\n",
      "x_t:  3 [0.096875   0.27083333 0.059375   0.30416667]\n",
      "Q values:  tensor([[-6.9235, -6.7743, -7.5229, -7.6104, -7.1952, -6.3498]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18179 1266 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2426\n",
      "545 22 True\n",
      "x_t:  2 [0.83125    0.40416667 0.078125   0.25833333]\n",
      "Q values:  tensor([[-4.5895, -4.9878, -4.9747, -4.5400, -5.1299, -3.9546]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23636 329 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2406\n",
      "546 0 True\n",
      "x_t:  3 [0.390625   0.28333333 0.125      0.325     ]\n",
      "Q values:  tensor([[-6.3710, -6.3050, -6.0049, -5.8294, -6.1535, -4.8675]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26176 1236 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 546: ep_len:1236 episode reward: total was -98.500000. running mean: -70.497333\n",
      "startIDX:  360\n",
      "546 1 True\n",
      "x_t:  0 [0.85625    0.375      0.09375    0.40416667]\n",
      "Q values:  tensor([[-5.3842, -4.4069, -5.0291, -4.6580, -4.9742, -3.8972]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29102 812 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 546: ep_len:812 episode reward: total was -50.900000. running mean: -70.301360\n",
      "startIDX:  672\n",
      "546 5 True\n",
      "x_t:  3 [0.221875   0.27916667 0.096875   0.35833333]\n",
      "Q values:  tensor([[-4.4556, -4.1912, -4.6304, -4.2317, -4.5108, -3.8250]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8790 1359 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 546: ep_len:1359 episode reward: total was -73.000000. running mean: -70.328346\n",
      "startIDX:  338\n",
      "546 10 True\n",
      "x_t:  3 [0.153125   0.22916667 0.06875    0.26666667]\n",
      "Q values:  tensor([[-3.7665, -3.3722, -3.4527, -3.3745, -3.6770, -2.8846]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5159 273 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 546: ep_len:273 episode reward: total was -143.500000. running mean: -71.060063\n",
      "startIDX:  294\n",
      "546 12 True\n",
      "x_t:  4 [0.046875   0.44583333 0.14375    0.3625    ]\n",
      "Q values:  tensor([[-3.3625, -2.9305, -3.4584, -2.8690, -3.0959, -2.5664]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7189 758 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 546: ep_len:758 episode reward: total was -40.400000. running mean: -70.753462\n",
      "startIDX:  626\n",
      "546 15 True\n",
      "x_t:  1 [0.478125   0.31666667 0.1        0.3       ]\n",
      "Q values:  tensor([[-3.8957, -3.9835, -4.1027, -3.8129, -4.0507, -3.0683]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5227 705 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 546: ep_len:705 episode reward: total was -55.200000. running mean: -70.597928\n",
      "startIDX:  869\n",
      "546 22 True\n",
      "x_t:  1 [0.14375    0.35833333 0.15625    0.39583333]\n",
      "Q values:  tensor([[-3.5099, -3.4993, -3.4986, -3.5761, -3.6719, -2.7689]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9498 259 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 546: ep_len:259 episode reward: total was -5.100000. running mean: -69.942948\n",
      "startIDX:  982\n",
      "547 0 True\n",
      "x_t:  1 [0.378125   0.33333333 0.190625   0.475     ]\n",
      "Q values:  tensor([[-3.8443, -3.8226, -3.8145, -3.6104, -3.7369, -3.0286]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11992 835 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  423\n",
      "547 1 True\n",
      "x_t:  1 [0.34375    0.3        0.196875   0.49583333]\n",
      "Q values:  tensor([[-3.7183, -4.0528, -3.5340, -3.2694, -3.4557, -3.1441]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30732 1296 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  210\n",
      "547 5 True\n",
      "x_t:  0 [0.703125   0.4        0.090625   0.38333333]\n",
      "Q values:  tensor([[-3.2722, -3.2805, -3.1594, -3.4314, -3.3139, -2.8020]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3583 745 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1104\n",
      "547 10 True\n",
      "x_t:  2 [0.703125   0.39166667 0.0625     0.25416667]\n",
      "Q values:  tensor([[-3.9618, -4.1286, -3.8182, -3.7055, -3.9851, -3.0996]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12080 353 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2030\n",
      "startIDX:  1441\n",
      "547 15 True\n",
      "x_t:  0 [0.865625   0.4125     0.096875   0.31666667]\n",
      "Q values:  tensor([[-4.7346, -5.1501, -5.1887, -4.5916, -5.0632, -3.8150]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13370 1529 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2209\n",
      "547 22 True\n",
      "x_t:  1 [0.85625 0.3125  0.1375  0.45   ]\n",
      "Q values:  tensor([[-5.1736, -5.1323, -4.5930, -4.8911, -5.2000, -4.2507]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22933 1105 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2463\n",
      "ep 548: ep_len:65 episode reward: total was 33.000000. running mean: -68.037362\n",
      "startIDX:  110\n",
      "548 1 False\n",
      "x_t:  3 [0.15       0.2375     0.071875   0.28333333]\n",
      "Q values:  tensor([[0.8306, 1.5805, 0.9196, 2.6148, 0.9656, 1.2255]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 25768 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 548: ep_len:200 episode reward: total was 31.900000. running mean: -67.037989\n",
      "startIDX:  850\n",
      "548 5 True\n",
      "x_t:  4 [0.334375   0.3875     0.140625   0.37083333]\n",
      "Q values:  tensor([[-4.3300, -4.3138, -4.3968, -4.2711, -4.2339, -3.5768]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10060 608 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 548: ep_len:608 episode reward: total was -38.000000. running mean: -66.747609\n",
      "startIDX:  2303\n",
      "548 10 True\n",
      "x_t:  1 [0.44375    0.30833333 0.10625    0.34166667]\n",
      "Q values:  tensor([[-5.9140, -5.7276, -5.8057, -5.8779, -6.3100, -4.8643]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22518 1257 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 548: ep_len:1257 episode reward: total was -5.000000. running mean: -66.130133\n",
      "startIDX:  1806\n",
      "548 12 True\n",
      "x_t:  0 [0.90625    0.40833333 0.0875     0.3625    ]\n",
      "Q values:  tensor([[-3.8810, -3.8467, -4.2789, -4.2425, -4.1987, -3.4126]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21093 567 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 548: ep_len:567 episode reward: total was -38.600000. running mean: -65.854831\n",
      "startIDX:  2846\n",
      "ep 548: ep_len:867 episode reward: total was -177.100000. running mean: -66.967283\n",
      "startIDX:  1887\n",
      "548 22 True\n",
      "x_t:  2 [0.26875    0.40833333 0.103125   0.2625    ]\n",
      "Q values:  tensor([[-4.8163, -4.3761, -4.9125, -4.7142, -4.7260, -3.9524]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18496 779 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 548: ep_len:779 episode reward: total was -60.600000. running mean: -66.903610\n",
      "startIDX:  848\n",
      "549 0 True\n",
      "x_t:  1 [0.221875   0.34583333 0.121875   0.40416667]\n",
      "Q values:  tensor([[-4.2908, -4.4387, -4.5797, -4.0546, -4.8943, -3.6318]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9432 218 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  894\n",
      "549 1 True\n",
      "x_t:  4 [0.365625   0.37916667 0.090625   0.39583333]\n",
      "Q values:  tensor([[-4.4884, -4.5776, -4.4763, -4.3677, -4.4035, -3.5277]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35478 549 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1499\n",
      "549 5 True\n",
      "x_t:  0 [0.940625 0.3875   0.053125 0.3375  ]\n",
      "Q values:  tensor([[-4.5141, -4.9006, -4.5846, -4.6990, -4.5993, -3.6758]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13494 452 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1541\n",
      "549 10 True\n",
      "x_t:  3 [0.43125 0.275   0.0875  0.3375 ]\n",
      "Q values:  tensor([[-4.0152, -3.9444, -3.9112, -3.7398, -3.8602, -3.1708]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16466 347 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1555\n",
      "549 12 True\n",
      "x_t:  2 [0.178125   0.4125     0.1        0.28333333]\n",
      "Q values:  tensor([[-3.7687, -3.7677, -4.0037, -3.7212, -4.1309, -3.2765]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19406 750 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1084\n",
      "549 15 True\n",
      "x_t:  4 [0.309375   0.37916667 0.084375   0.29166667]\n",
      "Q values:  tensor([[-3.8141, -3.9099, -3.9919, -3.5076, -4.0092, -3.1430]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9869 595 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1747\n",
      "549 22 False\n",
      "x_t:  3 [0.61875    0.32083333 0.11875    0.37083333]\n",
      "Q values:  tensor([[3.6382, 5.0188, 4.0718, 7.0483, 4.1701, 4.6559]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 16881 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  4907.370230913162\n",
      "startIDX:  2002\n",
      "550 0 True\n",
      "x_t:  1 [0.146875   0.35833333 0.1625     0.4125    ]\n",
      "Q values:  tensor([[-4.9400, -5.1470, -5.0704, -4.3955, -4.6017, -3.6997]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18938 206 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 550: ep_len:206 episode reward: total was -17.000000. running mean: -65.060098\n",
      "startIDX:  583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550 1 True\n",
      "x_t:  2 [0.46875    0.38333333 0.059375   0.30416667]\n",
      "Q values:  tensor([[-3.5978, -3.1639, -3.3667, -3.2244, -3.8974, -2.9117]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31520 424 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 550: ep_len:424 episode reward: total was -37.100000. running mean: -64.780497\n",
      "startIDX:  2572\n",
      "550 5 True\n",
      "x_t:  2 [0.790625   0.3875     0.065625   0.27083333]\n",
      "Q values:  tensor([[-5.5738, -4.7145, -5.2254, -4.7740, -4.8777, -4.1614]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21675 849 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 550: ep_len:849 episode reward: total was -114.700000. running mean: -65.279692\n",
      "startIDX:  1551\n",
      "550 10 True\n",
      "x_t:  3 [0.621875   0.3        0.075      0.35416667]\n",
      "Q values:  tensor([[-4.3060, -4.2918, -4.5337, -3.9861, -4.8142, -3.5887]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16439 329 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 550: ep_len:329 episode reward: total was -123.600000. running mean: -65.862895\n",
      "startIDX:  134\n",
      "550 12 True\n",
      "x_t:  2 [0.1625     0.41666667 0.0875     0.2375    ]\n",
      "Q values:  tensor([[-5.0527, -5.1047, -5.4653, -5.0655, -5.8480, -4.4299]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2903 343 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 550: ep_len:343 episode reward: total was -44.400000. running mean: -65.648266\n",
      "startIDX:  2563\n",
      "550 15 False\n",
      "x_t:  3 [0.35       0.27083333 0.103125   0.28333333]\n",
      "Q values:  tensor([[ 0.2768, -0.3301,  0.0336,  2.1904, -2.0510, -0.5035]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19750 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 550: ep_len:201 episode reward: total was -11.900000. running mean: -65.110783\n",
      "startIDX:  108\n",
      "550 22 True\n",
      "x_t:  2 [0.3125  0.4125  0.09375 0.25   ]\n",
      "Q values:  tensor([[-6.1220, -5.9186, -5.9684, -6.1738, -6.0386, -4.9585]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2363 1062 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 550: ep_len:1062 episode reward: total was -132.100000. running mean: -65.780676\n",
      "startIDX:  274\n",
      "551 0 True\n",
      "x_t:  3 [0.059375   0.23333333 0.0625     0.225     ]\n",
      "Q values:  tensor([[-6.1547, -6.6493, -5.9794, -5.1964, -6.1428, -4.9257]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4828 1254 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  230\n",
      "551 1 True\n",
      "x_t:  2 [0.2375  0.3625  0.13125 0.4375 ]\n",
      "Q values:  tensor([[-5.3652, -5.1293, -5.5743, -4.6240, -5.2395, -4.4015]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27469 853 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  398\n",
      "551 5 True\n",
      "x_t:  1 [0.8375     0.27916667 0.08125    0.38333333]\n",
      "Q values:  tensor([[-6.4885, -5.2898, -6.2977, -6.2646, -5.9665, -5.1130]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5034 690 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1381\n",
      "551 10 True\n",
      "x_t:  4 [0.346875   0.34166667 0.0875     0.24583333]\n",
      "Q values:  tensor([[-5.6764, -5.5119, -5.3121, -5.5374, -5.9735, -4.7945]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15902 634 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1357\n",
      "551 12 True\n",
      "x_t:  2 [0.6125     0.40833333 0.065625   0.3       ]\n",
      "Q values:  tensor([[-7.3857, -7.3164, -7.4714, -7.3608, -7.9017, -6.3984]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19458 1028 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2130\n",
      "551 15 True\n",
      "x_t:  2 [0.753125   0.40416667 0.05       0.2625    ]\n",
      "Q values:  tensor([[-4.4725, -4.2495, -4.3633, -4.0332, -4.5410, -3.5853]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15575 345 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1696\n",
      "551 22 True\n",
      "x_t:  3 [0.796875   0.34166667 0.121875   0.41666667]\n",
      "Q values:  tensor([[-4.0337, -4.4871, -4.5540, -3.5262, -4.4525, -3.3713]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16853 208 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1135\n",
      "552 0 True\n",
      "x_t:  2 [0.75       0.40833333 0.059375   0.27916667]\n",
      "Q values:  tensor([[-4.0121, -4.3684, -4.2315, -4.1421, -4.2427, -3.5161]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12641 335 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 552: ep_len:335 episode reward: total was -21.800000. running mean: -65.118788\n",
      "startIDX:  244\n",
      "552 1 True\n",
      "x_t:  2 [0.74375    0.375      0.18125    0.44583333]\n",
      "Q values:  tensor([[-7.0675, -7.0489, -7.0379, -6.4436, -7.2881, -5.8311]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27538 901 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 552: ep_len:901 episode reward: total was -129.700000. running mean: -65.764600\n",
      "startIDX:  2763\n",
      "552 5 True\n",
      "x_t:  0 [0.940625 0.3875   0.05     0.3125  ]\n",
      "Q values:  tensor([[-5.2516, -5.2523, -5.2499, -4.8370, -5.1032, -4.0841]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23148 510 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 552: ep_len:510 episode reward: total was -33.500000. running mean: -65.441954\n",
      "startIDX:  2189\n",
      "552 10 True\n",
      "x_t:  0 [0.840625   0.39166667 0.078125   0.34166667]\n",
      "Q values:  tensor([[-5.6189, -5.5116, -5.4113, -5.1112, -5.5764, -4.4912]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19944 504 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 552: ep_len:504 episode reward: total was -32.100000. running mean: -65.108534\n",
      "startIDX:  1648\n",
      "552 12 True\n",
      "x_t:  0 [0.6875     0.41666667 0.128125   0.3375    ]\n",
      "Q values:  tensor([[-5.6773, -5.2515, -5.8960, -5.5005, -5.3466, -4.6838]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21119 857 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 552: ep_len:857 episode reward: total was -59.700000. running mean: -65.054449\n",
      "startIDX:  883\n",
      "552 15 True\n",
      "x_t:  3 [0.1      0.2375   0.053125 0.2375  ]\n",
      "Q values:  tensor([[-8.1821, -8.4193, -7.7044, -7.3849, -8.2898, -6.2257]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8511 1224 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 552: ep_len:1224 episode reward: total was -82.300000. running mean: -65.226904\n",
      "startIDX:  848\n",
      "552 22 True\n",
      "x_t:  1 [0.165625   0.35833333 0.146875   0.39583333]\n",
      "Q values:  tensor([[-4.7635, -4.9020, -4.7178, -4.7985, -5.2924, -4.0425]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9502 270 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 552: ep_len:270 episode reward: total was 9.900000. running mean: -64.475635\n",
      "startIDX:  843\n",
      "553 0 True\n",
      "x_t:  1 [0.571875   0.31666667 0.121875   0.44583333]\n",
      "Q values:  tensor([[-4.9190, -5.0277, -4.9593, -5.4021, -4.8199, -4.4252]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9470 232 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1193\n",
      "startIDX:  2607\n",
      "553 5 True\n",
      "x_t:  1 [0.071875 0.3625   0.196875 0.5     ]\n",
      "Q values:  tensor([[-5.2549, -5.3893, -5.6443, -5.1378, -5.5382, -4.4164]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22112 273 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1090\n",
      "553 10 True\n",
      "x_t:  2 [0.76875    0.39583333 0.046875   0.25      ]\n",
      "Q values:  tensor([[-5.0118, -5.2882, -5.0648, -5.1747, -4.5511, -4.3895]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12070 379 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1809\n",
      "553 12 True\n",
      "x_t:  0 [0.340625   0.42083333 0.078125   0.2625    ]\n",
      "Q values:  tensor([[-7.5064, -7.1140, -7.7932, -7.0383, -7.8451, -6.1678]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21163 624 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  879\n",
      "553 15 True\n",
      "x_t:  3 [0.146875   0.24166667 0.059375   0.2375    ]\n",
      "Q values:  tensor([[-7.6262, -7.3954, -8.1594, -7.2495, -7.9479, -6.4796]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8538 1250 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2271\n",
      "553 22 True\n",
      "x_t:  1 [0.2125     0.3625     0.15625    0.46666667]\n",
      "Q values:  tensor([[-7.3148, -6.7671, -6.7194, -7.4092, -7.5560, -5.8602]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22992 1103 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1590\n",
      "554 0 True\n",
      "x_t:  3 [0.3625     0.29166667 0.115625   0.32916667]\n",
      "Q values:  tensor([[-5.7882, -5.7276, -5.5759, -5.3514, -6.2652, -4.5764]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16884 242 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 554: ep_len:242 episode reward: total was -47.100000. running mean: -61.896075\n",
      "startIDX:  429\n",
      "554 1 True\n",
      "x_t:  1 [0.84375    0.26666667 0.084375   0.45833333]\n",
      "Q values:  tensor([[-5.2230, -5.4918, -5.3483, -5.0151, -5.9534, -4.5404]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30686 787 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 554: ep_len:787 episode reward: total was 1.800000. running mean: -61.259114\n",
      "startIDX:  2369\n",
      "554 5 False\n",
      "x_t:  3 [0.0625     0.24583333 0.078125   0.25833333]\n",
      "Q values:  tensor([[2.5785, 4.7294, 3.2422, 4.8772, 1.7608, 2.0314]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 20017 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 554: ep_len:200 episode reward: total was -49.400000. running mean: -61.140523\n",
      "startIDX:  196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554 10 True\n",
      "x_t:  4 [0.20625    0.34583333 0.090625   0.2375    ]\n",
      "Q values:  tensor([[-5.7692, -6.0606, -5.9456, -5.7281, -6.1671, -5.0077]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4578 472 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 554: ep_len:472 episode reward: total was -20.900000. running mean: -60.738117\n",
      "startIDX:  1750\n",
      "554 12 True\n",
      "x_t:  0 [0.334375   0.42916667 0.090625   0.2625    ]\n",
      "Q values:  tensor([[-7.5547, -6.6825, -7.3507, -6.8530, -7.3905, -5.8024]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23006 1542 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 554: ep_len:1542 episode reward: total was -120.600000. running mean: -61.336736\n",
      "startIDX:  1801\n",
      "554 15 True\n",
      "x_t:  0 [0.58125    0.40416667 0.1125     0.35416667]\n",
      "Q values:  tensor([[-5.0685, -5.2842, -5.2846, -5.2062, -5.2478, -4.3972]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13415 450 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 554: ep_len:450 episode reward: total was -57.300000. running mean: -61.296369\n",
      "startIDX:  2846\n",
      "ep 554: ep_len:85 episode reward: total was 59.000000. running mean: -60.093405\n",
      "startIDX:  1118\n",
      "555 0 True\n",
      "x_t:  2 [0.4        0.41666667 0.115625   0.29583333]\n",
      "Q values:  tensor([[-4.5481, -4.8014, -4.3199, -4.5521, -4.6295, -3.7096]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12687 368 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  21\n",
      "555 1 False\n",
      "x_t:  3 [0.51875    0.26666667 0.1        0.37916667]\n",
      "Q values:  tensor([[2.8751, 2.4777, 3.5665, 3.6287, 1.9267, 2.2186]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 25683 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  974\n",
      "555 5 True\n",
      "x_t:  3 [0.15       0.23333333 0.11875    0.29166667]\n",
      "Q values:  tensor([[-3.5711, -3.7066, -3.6976, -3.4008, -3.3439, -3.0475]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10592 263 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2631\n",
      "startIDX:  1746\n",
      "555 12 True\n",
      "x_t:  0 [0.521875   0.41666667 0.1125     0.34583333]\n",
      "Q values:  tensor([[-4.9133, -4.9262, -4.8374, -4.4976, -4.8065, -3.6926]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21138 635 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1308\n",
      "555 15 True\n",
      "x_t:  3 [0.753125   0.32916667 0.0625     0.3625    ]\n",
      "Q values:  tensor([[-5.2256, -5.0575, -5.1268, -4.7243, -4.1141, -4.0272]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10357 225 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1751\n",
      "555 22 True\n",
      "x_t:  3 [0.121875   0.25416667 0.078125   0.275     ]\n",
      "Q values:  tensor([[-10.1001,  -9.7662, -10.9367,  -9.5000,  -8.2046,  -9.1604]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16977 238 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  679\n",
      "556 0 True\n",
      "x_t:  2 [0.50625    0.40416667 0.08125    0.25416667]\n",
      "Q values:  tensor([[-3.7388, -4.5385, -3.9568, -3.9033, -3.6018, -3.2477]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8945 902 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 556: ep_len:902 episode reward: total was -91.800000. running mean: -60.225159\n",
      "startIDX:  464\n",
      "556 1 True\n",
      "x_t:  1 [0.728125 0.275    0.084375 0.4625  ]\n",
      "Q values:  tensor([[-3.9564, -4.0494, -4.1429, -3.6294, -3.9493, -3.2258]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30699 787 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 556: ep_len:787 episode reward: total was -52.700000. running mean: -60.149908\n",
      "startIDX:  2501\n",
      "556 5 True\n",
      "x_t:  1 [0.09375    0.3625     0.1875     0.50416667]\n",
      "Q values:  tensor([[-5.1342, -5.6113, -5.0177, -5.0448, -4.9792, -4.2525]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22115 1080 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 556: ep_len:1080 episode reward: total was -142.300000. running mean: -60.971409\n",
      "startIDX:  266\n",
      "556 10 True\n",
      "x_t:  4 [0.278125   0.34583333 0.06875    0.24166667]\n",
      "Q values:  tensor([[-4.3828, -4.4953, -4.1457, -4.0275, -3.8736, -3.5075]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4726 514 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 556: ep_len:514 episode reward: total was -131.600000. running mean: -61.677695\n",
      "startIDX:  443\n",
      "556 12 True\n",
      "x_t:  1 [0.303125   0.37083333 0.153125   0.49583333]\n",
      "Q values:  tensor([[-5.7897, -5.8254, -5.4554, -4.9180, -5.4432, -4.4641]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10325 1556 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 556: ep_len:1556 episode reward: total was -238.400000. running mean: -63.444918\n",
      "startIDX:  846\n",
      "556 15 True\n",
      "x_t:  3 [0.071875   0.2375     0.05625    0.23333333]\n",
      "Q values:  tensor([[-5.0563, -4.9708, -5.2000, -5.0311, -5.0597, -4.1834]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8501 1246 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 556: ep_len:1246 episode reward: total was -53.500000. running mean: -63.345469\n",
      "startIDX:  555\n",
      "556 22 True\n",
      "x_t:  3 [0.884375   0.34166667 0.109375   0.40416667]\n",
      "Q values:  tensor([[-4.2010, -4.1882, -4.1118, -4.3521, -3.7690, -3.4176]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7052 216 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 556: ep_len:216 episode reward: total was -25.500000. running mean: -62.967014\n",
      "startIDX:  1867\n",
      "557 0 True\n",
      "x_t:  1 [0.678125   0.30416667 0.140625   0.37083333]\n",
      "Q values:  tensor([[-3.4823, -4.0228, -3.5888, -3.4308, -3.8938, -2.9205]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18997 297 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  623\n",
      "557 1 True\n",
      "x_t:  2 [0.8125     0.38333333 0.1125     0.30833333]\n",
      "Q values:  tensor([[-4.4835, -3.9501, -3.6312, -4.0175, -3.7540, -3.2477]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31459 380 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2965\n",
      "startIDX:  103\n",
      "557 10 True\n",
      "x_t:  3 [0.265625   0.27083333 0.08125    0.32083333]\n",
      "Q values:  tensor([[-6.3847, -6.2977, -6.7118, -6.1912, -6.4829, -5.0592]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3640 1097 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  731\n",
      "557 12 True\n",
      "x_t:  1 [0.215625   0.38333333 0.2375     0.4875    ]\n",
      "Q values:  tensor([[-3.9796, -4.1306, -4.1037, -3.7684, -4.0077, -3.1748]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10320 210 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2715\n",
      "557 15 True\n",
      "x_t:  0 [0.775  0.4125 0.0875 0.35  ]\n",
      "Q values:  tensor([[-9.1880, -9.2787, -9.9831, -9.5010, -8.6935, -7.6740]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23090 1657 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1137\n",
      "557 22 True\n",
      "x_t:  2 [0.8        0.4        0.08125    0.26666667]\n",
      "Q values:  tensor([[-5.7620, -6.1829, -5.5674, -5.7354, -6.2385, -5.0030]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12587 1053 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2154\n",
      "558 0 True\n",
      "x_t:  2 [0.73125 0.4125  0.08125 0.2375 ]\n",
      "Q values:  tensor([[-7.9386, -8.2460, -8.6319, -7.5832, -8.1899, -6.6359]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23601 1460 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 558: ep_len:1460 episode reward: total was -92.700000. running mean: -62.513665\n",
      "startIDX:  589\n",
      "558 1 True\n",
      "x_t:  2 [0.140625   0.3875     0.1125     0.30833333]\n",
      "Q values:  tensor([[-4.8387, -4.7535, -4.6426, -4.4864, -4.9552, -4.0805]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31569 446 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 558: ep_len:446 episode reward: total was -104.700000. running mean: -62.935529\n",
      "startIDX:  469\n",
      "558 5 True\n",
      "x_t:  1 [0.75       0.28333333 0.0875     0.36666667]\n",
      "Q values:  tensor([[-5.8035, -5.5427, -5.5944, -5.1959, -5.5097, -4.7571]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5044 657 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 558: ep_len:657 episode reward: total was -36.900000. running mean: -62.675173\n",
      "startIDX:  1250\n",
      "558 10 True\n",
      "x_t:  3 [0.0625     0.22083333 0.059375   0.24166667]\n",
      "Q values:  tensor([[-6.6203, -6.7659, -6.7599, -6.0432, -6.5329, -5.3457]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14573 1222 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 558: ep_len:1222 episode reward: total was -60.400000. running mean: -62.652422\n",
      "startIDX:  1961\n",
      "ep 558: ep_len:68 episode reward: total was -19.200000. running mean: -62.217897\n",
      "startIDX:  783\n",
      "558 15 True\n",
      "x_t:  2 [0.13125 0.4125  0.09375 0.3    ]\n",
      "Q values:  tensor([[-4.9950, -4.9704, -5.1441, -4.7723, -5.1777, -4.2794]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6065 399 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 558: ep_len:399 episode reward: total was -72.500000. running mean: -62.320719\n",
      "startIDX:  2100\n",
      "558 22 True\n",
      "x_t:  0 [0.846875   0.39583333 0.084375   0.34166667]\n",
      "Q values:  tensor([[-6.2426, -6.7721, -6.8856, -5.8025, -6.2908, -5.3894]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20706 870 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 558: ep_len:870 episode reward: total was -84.500000. running mean: -62.542511\n",
      "startIDX:  1994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559 0 True\n",
      "x_t:  1 [0.1375     0.35833333 0.14375    0.4125    ]\n",
      "Q values:  tensor([[-4.9713, -4.4271, -4.7543, -4.2935, -5.1728, -3.8771]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18936 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  23\n",
      "559 1 True\n",
      "x_t:  3 [0.2125     0.23333333 0.08125    0.30416667]\n",
      "Q values:  tensor([[-5.0716, -5.1416, -5.1121, -4.9976, -6.0095, -4.2187]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25748 234 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2689\n",
      "559 5 True\n",
      "x_t:  1 [0.36875    0.32916667 0.159375   0.52083333]\n",
      "Q values:  tensor([[-4.7462, -4.8918, -4.7384, -4.7078, -4.9082, -3.7371]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22136 245 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2556\n",
      "startIDX:  1185\n",
      "559 12 True\n",
      "x_t:  3 [0.134375   0.2625     0.084375   0.26666667]\n",
      "Q values:  tensor([[-4.8689, -4.6766, -4.3974, -4.5214, -5.0386, -3.8010]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17972 804 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  57\n",
      "559 15 True\n",
      "x_t:  3 [0.840625   0.35833333 0.15625    0.43333333]\n",
      "Q values:  tensor([[-4.3659, -4.5824, -4.3642, -4.3933, -4.3854, -3.5073]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 520 228 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2158\n",
      "559 22 True\n",
      "x_t:  0 [0.675      0.40833333 0.059375   0.31666667]\n",
      "Q values:  tensor([[-4.3865, -5.0852, -4.8176, -4.5153, -4.6248, -3.6488]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20768 865 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  4993.267379045486\n",
      "startIDX:  1516\n",
      "560 0 True\n",
      "x_t:  3 [0.878125   0.34166667 0.115625   0.43333333]\n",
      "Q values:  tensor([[-4.7947, -4.6557, -4.5906, -4.5066, -4.8187, -3.6238]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16811 233 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 560: ep_len:233 episode reward: total was -20.800000. running mean: -60.890851\n",
      "startIDX:  566\n",
      "560 1 True\n",
      "x_t:  1 [0.765625   0.275      0.15625    0.45416667]\n",
      "Q values:  tensor([[-3.7115, -3.6064, -3.7614, -3.5043, -3.6928, -3.0592]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30689 727 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 560: ep_len:727 episode reward: total was -45.400000. running mean: -60.735942\n",
      "startIDX:  1521\n",
      "560 5 True\n",
      "x_t:  0 [0.234375   0.40833333 0.08125    0.31666667]\n",
      "Q values:  tensor([[-4.8253, -4.0075, -4.9145, -4.3584, -4.6407, -3.5274]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13654 509 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 560: ep_len:509 episode reward: total was -96.700000. running mean: -61.095583\n",
      "startIDX:  549\n",
      "560 10 True\n",
      "x_t:  2 [0.39375 0.4     0.05    0.25   ]\n",
      "Q values:  tensor([[-4.6405, -4.1774, -4.3113, -3.9514, -4.4016, -3.2816]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6646 790 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 560: ep_len:790 episode reward: total was -23.400000. running mean: -60.718627\n",
      "startIDX:  1879\n",
      "560 12 True\n",
      "x_t:  0 [0.421875   0.41666667 0.109375   0.37083333]\n",
      "Q values:  tensor([[-4.7743, -5.2918, -4.7712, -4.8340, -5.3498, -4.1447]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23020 949 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 560: ep_len:949 episode reward: total was -65.700000. running mean: -60.768441\n",
      "startIDX:  1839\n",
      "560 15 True\n",
      "x_t:  0 [0.83125    0.40416667 0.1        0.3375    ]\n",
      "Q values:  tensor([[-4.1720, -3.9820, -3.8795, -3.9927, -4.0047, -3.3339]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13375 415 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 560: ep_len:415 episode reward: total was -21.400000. running mean: -60.374756\n",
      "startIDX:  709\n",
      "560 22 True\n",
      "x_t:  2 [0.3875     0.40833333 0.096875   0.2625    ]\n",
      "Q values:  tensor([[-4.2656, -4.7464, -5.6499, -4.9770, -5.0343, -3.9903]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8979 908 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 560: ep_len:908 episode reward: total was -47.300000. running mean: -60.244009\n",
      "startIDX:  909\n",
      "561 0 True\n",
      "x_t:  1 [0.36875    0.34166667 0.171875   0.47916667]\n",
      "Q values:  tensor([[-6.1647, -6.0758, -6.3814, -5.8106, -5.8702, -4.9842]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11995 1270 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  348\n",
      "561 1 True\n",
      "x_t:  1 [0.734375 0.2875   0.15625  0.45    ]\n",
      "Q values:  tensor([[-7.2104, -6.4283, -6.2434, -7.4466, -7.9880, -5.7740]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30695 1623 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1751\n",
      "561 5 True\n",
      "x_t:  1 [0.81875    0.28333333 0.084375   0.31666667]\n",
      "Q values:  tensor([[-5.3803, -5.4044, -5.2574, -5.1761, -5.3518, -4.2545]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14932 585 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2366\n",
      "561 10 True\n",
      "x_t:  1 [0.540625 0.3      0.096875 0.325   ]\n",
      "Q values:  tensor([[-5.7559, -5.8523, -5.7559, -5.8860, -5.6413, -4.5771]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22507 1240 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1578\n",
      "561 12 True\n",
      "x_t:  2 [0.065625   0.40833333 0.0875     0.29583333]\n",
      "Q values:  tensor([[-5.8867, -5.7068, -6.1457, -5.6160, -5.4617, -4.9249]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19388 736 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2072\n",
      "561 15 True\n",
      "x_t:  2 [0.759375   0.40833333 0.05625    0.26666667]\n",
      "Q values:  tensor([[-4.9943, -4.6975, -4.7282, -3.9971, -4.6750, -3.7978]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15574 371 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1614\n",
      "561 22 True\n",
      "x_t:  3 [0.528125   0.3125     0.115625   0.34166667]\n",
      "Q values:  tensor([[-5.6135, -5.2321, -5.6609, -5.2291, -5.7902, -4.3981]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16892 268 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  435\n",
      "562 0 True\n",
      "x_t:  3 [0.759375   0.375      0.109375   0.44583333]\n",
      "Q values:  tensor([[-5.9290, -6.0974, -5.8910, -6.3569, -6.3427, -4.8534]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7000 1069 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 562: ep_len:1069 episode reward: total was -19.200000. running mean: -61.044250\n",
      "startIDX:  58\n",
      "562 1 False\n",
      "x_t:  3 [0.315625   0.24583333 0.0875     0.325     ]\n",
      "Q values:  tensor([[0.9652, 1.6589, 1.5693, 3.2877, 0.2766, 1.4458]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 25722 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 562: ep_len:200 episode reward: total was 14.800000. running mean: -60.285808\n",
      "startIDX:  1637\n",
      "562 5 True\n",
      "x_t:  1 [0.728125   0.29166667 0.109375   0.29583333]\n",
      "Q values:  tensor([[-4.6002, -4.8385, -5.0448, -4.7337, -4.9078, -3.9673]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14941 653 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 562: ep_len:653 episode reward: total was -80.200000. running mean: -60.484949\n",
      "startIDX:  1314\n",
      "562 10 True\n",
      "x_t:  4 [0.18125    0.35833333 0.1        0.26666667]\n",
      "Q values:  tensor([[-3.8172, -3.8389, -3.5528, -3.6030, -4.0014, -3.1450]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15734 568 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 562: ep_len:568 episode reward: total was 21.300000. running mean: -59.667100\n",
      "startIDX:  1848\n",
      "ep 562: ep_len:1012 episode reward: total was -116.300000. running mean: -60.233429\n",
      "startIDX:  97\n",
      "562 15 True\n",
      "x_t:  3 [0.403125 0.3      0.08125  0.3375  ]\n",
      "Q values:  tensor([[-4.3664, -4.5720, -4.4143, -4.0521, -4.6586, -3.5805]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 591 236 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 562: ep_len:236 episode reward: total was -51.800000. running mean: -60.149095\n",
      "startIDX:  2362\n",
      "562 22 True\n",
      "x_t:  1 [0.79375    0.30416667 0.1        0.4625    ]\n",
      "Q values:  tensor([[-4.9263, -5.4244, -5.1979, -4.7941, -4.9993, -4.1401]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22940 1036 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 562: ep_len:1036 episode reward: total was -52.900000. running mean: -60.076604\n",
      "startIDX:  221\n",
      "563 0 True\n",
      "x_t:  3 [0.815625   0.39166667 0.16875    0.42916667]\n",
      "Q values:  tensor([[-8.7662, -7.9421, -7.9998, -8.1456, -7.6176, -6.4957]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 6994 2695 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1054\n",
      "563 1 True\n",
      "x_t:  3 [0.753125   0.29166667 0.103125   0.40833333]\n",
      "Q values:  tensor([[-4.4682, -4.5699, -4.5594, -4.1292, -4.2646, -3.5520]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35916 214 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3067\n",
      "startIDX:  584\n",
      "563 10 True\n",
      "x_t:  2 [0.509375   0.39583333 0.09375    0.2625    ]\n",
      "Q values:  tensor([[-4.1016, -4.1821, -4.1276, -4.0038, -3.9719, -3.2076]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6669 765 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1586\n",
      "563 12 True\n",
      "x_t:  1 [0.096875   0.35833333 0.0875     0.36666667]\n",
      "Q values:  tensor([[-3.6566, -3.6780, -3.6688, -3.7084, -3.7785, -3.0712]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19880 967 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  1893\n",
      "563 15 True\n",
      "x_t:  1 [0.753125   0.30416667 0.071875   0.30416667]\n",
      "Q values:  tensor([[-3.7888, -4.0992, -3.7821, -4.1287, -3.8708, -3.2363]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14860 722 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1303\n",
      "563 22 True\n",
      "x_t:  3 [0.096875   0.25833333 0.084375   0.27916667]\n",
      "Q values:  tensor([[-3.8594, -3.7364, -3.8664, -3.6116, -3.8436, -3.1896]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15210 1300 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1964\n",
      "564 0 True\n",
      "x_t:  1 [0.003125 0.375    0.146875 0.4125  ]\n",
      "Q values:  tensor([[-3.6375, -4.1333, -3.9231, -3.8853, -4.0149, -3.1938]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18923 209 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 564: ep_len:209 episode reward: total was -16.300000. running mean: -61.731404\n",
      "startIDX:  840\n",
      "564 1 True\n",
      "x_t:  4 [0.365625   0.37083333 0.096875   0.40833333]\n",
      "Q values:  tensor([[-3.5566, -3.8015, -3.5100, -3.8508, -3.5606, -3.0190]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35479 576 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 564: ep_len:576 episode reward: total was -0.600000. running mean: -61.120090\n",
      "startIDX:  2634\n",
      "564 5 True\n",
      "x_t:  1 [0.01875  0.35     0.128125 0.525   ]\n",
      "Q values:  tensor([[-4.2834, -4.2542, -4.0858, -3.9323, -4.1251, -3.3035]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22107 271 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 564: ep_len:271 episode reward: total was -0.000000. running mean: -60.508889\n",
      "startIDX:  1910\n",
      "564 10 True\n",
      "x_t:  1 [0.53125    0.29583333 0.084375   0.32916667]\n",
      "Q values:  tensor([[-3.3470, -3.2908, -3.6725, -3.1534, -3.4453, -2.7795]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18885 1154 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 564: ep_len:1154 episode reward: total was -145.100000. running mean: -61.354801\n",
      "startIDX:  404\n",
      "564 12 True\n",
      "x_t:  2 [0.246875   0.41666667 0.096875   0.24583333]\n",
      "Q values:  tensor([[-3.5380, -3.2407, -3.5703, -3.5260, -3.2531, -2.6981]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9866 1319 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 564: ep_len:1319 episode reward: total was -138.400000. running mean: -62.125253\n",
      "startIDX:  1483\n",
      "564 15 True\n",
      "x_t:  1 [0.91875    0.2875     0.078125   0.37083333]\n",
      "Q values:  tensor([[-2.8307, -3.1362, -2.9115, -3.1346, -3.0372, -2.4638]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12550 1101 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 564: ep_len:1101 episode reward: total was -99.600000. running mean: -62.500000\n",
      "startIDX:  1845\n",
      "564 22 True\n",
      "x_t:  2 [0.378125   0.40833333 0.078125   0.2625    ]\n",
      "Q values:  tensor([[-3.7940, -3.8394, -3.9932, -3.9755, -3.9142, -3.0919]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18511 810 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 564: ep_len:810 episode reward: total was -22.300000. running mean: -62.098000\n",
      "startIDX:  2395\n",
      "startIDX:  447\n",
      "565 1 True\n",
      "x_t:  2 [0.65       0.3875     0.115625   0.30833333]\n",
      "Q values:  tensor([[-3.9696, -4.3183, -4.2144, -3.6252, -3.8501, -3.0769]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31487 1191 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  552\n",
      "565 5 True\n",
      "x_t:  2 [0.821875   0.375      0.1        0.28333333]\n",
      "Q values:  tensor([[-3.8180, -3.8689, -3.8278, -3.7661, -3.8159, -3.1073]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6034 466 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  256\n",
      "565 10 True\n",
      "x_t:  4 [0.4875     0.33333333 0.0625     0.23333333]\n",
      "Q values:  tensor([[-4.0484, -3.5994, -3.7390, -3.4885, -4.0166, -3.2043]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4667 488 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  738\n",
      "565 12 True\n",
      "x_t:  0 [0.596875   0.42083333 0.090625   0.30833333]\n",
      "Q values:  tensor([[-4.5979, -4.3894, -4.9199, -4.6408, -4.4798, -3.7134]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11685 876 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2612\n",
      "565 15 True\n",
      "x_t:  2 [0.284375   0.40833333 0.109375   0.32916667]\n",
      "Q values:  tensor([[-5.6508, -5.3444, -5.3156, -5.1105, -5.5379, -4.2551]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21512 926 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  962\n",
      "565 22 True\n",
      "x_t:  0 [0.58125    0.40833333 0.0625     0.30833333]\n",
      "Q values:  tensor([[-4.6148, -4.7552, -4.3676, -4.6602, -4.9339, -3.8286]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10464 492 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  860\n",
      "566 0 True\n",
      "x_t:  0 [0.63125    0.40833333 0.075      0.35      ]\n",
      "Q values:  tensor([[-6.2170, -6.0304, -6.0388, -5.7548, -5.9986, -4.7695]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10395 492 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 566: ep_len:492 episode reward: total was -91.300000. running mean: -63.091632\n",
      "startIDX:  13\n",
      "566 1 True\n",
      "x_t:  3 [0.375      0.25416667 0.1        0.34166667]\n",
      "Q values:  tensor([[-4.9742, -4.9472, -5.0643, -4.3824, -4.6343, -3.9339]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25709 213 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 566: ep_len:213 episode reward: total was -11.800000. running mean: -62.578716\n",
      "startIDX:  1350\n",
      "566 5 True\n",
      "x_t:  1 [0.046875   0.34583333 0.15       0.40416667]\n",
      "Q values:  tensor([[-4.8889, -5.3073, -5.5398, -4.9554, -5.2076, -4.1422]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12512 250 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 566: ep_len:250 episode reward: total was 19.200000. running mean: -61.760929\n",
      "startIDX:  1642\n",
      "566 10 True\n",
      "x_t:  3 [0.140625   0.2375     0.078125   0.27916667]\n",
      "Q values:  tensor([[-5.6658, -5.7818, -6.0170, -5.4540, -5.6955, -4.7278]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16535 341 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 566: ep_len:341 episode reward: total was -51.300000. running mean: -61.656320\n",
      "startIDX:  157\n",
      "566 12 True\n",
      "x_t:  2 [0.321875   0.40833333 0.084375   0.25      ]\n",
      "Q values:  tensor([[-5.2779, -5.4292, -5.4680, -4.8484, -5.2010, -4.0793]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2882 323 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 566: ep_len:323 episode reward: total was -35.000000. running mean: -61.389756\n",
      "startIDX:  2197\n",
      "566 15 True\n",
      "x_t:  4 [0.259375   0.37083333 0.06875    0.25833333]\n",
      "Q values:  tensor([[-10.5538, -10.4132, -11.0734, -10.0637, -10.5273,  -8.7362]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19312 1867 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 566: ep_len:1867 episode reward: total was -143.000000. running mean: -62.205859\n",
      "startIDX:  2527\n",
      "566 22 True\n",
      "x_t:  3 [0.10625    0.24583333 0.059375   0.25      ]\n",
      "Q values:  tensor([[-8.4343, -9.0791, -8.7719, -8.1114, -8.8660, -7.0156]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26186 1266 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 566: ep_len:1266 episode reward: total was -45.300000. running mean: -62.036800\n",
      "startIDX:  632\n",
      "567 0 True\n",
      "x_t:  2 [0.203125   0.40833333 0.115625   0.26666667]\n",
      "Q values:  tensor([[-5.3099, -5.0618, -4.6539, -5.2140, -5.4328, -4.6363]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8901 915 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  322\n",
      "567 1 True\n",
      "x_t:  0 [0.49375    0.375      0.115625   0.44583333]\n",
      "Q values:  tensor([[-7.6836, -7.0745, -6.6725, -7.0729, -6.9994, -6.0573]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29172 827 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2503\n",
      "567 5 True\n",
      "x_t:  2 [0.003125   0.40416667 0.071875   0.25416667]\n",
      "Q values:  tensor([[-5.9787, -6.6278, -7.1690, -6.8607, -6.6088, -5.4280]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21544 796 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2286\n",
      "567 10 True\n",
      "x_t:  1 [0.884375   0.2875     0.1125     0.33333333]\n",
      "Q values:  tensor([[-7.9749, -7.7692, -7.3256, -7.8990, -7.9468, -6.4202]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22468 1260 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1373\n",
      "567 12 True\n",
      "x_t:  0 [0.259375   0.42083333 0.090625   0.27083333]\n",
      "Q values:  tensor([[-8.2837, -8.5225, -8.1589, -7.9364, -8.5808, -6.9231]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21172 1868 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  997\n",
      "567 15 True\n",
      "x_t:  4 [0.003125   0.39583333 0.084375   0.29166667]\n",
      "Q values:  tensor([[-5.5022, -4.7889, -5.3541, -5.1222, -5.5090, -4.3564]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9810 625 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1861\n",
      "567 22 True\n",
      "x_t:  2 [0.428125   0.40416667 0.071875   0.26666667]\n",
      "Q values:  tensor([[-5.7148, -5.8908, -5.4532, -5.9577, -5.8888, -4.6377]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18516 792 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  644\n",
      "568 0 True\n",
      "x_t:  1 [0.225  0.35   0.1375 0.4   ]\n",
      "Q values:  tensor([[-7.5990, -7.1820, -7.1908, -6.5287, -7.7196, -5.9260]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9433 1176 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 568: ep_len:1176 episode reward: total was -104.200000. running mean: -63.279089\n",
      "startIDX:  461\n",
      "568 1 True\n",
      "x_t:  1 [0.590625   0.28333333 0.084375   0.47083333]\n",
      "Q values:  tensor([[-5.6443, -4.9391, -5.4194, -5.2418, -5.4240, -4.5611]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30713 775 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 568: ep_len:775 episode reward: total was -56.200000. running mean: -63.208298\n",
      "startIDX:  2388\n",
      "568 5 True\n",
      "x_t:  2 [0.0875   0.3875   0.065625 0.275   ]\n",
      "Q values:  tensor([[-6.1770, -6.0270, -6.1595, -5.5469, -6.0767, -4.9002]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21560 952 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 568: ep_len:952 episode reward: total was -41.000000. running mean: -62.986215\n",
      "startIDX:  1349\n",
      "568 10 True\n",
      "x_t:  4 [0.103125   0.37083333 0.1        0.27083333]\n",
      "Q values:  tensor([[-5.3127, -5.1918, -5.3422, -5.1789, -5.0686, -4.2740]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15720 564 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 568: ep_len:564 episode reward: total was -7.500000. running mean: -62.431353\n",
      "startIDX:  663\n",
      "568 12 True\n",
      "x_t:  1 [0.378125 0.35     0.1125   0.525   ]\n",
      "Q values:  tensor([[-4.5520, -4.9031, -4.4571, -4.5264, -4.5311, -3.6315]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10328 245 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 568: ep_len:245 episode reward: total was 22.300000. running mean: -61.584039\n",
      "startIDX:  2523\n",
      "568 15 False\n",
      "x_t:  3 [0.428125   0.27916667 0.078125   0.3       ]\n",
      "Q values:  tensor([[3.2239, 3.4153, 3.8304, 6.9338, 3.5982, 2.5510]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 19737 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 568: ep_len:200 episode reward: total was -14.000000. running mean: -61.108199\n",
      "startIDX:  1979\n",
      "568 22 True\n",
      "x_t:  1 [0.546875   0.32083333 0.1375     0.35833333]\n",
      "Q values:  tensor([[-4.6595, -4.5202, -4.3813, -4.1531, -4.5718, -3.6266]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19051 295 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 568: ep_len:295 episode reward: total was -0.900000. running mean: -60.506117\n",
      "startIDX:  378\n",
      "569 0 True\n",
      "x_t:  3 [0.203125   0.25416667 0.075      0.26666667]\n",
      "Q values:  tensor([[-6.7441, -6.5778, -7.1736, -6.3803, -6.5538, -5.4422]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4884 1215 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  552\n",
      "569 1 True\n",
      "x_t:  1 [0.8625  0.2625  0.10625 0.4625 ]\n",
      "Q values:  tensor([[-4.5845, -4.7427, -4.7160, -4.2430, -4.6472, -3.6895]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30683 728 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  331\n",
      "569 5 True\n",
      "x_t:  1 [0.8625     0.28333333 0.121875   0.39166667]\n",
      "Q values:  tensor([[-4.5252, -4.1911, -4.4345, -3.9294, -4.0631, -3.4987]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5029 754 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1522\n",
      "569 10 True\n",
      "x_t:  2 [0.26875    0.39583333 0.04375    0.25      ]\n",
      "Q values:  tensor([[-4.9481, -5.2627, -4.8870, -4.6517, -4.9462, -4.2833]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18189 1206 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  932\n",
      "569 12 True\n",
      "x_t:  1 [0.321875   0.375      0.11875    0.49166667]\n",
      "Q values:  tensor([[-4.1409, -4.1582, -4.2909, -3.7530, -4.2641, -3.2975]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12944 610 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2164\n",
      "569 15 True\n",
      "x_t:  4 [0.190625   0.39583333 0.08125    0.325     ]\n",
      "Q values:  tensor([[-7.3356, -7.6937, -7.6147, -7.9314, -7.7500, -6.2992]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19279 2148 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1652\n",
      "569 22 True\n",
      "x_t:  3 [0.528125   0.3125     0.115625   0.34166667]\n",
      "Q values:  tensor([[-3.1577, -3.2115, -3.3011, -3.4020, -3.3690, -2.7134]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16892 246 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  5108.669846773148\n",
      "startIDX:  266\n",
      "570 0 True\n",
      "x_t:  3 [0.0625 0.2375 0.0625 0.225 ]\n",
      "Q values:  tensor([[-5.0220, -4.9605, -4.9036, -4.6686, -5.1658, -3.8350]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4831 1237 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 570: ep_len:1237 episode reward: total was -28.500000. running mean: -61.363966\n",
      "startIDX:  1048\n",
      "ep 570: ep_len:244 episode reward: total was -44.200000. running mean: -61.192327\n",
      "startIDX:  2320\n",
      "570 5 False\n",
      "x_t:  3 [0.246875   0.26666667 0.1        0.31666667]\n",
      "Q values:  tensor([[1.7511, 2.9496, 2.9917, 5.8237, 3.2038, 2.7701]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 19969 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 570: ep_len:201 episode reward: total was -3.900000. running mean: -60.619403\n",
      "startIDX:  523\n",
      "570 10 True\n",
      "x_t:  2 [0.059375 0.4      0.059375 0.25    ]\n",
      "Q values:  tensor([[-4.5655, -4.4544, -4.0533, -4.6613, -4.5472, -3.6148]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6594 783 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 570: ep_len:783 episode reward: total was 15.500000. running mean: -59.858209\n",
      "startIDX:  1260\n",
      "570 12 True\n",
      "x_t:  4 [0.3375  0.3625  0.06875 0.2375 ]\n",
      "Q values:  tensor([[-3.5674, -3.5456, -3.0185, -3.3266, -3.2977, -2.6588]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17497 530 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 570: ep_len:530 episode reward: total was -67.300000. running mean: -59.932627\n",
      "startIDX:  1643\n",
      "570 15 True\n",
      "x_t:  1 [0.28125    0.33333333 0.1125     0.37916667]\n",
      "Q values:  tensor([[-3.9159, -4.2584, -4.1253, -4.1000, -4.1850, -3.3517]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12478 277 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 570: ep_len:277 episode reward: total was 12.200000. running mean: -59.211301\n",
      "startIDX:  1895\n",
      "570 22 True\n",
      "x_t:  2 [0.415625   0.40416667 0.05       0.2625    ]\n",
      "Q values:  tensor([[-3.4986, -3.8648, -3.7043, -3.5854, -3.8426, -2.9215]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18514 785 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 570: ep_len:785 episode reward: total was -49.000000. running mean: -59.109188\n",
      "startIDX:  2069\n",
      "571 0 True\n",
      "x_t:  0 [0.671875   0.40833333 0.08125    0.35833333]\n",
      "Q values:  tensor([[-3.9123, -4.2605, -3.9231, -3.7237, -3.9375, -3.3004]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20687 857 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  317\n",
      "571 1 True\n",
      "x_t:  1 [0.53125    0.30833333 0.246875   0.56666667]\n",
      "Q values:  tensor([[-3.2850, -3.6056, -3.1831, -3.4149, -3.8561, -2.7290]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28101 326 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1952\n",
      "571 5 True\n",
      "x_t:  4 [0.34375    0.39166667 0.075      0.425     ]\n",
      "Q values:  tensor([[-7.8627, -7.8285, -8.1056, -7.0034, -8.3964, -6.0679]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19493 1894 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2569\n",
      "startIDX:  706\n",
      "571 12 True\n",
      "x_t:  0 [0.640625   0.40416667 0.084375   0.37916667]\n",
      "Q values:  tensor([[-4.8545, -4.3372, -4.1972, -4.2399, -4.3849, -3.4918]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11711 908 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2916\n",
      "571 15 True\n",
      "x_t:  0 [0.69375    0.40833333 0.1125     0.36666667]\n",
      "Q values:  tensor([[-3.7106, -3.8095, -3.6366, -3.3601, -3.8158, -3.0564]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23098 505 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1583\n",
      "571 22 True\n",
      "x_t:  3 [0.265625   0.275      0.09375    0.30416667]\n",
      "Q values:  tensor([[-3.8901, -4.0671, -4.1185, -3.7952, -4.0486, -2.9895]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16943 311 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  33\n",
      "572 0 True\n",
      "x_t:  2 [0.796875   0.40833333 0.09375    0.28333333]\n",
      "Q values:  tensor([[-4.1445, -4.1313, -3.9667, -3.5905, -4.1505, -3.1695]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2321 1105 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 572: ep_len:1105 episode reward: total was -51.600000. running mean: -59.332965\n",
      "startIDX:  967\n",
      "572 1 True\n",
      "x_t:  4 [0.18125    0.37916667 0.125      0.40833333]\n",
      "Q values:  tensor([[-3.5081, -3.7128, -3.4204, -4.1454, -3.6455, -3.0756]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35447 490 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 572: ep_len:490 episode reward: total was -34.100000. running mean: -59.080635\n",
      "startIDX:  510\n",
      "572 5 True\n",
      "x_t:  2 [0.2875     0.39166667 0.11875    0.3       ]\n",
      "Q values:  tensor([[-4.3385, -4.4828, -4.4693, -4.3740, -4.4932, -3.4703]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6107 550 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 572: ep_len:550 episode reward: total was -117.600000. running mean: -59.665829\n",
      "startIDX:  1485\n",
      "572 10 True\n",
      "x_t:  3 [0.803125   0.30416667 0.090625   0.40416667]\n",
      "Q values:  tensor([[-4.6553, -4.3973, -4.4153, -4.5311, -4.5969, -3.5314]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16411 336 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 572: ep_len:336 episode reward: total was -18.800000. running mean: -59.257171\n",
      "startIDX:  1345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572 12 True\n",
      "x_t:  3 [0.134375   0.2625     0.084375   0.26666667]\n",
      "Q values:  tensor([[-3.8960, -3.8705, -3.9524, -3.9696, -4.0682, -3.2682]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17972 268 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 572: ep_len:268 episode reward: total was -93.800000. running mean: -59.602599\n",
      "startIDX:  787\n",
      "572 15 True\n",
      "x_t:  2 [0.79375 0.4125  0.08125 0.2875 ]\n",
      "Q values:  tensor([[-4.4690, -4.8105, -4.4052, -4.4689, -4.6243, -3.5958]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5967 345 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 572: ep_len:345 episode reward: total was -25.100000. running mean: -59.257573\n",
      "startIDX:  2161\n",
      "572 22 True\n",
      "x_t:  0 [0.940625   0.39583333 0.05625    0.34583333]\n",
      "Q values:  tensor([[-4.7939, -4.3662, -4.3465, -5.1838, -5.2533, -3.9374]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20684 825 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 572: ep_len:825 episode reward: total was -44.400000. running mean: -59.108997\n",
      "startIDX:  1006\n",
      "573 0 True\n",
      "x_t:  2 [0.446875   0.40416667 0.075      0.30416667]\n",
      "Q values:  tensor([[-6.5777, -5.6577, -6.3439, -6.4181, -5.9982, -5.1579]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12683 1148 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  442\n",
      "573 1 True\n",
      "x_t:  2 [0.553125   0.3875     0.10625    0.30833333]\n",
      "Q values:  tensor([[-7.1719, -7.0229, -6.5713, -6.7521, -7.4291, -5.4795]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31503 1190 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  698\n",
      "573 5 True\n",
      "x_t:  3 [0.171875   0.27083333 0.096875   0.3375    ]\n",
      "Q values:  tensor([[-7.6234, -7.4441, -7.3400, -7.3811, -7.6672, -5.8638]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8780 1340 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2405\n",
      "573 10 True\n",
      "x_t:  1 [0.515625   0.3        0.071875   0.33333333]\n",
      "Q values:  tensor([[-6.6331, -6.5961, -5.9740, -6.1486, -7.0827, -5.3323]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22511 1211 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2001\n",
      "startIDX:  2137\n",
      "573 15 True\n",
      "x_t:  2 [0.859375   0.39166667 0.090625   0.25833333]\n",
      "Q values:  tensor([[-4.5681, -4.8190, -4.8560, -5.0276, -4.9147, -3.8742]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15558 338 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1414\n",
      "573 22 True\n",
      "x_t:  3 [0.509375   0.30416667 0.096875   0.375     ]\n",
      "Q values:  tensor([[-6.8255, -5.9750, -6.3059, -6.6094, -6.2107, -5.2516]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15294 1301 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1609\n",
      "574 0 True\n",
      "x_t:  3 [0.8        0.34583333 0.1875     0.41666667]\n",
      "Q values:  tensor([[-4.5634, -4.8077, -4.6882, -4.2262, -4.6777, -3.7014]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16817 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 574: ep_len:200 episode reward: total was 11.900000. running mean: -59.459804\n",
      "startIDX:  419\n",
      "574 1 True\n",
      "x_t:  0 [0.759375   0.375      0.11875    0.39583333]\n",
      "Q values:  tensor([[-4.6801, -5.0116, -4.8319, -4.4573, -4.8595, -3.9406]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29111 508 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 574: ep_len:508 episode reward: total was -25.700000. running mean: -59.122206\n",
      "startIDX:  2176\n",
      "574 5 True\n",
      "x_t:  4 [0.0625     0.40833333 0.1125     0.42916667]\n",
      "Q values:  tensor([[-4.5626, -4.2663, -4.4059, -4.1842, -4.5503, -3.5932]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19471 606 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 574: ep_len:606 episode reward: total was -28.200000. running mean: -58.812984\n",
      "startIDX:  89\n",
      "574 10 True\n",
      "x_t:  3 [0.753125   0.325      0.125      0.39166667]\n",
      "Q values:  tensor([[-5.6102, -5.3966, -5.6060, -5.6450, -6.0071, -4.6111]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3703 1122 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 574: ep_len:1122 episode reward: total was -73.000000. running mean: -58.954854\n",
      "startIDX:  1359\n",
      "574 12 True\n",
      "x_t:  3 [0.796875   0.37083333 0.1875     0.425     ]\n",
      "Q values:  tensor([[-4.4126, -4.5793, -4.3255, -4.3326, -4.3344, -3.3798]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17848 211 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 574: ep_len:211 episode reward: total was 22.300000. running mean: -58.142305\n",
      "startIDX:  94\n",
      "574 15 True\n",
      "x_t:  3 [0.26875    0.28333333 0.0875     0.30833333]\n",
      "Q values:  tensor([[-3.9041, -4.3159, -4.1747, -4.3102, -4.2427, -3.3350]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 617 257 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 574: ep_len:257 episode reward: total was -59.600000. running mean: -58.156882\n",
      "startIDX:  1125\n",
      "574 22 True\n",
      "x_t:  2 [0.4625     0.40833333 0.0875     0.25833333]\n",
      "Q values:  tensor([[-5.4866, -5.2285, -5.2291, -5.3383, -5.6029, -4.5399]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12644 1080 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 574: ep_len:1080 episode reward: total was -72.800000. running mean: -58.303314\n",
      "startIDX:  868\n",
      "575 0 True\n",
      "x_t:  0 [0.6375     0.40416667 0.1        0.35416667]\n",
      "Q values:  tensor([[-5.2115, -5.3697, -5.0732, -4.9418, -5.5040, -3.8849]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10379 477 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1099\n",
      "startIDX:  1728\n",
      "575 5 True\n",
      "x_t:  1 [0.65       0.29583333 0.096875   0.29583333]\n",
      "Q values:  tensor([[-4.8791, -4.1905, -4.1561, -4.2999, -4.5438, -3.3896]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14954 612 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1123\n",
      "575 10 True\n",
      "x_t:  2 [0.7875     0.40416667 0.1        0.24166667]\n",
      "Q values:  tensor([[-4.3849, -4.3682, -4.3153, -4.4919, -4.4793, -3.5073]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12062 340 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1750\n",
      "575 12 True\n",
      "x_t:  0 [0.475      0.4125     0.11875    0.35416667]\n",
      "Q values:  tensor([[-5.5079, -5.2258, -5.4790, -4.9736, -5.3451, -4.3398]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21145 632 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2122\n",
      "575 15 True\n",
      "x_t:  2 [0.53125 0.4125  0.09375 0.25   ]\n",
      "Q values:  tensor([[-4.6184, -4.3934, -4.2530, -4.1410, -4.6815, -3.5358]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15607 354 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  251\n",
      "575 22 True\n",
      "x_t:  3 [0.10625    0.2375     0.065625   0.25833333]\n",
      "Q values:  tensor([[-8.3713, -7.5388, -7.4146, -7.6908, -7.7063, -6.0645]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4885 1281 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1695\n",
      "576 0 False\n",
      "x_t:  3 [0.16875    0.25416667 0.071875   0.275     ]\n",
      "Q values:  tensor([[2.5612, 2.9416, 4.0218, 5.1027, 2.7857, 3.7126]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 16930 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 576: ep_len:200 episode reward: total was -27.900000. running mean: -58.437178\n",
      "startIDX:  378\n",
      "576 1 True\n",
      "x_t:  0 [0.740625   0.37916667 0.1375     0.4       ]\n",
      "Q values:  tensor([[-5.5424, -5.5920, -5.0985, -5.3910, -5.4183, -4.0054]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29112 777 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 576: ep_len:777 episode reward: total was -29.700000. running mean: -58.149806\n",
      "startIDX:  1023\n",
      "576 5 False\n",
      "x_t:  3 [0.528125   0.29166667 0.078125   0.32916667]\n",
      "Q values:  tensor([[1.5954, 2.3179, 1.8132, 3.3831, 1.5945, 2.3377]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 10527 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 576: ep_len:200 episode reward: total was 53.100000. running mean: -57.037308\n",
      "startIDX:  487\n",
      "576 10 True\n",
      "x_t:  2 [0.115625   0.4        0.0875     0.26666667]\n",
      "Q values:  tensor([[-4.8569, -4.8069, -4.3928, -4.8014, -5.1793, -3.9886]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6604 919 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 576: ep_len:919 episode reward: total was -118.300000. running mean: -57.649935\n",
      "startIDX:  236\n",
      "576 12 True\n",
      "x_t:  3 [0.296875   0.27916667 0.0625     0.30416667]\n",
      "Q values:  tensor([[-6.9941, -6.9240, -6.7504, -6.4822, -7.1544, -5.5956]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5708 1399 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 576: ep_len:1399 episode reward: total was -69.700000. running mean: -57.770436\n",
      "startIDX:  776\n",
      "576 15 True\n",
      "x_t:  2 [0.003125   0.40833333 0.065625   0.30416667]\n",
      "Q values:  tensor([[-5.2284, -4.7825, -4.7689, -4.7906, -4.9673, -3.9151]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6085 424 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 576: ep_len:424 episode reward: total was -90.900000. running mean: -58.101732\n",
      "startIDX:  1034\n",
      "576 22 True\n",
      "x_t:  0 [0.565625   0.40416667 0.078125   0.34166667]\n",
      "Q values:  tensor([[-4.9096, -4.8634, -4.6909, -5.2403, -5.4975, -4.2402]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10490 457 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 576: ep_len:457 episode reward: total was -77.700000. running mean: -58.297714\n",
      "startIDX:  775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577 0 True\n",
      "x_t:  1 [0.003125   0.36666667 0.06875    0.4       ]\n",
      "Q values:  tensor([[-4.4371, -4.8951, -5.3579, -4.6268, -4.7154, -3.9647]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9403 237 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  591\n",
      "577 1 True\n",
      "x_t:  2 [0.746875   0.37916667 0.1        0.31666667]\n",
      "Q values:  tensor([[-3.9225, -3.8711, -3.8562, -3.7343, -3.9118, -3.1805]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31471 394 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1333\n",
      "577 5 True\n",
      "x_t:  1 [0.634375   0.3        0.13125    0.37916667]\n",
      "Q values:  tensor([[-3.9287, -3.9062, -3.8297, -3.8272, -4.1680, -3.0691]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12572 273 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1543\n",
      "577 10 True\n",
      "x_t:  3 [0.721875   0.29583333 0.071875   0.37916667]\n",
      "Q values:  tensor([[-4.4731, -4.5789, -5.1393, -4.5151, -4.6125, -3.7222]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16423 327 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  437\n",
      "577 12 True\n",
      "x_t:  3 [0.590625   0.325      0.134375   0.36666667]\n",
      "Q values:  tensor([[-4.9655, -5.0552, -5.3641, -4.3808, -5.3193, -3.9981]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7743 260 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2111\n",
      "577 15 True\n",
      "x_t:  2 [0.784375 0.4125   0.0875   0.2625  ]\n",
      "Q values:  tensor([[-4.2871, -4.1712, -4.3965, -3.9629, -4.3031, -3.4184]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15567 345 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2267\n",
      "577 22 True\n",
      "x_t:  2 [0.44375    0.40833333 0.084375   0.25416667]\n",
      "Q values:  tensor([[-7.3378, -7.1468, -7.5052, -6.8237, -7.2952, -5.6113]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23698 1481 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1649\n",
      "578 0 False\n",
      "x_t:  3 [0.43125    0.3125     0.1125     0.34583333]\n",
      "Q values:  tensor([[1.8110, 2.8130, 2.9429, 4.3573, 2.8164, 3.2636]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 16868 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 578: ep_len:201 episode reward: total was -23.800000. running mean: -56.686624\n",
      "startIDX:  787\n",
      "578 1 True\n",
      "x_t:  3 [0.896875   0.34166667 0.1        0.45833333]\n",
      "Q values:  tensor([[-7.1162, -7.5130, -7.3304, -7.4288, -7.7119, -6.0014]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34469 1456 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 578: ep_len:1456 episode reward: total was -128.400000. running mean: -57.403758\n",
      "startIDX:  2007\n",
      "578 5 True\n",
      "x_t:  3 [0.0625     0.25       0.084375   0.27083333]\n",
      "Q values:  tensor([[-6.4047, -5.7698, -5.7671, -5.3567, -6.0770, -4.7203]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18204 1243 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 578: ep_len:1243 episode reward: total was -28.700000. running mean: -57.116721\n",
      "startIDX:  1080\n",
      "578 10 True\n",
      "x_t:  2 [0.775      0.39583333 0.05625    0.25      ]\n",
      "Q values:  tensor([[-4.0219, -3.8618, -4.0637, -3.5007, -4.0222, -3.1779]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12068 358 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 578: ep_len:358 episode reward: total was -59.800000. running mean: -57.143553\n",
      "startIDX:  991\n",
      "578 12 True\n",
      "x_t:  2 [0.590625   0.4125     0.06875    0.24583333]\n",
      "Q values:  tensor([[-3.8197, -3.4721, -3.9192, -3.6667, -3.6325, -3.0729]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13608 329 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 578: ep_len:329 episode reward: total was -56.600000. running mean: -57.138118\n",
      "startIDX:  782\n",
      "578 15 True\n",
      "x_t:  2 [0.459375 0.4125   0.10625  0.3     ]\n",
      "Q values:  tensor([[-4.6102, -4.6651, -4.7941, -4.7169, -4.6375, -3.6819]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6019 372 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 578: ep_len:372 episode reward: total was -54.700000. running mean: -57.113737\n",
      "startIDX:  1440\n",
      "578 22 True\n",
      "x_t:  4 [0.009375   0.39166667 0.084375   0.3       ]\n",
      "Q values:  tensor([[-4.5420, -5.0934, -4.9357, -4.7528, -5.0450, -3.8023]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16325 558 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 578: ep_len:558 episode reward: total was 8.300000. running mean: -56.459599\n",
      "startIDX:  2073\n",
      "579 0 True\n",
      "x_t:  0 [0.840625   0.39583333 0.103125   0.35416667]\n",
      "Q values:  tensor([[-5.4904, -4.9130, -5.6812, -5.2353, -5.4012, -4.6429]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20639 824 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1016\n",
      "579 1 True\n",
      "x_t:  3 [0.715625   0.3        0.090625   0.39166667]\n",
      "Q values:  tensor([[-4.2827, -4.2975, -4.1141, -4.0095, -4.0917, -3.1770]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35921 227 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  496\n",
      "579 5 True\n",
      "x_t:  1 [0.75    0.2875  0.14375 0.375  ]\n",
      "Q values:  tensor([[-6.3090, -6.0164, -6.2191, -5.8210, -5.9431, -4.7353]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5041 638 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2618\n",
      "startIDX:  481\n",
      "579 12 True\n",
      "x_t:  3 [0.51875    0.31666667 0.109375   0.35416667]\n",
      "Q values:  tensor([[-4.0642, -4.1474, -4.6391, -4.1400, -4.4662, -3.5302]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7754 237 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1829\n",
      "579 15 True\n",
      "x_t:  0 [0.834375   0.4        0.146875   0.45833333]\n",
      "Q values:  tensor([[-5.4258, -5.7636, -5.4599, -5.0637, -5.5575, -4.5572]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13570 527 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1157\n",
      "579 22 True\n",
      "x_t:  3 [0.19375    0.2625     0.065625   0.29583333]\n",
      "Q values:  tensor([[-7.1542, -7.8308, -8.0318, -7.7533, -7.6198, -6.4760]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15231 2358 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  5199.842476844788\n",
      "startIDX:  1113\n",
      "580 0 True\n",
      "x_t:  2 [0.75       0.40833333 0.059375   0.27916667]\n",
      "Q values:  tensor([[-4.4909, -4.3622, -4.3784, -4.0171, -4.6723, -3.5158]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12641 339 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 580: ep_len:339 episode reward: total was -24.900000. running mean: -57.037741\n",
      "startIDX:  745\n",
      "580 1 True\n",
      "x_t:  3 [0.209375   0.25       0.10625    0.32916667]\n",
      "Q values:  tensor([[-7.1043, -7.1928, -6.6783, -6.8266, -7.8901, -5.8515]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34354 1425 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 580: ep_len:1425 episode reward: total was -71.700000. running mean: -57.184364\n",
      "startIDX:  672\n",
      "580 5 True\n",
      "x_t:  3 [0.171875   0.27083333 0.096875   0.3375    ]\n",
      "Q values:  tensor([[-7.4472, -6.8703, -7.0976, -7.4518, -7.4865, -5.8217]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8780 1354 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 580: ep_len:1354 episode reward: total was -58.200000. running mean: -57.194520\n",
      "startIDX:  1097\n",
      "580 10 True\n",
      "x_t:  2 [0.003125   0.40416667 0.084375   0.24583333]\n",
      "Q values:  tensor([[-4.6484, -4.4148, -4.6028, -4.2732, -4.6663, -3.5981]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12189 406 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 580: ep_len:406 episode reward: total was -101.600000. running mean: -57.638575\n",
      "startIDX:  1552\n",
      "580 12 True\n",
      "x_t:  2 [0.33125    0.4        0.05       0.30416667]\n",
      "Q values:  tensor([[-3.4258, -4.1857, -3.7443, -3.5567, -3.9973, -3.0822]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19422 759 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 580: ep_len:759 episode reward: total was -53.400000. running mean: -57.596189\n",
      "startIDX:  3153\n",
      "ep 580: ep_len:5 episode reward: total was -1.000000. running mean: -57.030227\n",
      "startIDX:  1304\n",
      "580 22 True\n",
      "x_t:  3 [0.3625     0.29166667 0.0875     0.3375    ]\n",
      "Q values:  tensor([[-4.1293, -4.2376, -4.1996, -4.0021, -3.7116, -3.2618]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15268 1336 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 580: ep_len:1336 episode reward: total was -54.600000. running mean: -57.005925\n",
      "startIDX:  102\n",
      "581 0 True\n",
      "x_t:  1 [0.303125   0.3375     0.103125   0.44166667]\n",
      "Q values:  tensor([[-4.0215, -4.0690, -4.1596, -4.0988, -4.3996, -3.2167]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1670 727 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  657\n",
      "581 1 True\n",
      "x_t:  2 [0.796875   0.37916667 0.075      0.30416667]\n",
      "Q values:  tensor([[-3.5506, -3.4073, -3.3811, -3.5945, -3.5680, -2.6828]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31467 349 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2422\n",
      "581 5 True\n",
      "x_t:  2 [0.053125   0.4        0.103125   0.27083333]\n",
      "Q values:  tensor([[-3.2653, -3.3880, -3.4505, -3.4537, -3.3273, -2.6398]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21556 931 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2088\n",
      "581 10 True\n",
      "x_t:  1 [0.203125   0.325      0.115625   0.37083333]\n",
      "Q values:  tensor([[-2.5439, -2.5009, -2.9442, -2.5459, -2.6694, -2.1693]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18836 264 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "581 12 True\n",
      "x_t:  2 [0.728125   0.40416667 0.075      0.30416667]\n",
      "Q values:  tensor([[-3.6793, -3.7352, -4.0363, -3.8650, -3.8937, -3.1877]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19472 762 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1911\n",
      "581 15 True\n",
      "x_t:  1 [0.890625   0.3        0.103125   0.30416667]\n",
      "Q values:  tensor([[-3.8149, -3.6487, -3.7900, -3.6829, -3.6368, -2.9854]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14840 699 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  884\n",
      "581 22 True\n",
      "x_t:  0 [0.928125   0.40416667 0.0625     0.3375    ]\n",
      "Q values:  tensor([[-4.7782, -4.6393, -4.4473, -4.5888, -4.9565, -3.8720]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10400 700 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2407\n",
      "582 0 True\n",
      "x_t:  3 [0.221875   0.26666667 0.084375   0.27916667]\n",
      "Q values:  tensor([[-4.5509, -4.5823, -4.6068, -4.4713, -4.6384, -3.5871]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26138 1231 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 582: ep_len:1231 episode reward: total was -59.900000. running mean: -55.805806\n",
      "startIDX:  766\n",
      "582 1 True\n",
      "x_t:  3 [0.2        0.24166667 0.084375   0.32083333]\n",
      "Q values:  tensor([[-4.2237, -4.3310, -4.5043, -4.4968, -4.5037, -3.5961]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34344 1392 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 582: ep_len:1392 episode reward: total was -68.600000. running mean: -55.933748\n",
      "startIDX:  1405\n",
      "582 5 True\n",
      "x_t:  1 [0.1625     0.32916667 0.125      0.38333333]\n",
      "Q values:  tensor([[-2.9524, -2.8854, -3.0506, -3.0843, -2.9880, -2.3939]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12521 215 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 582: ep_len:215 episode reward: total was -8.100000. running mean: -55.455411\n",
      "startIDX:  1499\n",
      "582 10 True\n",
      "x_t:  3 [0.396875 0.275    0.11875  0.3375  ]\n",
      "Q values:  tensor([[-3.9246, -3.5428, -3.7015, -3.8120, -3.8979, -2.9278]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16470 380 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 582: ep_len:380 episode reward: total was -1.700000. running mean: -54.917857\n",
      "startIDX:  362\n",
      "582 12 True\n",
      "x_t:  4 [0.003125   0.44166667 0.103125   0.375     ]\n",
      "Q values:  tensor([[-3.4844, -3.9834, -3.8311, -3.6314, -3.9558, -3.0407]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7183 713 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 582: ep_len:713 episode reward: total was -21.300000. running mean: -54.581678\n",
      "startIDX:  624\n",
      "582 15 True\n",
      "x_t:  2 [0.68125    0.40416667 0.059375   0.3       ]\n",
      "Q values:  tensor([[-3.4639, -3.9897, -3.9325, -3.5778, -3.8474, -3.0061]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5989 1062 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 582: ep_len:1062 episode reward: total was -141.500000. running mean: -55.450861\n",
      "startIDX:  1045\n",
      "582 22 True\n",
      "x_t:  0 [0.75625    0.40833333 0.1125     0.32083333]\n",
      "Q values:  tensor([[-3.1502, -3.4003, -3.2162, -3.6017, -3.2137, -2.5443]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10421 423 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 582: ep_len:423 episode reward: total was -29.600000. running mean: -55.192353\n",
      "startIDX:  1608\n",
      "583 0 False\n",
      "x_t:  3 [0.678125   0.33333333 0.0875     0.38333333]\n",
      "Q values:  tensor([[2.0569, 3.2453, 3.2474, 4.5431, 2.9194, 2.4087]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 16836 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1009\n",
      "startIDX:  620\n",
      "583 5 True\n",
      "x_t:  2 [0.66875    0.39166667 0.075      0.30416667]\n",
      "Q values:  tensor([[-4.0473, -4.0845, -3.7899, -3.7480, -3.9365, -3.1585]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6060 469 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2424\n",
      "583 10 True\n",
      "x_t:  1 [0.778125   0.29166667 0.1375     0.32916667]\n",
      "Q values:  tensor([[-3.6264, -3.6959, -4.2170, -3.6194, -3.9654, -3.1468]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22479 1185 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  388\n",
      "583 12 True\n",
      "x_t:  3 [0.728125   0.34166667 0.115625   0.40833333]\n",
      "Q values:  tensor([[-3.6199, -4.2976, -3.8561, -3.6404, -3.6309, -3.0338]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7726 271 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2140\n",
      "583 15 True\n",
      "x_t:  3 [0.190625   0.2875     0.084375   0.32083333]\n",
      "Q values:  tensor([[-4.1798, -4.4976, -4.5024, -4.2227, -4.2348, -3.4708]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18201 1640 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  29\n",
      "583 22 True\n",
      "x_t:  1 [0.371875   0.35       0.140625   0.39166667]\n",
      "Q values:  tensor([[-3.8956, -4.2408, -4.1415, -3.8909, -4.3762, -3.0747]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1630 750 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1656\n",
      "584 0 False\n",
      "x_t:  3 [0.496875   0.3        0.08125    0.35416667]\n",
      "Q values:  tensor([[1.9957, 2.7601, 3.0346, 3.5062, 2.2895, 1.9788]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 16862 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 584: ep_len:200 episode reward: total was -4.000000. running mean: -54.326022\n",
      "startIDX:  576\n",
      "584 1 True\n",
      "x_t:  3 [0.06875    0.23333333 0.065625   0.28333333]\n",
      "Q values:  tensor([[-6.0022, -5.6627, -6.2288, -6.0472, -6.0502, -4.7526]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34305 1820 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 584: ep_len:1820 episode reward: total was -189.000000. running mean: -55.672762\n",
      "startIDX:  2856\n",
      "ep 584: ep_len:110 episode reward: total was 66.000000. running mean: -54.456034\n",
      "startIDX:  198\n",
      "584 10 True\n",
      "x_t:  4 [0.0375     0.35833333 0.053125   0.25416667]\n",
      "Q values:  tensor([[-3.0638, -2.8531, -2.9566, -3.2358, -3.1789, -2.4024]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4548 443 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 584: ep_len:443 episode reward: total was -9.200000. running mean: -54.003474\n",
      "startIDX:  790\n",
      "584 12 True\n",
      "x_t:  0 [0.790625   0.40833333 0.128125   0.30833333]\n",
      "Q values:  tensor([[-3.3948, -3.3202, -3.3922, -3.4476, -3.3502, -2.7030]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11647 672 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 584: ep_len:672 episode reward: total was -73.100000. running mean: -54.194439\n",
      "startIDX:  1261\n",
      "584 15 True\n",
      "x_t:  3 [0.7        0.32916667 0.103125   0.36666667]\n",
      "Q values:  tensor([[-3.8708, -3.7607, -3.7205, -3.5536, -3.7824, -3.0561]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10360 255 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 584: ep_len:255 episode reward: total was 0.900000. running mean: -53.643495\n",
      "startIDX:  1600\n",
      "584 22 True\n",
      "x_t:  3 [0.365625   0.28333333 0.071875   0.3125    ]\n",
      "Q values:  tensor([[-2.7299, -3.1216, -3.0443, -3.0652, -3.2024, -2.3892]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16924 297 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 584: ep_len:297 episode reward: total was -16.400000. running mean: -53.271060\n",
      "startIDX:  2350\n",
      "585 0 True\n",
      "x_t:  3 [0.25       0.25416667 0.071875   0.29166667]\n",
      "Q values:  tensor([[-3.5466, -3.3470, -3.5194, -3.5669, -3.5863, -2.9186]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26144 1266 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  621\n",
      "585 1 True\n",
      "x_t:  4 [0.171875   0.375      0.078125   0.42083333]\n",
      "Q values:  tensor([[-4.5249, -5.3253, -5.2672, -4.9979, -5.6807, -4.0775]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35445 2348 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2962\n",
      "startIDX:  741\n",
      "585 10 True\n",
      "x_t:  1 [0.259375   0.32916667 0.1        0.34583333]\n",
      "Q values:  tensor([[-3.8334, -3.4936, -3.5362, -3.8253, -3.5761, -2.8221]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7131 230 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  339\n",
      "585 12 True\n",
      "x_t:  4 [0.425      0.39166667 0.1        0.3375    ]\n",
      "Q values:  tensor([[-2.8480, -3.0959, -3.1799, -2.9688, -3.2014, -2.5814]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7235 744 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1271\n",
      "585 15 True\n",
      "x_t:  3 [0.60625    0.30833333 0.1        0.35      ]\n",
      "Q values:  tensor([[-3.3623, -3.7628, -3.8205, -3.3393, -3.6523, -2.9849]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10378 253 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2517\n",
      "585 22 True\n",
      "x_t:  4 [0.025      0.40416667 0.10625    0.31666667]\n",
      "Q values:  tensor([[-5.9927, -5.8046, -6.1860, -5.4151, -6.4087, -4.6951]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27269 1803 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2082\n",
      "586 0 True\n",
      "x_t:  0 [0.715625 0.4      0.1      0.3875  ]\n",
      "Q values:  tensor([[-4.1379, -4.4645, -4.4503, -4.6090, -4.6774, -3.7577]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20712 852 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 586: ep_len:852 episode reward: total was -88.100000. running mean: -54.331086\n",
      "startIDX:  408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586 1 True\n",
      "x_t:  0 [0.50625    0.37083333 0.1375     0.44583333]\n",
      "Q values:  tensor([[-3.3077, -3.5434, -3.5695, -3.3934, -3.7264, -2.7762]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29154 516 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 586: ep_len:516 episode reward: total was -56.500000. running mean: -54.352775\n",
      "startIDX:  1704\n",
      "586 5 True\n",
      "x_t:  1 [0.740625   0.29166667 0.096875   0.3       ]\n",
      "Q values:  tensor([[-4.4644, -4.1795, -4.8729, -4.0787, -4.3525, -3.6302]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14940 615 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 586: ep_len:615 episode reward: total was -25.600000. running mean: -54.065247\n",
      "startIDX:  1841\n",
      "586 10 True\n",
      "x_t:  2 [0.2        0.4        0.071875   0.24583333]\n",
      "Q values:  tensor([[-3.5155, -3.4977, -3.3769, -3.2026, -3.1582, -2.7319]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18178 840 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 586: ep_len:840 episode reward: total was -30.600000. running mean: -53.830595\n",
      "startIDX:  433\n",
      "586 12 True\n",
      "x_t:  0 [0.896875   0.41666667 0.096875   0.30416667]\n",
      "Q values:  tensor([[-6.2445, -7.1991, -7.0078, -6.5931, -7.1869, -5.4165]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11634 2218 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 586: ep_len:2218 episode reward: total was -257.900000. running mean: -55.871289\n",
      "startIDX:  734\n",
      "586 15 True\n",
      "x_t:  2 [0.371875   0.40416667 0.0875     0.30833333]\n",
      "Q values:  tensor([[-3.1208, -3.4588, -3.3481, -3.1789, -3.3822, -2.6571]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6033 392 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 586: ep_len:392 episode reward: total was -58.700000. running mean: -55.899576\n",
      "startIDX:  956\n",
      "586 22 True\n",
      "x_t:  0 [0.81875    0.39583333 0.059375   0.32916667]\n",
      "Q values:  tensor([[-3.7837, -4.6279, -4.1351, -4.2278, -4.5075, -3.4236]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10417 476 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 586: ep_len:476 episode reward: total was -58.000000. running mean: -55.920580\n",
      "startIDX:  1571\n",
      "587 0 True\n",
      "x_t:  3 [0.68125    0.33333333 0.11875    0.375     ]\n",
      "Q values:  tensor([[-3.8675, -3.8409, -4.2998, -3.4950, -4.1725, -3.2236]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16834 219 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  220\n",
      "587 1 True\n",
      "x_t:  2 [0.340625   0.37083333 0.146875   0.42916667]\n",
      "Q values:  tensor([[-4.4794, -4.5517, -4.4774, -4.2658, -4.9802, -3.5710]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27481 876 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1859\n",
      "587 5 True\n",
      "x_t:  2 [0.371875   0.39583333 0.05       0.24583333]\n",
      "Q values:  tensor([[-4.6378, -4.6082, -4.7455, -4.7261, -5.0932, -3.8818]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15720 362 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1845\n",
      "587 10 True\n",
      "x_t:  2 [0.11875 0.4     0.08125 0.25   ]\n",
      "Q values:  tensor([[-4.2581, -4.6150, -4.8787, -4.8449, -4.6767, -3.9615]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18164 851 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  83\n",
      "587 12 True\n",
      "x_t:  1 [0.671875   0.31666667 0.075      0.45      ]\n",
      "Q values:  tensor([[-5.0026, -4.8978, -4.6783, -4.8054, -4.5325, -3.9646]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2235 623 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1690\n",
      "587 15 True\n",
      "x_t:  1 [0.5875     0.32083333 0.13125    0.35833333]\n",
      "Q values:  tensor([[-5.4547, -4.4578, -5.0335, -4.8861, -5.1520, -4.0729]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12511 273 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2303\n",
      "587 22 True\n",
      "x_t:  1 [0.2        0.37083333 0.165625   0.45833333]\n",
      "Q values:  tensor([[-6.3840, -6.1063, -6.1288, -6.0817, -6.4483, -5.2508]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22993 1130 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1185\n",
      "588 0 True\n",
      "x_t:  3 [0.075      0.24583333 0.084375   0.25833333]\n",
      "Q values:  tensor([[-6.2333, -6.1402, -6.0725, -5.5938, -5.9696, -4.8669]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15163 1273 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 588: ep_len:1273 episode reward: total was -27.800000. running mean: -54.436690\n",
      "startIDX:  496\n",
      "588 1 True\n",
      "x_t:  1 [0.84375    0.26666667 0.084375   0.45833333]\n",
      "Q values:  tensor([[-4.5760, -4.4490, -5.0744, -4.4022, -4.7027, -3.8814]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30686 759 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 588: ep_len:759 episode reward: total was -21.500000. running mean: -54.107323\n",
      "startIDX:  2224\n",
      "588 5 True\n",
      "x_t:  3 [0.059375   0.24166667 0.071875   0.26666667]\n",
      "Q values:  tensor([[-5.1592, -4.8176, -4.7002, -4.5757, -4.9001, -3.9946]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 20019 274 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 588: ep_len:274 episode reward: total was -38.800000. running mean: -53.954250\n",
      "startIDX:  1394\n",
      "588 10 True\n",
      "x_t:  4 [0.403125   0.35       0.075      0.22916667]\n",
      "Q values:  tensor([[-4.5731, -4.6890, -4.4196, -4.1875, -4.7059, -3.6952]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15888 625 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 588: ep_len:625 episode reward: total was -90.300000. running mean: -54.317707\n",
      "startIDX:  2029\n",
      "ep 588: ep_len:19 episode reward: total was 7.000000. running mean: -53.704530\n",
      "startIDX:  519\n",
      "588 15 True\n",
      "x_t:  1 [0.528125   0.32083333 0.0625     0.275     ]\n",
      "Q values:  tensor([[-4.4990, -5.1382, -5.0225, -4.5316, -5.2130, -4.1636]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5222 733 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 588: ep_len:733 episode reward: total was -92.000000. running mean: -54.087485\n",
      "startIDX:  1662\n",
      "588 22 False\n",
      "x_t:  3 [0.721875   0.3375     0.1        0.38333333]\n",
      "Q values:  tensor([[-4.1439, -4.0901, -4.4375, -3.5379, -4.0595, -3.5388]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16864 234 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 588: ep_len:234 episode reward: total was -4.100000. running mean: -53.587610\n",
      "startIDX:  1144\n",
      "589 0 True\n",
      "x_t:  3 [0.1625     0.25833333 0.065625   0.28333333]\n",
      "Q values:  tensor([[-4.6625, -5.3822, -5.2430, -5.3139, -5.6486, -4.5626]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15187 1595 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  633\n",
      "589 1 False\n",
      "x_t:  3 [0.109375   0.23333333 0.078125   0.30416667]\n",
      "Q values:  tensor([[-5.9164, -5.6621, -5.9651, -5.0771, -5.5046, -5.3126]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34319 1781 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1077\n",
      "589 5 False\n",
      "x_t:  3 [0.121875   0.24166667 0.13125    0.27916667]\n",
      "Q values:  tensor([[2.0418, 3.3025, 2.7821, 5.3115, 2.8416, 2.8271]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 10596 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  350\n",
      "589 10 True\n",
      "x_t:  3 [0.715625   0.3        0.1375     0.39166667]\n",
      "Q values:  tensor([[-4.3312, -4.7473, -4.7158, -4.6782, -4.7673, -3.8476]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5051 216 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  797\n",
      "589 12 True\n",
      "x_t:  1 [0.103125   0.39583333 0.165625   0.475     ]\n",
      "Q values:  tensor([[-5.1351, -4.7598, -5.2500, -4.6457, -5.5232, -4.5059]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12966 1331 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3086\n",
      "startIDX:  2202\n",
      "589 22 True\n",
      "x_t:  0 [0.9        0.39583333 0.084375   0.3375    ]\n",
      "Q values:  tensor([[-4.8416, -4.8814, -5.0810, -4.5785, -5.3658, -4.1110]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20691 807 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  5303.5579352378845\n",
      "startIDX:  1104\n",
      "590 0 True\n",
      "x_t:  3 [0.221875   0.275      0.096875   0.29583333]\n",
      "Q values:  tensor([[-6.6361, -6.7592, -7.0469, -6.0656, -7.0360, -5.6732]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15205 1649 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 590: ep_len:1649 episode reward: total was -153.100000. running mean: -55.703514\n",
      "startIDX:  806\n",
      "590 1 True\n",
      "x_t:  4 [0.046875   0.38333333 0.1        0.425     ]\n",
      "Q values:  tensor([[-4.5269, -4.3013, -4.2037, -4.0146, -4.2105, -3.6077]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35430 561 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 590: ep_len:561 episode reward: total was 34.100000. running mean: -54.805479\n",
      "startIDX:  2527\n",
      "590 5 True\n",
      "x_t:  2 [0.109375   0.39583333 0.109375   0.27083333]\n",
      "Q values:  tensor([[-4.0691, -3.8960, -4.2331, -3.7997, -3.9868, -3.4375]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21567 804 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 590: ep_len:804 episode reward: total was -25.900000. running mean: -54.516424\n",
      "startIDX:  2542\n",
      "ep 590: ep_len:47 episode reward: total was 22.100000. running mean: -53.750259\n",
      "startIDX:  1862\n",
      "590 12 True\n",
      "x_t:  0 [0.28125    0.42083333 0.1        0.275     ]\n",
      "Q values:  tensor([[-4.7497, -4.7956, -5.1548, -4.7354, -5.2090, -4.0986]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23002 937 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 590: ep_len:937 episode reward: total was -31.600000. running mean: -53.528757\n",
      "startIDX:  578\n",
      "590 15 True\n",
      "x_t:  1 [0.775      0.3        0.053125   0.27083333]\n",
      "Q values:  tensor([[-3.4319, -2.9817, -3.4119, -3.2517, -3.2217, -2.9479]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5185 684 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 590: ep_len:684 episode reward: total was -25.600000. running mean: -53.249469\n",
      "startIDX:  1940\n",
      "590 22 True\n",
      "x_t:  2 [0.13125    0.40833333 0.078125   0.26666667]\n",
      "Q values:  tensor([[-4.3083, -4.4440, -4.3758, -4.5694, -4.4519, -3.8105]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18475 751 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 590: ep_len:751 episode reward: total was -46.400000. running mean: -53.180975\n",
      "startIDX:  1915\n",
      "591 0 True\n",
      "x_t:  0 [0.6625     0.40416667 0.0875     0.35416667]\n",
      "Q values:  tensor([[-3.5531, -3.5957, -4.0975, -3.6513, -3.7298, -3.2457]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20689 1127 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  244\n",
      "591 1 True\n",
      "x_t:  2 [0.2        0.35833333 0.14375    0.45416667]\n",
      "Q values:  tensor([[-3.2089, -3.1401, -3.2552, -3.1441, -3.4984, -2.7455]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27465 852 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1372\n",
      "591 5 True\n",
      "x_t:  0 [0.428125   0.3875     0.096875   0.32916667]\n",
      "Q values:  tensor([[-3.4232, -3.1655, -3.6686, -3.7123, -3.4378, -3.1681]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13587 740 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2256\n",
      "591 10 True\n",
      "x_t:  1 [0.825      0.28333333 0.096875   0.3375    ]\n",
      "Q values:  tensor([[-3.5706, -4.2305, -3.8259, -4.1295, -4.5967, -3.3010]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22475 1270 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  485\n",
      "591 12 True\n",
      "x_t:  3 [0.79375    0.35416667 0.14375    0.4125    ]\n",
      "Q values:  tensor([[-3.5565, -3.2956, -3.2610, -3.5407, -3.5869, -2.9639]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7719 212 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2183\n",
      "591 15 True\n",
      "x_t:  2 [0.49375    0.40833333 0.05625    0.25833333]\n",
      "Q values:  tensor([[-3.8026, -3.3556, -4.0298, -3.5710, -3.8419, -3.0299]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15614 320 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1657\n",
      "591 22 True\n",
      "x_t:  2 [0.275      0.40833333 0.096875   0.26666667]\n",
      "Q values:  tensor([[-2.8549, -2.9338, -2.7317, -3.0442, -3.0638, -2.4637]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18497 1056 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2469\n",
      "ep 592: ep_len:59 episode reward: total was 41.000000. running mean: -53.464409\n",
      "startIDX:  21\n",
      "592 1 True\n",
      "x_t:  3 [0.09375    0.22916667 0.084375   0.275     ]\n",
      "Q values:  tensor([[-5.0720, -4.7154, -5.1548, -4.8753, -5.1848, -4.2724]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25782 244 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 592: ep_len:244 episode reward: total was -75.000000. running mean: -53.679765\n",
      "startIDX:  1128\n",
      "592 5 True\n",
      "x_t:  2 [0.45       0.4        0.096875   0.30416667]\n",
      "Q values:  tensor([[-3.7816, -3.9100, -4.3787, -3.8312, -3.9714, -3.3207]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12066 919 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 592: ep_len:919 episode reward: total was -136.400000. running mean: -54.506967\n",
      "startIDX:  1004\n",
      "592 10 True\n",
      "x_t:  1 [0.103125   0.3375     0.1625     0.39166667]\n",
      "Q values:  tensor([[-4.1343, -4.1490, -3.9905, -4.0958, -4.0852, -3.3906]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11420 1595 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 592: ep_len:1595 episode reward: total was -164.500000. running mean: -55.606898\n",
      "startIDX:  377\n",
      "592 12 True\n",
      "x_t:  4 [0.384375   0.40833333 0.128125   0.34583333]\n",
      "Q values:  tensor([[-3.3792, -3.2980, -3.3139, -3.5081, -3.5789, -2.9203]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7223 725 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 592: ep_len:725 episode reward: total was -71.300000. running mean: -55.763829\n",
      "startIDX:  2313\n",
      "592 15 True\n",
      "x_t:  3 [0.109375   0.28333333 0.090625   0.30416667]\n",
      "Q values:  tensor([[-3.8163, -3.7805, -4.1858, -4.0611, -4.0130, -3.2518]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18185 1259 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 592: ep_len:1259 episode reward: total was -79.500000. running mean: -56.001190\n",
      "startIDX:  2289\n",
      "592 22 True\n",
      "x_t:  1 [0.81875  0.3      0.096875 0.4625  ]\n",
      "Q values:  tensor([[-4.6868, -4.2301, -4.3645, -4.8337, -4.5485, -3.6902]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22938 1081 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 592: ep_len:1081 episode reward: total was -43.200000. running mean: -55.873178\n",
      "startIDX:  1359\n",
      "593 0 True\n",
      "x_t:  4 [0.54375  0.35     0.071875 0.2625  ]\n",
      "Q values:  tensor([[-4.5448, -4.3238, -4.2180, -4.0669, -4.6776, -3.5013]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16407 616 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  768\n",
      "593 1 False\n",
      "x_t:  3 [0.18125    0.24583333 0.090625   0.32083333]\n",
      "Q values:  tensor([[-4.5441, -4.6886, -4.5705, -3.7757, -4.9154, -3.8374]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34341 1393 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2218\n",
      "593 5 True\n",
      "x_t:  2 [0.265625   0.39583333 0.096875   0.2625    ]\n",
      "Q values:  tensor([[-3.9077, -4.2398, -4.2715, -4.0795, -4.3833, -3.5042]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21591 1058 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  218\n",
      "593 10 True\n",
      "x_t:  4 [0.259375   0.34583333 0.053125   0.2375    ]\n",
      "Q values:  tensor([[-4.7880, -4.7789, -4.8889, -4.5531, -4.9331, -4.1949]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4586 466 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  969\n",
      "593 12 False\n",
      "x_t:  1 [0.165625   0.37916667 0.134375   0.49166667]\n",
      "Q values:  tensor([[-5.2048, -4.6394, -5.4736, -5.1689, -5.4486, -4.8040]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12960 594 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  163\n",
      "593 15 True\n",
      "x_t:  2 [0.38125    0.4        0.06875    0.34583333]\n",
      "Q values:  tensor([[-5.0156, -4.7866, -4.6797, -4.8941, -4.9865, -3.8648]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2239 828 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2992\n",
      "startIDX:  2035\n",
      "594 0 True\n",
      "x_t:  0 [0.765625   0.4        0.115625   0.34583333]\n",
      "Q values:  tensor([[-5.3320, -5.1705, -4.9423, -4.9374, -5.3026, -4.4272]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20648 843 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 594: ep_len:843 episode reward: total was -66.500000. running mean: -55.635988\n",
      "startIDX:  727\n",
      "594 1 True\n",
      "x_t:  3 [0.0875     0.23333333 0.08125    0.29583333]\n",
      "Q values:  tensor([[-6.3832, -6.5615, -6.3874, -7.3122, -6.8237, -5.0820]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34311 1409 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 594: ep_len:1409 episode reward: total was -52.300000. running mean: -55.602628\n",
      "startIDX:  1921\n",
      "594 5 True\n",
      "x_t:  2 [0.71875    0.39583333 0.08125    0.24583333]\n",
      "Q values:  tensor([[-4.9720, -5.3451, -5.1502, -5.2191, -5.2512, -4.3486]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15662 308 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 594: ep_len:308 episode reward: total was -44.400000. running mean: -55.490602\n",
      "startIDX:  569\n",
      "594 10 True\n",
      "x_t:  2 [0.078125   0.39583333 0.075      0.26666667]\n",
      "Q values:  tensor([[-4.9565, -4.4667, -4.4331, -4.9226, -5.1583, -3.8655]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6597 747 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 594: ep_len:747 episode reward: total was -17.800000. running mean: -55.113696\n",
      "startIDX:  957\n",
      "594 12 True\n",
      "x_t:  1 [0.765625   0.35       0.15       0.52083333]\n",
      "Q values:  tensor([[-5.4439, -5.6688, -5.3330, -5.1848, -5.8162, -4.2763]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12920 580 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 594: ep_len:580 episode reward: total was -42.900000. running mean: -54.991559\n",
      "startIDX:  1070\n",
      "594 15 True\n",
      "x_t:  4 [0.3875     0.3625     0.071875   0.22083333]\n",
      "Q values:  tensor([[-5.6142, -5.3674, -5.4698, -5.6640, -5.5360, -4.4619]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9934 645 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 594: ep_len:645 episode reward: total was -40.100000. running mean: -54.842643\n",
      "startIDX:  2005\n",
      "594 22 True\n",
      "x_t:  1 [0.15625    0.34583333 0.09375    0.38333333]\n",
      "Q values:  tensor([[-5.1237, -4.9486, -5.3403, -4.9161, -4.3433, -4.2822]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19006 260 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 594: ep_len:260 episode reward: total was 33.100000. running mean: -53.963217\n",
      "startIDX:  2203\n",
      "595 0 False\n",
      "x_t:  1 [0.3125     0.35416667 0.240625   0.5       ]\n",
      "Q values:  tensor([[-4.0609, -3.8704, -4.4231, -4.2114, -4.7958, -3.8954]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22958 1116 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  951\n",
      "595 1 True\n",
      "x_t:  4 [0.359375   0.37083333 0.078125   0.40416667]\n",
      "Q values:  tensor([[-4.1443, -3.8095, -4.0767, -3.8612, -4.0700, -3.4136]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35473 501 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2561\n",
      "595 5 True\n",
      "x_t:  2 [0.04375    0.40416667 0.109375   0.26666667]\n",
      "Q values:  tensor([[-4.8318, -4.8010, -4.3613, -4.4754, -4.9044, -3.8840]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21554 790 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2386\n",
      "595 10 True\n",
      "x_t:  1 [0.2375 0.325  0.125  0.35  ]\n",
      "Q values:  tensor([[-3.5149, -3.9951, -4.1044, -3.5182, -3.8259, -3.2793]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22538 1239 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1253\n",
      "595 12 True\n",
      "x_t:  4 [0.0375     0.38333333 0.078125   0.25416667]\n",
      "Q values:  tensor([[-3.7450, -3.8313, -4.2388, -3.4045, -4.0378, -3.4475]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17552 562 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1425\n",
      "595 15 False\n",
      "x_t:  3 [0.425      0.28333333 0.1        0.3125    ]\n",
      "Q values:  tensor([[2.7782, 1.4341, 3.4467, 3.6500, 2.2502, 3.1107]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 10414 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1193\n",
      "595 22 True\n",
      "x_t:  2 [0.78125    0.40833333 0.09375    0.2625    ]\n",
      "Q values:  tensor([[-4.1493, -3.7890, -3.8484, -3.8575, -3.9806, -3.3704]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12589 1044 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  886\n",
      "596 0 True\n",
      "x_t:  0 [0.765625   0.40416667 0.09375    0.34583333]\n",
      "Q values:  tensor([[-3.7730, -3.4798, -4.2789, -3.8799, -3.8508, -3.3943]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10353 453 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 596: ep_len:453 episode reward: total was -23.300000. running mean: -54.435579\n",
      "startIDX:  629\n",
      "596 1 True\n",
      "x_t:  2 [0.378125   0.38333333 0.096875   0.30833333]\n",
      "Q values:  tensor([[-3.9916, -3.9424, -3.9713, -3.4664, -4.1504, -3.1590]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31532 407 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 596: ep_len:407 episode reward: total was -65.900000. running mean: -54.550224\n",
      "startIDX:  1387\n",
      "596 5 True\n",
      "x_t:  1 [0.2875     0.325      0.146875   0.37916667]\n",
      "Q values:  tensor([[-4.1847, -3.9766, -4.0866, -4.1265, -3.9502, -3.3488]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12537 232 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 596: ep_len:232 episode reward: total was -5.400000. running mean: -54.058721\n",
      "startIDX:  941\n",
      "596 10 True\n",
      "x_t:  1 [0.3625     0.3125     0.11875    0.35833333]\n",
      "Q values:  tensor([[-5.1072, -4.6737, -4.7684, -5.2399, -5.6728, -4.3006]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11393 1597 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 596: ep_len:1597 episode reward: total was -123.800000. running mean: -54.756134\n",
      "startIDX:  2019\n",
      "ep 596: ep_len:27 episode reward: total was 7.000000. running mean: -54.138573\n",
      "startIDX:  385\n",
      "596 15 True\n",
      "x_t:  0 [0.84375    0.40833333 0.1125     0.3375    ]\n",
      "Q values:  tensor([[-4.2669, -4.1700, -4.5690, -3.9074, -4.4770, -3.5080]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3663 455 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 596: ep_len:455 episode reward: total was -4.900000. running mean: -53.646187\n",
      "startIDX:  206\n",
      "596 22 True\n",
      "x_t:  2 [0.71875    0.40416667 0.0625     0.24583333]\n",
      "Q values:  tensor([[-4.1687, -4.2743, -4.3294, -4.2443, -4.3565, -3.5662]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2296 322 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 596: ep_len:322 episode reward: total was -22.700000. running mean: -53.336725\n",
      "startIDX:  896\n",
      "597 0 True\n",
      "x_t:  0 [0.88125    0.40416667 0.109375   0.35833333]\n",
      "Q values:  tensor([[-4.7215, -4.6191, -4.9988, -5.0559, -4.9493, -4.1210]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10330 440 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  334\n",
      "597 1 True\n",
      "x_t:  0 [0.5625     0.375      0.115625   0.41666667]\n",
      "Q values:  tensor([[-4.2724, -4.4047, -4.0352, -4.1399, -4.5934, -3.4986]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29149 827 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1815\n",
      "597 5 True\n",
      "x_t:  2 [0.45625    0.39583333 0.075      0.25833333]\n",
      "Q values:  tensor([[-6.1427, -5.7438, -5.6496, -5.8837, -6.3000, -4.8084]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15705 375 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  992\n",
      "597 10 True\n",
      "x_t:  2 [0.88125 0.35    0.0625  0.25   ]\n",
      "Q values:  tensor([[-6.4408, -6.5827, -6.7825, -6.3058, -6.5601, -5.4730]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12050 1910 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  974\n",
      "597 12 True\n",
      "x_t:  2 [0.50625  0.4125   0.071875 0.25    ]\n",
      "Q values:  tensor([[-4.9336, -4.6031, -4.4302, -4.4062, -4.8379, -3.8602]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13621 349 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2950\n",
      "597 15 True\n",
      "x_t:  0 [0.675      0.4125     0.11875    0.35833333]\n",
      "Q values:  tensor([[-5.0437, -4.8890, -4.8142, -4.9392, -5.2198, -4.1117]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23102 490 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  48\n",
      "597 22 True\n",
      "x_t:  1 [0.6125     0.32916667 0.1125     0.3875    ]\n",
      "Q values:  tensor([[-5.0514, -4.6320, -5.0668, -5.2189, -5.0427, -4.1430]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1607 725 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1858\n",
      "598 0 True\n",
      "x_t:  0 [0.66875    0.4        0.09375    0.36666667]\n",
      "Q values:  tensor([[-4.0519, -4.4526, -4.5415, -4.5368, -4.4718, -3.6786]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20696 1132 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 598: ep_len:1132 episode reward: total was -88.700000. running mean: -54.389627\n",
      "startIDX:  646\n",
      "598 1 True\n",
      "x_t:  2 [0.209375   0.37916667 0.11875    0.3125    ]\n",
      "Q values:  tensor([[-4.7574, -4.7219, -4.6541, -4.8679, -5.2565, -4.1280]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31558 397 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 598: ep_len:397 episode reward: total was -96.600000. running mean: -54.811730\n",
      "startIDX:  786\n",
      "598 5 True\n",
      "x_t:  4 [0.590625   0.34166667 0.0625     0.27083333]\n",
      "Q values:  tensor([[-4.4294, -5.2412, -4.6795, -4.6072, -4.5467, -4.1824]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10143 686 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 598: ep_len:686 episode reward: total was -77.900000. running mean: -55.042613\n",
      "startIDX:  479\n",
      "598 10 False\n",
      "x_t:  3 [0.203125 0.2375   0.078125 0.275   ]\n",
      "Q values:  tensor([[-0.0144,  0.2639,  0.8348,  1.5539,  0.5803, -0.1613]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5145 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 598: ep_len:202 episode reward: total was 14.800000. running mean: -54.344187\n",
      "startIDX:  713\n",
      "598 12 True\n",
      "x_t:  1 [0.1625     0.375      0.11875    0.49583333]\n",
      "Q values:  tensor([[-4.7059, -4.9268, -4.7002, -4.4108, -4.8764, -3.8507]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10314 217 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 598: ep_len:217 episode reward: total was 8.800000. running mean: -53.712745\n",
      "startIDX:  2089\n",
      "598 15 True\n",
      "x_t:  2 [0.296875   0.40416667 0.09375    0.26666667]\n",
      "Q values:  tensor([[-4.5858, -5.1659, -5.1008, -5.1775, -5.0538, -4.0996]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15642 395 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 598: ep_len:395 episode reward: total was -64.300000. running mean: -53.818618\n",
      "startIDX:  1032\n",
      "598 22 True\n",
      "x_t:  0 [0.615625   0.4125     0.090625   0.31666667]\n",
      "Q values:  tensor([[-4.7454, -4.8870, -4.2403, -4.8153, -4.7913, -3.9211]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10451 457 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 598: ep_len:457 episode reward: total was -57.800000. running mean: -53.858431\n",
      "startIDX:  1578\n",
      "599 0 True\n",
      "x_t:  3 [0.653125   0.32916667 0.096875   0.38333333]\n",
      "Q values:  tensor([[-4.6131, -4.6773, -5.0459, -4.5669, -4.9962, -3.7374]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16838 227 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  333\n",
      "599 1 True\n",
      "x_t:  1 [0.578125   0.30833333 0.23125    0.56666667]\n",
      "Q values:  tensor([[-5.2375, -5.1812, -4.8323, -5.1158, -5.1858, -4.2636]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28103 306 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  646\n",
      "599 5 True\n",
      "x_t:  3 [0.890625   0.36666667 0.103125   0.4625    ]\n",
      "Q values:  tensor([[-7.2982, -7.7269, -7.2485, -7.9325, -7.6042, -6.3769]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8897 1418 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1762\n",
      "599 10 True\n",
      "x_t:  3 [0.703125   0.29583333 0.08125    0.37083333]\n",
      "Q values:  tensor([[-6.4810, -5.7409, -6.6333, -5.9434, -6.8595, -5.1530]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16425 221 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599 12 False\n",
      "x_t:  3 [0.315625   0.27916667 0.071875   0.30833333]\n",
      "Q values:  tensor([[2.6042, 2.7573, 3.2916, 6.0187, 2.3109, 2.0182]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 17929 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2913\n",
      "startIDX:  97\n",
      "599 22 True\n",
      "x_t:  1 [0.6125     0.32083333 0.146875   0.3875    ]\n",
      "Q values:  tensor([[-5.4135, -5.6076, -5.4151, -5.5118, -5.5285, -4.6834]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1605 698 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  5400.565464496613\n",
      "startIDX:  2\n",
      "600 0 True\n",
      "x_t:  2 [0.79375    0.40416667 0.075      0.28333333]\n",
      "Q values:  tensor([[-6.8357, -7.2191, -7.6621, -6.9374, -7.5912, -5.8537]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2325 1118 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 600: ep_len:1118 episode reward: total was -114.700000. running mean: -55.012950\n",
      "startIDX:  206\n",
      "600 1 True\n",
      "x_t:  2 [0.646875   0.37083333 0.15       0.44583333]\n",
      "Q values:  tensor([[-8.4307, -7.8901, -8.5324, -8.1716, -8.6903, -7.4865]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27523 892 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 600: ep_len:892 episode reward: total was -79.800000. running mean: -55.260821\n",
      "startIDX:  2265\n",
      "600 5 False\n",
      "x_t:  3 [0.615625   0.30833333 0.096875   0.40416667]\n",
      "Q values:  tensor([[2.3472, 3.7422, 5.6982, 7.3304, 3.4291, 2.8271]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 19912 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 600: ep_len:201 episode reward: total was -36.300000. running mean: -55.071212\n",
      "startIDX:  2068\n",
      "600 10 True\n",
      "x_t:  1 [0.51875    0.3        0.1        0.33333333]\n",
      "Q values:  tensor([[-5.7381, -5.8632, -5.3234, -5.3528, -6.0705, -4.8357]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18884 292 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 600: ep_len:292 episode reward: total was -34.100000. running mean: -54.861500\n",
      "startIDX:  253\n",
      "600 12 True\n",
      "x_t:  3 [0.546875   0.30416667 0.090625   0.35833333]\n",
      "Q values:  tensor([[-8.8761, -8.9869, -8.1029, -8.1198, -8.4849, -6.9948]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5746 1403 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 600: ep_len:1403 episode reward: total was -118.100000. running mean: -55.493885\n",
      "startIDX:  1839\n",
      "600 15 True\n",
      "x_t:  0 [0.865625   0.4125     0.096875   0.31666667]\n",
      "Q values:  tensor([[-6.2059, -6.1410, -5.6673, -6.3798, -6.4388, -5.3614]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13370 410 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 600: ep_len:410 episode reward: total was -27.300000. running mean: -55.211946\n",
      "startIDX:  1986\n",
      "600 22 True\n",
      "x_t:  1 [0.371875   0.32916667 0.103125   0.37083333]\n",
      "Q values:  tensor([[-5.4647, -5.0316, -5.1188, -5.2294, -5.4130, -4.3972]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19030 274 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 600: ep_len:274 episode reward: total was 13.500000. running mean: -54.524827\n",
      "startIDX:  1112\n",
      "601 0 True\n",
      "x_t:  2 [0.0125     0.40833333 0.11875    0.30833333]\n",
      "Q values:  tensor([[-7.0082, -6.9436, -6.7906, -6.3643, -7.3029, -5.6000]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12758 400 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  767\n",
      "601 1 True\n",
      "x_t:  3 [0.10625    0.22916667 0.075      0.30416667]\n",
      "Q values:  tensor([[-9.0871, -8.9026, -9.5274, -8.5087, -9.6672, -8.0646]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34317 1380 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1357\n",
      "601 5 True\n",
      "x_t:  1 [0.153125   0.33333333 0.125      0.39166667]\n",
      "Q values:  tensor([[-5.2594, -5.0681, -5.2774, -4.9712, -5.2784, -4.3962]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12520 243 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2033\n",
      "601 10 True\n",
      "x_t:  1 [0.390625   0.30833333 0.10625    0.35      ]\n",
      "Q values:  tensor([[-4.9658, -5.0647, -4.8788, -4.7876, -5.0230, -4.1713]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18863 312 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1427\n",
      "601 12 False\n",
      "x_t:  3 [0.50625    0.31666667 0.08125    0.35833333]\n",
      "Q values:  tensor([[3.1729, 3.6407, 3.9981, 7.0801, 1.0075, 2.4865]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 17889 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  27\n",
      "601 15 True\n",
      "x_t:  3 [0.840625   0.35833333 0.15625    0.425     ]\n",
      "Q values:  tensor([[-4.7876, -5.7290, -5.1753, -4.9468, -5.1361, -4.2657]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 518 245 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2218\n",
      "601 22 True\n",
      "x_t:  1 [0.4625     0.34166667 0.171875   0.42916667]\n",
      "Q values:  tensor([[-5.9839, -5.3004, -5.9487, -5.4126, -6.1466, -4.8602]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22969 1131 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  138\n",
      "602 0 True\n",
      "x_t:  1 [0.2875   0.35     0.084375 0.4375  ]\n",
      "Q values:  tensor([[-5.0540, -5.1988, -5.0505, -5.2856, -5.1693, -4.4276]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1672 719 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 602: ep_len:719 episode reward: total was -43.900000. running mean: -53.435001\n",
      "startIDX:  696\n",
      "602 1 True\n",
      "x_t:  3 [0.859375   0.34583333 0.13125    0.45      ]\n",
      "Q values:  tensor([[-7.0610, -6.8246, -6.4813, -6.3662, -6.8931, -5.4283]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34467 1503 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 602: ep_len:1503 episode reward: total was -118.900000. running mean: -54.089651\n",
      "startIDX:  546\n",
      "602 5 True\n",
      "x_t:  2 [0.478125   0.39583333 0.11875    0.3       ]\n",
      "Q values:  tensor([[-5.0402, -5.8225, -5.4039, -5.0174, -5.4674, -4.4033]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6081 509 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 602: ep_len:509 episode reward: total was -29.600000. running mean: -53.844755\n",
      "startIDX:  2590\n",
      "ep 602: ep_len:23 episode reward: total was 9.000000. running mean: -53.216307\n",
      "startIDX:  1249\n",
      "602 12 True\n",
      "x_t:  4 [0.021875   0.43333333 0.125      0.3625    ]\n",
      "Q values:  tensor([[-3.8919, -3.6098, -3.7699, -4.1953, -3.8121, -3.1970]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17392 466 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 602: ep_len:466 episode reward: total was 12.800000. running mean: -52.556144\n",
      "startIDX:  2322\n",
      "602 15 True\n",
      "x_t:  3 [0.86875    0.3375     0.10625    0.39583333]\n",
      "Q values:  tensor([[-3.7761, -3.8919, -3.7627, -3.8330, -3.9594, -3.0897]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19657 737 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 602: ep_len:737 episode reward: total was -45.300000. running mean: -52.483583\n",
      "startIDX:  2474\n",
      "602 22 True\n",
      "x_t:  2 [0.890625 0.3875   0.078125 0.1875  ]\n",
      "Q values:  tensor([[-4.1584, -4.5750, -4.5395, -4.1629, -4.3416, -3.5115]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23623 306 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 602: ep_len:306 episode reward: total was -24.600000. running mean: -52.204747\n",
      "startIDX:  1474\n",
      "603 0 True\n",
      "x_t:  4 [0.421875   0.36666667 0.096875   0.275     ]\n",
      "Q values:  tensor([[-4.2355, -4.3177, -4.2014, -4.2059, -4.1493, -3.3365]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16353 520 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  5\n",
      "603 1 True\n",
      "x_t:  2 [0.159375   0.3625     0.121875   0.44166667]\n",
      "Q values:  tensor([[-4.3920, -4.1352, -4.4819, -4.2664, -4.8240, -3.7411]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27457 1089 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1171\n",
      "603 5 True\n",
      "x_t:  2 [0.421875   0.39166667 0.075      0.30416667]\n",
      "Q values:  tensor([[-4.4469, -4.1991, -4.0062, -3.9925, -4.5783, -3.4720]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12060 874 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  301\n",
      "603 10 True\n",
      "x_t:  3 [0.265625   0.25       0.084375   0.29166667]\n",
      "Q values:  tensor([[-3.8417, -3.8304, -3.9629, -3.6995, -4.0034, -3.1903]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5130 277 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1034\n",
      "603 12 True\n",
      "x_t:  2 [0.7        0.40833333 0.05       0.25      ]\n",
      "Q values:  tensor([[-3.7018, -3.7992, -3.7367, -3.4456, -3.3381, -2.9328]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13593 314 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2542\n",
      "603 15 True\n",
      "x_t:  3 [0.409375   0.26666667 0.065625   0.3       ]\n",
      "Q values:  tensor([[-4.0183, -3.9942, -3.9289, -3.9093, -4.0667, -3.1042]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19741 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  367\n",
      "603 22 True\n",
      "x_t:  3 [0.525      0.31666667 0.121875   0.35416667]\n",
      "Q values:  tensor([[-5.4629, -5.2339, -5.1678, -5.7706, -5.6775, -4.4188]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4983 1309 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1278\n",
      "604 0 True\n",
      "x_t:  3 [0.303125   0.275      0.084375   0.31666667]\n",
      "Q values:  tensor([[-6.1701, -6.3064, -6.4359, -6.3089, -6.8398, -4.9843]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15224 1237 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 604: ep_len:1237 episode reward: total was -52.800000. running mean: -54.016918\n",
      "startIDX:  514\n",
      "604 1 True\n",
      "x_t:  1 [0.534375   0.29166667 0.1375     0.4625    ]\n",
      "Q values:  tensor([[-4.3639, -4.6462, -4.1672, -3.8951, -4.6512, -3.5527]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30716 773 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 604: ep_len:773 episode reward: total was -38.500000. running mean: -53.861749\n",
      "startIDX:  1912\n",
      "604 5 True\n",
      "x_t:  2 [0.76875    0.39583333 0.06875    0.25416667]\n",
      "Q values:  tensor([[-5.8010, -5.7415, -5.4817, -5.4968, -5.9711, -4.5267]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15657 322 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 604: ep_len:322 episode reward: total was -32.800000. running mean: -53.651132\n",
      "startIDX:  878\n",
      "604 10 True\n",
      "x_t:  2 [0.359375   0.39166667 0.053125   0.25      ]\n",
      "Q values:  tensor([[-10.2216,  -9.1982,  -9.7203,  -8.8771,  -9.9697,  -7.7032]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12135 2465 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 604: ep_len:2465 episode reward: total was -316.900000. running mean: -56.283620\n",
      "startIDX:  81\n",
      "604 12 True\n",
      "x_t:  2 [0.790625 0.4125   0.075    0.25    ]\n",
      "Q values:  tensor([[-4.7239, -4.4412, -4.3197, -4.3475, -4.0271, -3.4867]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2809 902 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 604: ep_len:902 episode reward: total was -47.800000. running mean: -56.198784\n",
      "startIDX:  0\n",
      "604 15 True\n",
      "x_t:  3 [0.734375   0.33333333 0.090625   0.40833333]\n",
      "Q values:  tensor([[-5.3493, -5.1804, -4.8382, -5.3797, -5.2877, -3.9850]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 537 262 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 604: ep_len:262 episode reward: total was -1.300000. running mean: -55.649796\n",
      "startIDX:  1490\n",
      "604 22 True\n",
      "x_t:  4 [0.54375  0.375    0.065625 0.3     ]\n",
      "Q values:  tensor([[-5.0815, -4.5133, -4.5622, -4.6446, -4.7395, -3.9493]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16452 591 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 604: ep_len:591 episode reward: total was -54.800000. running mean: -55.641298\n",
      "startIDX:  1894\n",
      "605 0 True\n",
      "x_t:  2 [0.76875    0.4        0.0625     0.24583333]\n",
      "Q values:  tensor([[-10.9343, -10.2610, -10.2010, -10.2386, -11.9912,  -8.6534]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23596 2586 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  612\n",
      "605 1 True\n",
      "x_t:  3 [0.1        0.23333333 0.075      0.3       ]\n",
      "Q values:  tensor([[-6.8647, -6.1953, -6.0887, -6.6319, -6.7712, -5.7414]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34315 1785 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3051\n",
      "startIDX:  2250\n",
      "605 10 True\n",
      "x_t:  1 [0.55625 0.3     0.14375 0.325  ]\n",
      "Q values:  tensor([[-7.0062, -6.6335, -6.7042, -6.6706, -6.3442, -5.3682]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22503 1289 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  27\n",
      "605 12 True\n",
      "x_t:  1 [0.640625   0.32083333 0.078125   0.42083333]\n",
      "Q values:  tensor([[-4.3481, -4.4732, -4.2488, -4.2151, -4.5500, -3.4800]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2238 635 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  664\n",
      "605 15 True\n",
      "x_t:  1 [0.634375 0.3      0.1      0.2875  ]\n",
      "Q values:  tensor([[-4.3107, -4.4486, -3.8755, -4.1127, -4.2575, -3.3458]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5203 652 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  90\n",
      "605 22 True\n",
      "x_t:  1 [0.8375     0.30833333 0.11875    0.39583333]\n",
      "Q values:  tensor([[-3.3487, -3.7273, -3.3181, -3.7164, -3.7164, -2.9369]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1583 678 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2108\n",
      "606 0 True\n",
      "x_t:  1 [0.50625    0.33333333 0.109375   0.5125    ]\n",
      "Q values:  tensor([[-4.9364, -4.7599, -4.5254, -4.3065, -4.8643, -3.6669]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22948 1150 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 606: ep_len:1150 episode reward: total was -65.300000. running mean: -58.160874\n",
      "startIDX:  775\n",
      "606 1 True\n",
      "x_t:  3 [0.171875   0.24166667 0.0875     0.31666667]\n",
      "Q values:  tensor([[-3.7340, -3.9486, -4.1125, -4.0741, -4.2584, -3.4106]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34336 1394 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 606: ep_len:1394 episode reward: total was -64.500000. running mean: -58.224265\n",
      "startIDX:  1320\n",
      "606 5 True\n",
      "x_t:  2 [0.303125   0.38333333 0.065625   0.2875    ]\n",
      "Q values:  tensor([[-3.7961, -4.2531, -3.7844, -4.1457, -4.1092, -3.1879]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12044 698 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 606: ep_len:698 episode reward: total was -62.400000. running mean: -58.266022\n",
      "startIDX:  2499\n",
      "606 10 True\n",
      "x_t:  1 [0.875      0.275      0.065625   0.34583333]\n",
      "Q values:  tensor([[-3.6085, -3.6358, -3.4528, -3.6970, -3.9165, -3.0401]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22472 1151 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 606: ep_len:1151 episode reward: total was -59.600000. running mean: -58.279362\n",
      "startIDX:  1047\n",
      "606 12 True\n",
      "x_t:  4 [0.2875     0.40833333 0.115625   0.3625    ]\n",
      "Q values:  tensor([[-4.2844, -4.4080, -4.5384, -4.1286, -4.8210, -3.7418]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17422 1929 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 606: ep_len:1929 episode reward: total was -78.500000. running mean: -58.481569\n",
      "startIDX:  2192\n",
      "606 15 True\n",
      "x_t:  3 [0.121875   0.28333333 0.090625   0.30833333]\n",
      "Q values:  tensor([[-3.7359, -4.2013, -3.5272, -3.6606, -4.2726, -3.2079]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18187 1312 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 606: ep_len:1312 episode reward: total was -24.500000. running mean: -58.141753\n",
      "startIDX:  520\n",
      "606 22 True\n",
      "x_t:  4 [0.003125 0.425    0.09375  0.35    ]\n",
      "Q values:  tensor([[-3.9837, -4.2684, -3.9481, -4.0028, -4.1041, -3.3534]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 6661 819 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 606: ep_len:819 episode reward: total was -41.700000. running mean: -57.977335\n",
      "startIDX:  2189\n",
      "607 0 True\n",
      "x_t:  1 [0.4        0.3375     0.171875   0.50833333]\n",
      "Q values:  tensor([[-3.0957, -3.3833, -3.1989, -3.3091, -3.4832, -2.6786]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22953 1116 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  619\n",
      "607 1 True\n",
      "x_t:  2 [0.634375   0.37916667 0.084375   0.32083333]\n",
      "Q values:  tensor([[-3.1818, -3.4332, -3.2269, -3.1063, -3.5103, -2.6486]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31492 385 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  494\n",
      "607 5 True\n",
      "x_t:  1 [0.171875   0.32916667 0.134375   0.33333333]\n",
      "Q values:  tensor([[-2.6751, -3.0034, -2.3589, -2.8494, -3.0716, -2.1200]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5117 693 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1709\n",
      "607 10 True\n",
      "x_t:  3 [0.396875 0.275    0.11875  0.3375  ]\n",
      "Q values:  tensor([[-2.7883, -2.4335, -2.6632, -2.5706, -2.7423, -2.0579]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16470 271 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  390\n",
      "607 12 True\n",
      "x_t:  3 [0.209375   0.27083333 0.103125   0.3       ]\n",
      "Q values:  tensor([[-3.6254, -3.4253, -3.1942, -3.1100, -3.4726, -2.7342]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7801 300 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1245\n",
      "607 15 True\n",
      "x_t:  3 [0.35625 0.2625  0.075   0.3    ]\n",
      "Q values:  tensor([[-3.2586, -3.4424, -3.3616, -3.3698, -3.4960, -2.5872]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10431 302 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1809\n",
      "607 22 True\n",
      "x_t:  2 [0.10625    0.41666667 0.1        0.2625    ]\n",
      "Q values:  tensor([[-2.4686, -2.4409, -2.7769, -2.7796, -2.7138, -2.2044]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18472 782 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  62\n",
      "608 0 False\n",
      "x_t:  2 [0.528125   0.40833333 0.084375   0.3       ]\n",
      "Q values:  tensor([[-2.7687, -2.6877, -2.3534, -3.1684, -2.7626, -2.4002]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2366 1107 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 608: ep_len:1107 episode reward: total was -144.400000. running mean: -58.699878\n",
      "startIDX:  1070\n",
      "ep 608: ep_len:236 episode reward: total was -50.200000. running mean: -58.614879\n",
      "startIDX:  2395\n",
      "608 5 True\n",
      "x_t:  2 [0.60625    0.39166667 0.075      0.27916667]\n",
      "Q values:  tensor([[-3.7016, -4.0145, -3.6697, -3.6841, -3.6964, -3.0129]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21647 1009 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 608: ep_len:1009 episode reward: total was -113.500000. running mean: -59.163730\n",
      "startIDX:  1988\n",
      "608 10 True\n",
      "x_t:  1 [0.24375    0.32083333 0.090625   0.35416667]\n",
      "Q values:  tensor([[-3.7812, -4.1471, -4.1441, -3.8357, -4.0763, -3.2021]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18842 328 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 608: ep_len:328 episode reward: total was 7.400000. running mean: -58.498093\n",
      "startIDX:  65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608 12 True\n",
      "x_t:  1 [0.825      0.30833333 0.146875   0.42916667]\n",
      "Q values:  tensor([[-3.5546, -3.8788, -3.8048, -3.7551, -4.2505, -2.9923]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2220 626 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 608: ep_len:626 episode reward: total was -37.100000. running mean: -58.284112\n",
      "startIDX:  507\n",
      "608 15 True\n",
      "x_t:  1 [0.7375     0.30416667 0.0875     0.27083333]\n",
      "Q values:  tensor([[-3.5046, -3.4200, -3.4332, -3.1762, -3.1079, -2.6149]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5189 754 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 608: ep_len:754 episode reward: total was -92.500000. running mean: -58.626271\n",
      "startIDX:  1685\n",
      "608 22 True\n",
      "x_t:  3 [0.70625    0.34166667 0.115625   0.37916667]\n",
      "Q values:  tensor([[-5.8730, -5.3399, -5.7140, -5.0467, -5.8252, -4.4889]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16865 217 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 608: ep_len:217 episode reward: total was -31.900000. running mean: -58.359008\n",
      "startIDX:  64\n",
      "609 0 True\n",
      "x_t:  1 [0.71875    0.30833333 0.16875    0.425     ]\n",
      "Q values:  tensor([[-4.6342, -4.6128, -4.2035, -4.4826, -4.6945, -3.6334]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1625 719 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1024\n",
      "609 1 True\n",
      "x_t:  3 [0.659375   0.30416667 0.134375   0.37916667]\n",
      "Q values:  tensor([[-4.3749, -4.5273, -4.4032, -4.5083, -4.6960, -3.4898]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35924 226 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2400\n",
      "609 5 True\n",
      "x_t:  2 [0.0875   0.3875   0.065625 0.275   ]\n",
      "Q values:  tensor([[-4.1710, -4.1029, -4.0105, -3.8294, -4.3472, -3.5268]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21560 955 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1718\n",
      "609 10 True\n",
      "x_t:  3 [0.4125     0.28333333 0.103125   0.32916667]\n",
      "Q values:  tensor([[-5.7390, -5.3183, -4.9701, -5.4251, -5.4333, -4.1819]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16468 260 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  439\n",
      "609 12 True\n",
      "x_t:  3 [0.371875   0.28333333 0.09375    0.33333333]\n",
      "Q values:  tensor([[-4.5792, -4.3682, -4.1593, -4.3385, -4.1028, -3.4340]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7776 273 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1820\n",
      "609 15 True\n",
      "x_t:  0 [0.609375   0.40833333 0.103125   0.33333333]\n",
      "Q values:  tensor([[-6.1687, -6.0799, -6.0580, -6.1843, -5.6703, -5.1560]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13409 450 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1822\n",
      "609 22 True\n",
      "x_t:  2 [0.496875 0.4      0.046875 0.2625  ]\n",
      "Q values:  tensor([[-4.8134, -5.0300, -4.8996, -4.8878, -5.1148, -4.3167]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18526 831 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  5506.304724216461\n",
      "startIDX:  1052\n",
      "610 0 True\n",
      "x_t:  1 [0.675      0.31666667 0.165625   0.44166667]\n",
      "Q values:  tensor([[-5.6284, -5.5112, -5.3875, -5.2114, -6.0085, -4.5262]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11966 765 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 610: ep_len:765 episode reward: total was -17.300000. running mean: -57.256745\n",
      "startIDX:  238\n",
      "610 1 True\n",
      "x_t:  1 [0.496875 0.3      0.240625 0.575   ]\n",
      "Q values:  tensor([[-5.8641, -5.6021, -5.9305, -5.5763, -6.3147, -5.0448]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28099 1167 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 610: ep_len:1167 episode reward: total was -87.300000. running mean: -57.557177\n",
      "startIDX:  1586\n",
      "610 5 True\n",
      "x_t:  2 [0.171875   0.40416667 0.1        0.23333333]\n",
      "Q values:  tensor([[-5.8103, -5.7051, -5.9412, -6.0736, -6.8121, -5.1444]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15752 1104 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 610: ep_len:1104 episode reward: total was -160.700000. running mean: -58.588605\n",
      "startIDX:  1551\n",
      "610 10 True\n",
      "x_t:  2 [0.003125 0.4      0.06875  0.25    ]\n",
      "Q values:  tensor([[-7.5473, -7.2833, -7.4752, -7.2131, -7.6220, -5.7095]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18142 1189 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 610: ep_len:1189 episode reward: total was -138.300000. running mean: -59.385719\n",
      "startIDX:  694\n",
      "610 12 True\n",
      "x_t:  0 [0.75       0.40833333 0.08125    0.30416667]\n",
      "Q values:  tensor([[-5.5159, -5.8370, -5.8752, -4.7879, -5.8081, -4.6913]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11659 893 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 610: ep_len:893 episode reward: total was -53.600000. running mean: -59.327862\n",
      "startIDX:  1892\n",
      "610 15 True\n",
      "x_t:  1 [0.4125     0.32083333 0.059375   0.30833333]\n",
      "Q values:  tensor([[-5.6723, -5.7181, -5.6110, -5.0717, -6.0429, -4.6275]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14905 748 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 610: ep_len:748 episode reward: total was -4.000000. running mean: -58.774584\n",
      "startIDX:  2630\n",
      "610 22 True\n",
      "x_t:  4 [0.228125   0.38333333 0.06875    0.31666667]\n",
      "Q values:  tensor([[-6.9129, -7.1670, -6.5087, -6.5544, -6.9483, -5.5093]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27296 563 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 610: ep_len:563 episode reward: total was 10.400000. running mean: -58.082838\n",
      "startIDX:  1650\n",
      "611 0 True\n",
      "x_t:  3 [0.4875     0.30416667 0.075      0.35833333]\n",
      "Q values:  tensor([[1.6824, 1.7453, 3.2259, 4.9639, 0.4787, 1.4223]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 16863 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  458\n",
      "611 1 True\n",
      "x_t:  2 [0.14375    0.38333333 0.115625   0.3125    ]\n",
      "Q values:  tensor([[-7.1423, -7.4937, -7.4007, -7.0517, -8.1084, -6.3855]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31568 1216 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  451\n",
      "611 5 True\n",
      "x_t:  1 [0.6375     0.29166667 0.06875    0.3625    ]\n",
      "Q values:  tensor([[-6.7819, -7.2479, -7.0244, -6.9669, -6.8563, -5.7156]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5059 687 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  167\n",
      "611 10 False\n",
      "x_t:  3 [0.784375   0.3        0.0875     0.39583333]\n",
      "Q values:  tensor([[-6.8181, -5.7258, -6.3276, -5.6807, -7.3626, -5.8588]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5045 708 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  567\n",
      "611 12 True\n",
      "x_t:  2 [0.3125     0.40833333 0.046875   0.25833333]\n",
      "Q values:  tensor([[-8.1532, -7.6441, -7.7044, -7.0763, -7.9504, -6.5986]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9873 1066 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  901\n",
      "611 15 True\n",
      "x_t:  3 [0.09375    0.23333333 0.065625   0.2375    ]\n",
      "Q values:  tensor([[-7.9353, -7.9213, -8.1623, -8.0191, -8.2287, -6.8586]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8510 1216 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1332\n",
      "611 22 True\n",
      "x_t:  3 [0.16875    0.26666667 0.075      0.29166667]\n",
      "Q values:  tensor([[-8.2239, -8.7223, -8.6458, -7.7815, -8.3597, -6.6298]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15227 1286 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1037\n",
      "612 0 True\n",
      "x_t:  1 [0.365625   0.34166667 0.184375   0.46666667]\n",
      "Q values:  tensor([[-5.8961, -6.0007, -6.3116, -5.6605, -6.0758, -5.1989]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11994 805 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 612: ep_len:805 episode reward: total was -58.900000. running mean: -58.124007\n",
      "startIDX:  660\n",
      "612 1 True\n",
      "x_t:  3 [0.440625   0.28333333 0.10625    0.38333333]\n",
      "Q values:  tensor([[ -9.8681,  -9.4812, -10.4723,  -9.2179, -10.4996,  -8.3002]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34403 1823 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 612: ep_len:1823 episode reward: total was -219.600000. running mean: -59.738767\n",
      "startIDX:  2649\n",
      "612 5 True\n",
      "x_t:  1 [0.3875     0.32083333 0.18125    0.52083333]\n",
      "Q values:  tensor([[-5.4985, -6.2601, -6.4356, -5.7772, -6.2629, -5.0140]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22141 265 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 612: ep_len:265 episode reward: total was 1.100000. running mean: -59.130379\n",
      "startIDX:  880\n",
      "612 10 True\n",
      "x_t:  1 [0.2625  0.325   0.11875 0.375  ]\n",
      "Q values:  tensor([[-8.0240, -7.7763, -7.9665, -7.4144, -8.5651, -6.7876]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11405 1653 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 612: ep_len:1653 episode reward: total was -151.200000. running mean: -60.051075\n",
      "startIDX:  790\n",
      "612 12 True\n",
      "x_t:  0 [0.621875   0.40833333 0.0875     0.30416667]\n",
      "Q values:  tensor([[-6.1726, -6.0102, -5.3075, -5.8704, -5.9960, -4.5596]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11676 685 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 612: ep_len:685 episode reward: total was -34.700000. running mean: -59.797565\n",
      "startIDX:  706\n",
      "612 15 True\n",
      "x_t:  3 [0.209375   0.2375     0.05625    0.25833333]\n",
      "Q values:  tensor([[-8.0381, -7.2829, -7.1080, -7.2692, -6.9986, -6.1363]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8586 1693 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 612: ep_len:1693 episode reward: total was -163.500000. running mean: -60.834589\n",
      "startIDX:  2326\n",
      "612 22 True\n",
      "x_t:  2 [0.496875   0.40416667 0.053125   0.25416667]\n",
      "Q values:  tensor([[-6.1740, -5.7847, -5.3801, -5.6164, -6.1118, -5.1120]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23691 1444 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 612: ep_len:1444 episode reward: total was -140.400000. running mean: -61.630243\n",
      "startIDX:  2463\n",
      "startIDX:  1019\n",
      "613 1 True\n",
      "x_t:  3 [0.459375   0.26666667 0.0625     0.32083333]\n",
      "Q values:  tensor([[-5.0090, -4.3689, -4.2573, -4.1693, -4.5271, -3.9525]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35974 248 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1872\n",
      "613 5 True\n",
      "x_t:  2 [0.35       0.39166667 0.065625   0.25      ]\n",
      "Q values:  tensor([[-4.0502, -4.0149, -3.6032, -3.6809, -4.5172, -3.3196]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15723 368 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1559\n",
      "613 10 True\n",
      "x_t:  3 [0.634375   0.29583333 0.0875     0.35833333]\n",
      "Q values:  tensor([[-4.7076, -4.1996, -4.3465, -4.1332, -4.1976, -3.5331]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16437 333 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1457\n",
      "613 12 False\n",
      "x_t:  3 [0.315625   0.27916667 0.071875   0.30833333]\n",
      "Q values:  tensor([[4.6168, 5.2205, 6.6078, 7.7830, 3.8242, 4.8508]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 17929 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  813\n",
      "613 15 True\n",
      "x_t:  3 [0.1625     0.2375     0.059375   0.24583333]\n",
      "Q values:  tensor([[-4.3606, -4.4790, -4.4252, -4.3936, -4.6749, -3.7225]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8552 1272 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  495\n",
      "613 22 True\n",
      "x_t:  4 [0.015625   0.42083333 0.0875     0.36666667]\n",
      "Q values:  tensor([[-4.1450, -4.1460, -3.7708, -4.6199, -4.5459, -3.5867]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 6649 840 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2170\n",
      "614 0 True\n",
      "x_t:  2 [0.775      0.40416667 0.103125   0.25      ]\n",
      "Q values:  tensor([[-5.2172, -4.8978, -5.3441, -5.1453, -5.2011, -4.2725]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23591 1457 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 614: ep_len:1457 episode reward: total was -94.900000. running mean: -58.669024\n",
      "startIDX:  333\n",
      "614 1 True\n",
      "x_t:  0 [0.734375   0.375      0.146875   0.39583333]\n",
      "Q values:  tensor([[-4.4335, -4.1228, -4.4354, -4.0171, -4.8384, -3.5669]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29114 815 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 614: ep_len:815 episode reward: total was -37.900000. running mean: -58.461333\n",
      "startIDX:  1053\n",
      "614 5 False\n",
      "x_t:  3 [0.240625 0.25     0.121875 0.3     ]\n",
      "Q values:  tensor([[ 4.4422,  5.9832, 10.1879, 10.2497,  4.9295,  5.4266]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10572 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 614: ep_len:200 episode reward: total was 22.200000. running mean: -57.654720\n",
      "startIDX:  1902\n",
      "614 10 True\n",
      "x_t:  2 [0.50625    0.40416667 0.09375    0.24583333]\n",
      "Q values:  tensor([[-4.4311, -4.1668, -3.7899, -3.9645, -4.4586, -3.4713]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18237 837 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 614: ep_len:837 episode reward: total was -76.400000. running mean: -57.842173\n",
      "startIDX:  579\n",
      "614 12 True\n",
      "x_t:  2 [0.234375   0.40833333 0.046875   0.25833333]\n",
      "Q values:  tensor([[-3.9486, -4.2385, -3.7114, -4.2558, -4.5280, -3.4596]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9861 1045 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 614: ep_len:1045 episode reward: total was -38.300000. running mean: -57.646751\n",
      "startIDX:  1013\n",
      "614 15 True\n",
      "x_t:  4 [0.134375   0.38333333 0.06875    0.30416667]\n",
      "Q values:  tensor([[-4.1812, -3.4634, -3.5429, -3.7094, -3.7085, -3.1628]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9835 629 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 614: ep_len:629 episode reward: total was 29.700000. running mean: -56.773284\n",
      "startIDX:  2566\n",
      "614 22 True\n",
      "x_t:  3 [0.134375 0.25     0.084375 0.2625  ]\n",
      "Q values:  tensor([[-5.6986, -5.3248, -5.7135, -5.2257, -6.1109, -4.5897]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26200 1244 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 614: ep_len:1244 episode reward: total was -55.100000. running mean: -56.756551\n",
      "startIDX:  316\n",
      "615 0 True\n",
      "x_t:  3 [0.209375   0.25416667 0.084375   0.27083333]\n",
      "Q values:  tensor([[-5.5541, -5.2054, -5.3302, -5.2794, -5.5802, -4.6185]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4888 1254 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  997\n",
      "startIDX:  920\n",
      "615 5 True\n",
      "x_t:  3 [0.8125     0.325      0.1375     0.39583333]\n",
      "Q values:  tensor([[-3.9073, -3.3324, -3.9000, -3.7539, -4.0246, -3.0200]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10490 236 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1709\n",
      "615 10 True\n",
      "x_t:  3 [0.74375    0.32083333 0.13125    0.37916667]\n",
      "Q values:  tensor([[-3.9250, -3.4949, -3.7291, -3.5988, -3.9351, -3.1617]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16416 241 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1172\n",
      "615 12 True\n",
      "x_t:  3 [0.146875   0.27916667 0.09375    0.3       ]\n",
      "Q values:  tensor([[-4.8530, -4.2231, -4.0297, -4.2175, -4.7683, -3.3068]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16394 1360 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2908\n",
      "615 15 True\n",
      "x_t:  0 [0.925      0.39583333 0.06875    0.3625    ]\n",
      "Q values:  tensor([[-3.8158, -4.0369, -3.8794, -3.8216, -4.0119, -3.2062]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23067 497 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  648\n",
      "615 22 True\n",
      "x_t:  2 [0.7625     0.40833333 0.084375   0.25833333]\n",
      "Q values:  tensor([[-3.4266, -3.5119, -3.5040, -3.6376, -4.0074, -3.1002]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9040 990 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1547\n",
      "616 0 True\n",
      "x_t:  3 [0.80625    0.33333333 0.090625   0.42083333]\n",
      "Q values:  tensor([[-3.6644, -3.4952, -3.5226, -3.3140, -3.8645, -2.8657]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16822 237 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 616: ep_len:237 episode reward: total was 29.200000. running mean: -54.655816\n",
      "startIDX:  388\n",
      "616 1 True\n",
      "x_t:  0 [0.53125    0.375      0.125      0.42916667]\n",
      "Q values:  tensor([[-3.8257, -3.7730, -3.5831, -3.8476, -4.3254, -3.3038]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29152 810 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 616: ep_len:810 episode reward: total was -68.500000. running mean: -54.794258\n",
      "startIDX:  2915\n",
      "ep 616: ep_len:83 episode reward: total was -21.900000. running mean: -54.465315\n",
      "startIDX:  857\n",
      "616 10 True\n",
      "x_t:  0 [0.728125 0.4      0.1125   0.3125  ]\n",
      "Q values:  tensor([[-4.5145, -4.5902, -4.0613, -4.4715, -4.5294, -3.4500]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8130 486 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 616: ep_len:486 episode reward: total was -44.800000. running mean: -54.368662\n",
      "startIDX:  1196\n",
      "616 12 True\n",
      "x_t:  4 [0.040625   0.43333333 0.15625    0.36666667]\n",
      "Q values:  tensor([[-3.6499, -3.3516, -3.6199, -3.2050, -3.3085, -2.8250]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17395 496 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 616: ep_len:496 episode reward: total was 7.400000. running mean: -53.750976\n",
      "startIDX:  2366\n",
      "616 15 True\n",
      "x_t:  4 [0.1625     0.40833333 0.0875     0.32916667]\n",
      "Q values:  tensor([[-3.1896, -2.8969, -3.3915, -2.8797, -3.2303, -2.5132]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19272 537 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 616: ep_len:537 episode reward: total was -9.600000. running mean: -53.309466\n",
      "startIDX:  2100\n",
      "616 22 True\n",
      "x_t:  0 [0.746875   0.40833333 0.059375   0.30416667]\n",
      "Q values:  tensor([[-3.2936, -3.5381, -3.2603, -3.3692, -3.4248, -2.7738]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20738 867 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 616: ep_len:867 episode reward: total was -51.700000. running mean: -53.293371\n",
      "startIDX:  1238\n",
      "617 0 True\n",
      "x_t:  3 [0.3375     0.2875     0.1125     0.33333333]\n",
      "Q values:  tensor([[-3.5427, -3.8491, -3.8545, -4.1571, -4.1008, -2.9792]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15232 1284 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  56\n",
      "617 1 True\n",
      "x_t:  3 [0.290625   0.25416667 0.103125   0.32083333]\n",
      "Q values:  tensor([[-3.9348, -4.0495, -4.1557, -4.2034, -4.1520, -3.3603]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25724 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  890\n",
      "617 5 True\n",
      "x_t:  4 [0.50625    0.36666667 0.084375   0.35      ]\n",
      "Q values:  tensor([[-4.0969, -4.2031, -3.9102, -3.9448, -4.1147, -3.2981]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10081 589 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  970\n",
      "617 10 True\n",
      "x_t:  1 [0.646875   0.29166667 0.0875     0.34166667]\n",
      "Q values:  tensor([[-4.4392, -4.1582, -3.9727, -4.2082, -4.5830, -3.4162]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11360 1554 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1463\n",
      "617 12 False\n",
      "x_t:  3 [0.290625   0.27916667 0.06875    0.30416667]\n",
      "Q values:  tensor([[3.5438, 5.0166, 4.6485, 8.8528, 5.3845, 3.4676]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 17937 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2885\n",
      "617 15 True\n",
      "x_t:  0 [0.21875    0.42083333 0.084375   0.32916667]\n",
      "Q values:  tensor([[-3.5065, -3.7266, -3.5371, -3.5022, -3.6342, -2.8863]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23199 574 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1400\n",
      "617 22 True\n",
      "x_t:  3 [0.096875   0.25416667 0.075      0.2875    ]\n",
      "Q values:  tensor([[-3.8386, -4.2995, -3.8160, -4.2184, -4.6975, -3.2087]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15209 1250 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  353\n",
      "618 0 True\n",
      "x_t:  3 [0.203125   0.25       0.071875   0.27083333]\n",
      "Q values:  tensor([[-4.6041, -4.6122, -4.5296, -4.1147, -4.5504, -3.6867]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4883 1260 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 618: ep_len:1260 episode reward: total was -41.800000. running mean: -53.028628\n",
      "startIDX:  176\n",
      "618 1 True\n",
      "x_t:  2 [0.11875    0.3625     0.134375   0.44166667]\n",
      "Q values:  tensor([[-3.7349, -3.8378, -4.2070, -3.8532, -4.1482, -3.4089]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27449 883 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 618: ep_len:883 episode reward: total was 17.300000. running mean: -52.325342\n",
      "startIDX:  1680\n",
      "618 5 True\n",
      "x_t:  1 [0.76875 0.2875  0.06875 0.3    ]\n",
      "Q values:  tensor([[-3.1710, -3.2434, -3.0882, -3.3484, -3.4553, -2.7323]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14938 644 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 618: ep_len:644 episode reward: total was -87.700000. running mean: -52.679089\n",
      "startIDX:  2558\n",
      "ep 618: ep_len:40 episode reward: total was 28.000000. running mean: -51.872298\n",
      "startIDX:  478\n",
      "618 12 True\n",
      "x_t:  2 [0.0875     0.4125     0.0875     0.25416667]\n",
      "Q values:  tensor([[-5.0627, -4.6547, -5.0738, -4.8021, -4.8335, -4.1305]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9840 1288 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 618: ep_len:1288 episode reward: total was -117.500000. running mean: -52.528575\n",
      "startIDX:  1315\n",
      "618 15 True\n",
      "x_t:  3 [0.896875   0.34583333 0.1        0.39166667]\n",
      "Q values:  tensor([[-3.5369, -3.8760, -3.7115, -3.9116, -3.9530, -2.7816]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10335 215 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 618: ep_len:215 episode reward: total was 18.200000. running mean: -51.821289\n",
      "startIDX:  1141\n",
      "618 22 True\n",
      "x_t:  1 [0.003125   0.39166667 0.1875     0.47916667]\n",
      "Q values:  tensor([[-4.0136, -3.8488, -3.9581, -3.7378, -3.8085, -3.1047]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11985 741 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 618: ep_len:741 episode reward: total was -48.100000. running mean: -51.784076\n",
      "startIDX:  478\n",
      "619 0 True\n",
      "x_t:  3 [0.63125    0.35416667 0.121875   0.4625    ]\n",
      "Q values:  tensor([[-3.0932, -3.2197, -3.1073, -3.5201, -3.7239, -2.6952]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7014 1046 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  482\n",
      "619 1 True\n",
      "x_t:  1 [0.84375    0.26666667 0.084375   0.45833333]\n",
      "Q values:  tensor([[-3.9543, -3.7173, -3.9677, -3.8120, -3.7467, -3.1663]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30686 773 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1181\n",
      "619 5 True\n",
      "x_t:  2 [0.13125    0.3875     0.0625     0.27916667]\n",
      "Q values:  tensor([[-3.4759, -3.3240, -3.3136, -3.5845, -3.5046, -2.8178]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12021 783 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2189\n",
      "619 10 True\n",
      "x_t:  0 [0.63125    0.39583333 0.084375   0.31666667]\n",
      "Q values:  tensor([[-2.2890, -2.4851, -2.3050, -2.5161, -2.2423, -1.9412]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19999 557 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  394\n",
      "619 12 True\n",
      "x_t:  2 [0.74375    0.4125     0.115625   0.25833333]\n",
      "Q values:  tensor([[-4.5771, -4.3686, -4.3971, -4.5609, -4.9428, -3.5113]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9944 1394 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2636\n",
      "619 15 True\n",
      "x_t:  2 [0.3625   0.4      0.059375 0.3375  ]\n",
      "Q values:  tensor([[-4.0417, -4.1787, -3.8637, -4.2526, -4.4834, -3.3008]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21519 872 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2147\n",
      "619 22 True\n",
      "x_t:  0 [0.76875    0.40416667 0.065625   0.325     ]\n",
      "Q values:  tensor([[-3.7009, -3.6914, -3.9170, -3.8620, -4.3888, -3.2209]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20731 849 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  5620.8972153663635\n",
      "startIDX:  1245\n",
      "620 0 True\n",
      "x_t:  4 [0.128125   0.37916667 0.103125   0.2625    ]\n",
      "Q values:  tensor([[-5.7241, -5.5409, -5.0435, -5.4926, -5.0047, -4.1645]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16500 1915 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 620: ep_len:1915 episode reward: total was -207.700000. running mean: -52.917253\n",
      "startIDX:  277\n",
      "620 1 True\n",
      "x_t:  2 [0.253125   0.37083333 0.11875    0.42916667]\n",
      "Q values:  tensor([[-4.2705, -4.2133, -4.0169, -4.3068, -4.7373, -3.3957]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27470 829 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 620: ep_len:829 episode reward: total was -63.600000. running mean: -53.024081\n",
      "startIDX:  524\n",
      "620 5 True\n",
      "x_t:  2 [0.753125   0.4        0.096875   0.29583333]\n",
      "Q values:  tensor([[-3.6616, -3.6765, -3.8642, -3.4902, -4.0848, -3.0320]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6046 507 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 620: ep_len:507 episode reward: total was -22.500000. running mean: -52.718840\n",
      "startIDX:  722\n",
      "620 10 True\n",
      "x_t:  1 [0.653125 0.2875   0.071875 0.35    ]\n",
      "Q values:  tensor([[-3.5383, -3.7728, -3.3393, -3.5278, -3.9084, -2.8809]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7177 262 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 620: ep_len:262 episode reward: total was -11.800000. running mean: -52.309652\n",
      "startIDX:  1814\n",
      "620 12 True\n",
      "x_t:  0 [0.484375   0.40833333 0.146875   0.35416667]\n",
      "Q values:  tensor([[-4.4532, -4.2466, -4.4030, -4.1380, -5.1146, -3.5235]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21139 621 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 620: ep_len:621 episode reward: total was -58.100000. running mean: -52.367555\n",
      "startIDX:  831\n",
      "620 15 True\n",
      "x_t:  3 [0.228125   0.24583333 0.06875    0.25833333]\n",
      "Q values:  tensor([[-6.5884, -6.5139, -6.8093, -6.5014, -6.6103, -5.2553]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8601 1322 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 620: ep_len:1322 episode reward: total was -69.000000. running mean: -52.533880\n",
      "startIDX:  2213\n",
      "620 22 True\n",
      "x_t:  2 [0.75       0.40416667 0.053125   0.25      ]\n",
      "Q values:  tensor([[-6.3030, -6.5918, -5.4000, -5.9147, -6.5259, -4.6001]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23650 1468 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 620: ep_len:1468 episode reward: total was -77.000000. running mean: -52.778541\n",
      "startIDX:  620\n",
      "621 0 True\n",
      "x_t:  2 [0.0875     0.40416667 0.059375   0.27083333]\n",
      "Q values:  tensor([[-4.6762, -5.0517, -4.7142, -4.7812, -5.1374, -3.9054]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8883 893 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1030\n",
      "621 1 True\n",
      "x_t:  3 [0.509375   0.29166667 0.11875    0.34583333]\n",
      "Q values:  tensor([[-4.8753, -4.6439, -4.6581, -4.6482, -5.2390, -3.7051]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35954 245 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  677\n",
      "621 5 True\n",
      "x_t:  2 [0.3375     0.39583333 0.10625    0.2875    ]\n",
      "Q values:  tensor([[-12.6647, -11.9708, -11.2208, -13.1772, -13.7181,  -9.9499]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12051 2988 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1704\n",
      "621 10 True\n",
      "x_t:  3 [0.0625     0.23333333 0.0625     0.24583333]\n",
      "Q values:  tensor([[-5.7558, -5.3777, -5.4647, -5.4780, -5.8324, -4.5470]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16563 327 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1585\n",
      "621 12 True\n",
      "x_t:  2 [0.234375   0.40833333 0.05625    0.29583333]\n",
      "Q values:  tensor([[-6.1030, -6.2181, -6.7710, -6.3236, -6.6423, -5.2198]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19410 738 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  597\n",
      "621 15 True\n",
      "x_t:  1 [0.85       0.2875     0.059375   0.27916667]\n",
      "Q values:  tensor([[-5.8135, -6.1419, -5.8189, -6.3080, -5.8907, -4.5800]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5173 682 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  751\n",
      "621 22 True\n",
      "x_t:  2 [0.003125 0.4125   0.0875   0.2625  ]\n",
      "Q values:  tensor([[-7.3121, -7.5755, -7.0608, -6.9333, -7.8279, -6.0113]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8917 856 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1449\n",
      "622 0 True\n",
      "x_t:  4 [0.34375    0.36666667 0.103125   0.27916667]\n",
      "Q values:  tensor([[-4.6920, -4.3373, -4.2996, -3.8954, -4.1309, -3.6435]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16341 527 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 622: ep_len:527 episode reward: total was -37.900000. running mean: -54.655499\n",
      "startIDX:  516\n",
      "622 1 True\n",
      "x_t:  1 [0.290625   0.30833333 0.115625   0.49166667]\n",
      "Q values:  tensor([[-6.7212, -6.2153, -5.3393, -6.3937, -6.6805, -4.9840]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30742 782 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 622: ep_len:782 episode reward: total was -62.100000. running mean: -54.729944\n",
      "startIDX:  2846\n",
      "ep 622: ep_len:117 episode reward: total was 29.000000. running mean: -53.892645\n",
      "startIDX:  2591\n",
      "ep 622: ep_len:23 episode reward: total was 1.000000. running mean: -53.343718\n",
      "startIDX:  244\n",
      "622 12 True\n",
      "x_t:  3 [0.371875 0.2875   0.084375 0.325   ]\n",
      "Q values:  tensor([[-7.0887, -7.2651, -7.4932, -6.6640, -7.9732, -5.8257]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5721 1409 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 622: ep_len:1409 episode reward: total was -82.700000. running mean: -53.637281\n",
      "startIDX:  1516\n",
      "622 15 True\n",
      "x_t:  1 [0.03125    0.36666667 0.1375     0.4       ]\n",
      "Q values:  tensor([[-5.3563, -5.5331, -6.0595, -4.9786, -5.5579, -4.5827]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12451 1011 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 622: ep_len:1011 episode reward: total was -59.700000. running mean: -53.697908\n",
      "startIDX:  2042\n",
      "622 22 True\n",
      "x_t:  1 [0.325      0.32916667 0.115625   0.37083333]\n",
      "Q values:  tensor([[-4.0113, -4.0043, -3.8108, -4.1295, -4.3105, -3.2826]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19023 248 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 622: ep_len:248 episode reward: total was -13.000000. running mean: -53.290929\n",
      "startIDX:  2111\n",
      "623 0 True\n",
      "x_t:  1 [0.690625   0.32083333 0.18125    0.5       ]\n",
      "Q values:  tensor([[-6.6978, -5.5457, -6.2026, -5.4274, -6.5930, -5.1521]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22932 1146 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  700\n",
      "623 1 True\n",
      "x_t:  3 [0.5875     0.30833333 0.146875   0.44166667]\n",
      "Q values:  tensor([[-6.9925, -6.5304, -6.1217, -6.5963, -7.1239, -5.2611]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34433 1470 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2651\n",
      "623 5 True\n",
      "x_t:  0 [0.80625    0.3875     0.06875    0.31666667]\n",
      "Q values:  tensor([[-4.6538, -4.9275, -5.1923, -4.8479, -5.0752, -4.0876]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23182 790 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  672\n",
      "623 10 True\n",
      "x_t:  1 [0.771875   0.29583333 0.140625   0.3375    ]\n",
      "Q values:  tensor([[-3.8994, -3.5327, -4.0444, -3.5367, -3.8397, -3.1239]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7196 306 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  204\n",
      "623 12 True\n",
      "x_t:  4 [0.3875     0.40416667 0.121875   0.34583333]\n",
      "Q values:  tensor([[-8.2186, -8.3182, -8.5304, -8.6638, -8.8225, -6.8928]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7224 2157 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1787\n",
      "623 15 True\n",
      "x_t:  0 [0.49375    0.4125     0.071875   0.34166667]\n",
      "Q values:  tensor([[-3.8477, -3.9390, -3.8343, -4.2201, -4.3567, -3.2311]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13430 473 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1829\n",
      "623 22 True\n",
      "x_t:  2 [0.253125   0.4        0.04375    0.27083333]\n",
      "Q values:  tensor([[-4.4338, -4.1905, -4.2892, -4.2117, -4.4182, -3.4132]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18490 814 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1158\n",
      "624 0 True\n",
      "x_t:  3 [0.259375   0.26666667 0.075      0.30833333]\n",
      "Q values:  tensor([[-7.6074, -8.6594, -7.4322, -7.9467, -8.7207, -6.3063]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15213 1617 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 624: ep_len:1617 episode reward: total was -183.100000. running mean: -54.558071\n",
      "startIDX:  81\n",
      "624 1 False\n",
      "x_t:  3 [0.2125     0.23333333 0.08125    0.30416667]\n",
      "Q values:  tensor([[1.6373, 2.4771, 3.0553, 4.5287, 2.0666, 2.4919]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 25748 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 624: ep_len:201 episode reward: total was -40.100000. running mean: -54.413490\n",
      "startIDX:  2609\n",
      "624 5 True\n",
      "x_t:  1 [0.775      0.28333333 0.0875     0.50416667]\n",
      "Q values:  tensor([[-3.7105, -3.8724, -3.1717, -3.4245, -3.8483, -2.8897]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22172 310 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 624: ep_len:310 episode reward: total was -8.300000. running mean: -53.952355\n",
      "startIDX:  1016\n",
      "624 10 True\n",
      "x_t:  1 [0.75       0.28333333 0.10625    0.34166667]\n",
      "Q values:  tensor([[-5.2584, -5.4451, -5.7342, -6.0143, -5.9625, -4.7109]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11345 1557 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 624: ep_len:1557 episode reward: total was -71.100000. running mean: -54.123831\n",
      "startIDX:  1823\n",
      "624 12 True\n",
      "x_t:  0 [0.790625   0.40833333 0.09375    0.275     ]\n",
      "Q values:  tensor([[-6.4480, -6.2903, -7.0298, -6.7769, -7.0391, -5.3466]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23104 1550 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 624: ep_len:1550 episode reward: total was -181.100000. running mean: -55.393593\n",
      "startIDX:  1505\n",
      "624 15 True\n",
      "x_t:  2 [0.296875   0.40416667 0.084375   0.26666667]\n",
      "Q values:  tensor([[-3.9356, -4.4897, -4.1876, -4.5015, -4.4045, -3.4360]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 11955 788 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 624: ep_len:788 episode reward: total was -30.000000. running mean: -55.139657\n",
      "startIDX:  2379\n",
      "624 22 True\n",
      "x_t:  1 [0.85625 0.3125  0.1375  0.45   ]\n",
      "Q values:  tensor([[-3.8133, -3.8972, -4.1333, -4.0307, -4.3327, -3.4402]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22933 1040 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 624: ep_len:1040 episode reward: total was -50.800000. running mean: -55.096261\n",
      "startIDX:  2036\n",
      "625 0 True\n",
      "x_t:  0 [0.840625   0.40416667 0.125      0.34166667]\n",
      "Q values:  tensor([[-3.7863, -3.9863, -3.6422, -3.8194, -4.0625, -3.0833]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20636 853 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1021\n",
      "625 1 True\n",
      "x_t:  3 [0.78125    0.30416667 0.121875   0.4125    ]\n",
      "Q values:  tensor([[-3.2091, -3.4692, -3.5649, -3.1224, -3.7900, -2.6949]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35909 217 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2042\n",
      "625 5 True\n",
      "x_t:  3 [0.45       0.32083333 0.121875   0.41666667]\n",
      "Q values:  tensor([[-6.2522, -6.1077, -6.6945, -6.5042, -6.8831, -5.3655]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18291 1289 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1306\n",
      "625 10 True\n",
      "x_t:  3 [0.078125 0.225    0.059375 0.25    ]\n",
      "Q values:  tensor([[-5.0718, -4.9314, -4.9810, -5.1834, -5.6399, -4.3276]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14578 1209 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1548\n",
      "625 12 True\n",
      "x_t:  2 [0.44375    0.41666667 0.11875    0.29166667]\n",
      "Q values:  tensor([[-3.3354, -3.4234, -3.2722, -3.4005, -3.9875, -2.9935]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19440 771 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2895\n",
      "625 15 True\n",
      "x_t:  0 [0.4875     0.40833333 0.13125    0.375     ]\n",
      "Q values:  tensor([[-3.2866, -3.4405, -3.3695, -3.1430, -3.4075, -2.7306]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23129 530 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2602\n",
      "625 22 True\n",
      "x_t:  3 [0.071875   0.24583333 0.065625   0.2375    ]\n",
      "Q values:  tensor([[-3.8724, -4.0492, -3.6636, -3.7951, -4.4048, -3.1208]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26179 1227 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2039\n",
      "626 0 True\n",
      "x_t:  0 [0.69375    0.4        0.0875     0.34166667]\n",
      "Q values:  tensor([[-4.3526, -4.6349, -4.3116, -4.5647, -4.6018, -3.6321]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20676 848 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 626: ep_len:848 episode reward: total was -63.100000. running mean: -54.194587\n",
      "startIDX:  604\n",
      "626 1 True\n",
      "x_t:  2 [0.646875   0.38333333 0.125      0.30833333]\n",
      "Q values:  tensor([[-4.3600, -4.3996, -4.3949, -4.6698, -4.8339, -3.6853]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31486 388 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 626: ep_len:388 episode reward: total was -29.400000. running mean: -53.946641\n",
      "startIDX:  2205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "626 5 True\n",
      "x_t:  4 [0.0625     0.40833333 0.1125     0.42916667]\n",
      "Q values:  tensor([[-3.3896, -3.1717, -3.3969, -3.1332, -3.5763, -2.6287]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19471 576 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 626: ep_len:576 episode reward: total was -17.100000. running mean: -53.578174\n",
      "startIDX:  796\n",
      "626 10 True\n",
      "x_t:  0 [0.54375    0.39583333 0.090625   0.29166667]\n",
      "Q values:  tensor([[-3.3897, -3.6080, -3.2297, -3.4732, -3.7804, -2.9494]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8173 722 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 626: ep_len:722 episode reward: total was -112.100000. running mean: -54.163393\n",
      "startIDX:  1032\n",
      "626 12 True\n",
      "x_t:  3 [0.190625   0.28333333 0.096875   0.32083333]\n",
      "Q values:  tensor([[-5.4460, -5.1109, -4.8742, -5.2534, -5.7889, -4.1471]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16405 1726 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 626: ep_len:1726 episode reward: total was -151.400000. running mean: -55.135759\n",
      "startIDX:  2371\n",
      "626 15 True\n",
      "x_t:  4 [0.2        0.39166667 0.0875     0.32916667]\n",
      "Q values:  tensor([[-3.2371, -3.4522, -2.9499, -2.7758, -3.4272, -2.6382]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19281 531 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 626: ep_len:531 episode reward: total was -14.700000. running mean: -54.731401\n",
      "startIDX:  202\n",
      "626 22 True\n",
      "x_t:  2 [0.4625     0.4125     0.0875     0.25416667]\n",
      "Q values:  tensor([[-3.4294, -3.3020, -3.3738, -3.3787, -3.3786, -2.5637]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2339 345 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 626: ep_len:345 episode reward: total was -52.400000. running mean: -54.708087\n",
      "startIDX:  1534\n",
      "627 0 True\n",
      "x_t:  3 [0.16875    0.25416667 0.071875   0.275     ]\n",
      "Q values:  tensor([[-3.2301, -3.2532, -3.4279, -3.2857, -3.5048, -2.6904]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16930 285 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  498\n",
      "627 1 True\n",
      "x_t:  2 [0.78125    0.37083333 0.084375   0.33333333]\n",
      "Q values:  tensor([[-3.7456, -4.2819, -3.7330, -4.0078, -4.0629, -3.2280]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31468 1159 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  487\n",
      "627 5 True\n",
      "x_t:  2 [0.5625     0.4        0.1125     0.29583333]\n",
      "Q values:  tensor([[-3.5958, -3.6384, -3.6495, -3.5476, -4.1232, -3.1823]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6071 1163 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1377\n",
      "627 10 True\n",
      "x_t:  4 [0.178125   0.35833333 0.103125   0.25833333]\n",
      "Q values:  tensor([[-3.5670, -3.2471, -3.6049, -3.2976, -3.3591, -2.7424]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15732 547 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1834\n",
      "627 12 True\n",
      "x_t:  0 [0.203125   0.42916667 0.065625   0.3375    ]\n",
      "Q values:  tensor([[-3.4071, -3.1554, -3.2073, -3.0964, -3.3585, -2.6553]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21188 615 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2220\n",
      "627 15 True\n",
      "x_t:  3 [0.24375    0.29166667 0.09375    0.35      ]\n",
      "Q values:  tensor([[-5.3576, -4.4718, -4.5426, -5.0741, -5.2375, -3.8187]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18211 1301 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  53\n",
      "627 22 True\n",
      "x_t:  1 [0.371875   0.34166667 0.15       0.4       ]\n",
      "Q values:  tensor([[-3.4394, -3.6603, -3.4008, -3.3616, -3.4594, -2.8571]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1629 730 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2495\n",
      "ep 628: ep_len:42 episode reward: total was 28.000000. running mean: -54.556158\n",
      "startIDX:  917\n",
      "628 1 True\n",
      "x_t:  4 [0.0875     0.39166667 0.15       0.4125    ]\n",
      "Q values:  tensor([[-4.2754, -3.8562, -3.9008, -3.8935, -3.9930, -3.2562]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35436 511 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 628: ep_len:511 episode reward: total was -22.600000. running mean: -54.236596\n",
      "startIDX:  945\n",
      "628 5 True\n",
      "x_t:  3 [0.621875   0.29583333 0.134375   0.37083333]\n",
      "Q values:  tensor([[-3.5132, -3.3845, -3.3526, -3.1980, -3.4464, -2.5660]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10511 237 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 628: ep_len:237 episode reward: total was 50.300000. running mean: -53.191230\n",
      "startIDX:  1998\n",
      "628 10 True\n",
      "x_t:  0 [0.703125   0.39583333 0.08125    0.33333333]\n",
      "Q values:  tensor([[-3.7907, -3.9337, -4.0306, -3.8168, -4.0775, -3.2404]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19976 882 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 628: ep_len:882 episode reward: total was -75.100000. running mean: -53.410318\n",
      "startIDX:  635\n",
      "628 12 True\n",
      "x_t:  2 [0.490625 0.4125   0.096875 0.25    ]\n",
      "Q values:  tensor([[-6.2687, -6.1174, -6.0852, -5.6359, -6.3573, -4.9004]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9902 1035 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 628: ep_len:1035 episode reward: total was -76.300000. running mean: -53.639215\n",
      "startIDX:  2607\n",
      "628 15 True\n",
      "x_t:  2 [0.2875   0.4      0.096875 0.3375  ]\n",
      "Q values:  tensor([[-4.9436, -5.3074, -4.9863, -4.9628, -5.4754, -4.1399]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21511 914 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 628: ep_len:914 episode reward: total was -0.200000. running mean: -53.104823\n",
      "startIDX:  1369\n",
      "628 22 True\n",
      "x_t:  4 [0.43125    0.37083333 0.109375   0.3125    ]\n",
      "Q values:  tensor([[-8.1641, -7.9406, -7.7905, -7.8988, -8.7026, -6.6736]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16474 1907 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 628: ep_len:1907 episode reward: total was -209.200000. running mean: -54.665774\n",
      "startIDX:  573\n",
      "629 0 True\n",
      "x_t:  2 [0.7875   0.4      0.071875 0.25    ]\n",
      "Q values:  tensor([[-5.0854, -5.6501, -5.4968, -5.4957, -5.5047, -4.4619]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8991 1007 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  527\n",
      "629 1 True\n",
      "x_t:  2 [0.334375   0.375      0.090625   0.31666667]\n",
      "Q values:  tensor([[-6.0695, -6.2400, -6.0864, -6.3954, -6.9319, -5.0083]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31538 1168 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  636\n",
      "629 5 True\n",
      "x_t:  3 [0.378125   0.3        0.10625    0.38333333]\n",
      "Q values:  tensor([[-5.1565, -5.4974, -5.8461, -5.0599, -5.7114, -4.6260]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8822 1411 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1711\n",
      "629 10 True\n",
      "x_t:  3 [0.721875   0.30416667 0.128125   0.3875    ]\n",
      "Q values:  tensor([[-5.8412, -5.3422, -5.5795, -5.2954, -5.9951, -4.3344]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16420 244 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1831\n",
      "629 12 True\n",
      "x_t:  0 [0.203125   0.42916667 0.09375    0.375     ]\n",
      "Q values:  tensor([[-5.3333, -5.3347, -5.1916, -5.4244, -5.6535, -4.5711]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21185 613 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  495\n",
      "629 15 True\n",
      "x_t:  1 [0.64375    0.30833333 0.1        0.26666667]\n",
      "Q values:  tensor([[-5.9687, -6.0375, -6.0141, -5.9563, -6.6595, -5.1576]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5201 759 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1862\n",
      "629 22 True\n",
      "x_t:  2 [0.828125   0.40833333 0.10625    0.25416667]\n",
      "Q values:  tensor([[-6.6774, -7.0071, -7.2265, -7.1219, -7.4751, -5.7481]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18582 832 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  5742.970556020737\n",
      "startIDX:  1617\n",
      "630 0 False\n",
      "x_t:  3 [0.50625    0.325      0.1125     0.35833333]\n",
      "Q values:  tensor([[2.5788, 3.0097, 4.3539, 4.4304, 4.2541, 3.2904]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 16858 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 630: ep_len:200 episode reward: total was 14.100000. running mean: -55.123986\n",
      "startIDX:  458\n",
      "630 1 True\n",
      "x_t:  1 [0.853125   0.27083333 0.134375   0.45833333]\n",
      "Q values:  tensor([[-6.6234, -7.0953, -6.6653, -6.9375, -7.3188, -6.1251]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30682 786 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 630: ep_len:786 episode reward: total was -35.900000. running mean: -54.931746\n",
      "startIDX:  2222\n",
      "630 5 True\n",
      "x_t:  3 [0.653125   0.325      0.16875    0.41666667]\n",
      "Q values:  tensor([[-4.0145, -3.9035, -4.0869, -4.0255, -4.3117, -3.1174]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19903 214 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 630: ep_len:214 episode reward: total was 51.000000. running mean: -53.872428\n",
      "startIDX:  1530\n",
      "630 10 True\n",
      "x_t:  3 [0.828125   0.33333333 0.165625   0.39583333]\n",
      "Q values:  tensor([[-5.0841, -5.1414, -5.2649, -5.0069, -4.9501, -3.9653]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16404 321 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 630: ep_len:321 episode reward: total was 53.100000. running mean: -52.802704\n",
      "startIDX:  553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630 12 True\n",
      "x_t:  2 [0.7875     0.41666667 0.06875    0.25416667]\n",
      "Q values:  tensor([[-8.7448, -8.5310, -7.5992, -8.9640, -9.1506, -6.7462]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9947 1078 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 630: ep_len:1078 episode reward: total was -60.300000. running mean: -52.877677\n",
      "startIDX:  1370\n",
      "630 15 True\n",
      "x_t:  3 [0.525      0.3        0.078125   0.31666667]\n",
      "Q values:  tensor([[-5.4442, -5.2709, -5.7824, -5.0111, -5.7748, -4.6715]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10397 211 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 630: ep_len:211 episode reward: total was -33.300000. running mean: -52.681900\n",
      "startIDX:  1056\n",
      "630 22 True\n",
      "x_t:  1 [0.615625   0.34166667 0.184375   0.47916667]\n",
      "Q values:  tensor([[-7.1898, -6.4625, -7.4356, -6.7863, -7.8774, -5.9995]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11936 783 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 630: ep_len:783 episode reward: total was -131.000000. running mean: -53.465081\n",
      "startIDX:  1335\n",
      "631 0 True\n",
      "x_t:  4 [0.228125   0.38333333 0.065625   0.2875    ]\n",
      "Q values:  tensor([[-6.5722, -7.2077, -6.7272, -7.0784, -7.3526, -5.6502]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16319 583 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  867\n",
      "631 1 True\n",
      "x_t:  4 [0.328125   0.36666667 0.1        0.40833333]\n",
      "Q values:  tensor([[-7.5753, -8.1077, -7.3776, -6.6354, -8.1614, -6.2776]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35470 562 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2088\n",
      "631 5 True\n",
      "x_t:  4 [0.534375   0.34583333 0.0625     0.25      ]\n",
      "Q values:  tensor([[-7.4024, -6.8302, -7.3058, -7.3073, -8.1555, -6.2983]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19596 692 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1096\n",
      "631 10 True\n",
      "x_t:  2 [0.74375    0.39583333 0.06875    0.25      ]\n",
      "Q values:  tensor([[-5.5615, -5.0721, -5.3773, -5.1342, -5.2104, -4.2569]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12072 359 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1775\n",
      "631 12 True\n",
      "x_t:  0 [0.840625   0.40833333 0.103125   0.35833333]\n",
      "Q values:  tensor([[-5.0649, -5.0937, -5.0038, -5.4103, -5.2420, -4.4044]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21098 595 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2899\n",
      "631 15 True\n",
      "x_t:  0 [0.3125     0.42083333 0.06875    0.27083333]\n",
      "Q values:  tensor([[-6.8012, -6.7975, -6.8114, -6.4945, -6.8620, -5.6754]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23210 570 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1023\n",
      "631 22 True\n",
      "x_t:  0 [0.75625    0.40833333 0.1125     0.32083333]\n",
      "Q values:  tensor([[-4.8906, -4.8628, -4.8518, -4.9847, -5.3331, -4.1677]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10421 440 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2124\n",
      "632 0 False\n",
      "x_t:  1 [0.69375    0.33333333 0.225      0.50416667]\n",
      "Q values:  tensor([[-7.0102, -6.6919, -7.7841, -7.6403, -8.0087, -6.8991]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22929 1150 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 632: ep_len:1150 episode reward: total was -52.300000. running mean: -52.068027\n",
      "startIDX:  399\n",
      "632 1 True\n",
      "x_t:  0 [0.48125    0.375      0.115625   0.48333333]\n",
      "Q values:  tensor([[-6.6773, -6.3526, -7.0934, -6.4030, -7.3920, -6.2003]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29182 550 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 632: ep_len:550 episode reward: total was -70.600000. running mean: -52.253346\n",
      "startIDX:  1579\n",
      "632 5 True\n",
      "x_t:  1 [0.53125    0.29583333 0.053125   0.29583333]\n",
      "Q values:  tensor([[-6.7844, -6.5289, -6.6934, -6.8006, -7.3463, -5.3582]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14975 710 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 632: ep_len:710 episode reward: total was -80.300000. running mean: -52.533813\n",
      "startIDX:  1582\n",
      "632 10 True\n",
      "x_t:  3 [0.721875   0.3        0.09375    0.37916667]\n",
      "Q values:  tensor([[-4.6888, -5.0056, -4.5571, -4.5047, -5.4465, -4.0860]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16422 305 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 632: ep_len:305 episode reward: total was -13.200000. running mean: -52.140475\n",
      "startIDX:  1371\n",
      "632 12 False\n",
      "x_t:  3 [0.68125    0.3375     0.078125   0.40833333]\n",
      "Q values:  tensor([[4.2132, 2.9921, 5.1090, 6.9378, 4.6163, 4.0894]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 17865 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 632: ep_len:201 episode reward: total was 14.500000. running mean: -51.474070\n",
      "startIDX:  492\n",
      "632 15 True\n",
      "x_t:  1 [0.8   0.3   0.1   0.275]\n",
      "Q values:  tensor([[-6.1751, -6.2275, -6.2161, -5.3690, -6.6213, -4.8765]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5178 742 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 632: ep_len:742 episode reward: total was -79.400000. running mean: -51.753329\n",
      "startIDX:  1981\n",
      "632 22 True\n",
      "x_t:  1 [0.66875    0.31666667 0.121875   0.3625    ]\n",
      "Q values:  tensor([[-4.8691, -4.6899, -4.8320, -4.8111, -5.2039, -4.0006]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19065 293 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 632: ep_len:293 episode reward: total was -0.600000. running mean: -51.241796\n",
      "startIDX:  1311\n",
      "633 0 False\n",
      "x_t:  3 [0.0625     0.24166667 0.06875    0.2625    ]\n",
      "Q values:  tensor([[-7.6651, -8.1381, -7.9929, -6.4359, -8.4702, -6.9526]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15158 1216 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  498\n",
      "633 1 False\n",
      "x_t:  1 [0.396875   0.29583333 0.14375    0.47916667]\n",
      "Q values:  tensor([[-6.8213, -5.8836, -6.9139, -6.5055, -6.4927, -6.0781]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30729 773 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  763\n",
      "633 5 True\n",
      "x_t:  3 [0.696875   0.29583333 0.078125   0.37916667]\n",
      "Q values:  tensor([[-7.3635, -7.8622, -7.0184, -7.1216, -7.9483, -5.9490]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10505 866 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2096\n",
      "633 10 True\n",
      "x_t:  1 [0.253125   0.3125     0.08125    0.35833333]\n",
      "Q values:  tensor([[-4.2149, -4.3495, -4.7163, -4.1268, -4.8259, -3.8039]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18843 269 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1783\n",
      "633 12 False\n",
      "x_t:  0 [0.7875     0.40833333 0.065625   0.35      ]\n",
      "Q values:  tensor([[-4.3146, -4.8380, -5.3661, -5.6070, -5.0369, -4.4736]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21109 599 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2894\n",
      "633 15 True\n",
      "x_t:  0 [0.33125    0.40833333 0.078125   0.275     ]\n",
      "Q values:  tensor([[-4.7029, -4.8825, -4.9239, -4.7865, -5.3924, -4.0460]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23213 581 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  284\n",
      "633 22 True\n",
      "x_t:  4 [0.021875   0.42083333 0.08125    0.36666667]\n",
      "Q values:  tensor([[-10.3892, -11.7968, -10.8923, -12.4230, -12.0244,  -9.5000]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 6648 2166 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2244\n",
      "634 0 True\n",
      "x_t:  2 [0.459375   0.41666667 0.10625    0.24583333]\n",
      "Q values:  tensor([[-5.2690, -5.6342, -5.5682, -5.3771, -5.9346, -4.6244]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23643 349 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 634: ep_len:349 episode reward: total was -43.000000. running mean: -53.890606\n",
      "startIDX:  494\n",
      "634 1 True\n",
      "x_t:  1 [0.740625   0.275      0.096875   0.45416667]\n",
      "Q values:  tensor([[-8.3298, -7.1907, -6.7930, -7.8134, -7.8863, -6.2927]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30698 783 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 634: ep_len:783 episode reward: total was -85.300000. running mean: -54.204700\n",
      "startIDX:  2115\n",
      "634 5 True\n",
      "x_t:  4 [0.6375     0.3625     0.075      0.31666667]\n",
      "Q values:  tensor([[-5.3026, -5.0422, -5.1386, -5.4079, -5.3939, -4.3588]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19547 663 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 634: ep_len:663 episode reward: total was -44.400000. running mean: -54.106653\n",
      "startIDX:  32\n",
      "634 10 True\n",
      "x_t:  3 [0.103125   0.23333333 0.0625     0.275     ]\n",
      "Q values:  tensor([[-6.8002, -6.8947, -7.4327, -6.8240, -7.4192, -5.7766]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3595 1110 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 634: ep_len:1110 episode reward: total was -48.900000. running mean: -54.054586\n",
      "startIDX:  1433\n",
      "634 12 False\n",
      "x_t:  3 [0.3875   0.3      0.109375 0.35    ]\n",
      "Q values:  tensor([[3.9400, 5.5469, 6.6120, 8.1424, 4.8857, 6.2294]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 17907 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 634: ep_len:200 episode reward: total was -17.600000. running mean: -53.690040\n",
      "startIDX:  1816\n",
      "634 15 True\n",
      "x_t:  0 [0.784375 0.4      0.084375 0.3375  ]\n",
      "Q values:  tensor([[-3.9275, -4.0159, -3.7035, -3.6812, -3.6661, -3.1435]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13383 439 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 634: ep_len:439 episode reward: total was -26.600000. running mean: -53.419140\n",
      "startIDX:  1150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634 22 False\n",
      "x_t:  1 [0.4125     0.32916667 0.096875   0.50833333]\n",
      "Q values:  tensor([[-4.8572, -4.0574, -4.5779, -5.1621, -5.0600, -4.5032]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11955 736 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 634: ep_len:736 episode reward: total was -51.100000. running mean: -53.395948\n",
      "startIDX:  127\n",
      "635 0 True\n",
      "x_t:  1 [0.315625 0.3375   0.1625   0.4375  ]\n",
      "Q values:  tensor([[-4.9265, -5.0614, -5.1397, -4.5548, -5.5328, -4.0457]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1667 717 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  590\n",
      "635 1 True\n",
      "x_t:  2 [0.640625   0.37916667 0.1        0.32083333]\n",
      "Q values:  tensor([[-3.6266, -3.8823, -3.6297, -3.2861, -4.0274, -3.0151]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31490 398 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  213\n",
      "635 5 True\n",
      "x_t:  1 [0.628125   0.30833333 0.215625   0.5625    ]\n",
      "Q values:  tensor([[-3.6143, -3.1254, -3.4884, -3.1456, -3.1265, -2.6408]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2556 229 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1313\n",
      "635 10 True\n",
      "x_t:  4 [0.20625    0.35833333 0.08125    0.25833333]\n",
      "Q values:  tensor([[-3.7224, -3.7560, -3.8088, -4.0883, -3.9801, -3.1498]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15737 584 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1734\n",
      "635 12 True\n",
      "x_t:  0 [0.59375    0.41666667 0.1125     0.32916667]\n",
      "Q values:  tensor([[-3.9070, -4.0615, -4.1818, -4.0879, -4.4933, -3.2885]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21130 841 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  461\n",
      "635 15 True\n",
      "x_t:  1 [0.31875    0.32916667 0.103125   0.31666667]\n",
      "Q values:  tensor([[-3.4028, -3.7696, -3.4274, -3.3255, -3.5143, -2.7243]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5248 793 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2239\n",
      "635 22 True\n",
      "x_t:  1 [0.590625   0.33333333 0.121875   0.44583333]\n",
      "Q values:  tensor([[-5.1897, -5.1589, -4.9950, -5.1439, -5.7986, -4.1134]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22960 1129 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1649\n",
      "636 0 False\n",
      "x_t:  3 [0.425   0.3     0.10625 0.35   ]\n",
      "Q values:  tensor([[6.4601, 5.4389, 7.5787, 8.3436, 4.1054, 6.2099]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 16872 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 636: ep_len:200 episode reward: total was 22.200000. running mean: -51.702506\n",
      "startIDX:  432\n",
      "636 1 True\n",
      "x_t:  2 [0.796875   0.37916667 0.075      0.30416667]\n",
      "Q values:  tensor([[-5.9406, -5.6127, -5.2100, -6.2409, -5.8704, -4.7344]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31467 1201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 636: ep_len:1201 episode reward: total was -77.800000. running mean: -51.963481\n",
      "startIDX:  12\n",
      "636 5 True\n",
      "x_t:  2 [0.053125   0.38333333 0.19375    0.43333333]\n",
      "Q values:  tensor([[-4.0805, -4.2666, -4.3549, -4.2255, -4.7046, -3.5814]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2061 931 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 636: ep_len:931 episode reward: total was 19.200000. running mean: -51.251846\n",
      "startIDX:  2460\n",
      "636 10 True\n",
      "x_t:  1 [0.86875    0.275      0.053125   0.34583333]\n",
      "Q values:  tensor([[-4.9659, -4.4303, -4.7820, -4.9518, -5.0956, -4.0144]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22473 1170 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 636: ep_len:1170 episode reward: total was -41.200000. running mean: -51.151327\n",
      "startIDX:  1759\n",
      "636 12 True\n",
      "x_t:  0 [0.90625    0.40833333 0.090625   0.37083333]\n",
      "Q values:  tensor([[-3.8409, -4.0095, -4.0082, -3.6825, -4.6183, -3.4173]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21094 603 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 636: ep_len:603 episode reward: total was -4.100000. running mean: -50.680814\n",
      "startIDX:  2450\n",
      "636 15 True\n",
      "x_t:  3 [0.515625   0.29166667 0.071875   0.3125    ]\n",
      "Q values:  tensor([[-3.6143, -3.4613, -3.4231, -3.2831, -3.6588, -2.7841]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19717 242 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 636: ep_len:242 episode reward: total was -3.200000. running mean: -50.206006\n",
      "startIDX:  904\n",
      "636 22 True\n",
      "x_t:  0 [0.56875    0.40416667 0.075      0.32916667]\n",
      "Q values:  tensor([[-4.7514, -4.3958, -4.1218, -4.3458, -4.5579, -3.6178]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10466 732 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 636: ep_len:732 episode reward: total was -90.500000. running mean: -50.608946\n",
      "startIDX:  13\n",
      "637 0 True\n",
      "x_t:  1 [0.15625    0.35833333 0.13125    0.45416667]\n",
      "Q values:  tensor([[-5.7539, -5.1394, -5.5392, -5.1706, -5.7522, -4.4019]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1683 803 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  789\n",
      "637 1 True\n",
      "x_t:  3 [0.29375    0.26666667 0.0875     0.3375    ]\n",
      "Q values:  tensor([[-5.6484, -4.7108, -5.0504, -4.5393, -5.6268, -4.0882]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34369 1376 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  219\n",
      "637 5 True\n",
      "x_t:  0 [0.540625   0.3875     0.096875   0.39583333]\n",
      "Q values:  tensor([[-3.6557, -4.1133, -4.2475, -4.0501, -4.0565, -3.2015]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3598 760 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1712\n",
      "637 10 True\n",
      "x_t:  3 [0.69375    0.29166667 0.08125    0.38333333]\n",
      "Q values:  tensor([[-3.0091, -2.9348, -3.0528, -2.9892, -2.8273, -2.4591]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16426 243 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1458\n",
      "637 12 True\n",
      "x_t:  1 [0.359375 0.3375   0.075    0.3625  ]\n",
      "Q values:  tensor([[-3.4082, -3.2409, -3.3344, -3.6016, -4.0591, -3.0713]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19906 1184 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  999\n",
      "637 15 True\n",
      "x_t:  4 [0.353125   0.375      0.0875     0.29583333]\n",
      "Q values:  tensor([[-3.6858, -3.4021, -3.1915, -3.6558, -4.2347, -2.8362]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9876 652 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2083\n",
      "637 22 True\n",
      "x_t:  1 [0.16875    0.35       0.084375   0.38333333]\n",
      "Q values:  tensor([[-3.7952, -3.2040, -3.3403, -3.3947, -3.1848, -2.6920]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19007 220 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1763\n",
      "638 0 True\n",
      "x_t:  2 [0.171875   0.40416667 0.05625    0.25      ]\n",
      "Q values:  tensor([[-4.5951, -4.1734, -4.4886, -4.7118, -4.7935, -3.9736]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18415 763 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 638: ep_len:763 episode reward: total was -24.500000. running mean: -50.587636\n",
      "startIDX:  1155\n",
      "ep 638: ep_len:30 episode reward: total was 22.000000. running mean: -49.861759\n",
      "startIDX:  1440\n",
      "638 5 True\n",
      "x_t:  0 [0.940625 0.3875   0.053125 0.3375  ]\n",
      "Q values:  tensor([[-4.2311, -4.2046, -3.9660, -4.5411, -4.2933, -3.4018]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13494 478 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 638: ep_len:478 episode reward: total was -12.300000. running mean: -49.486142\n",
      "startIDX:  1601\n",
      "638 10 True\n",
      "x_t:  3 [0.3875  0.275   0.11875 0.3375 ]\n",
      "Q values:  tensor([[-4.4524, -4.1845, -4.4014, -4.5682, -4.5570, -3.4893]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16472 324 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 638: ep_len:324 episode reward: total was -4.000000. running mean: -49.031280\n",
      "startIDX:  2060\n",
      "ep 638: ep_len:3 episode reward: total was -1.000000. running mean: -48.550968\n",
      "startIDX:  1314\n",
      "638 15 True\n",
      "x_t:  3 [0.11875    0.24583333 0.075      0.25416667]\n",
      "Q values:  tensor([[-4.0402, -4.0522, -4.0032, -4.0443, -4.3872, -3.3447]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10489 291 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 638: ep_len:291 episode reward: total was -72.500000. running mean: -48.790458\n",
      "startIDX:  1657\n",
      "638 22 True\n",
      "x_t:  3 [0.68125    0.32916667 0.1125     0.37916667]\n",
      "Q values:  tensor([[-4.1624, -4.6931, -4.4608, -3.9737, -4.2685, -3.4095]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16871 228 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 638: ep_len:228 episode reward: total was 9.900000. running mean: -48.203553\n",
      "startIDX:  1112\n",
      "639 0 True\n",
      "x_t:  2 [0.284375   0.40416667 0.1125     0.3125    ]\n",
      "Q values:  tensor([[-4.7590, -4.4246, -4.4580, -4.5853, -4.5272, -3.6821]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12705 374 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  413\n",
      "639 1 True\n",
      "x_t:  0 [0.759375   0.375      0.115625   0.39166667]\n",
      "Q values:  tensor([[-4.7058, -4.5679, -5.1211, -4.6969, -5.3764, -4.0153]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29110 498 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2824\n",
      "startIDX:  466\n",
      "639 10 False\n",
      "x_t:  3 [0.25       0.24166667 0.078125   0.2875    ]\n",
      "Q values:  tensor([[4.5741, 5.0481, 7.8126, 8.4965, 5.2494, 6.8131]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 5132 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639 12 True\n",
      "x_t:  2 [0.1625     0.4125     0.1125     0.25416667]\n",
      "Q values:  tensor([[-7.9372, -8.1007, -8.6788, -7.1981, -8.5063, -7.1150]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9855 1037 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  223\n",
      "639 15 True\n",
      "x_t:  1 [0.021875   0.38333333 0.146875   0.48333333]\n",
      "Q values:  tensor([[-6.2931, -6.9579, -6.2572, -6.6455, -6.7062, -5.5222]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2754 1064 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  371\n",
      "639 22 True\n",
      "x_t:  4 [0.003125   0.425      0.090625   0.34583333]\n",
      "Q values:  tensor([[-11.3559, -12.3235, -11.9242, -13.3296, -10.9470,  -9.5196]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 6670 2119 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  5835.085020542145\n",
      "startIDX:  157\n",
      "640 0 True\n",
      "x_t:  1 [0.0125     0.37916667 0.203125   0.48333333]\n",
      "Q values:  tensor([[-7.2395, -7.1413, -6.9832, -7.6557, -7.5053, -5.8679]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1692 718 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 640: ep_len:718 episode reward: total was -98.000000. running mean: -49.201843\n",
      "startIDX:  1153\n",
      "ep 640: ep_len:28 episode reward: total was 16.000000. running mean: -48.549825\n",
      "startIDX:  1730\n",
      "640 5 True\n",
      "x_t:  1 [0.003125   0.35833333 0.09375    0.325     ]\n",
      "Q values:  tensor([[-5.5222, -6.0666, -6.1134, -5.2707, -5.7433, -4.8842]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 15046 659 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 640: ep_len:659 episode reward: total was -72.300000. running mean: -48.787327\n",
      "startIDX:  1414\n",
      "640 10 True\n",
      "x_t:  4 [0.53125    0.32916667 0.059375   0.25      ]\n",
      "Q values:  tensor([[-6.4538, -5.8995, -6.3693, -6.0866, -6.0229, -5.2165]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15815 560 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 640: ep_len:560 episode reward: total was -80.200000. running mean: -49.101453\n",
      "startIDX:  1894\n",
      "640 12 True\n",
      "x_t:  0 [0.81875    0.39583333 0.06875    0.29166667]\n",
      "Q values:  tensor([[-6.7825, -6.6898, -6.3341, -7.0603, -7.4434, -5.5422]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23109 979 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 640: ep_len:979 episode reward: total was -72.600000. running mean: -49.336439\n",
      "startIDX:  1962\n",
      "640 15 True\n",
      "x_t:  1 [0.8875     0.29583333 0.078125   0.3125    ]\n",
      "Q values:  tensor([[-5.1940, -5.4204, -5.3654, -4.7222, -5.3898, -4.4285]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14843 693 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 640: ep_len:693 episode reward: total was -3.300000. running mean: -48.876074\n",
      "startIDX:  2026\n",
      "640 22 True\n",
      "x_t:  1 [0.296875   0.32916667 0.0625     0.375     ]\n",
      "Q values:  tensor([[-4.6917, -4.6798, -4.3324, -4.3457, -4.5678, -3.6636]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19019 246 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 640: ep_len:246 episode reward: total was -52.800000. running mean: -48.915314\n",
      "startIDX:  986\n",
      "641 0 True\n",
      "x_t:  1 [0.80625    0.3125     0.171875   0.42916667]\n",
      "Q values:  tensor([[-5.5829, -5.1425, -5.7635, -5.2355, -5.9222, -4.5127]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11952 798 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  789\n",
      "641 1 True\n",
      "x_t:  3 [0.515625   0.28333333 0.09375    0.42083333]\n",
      "Q values:  tensor([[-7.9609, -7.9769, -8.8079, -8.1639, -7.8625, -6.8899]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34415 1430 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  532\n",
      "641 5 True\n",
      "x_t:  3 [0.325      0.28333333 0.103125   0.37083333]\n",
      "Q values:  tensor([[-12.4256, -11.1576, -10.9745, -10.9964, -12.2702,  -9.4338]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8811 1892 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1181\n",
      "641 10 True\n",
      "x_t:  3 [0.73125  0.3125   0.128125 0.3875  ]\n",
      "Q values:  tensor([[-7.7091, -7.3154, -8.6209, -7.8200, -8.5480, -6.6869]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14720 1330 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1832\n",
      "641 12 True\n",
      "x_t:  0 [0.8125     0.40833333 0.096875   0.35416667]\n",
      "Q values:  tensor([[-6.8518, -6.4579, -7.5942, -6.5644, -6.9402, -5.9069]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21106 569 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  760\n",
      "641 15 True\n",
      "x_t:  2 [0.38125    0.40416667 0.103125   0.30416667]\n",
      "Q values:  tensor([[-4.8996, -4.8002, -4.7359, -4.6448, -5.5275, -4.0416]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6029 385 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  88\n",
      "641 22 True\n",
      "x_t:  1 [0.209375   0.35416667 0.0875     0.4125    ]\n",
      "Q values:  tensor([[-4.8351, -5.5093, -5.6838, -5.2768, -5.5680, -4.4888]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1648 714 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  186\n",
      "642 0 True\n",
      "x_t:  2 [0.790625   0.40416667 0.05       0.27916667]\n",
      "Q values:  tensor([[-4.4225, -4.5380, -4.8443, -4.1625, -4.1184, -3.8661]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2328 351 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 642: ep_len:351 episode reward: total was -1.300000. running mean: -52.013894\n",
      "startIDX:  644\n",
      "642 1 True\n",
      "x_t:  2 [0.46875    0.38333333 0.059375   0.30416667]\n",
      "Q values:  tensor([[-5.2135, -5.1605, -5.4584, -5.1199, -5.8305, -4.4377]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31520 375 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 642: ep_len:375 episode reward: total was -50.800000. running mean: -52.001755\n",
      "startIDX:  2681\n",
      "642 5 True\n",
      "x_t:  1 [0.228125   0.35       0.184375   0.50416667]\n",
      "Q values:  tensor([[-5.8552, -5.4812, -5.0929, -5.6668, -5.6837, -4.5674]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22126 240 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 642: ep_len:240 episode reward: total was -55.600000. running mean: -52.037737\n",
      "startIDX:  2566\n",
      "ep 642: ep_len:35 episode reward: total was 13.000000. running mean: -51.387360\n",
      "startIDX:  1985\n",
      "ep 642: ep_len:54 episode reward: total was -21.400000. running mean: -51.087486\n",
      "startIDX:  2942\n",
      "642 15 True\n",
      "x_t:  0 [0.675      0.4125     0.11875    0.35833333]\n",
      "Q values:  tensor([[-5.0173, -5.4605, -5.6925, -4.7691, -5.4806, -4.4740]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23102 499 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 642: ep_len:499 episode reward: total was -53.200000. running mean: -51.108611\n",
      "startIDX:  1547\n",
      "642 22 True\n",
      "x_t:  4 [0.128125   0.3875     0.071875   0.30416667]\n",
      "Q values:  tensor([[-5.5440, -5.4984, -5.0429, -5.1554, -5.4572, -4.5079]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16342 516 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 642: ep_len:516 episode reward: total was -41.700000. running mean: -51.014525\n",
      "startIDX:  2253\n",
      "643 0 True\n",
      "x_t:  2 [0.5375     0.40833333 0.08125    0.25833333]\n",
      "Q values:  tensor([[-4.6540, -4.5039, -4.8656, -4.7688, -5.0671, -4.0295]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23635 346 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  821\n",
      "startIDX:  1647\n",
      "643 5 False\n",
      "x_t:  1 [0.528125   0.29583333 0.115625   0.28333333]\n",
      "Q values:  tensor([[-5.2667, -3.9878, -5.0345, -4.6419, -4.4615, -4.0517]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14971 674 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  39\n",
      "643 10 True\n",
      "x_t:  3 [0.165625   0.25416667 0.09375    0.28333333]\n",
      "Q values:  tensor([[-7.4391, -6.6617, -7.6376, -6.9831, -6.4167, -6.1861]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3613 1112 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1461\n",
      "643 12 True\n",
      "x_t:  2 [0.003125   0.41666667 0.1        0.27083333]\n",
      "Q values:  tensor([[-5.2902, -5.9298, -5.7746, -5.1290, -5.0475, -4.7545]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19378 931 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  251\n",
      "643 15 True\n",
      "x_t:  2 [0.0375     0.40833333 0.109375   0.325     ]\n",
      "Q values:  tensor([[-5.0760, -5.3823, -6.1655, -5.6916, -5.7999, -5.2641]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2200 775 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  238\n",
      "643 22 True\n",
      "x_t:  3 [0.2        0.2625     0.090625   0.27916667]\n",
      "Q values:  tensor([[-8.9918, -8.3613, -9.5846, -7.9038, -8.4585, -8.0151]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4915 1631 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  983\n",
      "644 0 False\n",
      "x_t:  1 [0.796875   0.29583333 0.090625   0.4375    ]\n",
      "Q values:  tensor([[-6.0449, -5.4043, -6.0530, -5.6333, -6.0162, -5.4440]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11957 789 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 644: ep_len:789 episode reward: total was -24.800000. running mean: -55.025851\n",
      "startIDX:  518\n",
      "644 1 True\n",
      "x_t:  1 [0.45625    0.29583333 0.090625   0.4625    ]\n",
      "Q values:  tensor([[-5.9779, -6.1137, -6.5862, -6.6803, -6.3593, -5.4491]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30726 770 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 644: ep_len:770 episode reward: total was -76.700000. running mean: -55.242592\n",
      "startIDX:  90\n",
      "644 5 True\n",
      "x_t:  2 [0.475      0.3875     0.178125   0.44166667]\n",
      "Q values:  tensor([[-7.0339, -7.5748, -8.4645, -7.5753, -7.9393, -7.0336]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2098 912 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 644: ep_len:912 episode reward: total was -133.200000. running mean: -56.022166\n",
      "startIDX:  334\n",
      "644 10 False\n",
      "x_t:  3 [0.65       0.29166667 0.10625    0.36666667]\n",
      "Q values:  tensor([[-3.4727, -3.6958, -4.0926, -3.3427, -4.0708, -3.3994]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5059 224 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 644: ep_len:224 episode reward: total was 27.900000. running mean: -55.182945\n",
      "startIDX:  901\n",
      "644 12 True\n",
      "x_t:  1 [0.646875   0.38333333 0.1625     0.48333333]\n",
      "Q values:  tensor([[-5.6771, -5.0477, -5.3289, -5.2031, -5.2709, -4.3741]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12926 615 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 644: ep_len:615 episode reward: total was -30.300000. running mean: -54.934115\n",
      "startIDX:  1149\n",
      "644 15 True\n",
      "x_t:  4 [0.075      0.39166667 0.103125   0.29583333]\n",
      "Q values:  tensor([[-5.1903, -4.6658, -4.9903, -4.3022, -4.7759, -4.2028]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9825 563 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 644: ep_len:563 episode reward: total was -46.100000. running mean: -54.845774\n",
      "startIDX:  1472\n",
      "644 22 True\n",
      "x_t:  4 [0.003125   0.39583333 0.090625   0.3       ]\n",
      "Q values:  tensor([[-5.7902, -5.6761, -5.1515, -4.8544, -5.4076, -4.4886]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16323 531 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 644: ep_len:531 episode reward: total was -48.300000. running mean: -54.780316\n",
      "startIDX:  889\n",
      "645 0 False\n",
      "x_t:  0 [0.88125    0.4        0.1125     0.37083333]\n",
      "Q values:  tensor([[-4.4423, -5.0317, -5.7121, -5.1755, -4.8350, -4.5466]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10331 454 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  721\n",
      "645 1 False\n",
      "x_t:  3 [0.059375   0.23333333 0.05625    0.27916667]\n",
      "Q values:  tensor([[-8.8854, -7.9802, -8.3127, -7.3250, -8.2776, -7.6161]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34299 1379 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  36\n",
      "645 5 True\n",
      "x_t:  2 [0.3        0.37083333 0.084375   0.44583333]\n",
      "Q values:  tensor([[-8.3481, -7.7985, -7.6634, -8.2028, -7.4198, -6.7058]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2079 924 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2608\n",
      "startIDX:  1115\n",
      "645 12 False\n",
      "x_t:  3 [0.071875 0.2625   0.071875 0.2875  ]\n",
      "Q values:  tensor([[-6.8153, -7.0354, -6.6099, -5.5563, -6.2001, -5.7171]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16375 1389 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  954\n",
      "645 15 True\n",
      "x_t:  4 [0.4375   0.3625   0.059375 0.25    ]\n",
      "Q values:  tensor([[-5.6070, -5.4351, -5.3786, -5.5531, -5.9482, -4.6570]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9911 688 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  701\n",
      "645 22 True\n",
      "x_t:  2 [0.090625   0.4125     0.08125    0.25833333]\n",
      "Q values:  tensor([[-5.6355, -5.8227, -6.2732, -5.8766, -5.7911, -5.0314]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8931 893 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1490\n",
      "646 0 True\n",
      "x_t:  3 [0.846875   0.34583333 0.15       0.425     ]\n",
      "Q values:  tensor([[-4.3030, -4.7896, -5.0998, -4.4753, -4.7417, -3.9036]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16812 252 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 646: ep_len:252 episode reward: total was -25.200000. running mean: -57.706220\n",
      "startIDX:  756\n",
      "646 1 False\n",
      "x_t:  3 [0.209375   0.24166667 0.071875   0.31666667]\n",
      "Q values:  tensor([[-6.7718, -6.3377, -7.4250, -5.9010, -7.5816, -5.9918]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34345 1383 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 646: ep_len:1383 episode reward: total was -117.500000. running mean: -58.304158\n",
      "startIDX:  1770\n",
      "646 5 True\n",
      "x_t:  1 [0.81875    0.28333333 0.1        0.325     ]\n",
      "Q values:  tensor([[-5.0443, -5.2972, -5.0317, -5.0415, -5.3761, -4.3502]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14930 579 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 646: ep_len:579 episode reward: total was -36.500000. running mean: -58.086116\n",
      "startIDX:  305\n",
      "646 10 True\n",
      "x_t:  3 [0.51875 0.3     0.11875 0.3375 ]\n",
      "Q values:  tensor([[-5.5363, -5.7035, -5.6215, -5.2353, -5.6700, -4.4910]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5076 246 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 646: ep_len:246 episode reward: total was 29.900000. running mean: -57.206255\n",
      "startIDX:  1089\n",
      "646 12 True\n",
      "x_t:  3 [0.321875   0.30833333 0.121875   0.35416667]\n",
      "Q values:  tensor([[-6.9143, -6.6339, -7.0799, -6.3691, -6.7960, -6.0509]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16433 1412 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 646: ep_len:1412 episode reward: total was -169.400000. running mean: -58.328192\n",
      "startIDX:  984\n",
      "646 15 True\n",
      "x_t:  4 [0.434375   0.3625     0.06875    0.26666667]\n",
      "Q values:  tensor([[-6.4866, -5.9627, -6.2706, -6.0415, -5.8707, -5.0243]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9902 673 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 646: ep_len:673 episode reward: total was -186.900000. running mean: -59.613911\n",
      "startIDX:  225\n",
      "646 22 True\n",
      "x_t:  2 [0.45       0.40416667 0.05       0.25416667]\n",
      "Q values:  tensor([[-4.8987, -5.3287, -5.3831, -5.1431, -5.3799, -4.4449]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2344 335 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 646: ep_len:335 episode reward: total was -64.800000. running mean: -59.665771\n",
      "startIDX:  408\n",
      "647 0 True\n",
      "x_t:  3 [0.646875   0.37083333 0.159375   0.44583333]\n",
      "Q values:  tensor([[-6.8536, -6.5533, -6.6454, -6.2156, -7.1034, -5.4785]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7010 1083 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  565\n",
      "647 1 True\n",
      "x_t:  2 [0.471875   0.38333333 0.11875    0.3125    ]\n",
      "Q values:  tensor([[-5.9159, -5.5660, -5.9035, -5.8459, -6.1232, -4.7766]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31514 1151 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  920\n",
      "647 5 True\n",
      "x_t:  3 [0.71875    0.30833333 0.184375   0.40416667]\n",
      "Q values:  tensor([[-4.2972, -4.5775, -4.6705, -4.3885, -4.6141, -3.5041]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10497 236 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2321\n",
      "startIDX:  1369\n",
      "647 12 True\n",
      "x_t:  3 [0.825    0.375    0.171875 0.4375  ]\n",
      "Q values:  tensor([[-4.6347, -5.1743, -5.5550, -4.8219, -5.2937, -4.3099]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17843 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  787\n",
      "647 15 True\n",
      "x_t:  2 [0.784375   0.40833333 0.090625   0.29166667]\n",
      "Q values:  tensor([[-5.0013, -5.0021, -4.6738, -4.3840, -4.5977, -4.0511]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5968 344 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  567\n",
      "647 22 True\n",
      "x_t:  3 [0.546875   0.30416667 0.128125   0.33333333]\n",
      "Q values:  tensor([[-5.3212, -5.0300, -5.4624, -4.4393, -5.2387, -4.2965]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7100 230 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2271\n",
      "648 0 True\n",
      "x_t:  2 [0.765625   0.40416667 0.0625     0.23333333]\n",
      "Q values:  tensor([[-6.3945, -5.5468, -5.5842, -5.2289, -6.0845, -4.9286]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23597 308 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 648: ep_len:308 episode reward: total was -47.500000. running mean: -58.068384\n",
      "startIDX:  569\n",
      "648 1 True\n",
      "x_t:  1 [0.853125   0.27083333 0.134375   0.45833333]\n",
      "Q values:  tensor([[-6.7637, -6.3970, -6.5043, -6.3244, -6.4286, -5.6614]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30682 720 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 648: ep_len:720 episode reward: total was -74.700000. running mean: -58.234700\n",
      "startIDX:  1513\n",
      "648 5 True\n",
      "x_t:  0 [0.85       0.39166667 0.065625   0.33333333]\n",
      "Q values:  tensor([[-6.3206, -5.7096, -6.8289, -5.7155, -5.6988, -5.2572]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13513 452 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 648: ep_len:452 episode reward: total was -47.400000. running mean: -58.126353\n",
      "startIDX:  970\n",
      "648 10 True\n",
      "x_t:  1 [0.1125     0.33333333 0.153125   0.39583333]\n",
      "Q values:  tensor([[-8.4746, -8.4362, -7.9679, -8.1400, -8.0005, -6.8153]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11419 1604 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 648: ep_len:1604 episode reward: total was -158.300000. running mean: -59.128090\n",
      "startIDX:  1741\n",
      "648 12 True\n",
      "x_t:  1 [0.109375   0.35833333 0.078125   0.36666667]\n",
      "Q values:  tensor([[-8.0989, -6.9946, -8.3436, -8.0867, -7.9460, -6.4575]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19881 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 648: ep_len:203 episode reward: total was -14.200000. running mean: -58.678809\n",
      "startIDX:  3064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 648: ep_len:53 episode reward: total was 45.000000. running mean: -57.642021\n",
      "startIDX:  90\n",
      "648 22 True\n",
      "x_t:  1 [0.934375   0.2875     0.0625     0.41666667]\n",
      "Q values:  tensor([[-5.5914, -4.8205, -5.5286, -5.3477, -5.4270, -4.8458]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1575 677 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 648: ep_len:677 episode reward: total was -27.900000. running mean: -57.344601\n",
      "startIDX:  1493\n",
      "649 0 True\n",
      "x_t:  3 [0.653125   0.32916667 0.096875   0.38333333]\n",
      "Q values:  tensor([[-5.3414, -6.0771, -5.8350, -5.4906, -5.9565, -4.5956]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16838 272 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1061\n",
      "649 1 True\n",
      "x_t:  3 [0.58125    0.29166667 0.09375    0.35833333]\n",
      "Q values:  tensor([[-7.6287, -7.4345, -8.3185, -6.8866, -7.4566, -5.7849]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35945 214 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2838\n",
      "startIDX:  2344\n",
      "649 10 True\n",
      "x_t:  1 [0.78125  0.2875   0.140625 0.3375  ]\n",
      "Q values:  tensor([[-7.6061, -7.0430, -8.3583, -7.1060, -8.0399, -7.1124]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22478 1220 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1086\n",
      "649 12 True\n",
      "x_t:  3 [0.190625   0.28333333 0.09375    0.31666667]\n",
      "Q values:  tensor([[-9.0991, -8.1191, -8.5044, -8.3092, -9.0166, -7.4577]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16403 1388 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1672\n",
      "649 15 True\n",
      "x_t:  1 [0.53125    0.32083333 0.084375   0.35833333]\n",
      "Q values:  tensor([[-5.8520, -5.3722, -6.5659, -5.5658, -5.6925, -4.7804]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12503 276 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2385\n",
      "649 22 True\n",
      "x_t:  1 [0.415625   0.33333333 0.084375   0.45416667]\n",
      "Q values:  tensor([[-6.6774, -6.1897, -6.3896, -6.3439, -6.6836, -5.4405]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22977 1043 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  5933.327566385269\n",
      "startIDX:  1386\n",
      "650 0 True\n",
      "x_t:  4 [0.003125 0.4      0.09375  0.275   ]\n",
      "Q values:  tensor([[-5.0118, -5.3815, -5.9435, -4.7257, -4.9003, -4.4461]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16284 535 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 650: ep_len:535 episode reward: total was -62.800000. running mean: -56.236622\n",
      "startIDX:  1017\n",
      "650 1 True\n",
      "x_t:  3 [0.5625     0.28333333 0.090625   0.35833333]\n",
      "Q values:  tensor([[-5.1035, -5.6225, -5.9763, -5.4186, -5.9133, -4.4262]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35948 241 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 650: ep_len:241 episode reward: total was -5.400000. running mean: -55.728256\n",
      "startIDX:  2859\n",
      "ep 650: ep_len:108 episode reward: total was 52.000000. running mean: -54.650973\n",
      "startIDX:  2611\n",
      "ep 650: ep_len:13 episode reward: total was -9.000000. running mean: -54.194463\n",
      "startIDX:  121\n",
      "650 12 True\n",
      "x_t:  2 [0.803125   0.40833333 0.0875     0.24583333]\n",
      "Q values:  tensor([[-5.4304, -5.3647, -5.2424, -5.2534, -5.8219, -4.7474]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2806 873 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 650: ep_len:873 episode reward: total was -85.300000. running mean: -54.505519\n",
      "startIDX:  522\n",
      "650 15 True\n",
      "x_t:  1 [0.93125    0.29583333 0.05625    0.27916667]\n",
      "Q values:  tensor([[-5.7570, -5.1663, -5.5029, -5.1700, -6.0642, -4.5280]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5163 724 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 650: ep_len:724 episode reward: total was -8.300000. running mean: -54.043464\n",
      "startIDX:  1495\n",
      "650 22 True\n",
      "x_t:  4 [0.128125   0.3875     0.071875   0.30416667]\n",
      "Q values:  tensor([[-5.0261, -4.9419, -5.2965, -5.2372, -4.9394, -4.2132]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16342 537 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 650: ep_len:537 episode reward: total was -69.900000. running mean: -54.202029\n",
      "startIDX:  1483\n",
      "651 0 False\n",
      "x_t:  3 [0.803125   0.34166667 0.159375   0.4125    ]\n",
      "Q values:  tensor([[-4.4678, -4.0665, -4.1607, -3.6970, -4.6614, -3.7107]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16819 264 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  34\n",
      "651 1 True\n",
      "x_t:  3 [0.45       0.25833333 0.09375    0.3625    ]\n",
      "Q values:  tensor([[-5.4666, -4.8823, -5.2531, -5.2524, -5.2819, -4.3148]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25695 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2699\n",
      "651 5 True\n",
      "x_t:  1 [0.06875    0.35833333 0.20625    0.50833333]\n",
      "Q values:  tensor([[-4.7539, -4.2720, -4.5043, -4.1910, -4.0410, -3.5549]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22113 231 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1211\n",
      "651 10 True\n",
      "x_t:  3 [0.5        0.275      0.090625   0.35833333]\n",
      "Q values:  tensor([[-6.0526, -6.2584, -6.9029, -6.2290, -6.5501, -5.5897]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14687 1301 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1024\n",
      "651 12 True\n",
      "x_t:  2 [0.365625   0.40833333 0.040625   0.25      ]\n",
      "Q values:  tensor([[-5.1109, -4.5239, -5.0842, -5.2451, -4.8393, -4.1480]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13644 323 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1738\n",
      "651 15 True\n",
      "x_t:  1 [0.209375   0.34583333 0.078125   0.37916667]\n",
      "Q values:  tensor([[-3.8652, -4.1252, -4.4446, -4.1786, -4.6103, -3.3835]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12467 220 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  272\n",
      "651 22 True\n",
      "x_t:  3 [0.109375   0.25       0.078125   0.24583333]\n",
      "Q values:  tensor([[-6.6419, -6.5296, -6.6618, -6.0403, -6.5192, -5.2689]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4888 1296 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1162\n",
      "652 0 True\n",
      "x_t:  2 [0.778125   0.4125     0.103125   0.27083333]\n",
      "Q values:  tensor([[-4.2712, -4.4836, -4.4737, -4.3010, -4.6716, -3.8512]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12631 304 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 652: ep_len:304 episode reward: total was -22.800000. running mean: -54.591204\n",
      "startIDX:  771\n",
      "652 1 False\n",
      "x_t:  3 [0.396875   0.27916667 0.096875   0.36666667]\n",
      "Q values:  tensor([[-5.1157, -4.8722, -5.8328, -4.5435, -5.0932, -4.6483]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34392 1398 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 652: ep_len:1398 episode reward: total was -132.100000. running mean: -55.366292\n",
      "startIDX:  2382\n",
      "652 5 False\n",
      "x_t:  1 [0.059375   0.35       0.184375   0.52083333]\n",
      "Q values:  tensor([[-5.0853, -5.0204, -6.0444, -5.2953, -5.9530, -5.1881]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22110 1242 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 652: ep_len:1242 episode reward: total was -200.200000. running mean: -56.814629\n",
      "startIDX:  853\n",
      "652 10 True\n",
      "x_t:  0 [0.603125   0.4        0.096875   0.29166667]\n",
      "Q values:  tensor([[-5.2569, -4.7277, -5.0719, -5.3039, -4.8949, -4.2107]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8156 476 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 652: ep_len:476 episode reward: total was -50.200000. running mean: -56.748483\n",
      "startIDX:  1319\n",
      "652 12 True\n",
      "x_t:  3 [0.684375   0.35       0.14375    0.42916667]\n",
      "Q values:  tensor([[-4.4539, -4.5633, -4.8303, -4.8179, -4.7702, -3.9159]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17861 230 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 652: ep_len:230 episode reward: total was 4.700000. running mean: -56.133998\n",
      "startIDX:  2074\n",
      "652 15 True\n",
      "x_t:  2 [0.371875   0.40833333 0.046875   0.25833333]\n",
      "Q values:  tensor([[-4.3260, -4.9270, -5.1977, -4.2757, -5.0232, -4.0719]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15635 406 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 652: ep_len:406 episode reward: total was -108.000000. running mean: -56.652658\n",
      "startIDX:  2131\n",
      "652 22 True\n",
      "x_t:  0 [0.6875     0.40833333 0.0625     0.3125    ]\n",
      "Q values:  tensor([[-4.8766, -5.0066, -5.0248, -4.7796, -5.0775, -4.5976]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20763 878 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 652: ep_len:878 episode reward: total was -124.400000. running mean: -57.330131\n",
      "startIDX:  2176\n",
      "653 0 True\n",
      "x_t:  1 [0.546875   0.3375     0.19375    0.49166667]\n",
      "Q values:  tensor([[-6.2016, -6.7506, -5.8619, -6.8778, -6.6254, -5.4561]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22940 1117 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  779\n",
      "653 1 True\n",
      "x_t:  3 [0.10625    0.2375     0.0875     0.30416667]\n",
      "Q values:  tensor([[-8.2962, -7.8837, -8.0676, -8.1047, -8.2262, -6.9381]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34323 1372 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2934\n",
      "startIDX:  562\n",
      "653 10 True\n",
      "x_t:  2 [0.84375    0.4        0.090625   0.25833333]\n",
      "Q values:  tensor([[-7.5582, -7.7017, -8.0520, -7.8423, -8.1170, -6.6678]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6722 807 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  1023\n",
      "653 12 True\n",
      "x_t:  2 [0.621875   0.40416667 0.04375    0.25416667]\n",
      "Q values:  tensor([[-6.4150, -6.4117, -6.4878, -6.3102, -6.6772, -5.4831]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13606 317 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1121\n",
      "653 15 True\n",
      "x_t:  4 [0.0125     0.39583333 0.0875     0.29583333]\n",
      "Q values:  tensor([[-5.4975, -5.8816, -6.1337, -4.9901, -5.8553, -5.1369]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9813 553 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2817\n",
      "startIDX:  117\n",
      "654 0 True\n",
      "x_t:  1 [0.840625 0.3      0.078125 0.425   ]\n",
      "Q values:  tensor([[-5.8601, -5.2496, -6.5703, -5.4585, -5.6685, -5.1879]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1616 701 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 654: ep_len:701 episode reward: total was -74.300000. running mean: -58.066783\n",
      "startIDX:  149\n",
      "654 1 True\n",
      "x_t:  2 [0.11875    0.3625     0.134375   0.44166667]\n",
      "Q values:  tensor([[-7.9217, -7.0407, -7.6574, -7.6169, -8.1905, -6.9678]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27449 890 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 654: ep_len:890 episode reward: total was -156.900000. running mean: -59.055115\n",
      "startIDX:  225\n",
      "654 5 True\n",
      "x_t:  1 [0.0625     0.37083333 0.20625    0.49583333]\n",
      "Q values:  tensor([[-5.3360, -5.8258, -6.1147, -5.7428, -6.4637, -5.3047]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2519 207 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 654: ep_len:207 episode reward: total was -35.600000. running mean: -58.820564\n",
      "startIDX:  1072\n",
      "654 10 True\n",
      "x_t:  2 [0.39375    0.4        0.096875   0.24583333]\n",
      "Q values:  tensor([[-7.0204, -6.2573, -6.8647, -6.6598, -7.0653, -5.8794]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12126 394 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 654: ep_len:394 episode reward: total was -93.100000. running mean: -59.163358\n",
      "startIDX:  1036\n",
      "654 12 True\n",
      "x_t:  2 [0.46875 0.4125  0.10625 0.25   ]\n",
      "Q values:  tensor([[-6.1680, -6.0497, -6.7942, -5.3121, -6.6920, -5.6382]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13623 322 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 654: ep_len:322 episode reward: total was -49.600000. running mean: -59.067725\n",
      "startIDX:  2569\n",
      "654 15 True\n",
      "x_t:  3 [0.2125     0.25416667 0.075      0.2625    ]\n",
      "Q values:  tensor([[-7.6371, -8.1225, -8.3014, -8.4602, -9.2794, -6.9178]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19785 209 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 654: ep_len:209 episode reward: total was -78.700000. running mean: -59.264047\n",
      "startIDX:  2911\n",
      "ep 654: ep_len:54 episode reward: total was 12.000000. running mean: -58.551407\n",
      "startIDX:  2377\n",
      "655 0 False\n",
      "x_t:  3 [0.06875    0.23333333 0.065625   0.24166667]\n",
      "Q values:  tensor([[-9.6088, -8.6440, -9.4024, -7.9156, -9.6082, -8.0464]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26094 1226 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  735\n",
      "655 1 False\n",
      "x_t:  3 [0.10625    0.22916667 0.08125    0.30833333]\n",
      "Q values:  tensor([[-11.2376, -11.1244, -13.1040, -10.3566, -12.0357, -10.4543]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34320 1390 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1290\n",
      "655 5 False\n",
      "x_t:  1 [0.2875     0.325      0.146875   0.37916667]\n",
      "Q values:  tensor([[-9.2560, -8.1089, -9.1094, -8.7356, -9.6921, -8.2956]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12537 976 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1138\n",
      "655 10 True\n",
      "x_t:  2 [0.709375   0.40416667 0.096875   0.2375    ]\n",
      "Q values:  tensor([[-7.1188, -7.6145, -8.0866, -7.5854, -7.7590, -7.1376]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12076 345 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  82\n",
      "655 12 False\n",
      "x_t:  1 [0.809375   0.30416667 0.096875   0.4375    ]\n",
      "Q values:  tensor([[-9.8877, -8.6934, -9.7288, -8.8033, -9.2042, -8.9830]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2224 620 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2492\n",
      "655 15 True\n",
      "x_t:  3 [0.515625   0.29166667 0.071875   0.3125    ]\n",
      "Q values:  tensor([[-12.5215, -11.2792, -12.7713, -13.0150, -12.8303, -10.8772]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19717 214 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2087\n",
      "655 22 False\n",
      "x_t:  1 [0.140625   0.35       0.10625    0.38333333]\n",
      "Q values:  tensor([[-10.1502,  -9.4273, -10.5884,  -9.8283, -10.0617,  -9.7774]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19005 213 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1662\n",
      "656 0 False\n",
      "x_t:  3 [0.321875   0.275      0.084375   0.31666667]\n",
      "Q values:  tensor([[-16.4865, -15.3318, -16.1491, -15.0018, -17.8471, -15.7295]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16893 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 656: ep_len:202 episode reward: total was -89.200000. running mean: -68.896051\n",
      "startIDX:  315\n",
      "656 1 False\n",
      "x_t:  1 [0.496875 0.3      0.240625 0.575   ]\n",
      "Q values:  tensor([[-13.9919, -11.8453, -12.9080, -12.4758, -13.1492, -12.6992]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28099 331 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 656: ep_len:331 episode reward: total was -204.800000. running mean: -70.255090\n",
      "startIDX:  950\n",
      "656 5 False\n",
      "x_t:  3 [0.734375   0.3125     0.178125   0.40416667]\n",
      "Q values:  tensor([[-13.8171, -13.4699, -15.1737, -12.6228, -13.8457, -13.3158]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10496 218 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 656: ep_len:218 episode reward: total was -114.100000. running mean: -70.693539\n",
      "startIDX:  2320\n",
      "656 10 False\n",
      "x_t:  1 [0.884375   0.2875     0.1125     0.34166667]\n",
      "Q values:  tensor([[-25.9703, -24.4224, -26.9506, -26.0321, -26.2754, -25.5483]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22467 1242 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 656: ep_len:1242 episode reward: total was -723.100000. running mean: -77.217604\n",
      "startIDX:  997\n",
      "656 12 False\n",
      "x_t:  2 [0.8        0.4125     0.09375    0.24583333]\n",
      "Q values:  tensor([[-16.7395, -17.8328, -15.5359, -16.8904, -18.2498, -15.5774]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13573 319 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 656: ep_len:319 episode reward: total was -179.900000. running mean: -78.244428\n",
      "startIDX:  179\n",
      "656 15 True\n",
      "x_t:  2 [0.028125   0.40416667 0.11875    0.3375    ]\n",
      "Q values:  tensor([[-22.6419, -21.4008, -22.8344, -21.8021, -23.8888, -21.2896]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2199 826 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 656: ep_len:826 episode reward: total was -541.800000. running mean: -82.879984\n",
      "startIDX:  2868\n",
      "ep 656: ep_len:71 episode reward: total was -15.000000. running mean: -82.201184\n",
      "startIDX:  955\n",
      "657 0 False\n",
      "x_t:  1 [0.79375    0.31666667 0.175      0.425     ]\n",
      "Q values:  tensor([[-34.6698, -34.3848, -36.4415, -38.2588, -35.6583, -35.6013]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11953 825 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  565\n",
      "657 1 False\n",
      "x_t:  1 [0.625      0.27083333 0.171875   0.46666667]\n",
      "Q values:  tensor([[-35.0285, -30.9094, -33.1834, -35.6661, -34.7704, -33.4686]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30703 732 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2393\n",
      "657 5 False\n",
      "x_t:  2 [0.0375     0.39583333 0.10625    0.27916667]\n",
      "Q values:  tensor([[-41.9337, -38.2860, -35.8449, -42.0331, -37.2411, -37.9048]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21553 953 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  499\n",
      "657 10 False\n",
      "x_t:  3 [0.0625     0.22916667 0.059375   0.2375    ]\n",
      "Q values:  tensor([[-29.6554, -30.6223, -31.2608, -28.8735, -30.8604, -28.9643]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5193 208 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  789\n",
      "657 12 False\n",
      "x_t:  0 [0.9125     0.40416667 0.08125    0.3125    ]\n",
      "Q values:  tensor([[-25.9968, -27.6745, -28.6773, -27.4357, -27.4061, -28.5368]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11630 672 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  583\n",
      "657 15 True\n",
      "x_t:  1 [0.91875    0.29583333 0.065625   0.28333333]\n",
      "Q values:  tensor([[-27.3302, -25.5410, -28.4573, -27.0215, -25.1495, -24.7308]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5164 694 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2410\n",
      "657 22 True\n",
      "x_t:  2 [0.903125   0.4        0.0375     0.17083333]\n",
      "Q values:  tensor([[-22.1929, -21.3025, -23.5955, -20.6204, -21.1876, -21.8311]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23626 341 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1993\n",
      "658 0 True\n",
      "x_t:  1 [0.003125 0.3875   0.18125  0.4     ]\n",
      "Q values:  tensor([[-26.7445, -26.1719, -26.4160, -23.8699, -27.5195, -25.9420]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18926 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 658: ep_len:200 episode reward: total was -136.600000. running mean: -103.067063\n",
      "startIDX:  660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658 1 False\n",
      "x_t:  2 [0.725      0.37916667 0.0875     0.31666667]\n",
      "Q values:  tensor([[-23.3017, -23.7014, -21.6062, -22.6127, -24.9707, -22.9258]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31478 364 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 658: ep_len:364 episode reward: total was -267.400000. running mean: -104.710393\n",
      "startIDX:  713\n",
      "658 5 False\n",
      "x_t:  3 [0.0625     0.25833333 0.075      0.3125    ]\n",
      "Q values:  tensor([[-39.7917, -39.3171, -40.2810, -35.5963, -37.9191, -38.7985]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8746 1300 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 658: ep_len:1300 episode reward: total was -1013.500000. running mean: -113.798289\n",
      "startIDX:  113\n",
      "658 10 False\n",
      "x_t:  3 [0.059375   0.24166667 0.05625    0.25      ]\n",
      "Q values:  tensor([[-29.3733, -29.5777, -30.9006, -29.2252, -31.1863, -29.9172]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3577 1076 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 658: ep_len:1076 episode reward: total was -846.500000. running mean: -121.125306\n",
      "startIDX:  626\n",
      "658 12 False\n",
      "x_t:  2 [0.0625     0.40416667 0.053125   0.25833333]\n",
      "Q values:  tensor([[-35.1915, -32.1702, -32.0569, -34.1957, -33.5483, -32.3584]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9835 1014 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 658: ep_len:1014 episode reward: total was -771.200000. running mean: -127.626053\n",
      "startIDX:  2174\n",
      "658 15 False\n",
      "x_t:  2 [0.7625     0.40833333 0.075      0.26666667]\n",
      "Q values:  tensor([[-30.1967, -30.6230, -29.7105, -30.7425, -33.8167, -29.9826]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15573 322 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 658: ep_len:322 episode reward: total was -239.600000. running mean: -128.745792\n",
      "startIDX:  2708\n",
      "658 22 False\n",
      "x_t:  4 [0.0875     0.40416667 0.125      0.3       ]\n",
      "Q values:  tensor([[-31.8267, -33.4235, -31.0653, -33.1057, -30.7722, -30.8796]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27279 514 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 658: ep_len:514 episode reward: total was -320.300000. running mean: -130.661334\n",
      "startIDX:  1930\n",
      "659 0 False\n",
      "x_t:  1 [0.071875   0.3625     0.115625   0.41666667]\n",
      "Q values:  tensor([[-32.9540, -32.0703, -38.2831, -34.7726, -34.5060, -35.6474]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18930 234 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  347\n",
      "659 1 True\n",
      "x_t:  1 [0.771875   0.27916667 0.153125   0.59166667]\n",
      "Q values:  tensor([[-28.9165, -29.6546, -28.2660, -31.1217, -29.7595, -28.4410]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28118 311 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1331\n",
      "659 5 False\n",
      "x_t:  1 [0.39375    0.30833333 0.109375   0.375     ]\n",
      "Q values:  tensor([[-28.5301, -27.1737, -27.3056, -28.2142, -28.9536, -28.2000]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12545 255 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1452\n",
      "659 10 True\n",
      "x_t:  4 [0.003125   0.36666667 0.075      0.2875    ]\n",
      "Q values:  tensor([[-24.8490, -22.7352, -22.6672, -25.3434, -24.4937, -23.2496]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15702 496 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  626\n",
      "659 12 False\n",
      "x_t:  2 [0.003125   0.4125     0.06875    0.25416667]\n",
      "Q values:  tensor([[-30.7466, -29.2525, -28.9210, -30.5584, -32.2703, -29.0214]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9824 1001 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2968\n",
      "startIDX:  2252\n",
      "659 22 False\n",
      "x_t:  1 [0.7625     0.31666667 0.13125    0.45416667]\n",
      "Q values:  tensor([[-28.0807, -25.8682, -27.4428, -27.7730, -26.9385, -26.8451]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22941 1078 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  6016.658202648163\n",
      "startIDX:  257\n",
      "660 0 True\n",
      "x_t:  3 [0.1125     0.2375     0.0625     0.25416667]\n",
      "Q values:  tensor([[-32.6618, -32.8657, -29.8036, -31.1758, -31.6598, -29.9759]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4855 1266 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 660: ep_len:1266 episode reward: total was -885.300000. running mean: -150.876918\n",
      "startIDX:  409\n",
      "660 1 False\n",
      "x_t:  0 [0.56875    0.37916667 0.128125   0.40833333]\n",
      "Q values:  tensor([[-21.2955, -23.0891, -28.0398, -23.1689, -22.1093, -23.5612]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29146 521 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 660: ep_len:521 episode reward: total was -371.100000. running mean: -153.079149\n",
      "startIDX:  180\n",
      "660 5 False\n",
      "x_t:  2 [0.003125   0.38333333 0.146875   0.44166667]\n",
      "Q values:  tensor([[-32.0854, -32.1558, -28.8202, -30.9112, -31.5141, -31.2287]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2056 843 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 660: ep_len:843 episode reward: total was -612.400000. running mean: -157.672358\n",
      "startIDX:  1575\n",
      "660 10 True\n",
      "x_t:  3 [0.721875   0.3        0.09375    0.37916667]\n",
      "Q values:  tensor([[-32.9885, -31.5460, -31.1372, -30.8581, -35.1351, -31.0953]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16422 301 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 660: ep_len:301 episode reward: total was -61.600000. running mean: -156.711634\n",
      "startIDX:  982\n",
      "660 12 False\n",
      "x_t:  2 [0.8875     0.39166667 0.0625     0.22083333]\n",
      "Q values:  tensor([[-27.1747, -26.3116, -25.6280, -26.1862, -26.7219, -26.0760]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13565 330 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 660: ep_len:330 episode reward: total was -184.000000. running mean: -156.984518\n",
      "startIDX:  731\n",
      "660 15 False\n",
      "x_t:  2 [0.784375   0.40833333 0.090625   0.29166667]\n",
      "Q values:  tensor([[-27.7649, -29.1296, -25.2233, -29.2912, -26.3920, -27.9427]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5968 361 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 660: ep_len:361 episode reward: total was -208.400000. running mean: -157.498673\n",
      "startIDX:  1249\n",
      "660 22 False\n",
      "x_t:  2 [0.846875   0.39583333 0.065625   0.23333333]\n",
      "Q values:  tensor([[-27.3396, -24.1518, -23.5415, -25.7328, -24.4975, -24.9625]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12582 321 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 660: ep_len:321 episode reward: total was -157.200000. running mean: -157.495686\n",
      "startIDX:  320\n",
      "661 0 True\n",
      "x_t:  3 [0.059375   0.23333333 0.0625     0.22916667]\n",
      "Q values:  tensor([[-33.4510, -36.2441, -39.3259, -34.8087, -33.5904, -33.4008]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4830 1246 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1189\n",
      "startIDX:  2691\n",
      "661 5 False\n",
      "x_t:  1 [0.271875   0.34166667 0.15625    0.51666667]\n",
      "Q values:  tensor([[-24.4439, -21.5640, -22.0029, -23.1520, -24.5380, -24.9260]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22129 240 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  429\n",
      "661 10 False\n",
      "x_t:  3 [0.434375   0.275      0.121875   0.32916667]\n",
      "Q values:  tensor([[-22.6233, -22.8240, -25.4543, -21.8110, -24.9723, -23.0847]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5090 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  518\n",
      "661 12 False\n",
      "x_t:  2 [0.29375    0.4125     0.059375   0.25833333]\n",
      "Q values:  tensor([[-31.0698, -29.7384, -27.6115, -31.1938, -29.2807, -29.3533]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9871 1071 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1707\n",
      "661 15 True\n",
      "x_t:  1 [0.303125   0.3375     0.09375    0.36666667]\n",
      "Q values:  tensor([[-22.3926, -22.8314, -23.8829, -24.3165, -24.1254, -21.8116]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12479 249 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  961\n",
      "661 22 False\n",
      "x_t:  0 [0.834375   0.40416667 0.10625    0.33333333]\n",
      "Q values:  tensor([[-29.0660, -31.7526, -32.2161, -31.9732, -29.5017, -29.9113]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10410 464 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1851\n",
      "662 0 True\n",
      "x_t:  2 [0.065625   0.40416667 0.065625   0.25416667]\n",
      "Q values:  tensor([[-24.2262, -27.6711, -27.2025, -25.9936, -24.7100, -26.1410]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18400 715 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 662: ep_len:715 episode reward: total was -443.700000. running mean: -170.499983\n",
      "startIDX:  517\n",
      "662 1 False\n",
      "x_t:  1 [0.765625   0.275      0.15625    0.45416667]\n",
      "Q values:  tensor([[-30.2952, -28.3615, -31.9930, -29.2699, -28.9206, -28.4816]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30689 754 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 662: ep_len:754 episode reward: total was -442.500000. running mean: -173.219984\n",
      "startIDX:  448\n",
      "662 5 False\n",
      "x_t:  1 [0.884375   0.26666667 0.109375   0.4       ]\n",
      "Q values:  tensor([[-27.2397, -25.5852, -29.6886, -27.2722, -25.8506, -27.0926]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5024 664 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 662: ep_len:664 episode reward: total was -386.200000. running mean: -175.349784\n",
      "startIDX:  959\n",
      "662 10 False\n",
      "x_t:  1 [0.85       0.2875     0.128125   0.33333333]\n",
      "Q values:  tensor([[-28.0767, -25.2008, -29.6245, -27.9930, -27.3655, -27.8054]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11331 1564 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 662: ep_len:1564 episode reward: total was -926.800000. running mean: -182.864286\n",
      "startIDX:  1225\n",
      "662 12 False\n",
      "x_t:  4 [0.278125   0.4125     0.10625    0.36666667]\n",
      "Q values:  tensor([[-23.8056, -23.5351, -22.0394, -22.4880, -21.4609, -22.6812]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17420 501 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 662: ep_len:501 episode reward: total was -295.800000. running mean: -183.993643\n",
      "startIDX:  2735\n",
      "662 15 True\n",
      "x_t:  2 [0.05625    0.40416667 0.078125   0.33333333]\n",
      "Q values:  tensor([[-24.9082, -24.5895, -25.9606, -23.4259, -24.8050, -22.6064]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21480 833 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 662: ep_len:833 episode reward: total was -490.600000. running mean: -187.059707\n",
      "startIDX:  2198\n",
      "662 22 False\n",
      "x_t:  0 [0.90625    0.40833333 0.0875     0.32916667]\n",
      "Q values:  tensor([[-20.9077, -21.0083, -21.2533, -21.0158, -21.7782, -21.1722]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20690 805 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 662: ep_len:805 episode reward: total was -508.600000. running mean: -190.275110\n",
      "startIDX:  234\n",
      "663 0 False\n",
      "x_t:  2 [0.803125   0.40833333 0.115625   0.27083333]\n",
      "Q values:  tensor([[-23.4450, -22.4548, -21.8263, -24.0197, -23.4626, -22.6942]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2317 319 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  16\n",
      "663 1 True\n",
      "x_t:  3 [0.540625   0.26666667 0.096875   0.375     ]\n",
      "Q values:  tensor([[-19.3052, -16.3780, -19.6819, -17.7248, -17.8569, -19.2683]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25679 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1247\n",
      "663 5 False\n",
      "x_t:  2 [0.13125    0.3875     0.0625     0.27916667]\n",
      "Q values:  tensor([[-21.4780, -21.8389, -20.8470, -21.9058, -22.8292, -20.9352]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12021 739 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1006\n",
      "663 10 False\n",
      "x_t:  1 [0.934375   0.27083333 0.059375   0.35416667]\n",
      "Q values:  tensor([[-28.2404, -25.1561, -27.3486, -27.2746, -27.9445, -27.3807]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11323 1550 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1507\n",
      "663 12 True\n",
      "x_t:  2 [0.059375   0.40833333 0.075      0.28333333]\n",
      "Q values:  tensor([[-28.2014, -27.5177, -24.7134, -26.4145, -26.8217, -24.3962]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19386 756 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  948\n",
      "663 15 True\n",
      "x_t:  4 [0.384375 0.3625   0.065625 0.225   ]\n",
      "Q values:  tensor([[-28.2699, -28.9428, -27.4252, -27.2875, -31.4331, -26.7658]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9936 696 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  42\n",
      "663 22 False\n",
      "x_t:  1 [0.875      0.29583333 0.121875   0.41666667]\n",
      "Q values:  tensor([[-17.4851, -17.2024, -17.7673, -17.6198, -18.4446, -17.2083]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1577 714 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  924\n",
      "664 0 True\n",
      "x_t:  0 [0.88125    0.4        0.1125     0.37083333]\n",
      "Q values:  tensor([[-17.5810, -18.9061, -17.3436, -18.0730, -18.8388, -17.1553]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10331 423 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 664: ep_len:423 episode reward: total was -107.000000. running mean: -198.163459\n",
      "startIDX:  326\n",
      "664 1 False\n",
      "x_t:  1 [0.609375   0.29583333 0.20625    0.58333333]\n",
      "Q values:  tensor([[-16.2493, -14.8263, -17.4065, -16.9767, -16.3493, -15.4051]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28105 315 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 664: ep_len:315 episode reward: total was -82.200000. running mean: -197.003824\n",
      "startIDX:  2396\n",
      "664 5 False\n",
      "x_t:  2 [0.090625   0.3875     0.071875   0.27083333]\n",
      "Q values:  tensor([[-14.4012, -14.5471, -12.9676, -13.4930, -14.6574, -13.1993]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21561 967 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 664: ep_len:967 episode reward: total was -185.600000. running mean: -196.889786\n",
      "startIDX:  1012\n",
      "664 10 True\n",
      "x_t:  1 [0.3625     0.3125     0.11875    0.35833333]\n",
      "Q values:  tensor([[-14.6206, -14.8116, -13.7853, -14.5436, -15.6647, -13.1503]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11393 1551 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 664: ep_len:1551 episode reward: total was -299.500000. running mean: -197.915888\n",
      "startIDX:  1652\n",
      "664 12 True\n",
      "x_t:  0 [0.565625   0.4        0.084375   0.34166667]\n",
      "Q values:  tensor([[-13.0461, -12.5174, -12.8623, -12.5279, -12.1686, -11.2455]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21135 872 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 664: ep_len:872 episode reward: total was -200.500000. running mean: -197.941729\n",
      "startIDX:  1914\n",
      "664 15 True\n",
      "x_t:  1 [0.003125   0.36666667 0.06875    0.35416667]\n",
      "Q values:  tensor([[ -9.9270, -10.7759, -10.0971, -10.3043, -10.5973,  -9.0474]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14953 775 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 664: ep_len:775 episode reward: total was -113.500000. running mean: -197.097312\n",
      "startIDX:  2223\n",
      "664 22 True\n",
      "x_t:  1 [0.71875    0.325      0.1125     0.43333333]\n",
      "Q values:  tensor([[-9.4464, -9.8784, -9.0589, -9.9127, -9.5112, -8.7746]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22948 1113 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 664: ep_len:1113 episode reward: total was -180.500000. running mean: -196.931339\n",
      "startIDX:  1577\n",
      "665 0 False\n",
      "x_t:  3 [0.421875   0.30833333 0.11875    0.34166667]\n",
      "Q values:  tensor([[-8.6502, -8.3140, -8.6309, -7.5521, -8.8326, -7.6173]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16870 241 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  454\n",
      "665 1 True\n",
      "x_t:  1 [0.734375 0.2875   0.15625  0.45    ]\n",
      "Q values:  tensor([[-6.6880, -6.2910, -6.2855, -6.1476, -7.1730, -5.6070]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30695 794 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2099\n",
      "665 5 False\n",
      "x_t:  4 [0.328125   0.39166667 0.084375   0.40833333]\n",
      "Q values:  tensor([[-5.2794, -4.7318, -4.8432, -5.1999, -4.4139, -4.4892]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19492 635 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  989\n",
      "665 10 True\n",
      "x_t:  2 [0.7875     0.40416667 0.1        0.24166667]\n",
      "Q values:  tensor([[-7.3896, -7.5417, -6.6646, -7.1999, -7.6920, -6.2433]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12062 1935 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1323\n",
      "665 12 True\n",
      "x_t:  3 [0.5125     0.325      0.121875   0.38333333]\n",
      "Q values:  tensor([[-6.9870, -6.5290, -6.4316, -6.0168, -6.5541, -5.4716]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17884 235 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1927\n",
      "665 15 True\n",
      "x_t:  1 [0.41875    0.31666667 0.075      0.31666667]\n",
      "Q values:  tensor([[-5.9559, -6.0355, -5.7390, -5.7962, -6.0599, -5.1183]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14904 742 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  283\n",
      "665 22 False\n",
      "x_t:  3 [0.078125   0.24583333 0.071875   0.24583333]\n",
      "Q values:  tensor([[-5.2318, -4.5884, -5.3622, -4.4656, -5.0003, -4.4902]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4878 1285 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  547\n",
      "666 0 True\n",
      "x_t:  3 [0.809375 0.375    0.109375 0.45    ]\n",
      "Q values:  tensor([[-5.2873, -4.9537, -5.0453, -5.2788, -5.2387, -4.3251]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 6997 980 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 666: ep_len:980 episode reward: total was -35.300000. running mean: -186.666433\n",
      "startIDX:  1115\n",
      "666 1 True\n",
      "x_t:  3 [0.465625 0.275    0.071875 0.3375  ]\n",
      "Q values:  tensor([[-6.0309, -5.9438, -5.7804, -5.8324, -6.2064, -4.9597]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35970 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 666: ep_len:201 episode reward: total was -46.500000. running mean: -185.264768\n",
      "startIDX:  1620\n",
      "666 5 False\n",
      "x_t:  2 [0.340625   0.4        0.078125   0.24166667]\n",
      "Q values:  tensor([[-4.6875, -4.2288, -4.0992, -4.5894, -4.8375, -4.1703]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15724 1069 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 666: ep_len:1069 episode reward: total was -204.100000. running mean: -185.453121\n",
      "startIDX:  867\n",
      "666 10 True\n",
      "x_t:  0 [0.678125   0.40416667 0.0875     0.29583333]\n",
      "Q values:  tensor([[-4.2692, -4.4613, -4.2097, -4.6424, -4.7422, -3.8062]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8141 460 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 666: ep_len:460 episode reward: total was -45.400000. running mean: -184.052589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  975\n",
      "666 12 True\n",
      "x_t:  2 [0.48125    0.41666667 0.09375    0.24583333]\n",
      "Q values:  tensor([[-4.2267, -4.4978, -4.4956, -4.3339, -4.5899, -3.7355]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13622 356 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 666: ep_len:356 episode reward: total was -30.200000. running mean: -182.514063\n",
      "startIDX:  1378\n",
      "666 15 True\n",
      "x_t:  3 [0.60625    0.32083333 0.109375   0.34166667]\n",
      "Q values:  tensor([[-3.6004, -3.3842, -3.4840, -3.3601, -3.7519, -2.9356]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10375 212 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 666: ep_len:212 episode reward: total was -11.900000. running mean: -180.807923\n",
      "startIDX:  230\n",
      "666 22 True\n",
      "x_t:  2 [0.375      0.40833333 0.05625    0.25      ]\n",
      "Q values:  tensor([[-3.1064, -3.2435, -2.8295, -3.2459, -3.2457, -2.6312]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2357 366 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 666: ep_len:366 episode reward: total was -52.800000. running mean: -179.527844\n",
      "startIDX:  1004\n",
      "667 0 False\n",
      "x_t:  2 [0.6875     0.4125     0.1125     0.28333333]\n",
      "Q values:  tensor([[-4.4464, -4.6196, -3.8640, -4.8249, -4.6609, -3.9853]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12647 1121 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  617\n",
      "667 1 True\n",
      "x_t:  2 [0.44375    0.3875     0.06875    0.30416667]\n",
      "Q values:  tensor([[-3.7380, -3.8950, -3.7696, -4.0511, -3.7455, -3.0177]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31523 397 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  986\n",
      "667 5 True\n",
      "x_t:  3 [0.30625    0.25416667 0.103125   0.30416667]\n",
      "Q values:  tensor([[-3.8351, -3.7874, -3.5156, -3.6493, -4.0308, -3.1269]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10562 235 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1449\n",
      "667 10 True\n",
      "x_t:  4 [0.446875 0.3375   0.059375 0.2375  ]\n",
      "Q values:  tensor([[-3.8391, -4.2290, -4.1215, -4.0484, -4.3034, -3.5751]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15875 583 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1407\n",
      "667 12 False\n",
      "x_t:  3 [0.50625    0.32083333 0.121875   0.38333333]\n",
      "Q values:  tensor([[-5.1161, -4.5332, -5.1083, -4.2166, -5.1712, -4.2431]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17885 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1252\n",
      "667 15 True\n",
      "x_t:  3 [0.54375    0.29583333 0.11875    0.33333333]\n",
      "Q values:  tensor([[-4.2102, -3.9127, -4.1899, -3.7964, -4.2707, -3.3082]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10388 266 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3002\n",
      "startIDX:  515\n",
      "668 0 True\n",
      "x_t:  3 [0.13125    0.27916667 0.090625   0.3       ]\n",
      "Q values:  tensor([[-5.3339, -5.7036, -6.0971, -5.2104, -5.7250, -4.5567]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7119 1084 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 668: ep_len:1084 episode reward: total was -103.300000. running mean: -168.445486\n",
      "startIDX:  602\n",
      "668 1 True\n",
      "x_t:  2 [0.553125   0.3875     0.10625    0.30833333]\n",
      "Q values:  tensor([[-4.5816, -4.2963, -4.5312, -4.5248, -4.3930, -3.9359]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31503 403 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 668: ep_len:403 episode reward: total was -40.300000. running mean: -167.164031\n",
      "startIDX:  2321\n",
      "668 5 True\n",
      "x_t:  3 [0.059375   0.24583333 0.08125    0.27083333]\n",
      "Q values:  tensor([[-5.0438, -5.1569, -5.2544, -4.4908, -4.8525, -4.0868]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 20016 219 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 668: ep_len:219 episode reward: total was -14.400000. running mean: -165.636391\n",
      "startIDX:  2220\n",
      "668 10 True\n",
      "x_t:  0 [0.621875 0.4      0.075    0.3125  ]\n",
      "Q values:  tensor([[-6.8447, -6.5516, -6.1716, -6.2417, -7.1690, -5.3764]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20001 526 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 668: ep_len:526 episode reward: total was -75.700000. running mean: -164.737027\n",
      "startIDX:  812\n",
      "668 12 True\n",
      "x_t:  1 [0.8125     0.35416667 0.146875   0.52083333]\n",
      "Q values:  tensor([[-7.7247, -8.0610, -8.1272, -8.2067, -8.6647, -7.3601]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12917 1293 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 668: ep_len:1293 episode reward: total was -140.100000. running mean: -164.490657\n",
      "startIDX:  1064\n",
      "668 15 True\n",
      "x_t:  4 [0.25625  0.3625   0.059375 0.2125  ]\n",
      "Q values:  tensor([[-7.3641, -6.7762, -6.9389, -7.0608, -6.8634, -5.9946]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9971 668 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 668: ep_len:668 episode reward: total was -147.100000. running mean: -164.316750\n",
      "startIDX:  206\n",
      "668 22 True\n",
      "x_t:  2 [0.5        0.40416667 0.05625    0.25833333]\n",
      "Q values:  tensor([[-6.2667, -5.5323, -5.9089, -5.8729, -6.1392, -5.1707]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2334 344 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 668: ep_len:344 episode reward: total was -48.200000. running mean: -163.155583\n",
      "startIDX:  2098\n",
      "669 0 True\n",
      "x_t:  1 [0.2375     0.35416667 0.14375    0.50833333]\n",
      "Q values:  tensor([[-12.8123, -10.4831, -11.3878, -11.7907, -12.2492, -10.0823]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22966 1964 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  500\n",
      "669 1 True\n",
      "x_t:  1 [0.61875    0.2875     0.178125   0.45416667]\n",
      "Q values:  tensor([[-9.9551, -8.8218, -8.8576, -9.1719, -9.5128, -8.1989]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30704 762 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3048\n",
      "startIDX:  556\n",
      "669 10 False\n",
      "x_t:  2 [0.575      0.4        0.071875   0.25833333]\n",
      "Q values:  tensor([[-7.9743, -6.9095, -6.0001, -6.9377, -7.3376, -6.3191]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6676 778 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1909\n",
      "669 12 True\n",
      "x_t:  0 [0.240625   0.425      0.0625     0.29166667]\n",
      "Q values:  tensor([[-8.5511, -7.4956, -6.7736, -7.2402, -7.8099, -6.6651]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 22993 904 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1952\n",
      "669 15 False\n",
      "x_t:  1 [0.890625   0.2875     0.059375   0.31666667]\n",
      "Q values:  tensor([[-7.4827, -6.6390, -7.3328, -7.7177, -7.9139, -6.6693]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14844 709 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1030\n",
      "669 22 True\n",
      "x_t:  0 [0.928125   0.40416667 0.0625     0.3375    ]\n",
      "Q values:  tensor([[-6.0111, -5.7438, -5.9637, -6.1951, -5.9301, -5.0067]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10400 413 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  6112.811817884445\n",
      "startIDX:  2031\n",
      "670 0 True\n",
      "x_t:  0 [0.8125     0.39583333 0.109375   0.4125    ]\n",
      "Q values:  tensor([[-6.9078, -7.6720, -7.8854, -7.5917, -7.5425, -6.6084]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20730 881 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 670: ep_len:881 episode reward: total was -101.800000. running mean: -157.668113\n",
      "startIDX:  170\n",
      "670 1 True\n",
      "x_t:  0 [0.5        0.37916667 0.125      0.44583333]\n",
      "Q values:  tensor([[-10.6275,  -9.5491, -10.0114, -10.9604, -10.5272,  -9.0045]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29161 1708 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 670: ep_len:1708 episode reward: total was -234.700000. running mean: -158.438432\n",
      "startIDX:  2450\n",
      "670 5 True\n",
      "x_t:  2 [0.0625     0.4        0.1        0.26666667]\n",
      "Q values:  tensor([[-5.7666, -5.4245, -5.5062, -5.3887, -5.4289, -4.9367]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21558 914 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 670: ep_len:914 episode reward: total was -113.800000. running mean: -157.992047\n",
      "startIDX:  1691\n",
      "670 10 True\n",
      "x_t:  3 [0.225      0.25       0.09375    0.29583333]\n",
      "Q values:  tensor([[-4.7518, -5.5163, -5.2806, -5.5783, -5.6029, -4.4697]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16511 298 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 670: ep_len:298 episode reward: total was -44.400000. running mean: -156.856127\n",
      "startIDX:  703\n",
      "670 12 True\n",
      "x_t:  1 [0.05625    0.39583333 0.184375   0.47083333]\n",
      "Q values:  tensor([[-4.5391, -3.9708, -4.5443, -3.9758, -4.3528, -3.7452]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10309 214 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 670: ep_len:214 episode reward: total was -51.300000. running mean: -155.800566\n",
      "startIDX:  628\n",
      "670 15 False\n",
      "x_t:  1 [0.91875    0.29583333 0.065625   0.28333333]\n",
      "Q values:  tensor([[-6.3955, -5.2029, -5.7713, -5.8254, -6.2379, -5.3408]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5164 658 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 670: ep_len:658 episode reward: total was -50.400000. running mean: -154.746560\n",
      "startIDX:  726\n",
      "670 22 True\n",
      "x_t:  2 [0.465625   0.4125     0.1        0.25416667]\n",
      "Q values:  tensor([[-4.4371, -3.7053, -4.0249, -4.0059, -4.2643, -3.5476]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8993 930 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 670: ep_len:930 episode reward: total was -109.200000. running mean: -154.291094\n",
      "startIDX:  343\n",
      "671 0 True\n",
      "x_t:  3 [0.365625   0.27916667 0.090625   0.30833333]\n",
      "Q values:  tensor([[-7.1083, -7.4984, -7.7075, -7.4631, -7.7553, -6.6459]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4925 1243 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  161\n",
      "671 1 True\n",
      "x_t:  2 [0.640625   0.37083333 0.134375   0.44583333]\n",
      "Q values:  tensor([[-6.3759, -4.9768, -5.4830, -5.4219, -6.2154, -5.1575]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27521 922 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1842\n",
      "671 5 True\n",
      "x_t:  2 [0.503125   0.4        0.0625     0.24583333]\n",
      "Q values:  tensor([[-4.5055, -4.0980, -4.3680, -4.2527, -4.5532, -3.8630]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15698 362 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  575\n",
      "671 10 True\n",
      "x_t:  2 [0.090625   0.40416667 0.10625    0.25833333]\n",
      "Q values:  tensor([[-5.1075, -5.0498, -5.2031, -5.0604, -5.2752, -4.3755]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6602 756 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1070\n",
      "671 12 True\n",
      "x_t:  3 [0.0625     0.26666667 0.065625   0.23333333]\n",
      "Q values:  tensor([[-6.6192, -6.2870, -6.6842, -6.5620, -7.3856, -5.7870]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16371 1391 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  825\n",
      "671 15 True\n",
      "x_t:  3 [0.225      0.24583333 0.065625   0.25833333]\n",
      "Q values:  tensor([[-6.5436, -5.9228, -5.8684, -5.9037, -6.2743, -5.1483]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8595 1274 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  802\n",
      "671 22 True\n",
      "x_t:  2 [0.3625     0.40416667 0.046875   0.2625    ]\n",
      "Q values:  tensor([[-5.4736, -5.1223, -5.0144, -5.2510, -5.7314, -4.4932]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8972 861 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1681\n",
      "672 0 True\n",
      "x_t:  3 [0.2      0.2625   0.071875 0.2875  ]\n",
      "Q values:  tensor([[-6.6627, -6.2196, -6.3023, -6.1423, -6.5518, -4.9501]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16920 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 672: ep_len:204 episode reward: total was -45.000000. running mean: -149.486812\n",
      "startIDX:  184\n",
      "672 1 True\n",
      "x_t:  2 [0.64375    0.37083333 0.153125   0.44166667]\n",
      "Q values:  tensor([[-5.7971, -5.2719, -5.7691, -5.8294, -5.9585, -4.9965]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27524 906 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 672: ep_len:906 episode reward: total was -161.600000. running mean: -149.607944\n",
      "startIDX:  1644\n",
      "672 5 True\n",
      "x_t:  1 [0.709375   0.28333333 0.059375   0.29166667]\n",
      "Q values:  tensor([[-5.4597, -4.7934, -5.1780, -5.0312, -5.3164, -4.3921]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14948 665 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 672: ep_len:665 episode reward: total was -87.200000. running mean: -148.983865\n",
      "startIDX:  2152\n",
      "672 10 True\n",
      "x_t:  0 [0.625      0.40416667 0.05       0.3       ]\n",
      "Q values:  tensor([[-3.9450, -4.0796, -4.0430, -4.5510, -4.4380, -3.5413]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20007 571 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 672: ep_len:571 episode reward: total was -52.100000. running mean: -148.015026\n",
      "startIDX:  1453\n",
      "672 12 False\n",
      "x_t:  3 [0.078125   0.24583333 0.053125   0.25416667]\n",
      "Q values:  tensor([[-6.0544, -5.9249, -5.7311, -5.1910, -6.4953, -5.3367]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17993 232 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 672: ep_len:232 episode reward: total was -68.900000. running mean: -147.223876\n",
      "startIDX:  1708\n",
      "672 15 False\n",
      "x_t:  0 [0.746875   0.40833333 0.0625     0.325     ]\n",
      "Q values:  tensor([[-4.5197, -5.0941, -5.1388, -5.4131, -5.2024, -4.5327]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13393 687 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 672: ep_len:687 episode reward: total was -118.200000. running mean: -146.933637\n",
      "startIDX:  2271\n",
      "672 22 True\n",
      "x_t:  1 [0.415625   0.33333333 0.0875     0.44166667]\n",
      "Q values:  tensor([[-5.3440, -5.0971, -5.4779, -5.6011, -5.5016, -4.7326]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22976 1100 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 672: ep_len:1100 episode reward: total was -96.400000. running mean: -146.428301\n",
      "startIDX:  1927\n",
      "673 0 True\n",
      "x_t:  1 [0.290625   0.34583333 0.15625    0.375     ]\n",
      "Q values:  tensor([[-5.2399, -5.7780, -5.1993, -5.8481, -5.8318, -4.7731]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18953 251 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  781\n",
      "673 1 False\n",
      "x_t:  3 [0.146875   0.24166667 0.084375   0.30833333]\n",
      "Q values:  tensor([[-5.9309, -6.2186, -6.7904, -5.7707, -6.3574, -5.9416]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34331 1411 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1954\n",
      "673 5 True\n",
      "x_t:  3 [0.521875   0.325      0.140625   0.43333333]\n",
      "Q values:  tensor([[-6.8899, -7.3677, -7.1073, -7.5383, -7.5249, -6.4004]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18300 1333 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1757\n",
      "673 10 True\n",
      "x_t:  3 [0.80625  0.3      0.078125 0.4     ]\n",
      "Q values:  tensor([[-5.5808, -5.5703, -5.6512, -5.5983, -5.6160, -4.8469]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16412 221 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1572\n",
      "673 12 True\n",
      "x_t:  2 [0.49375  0.4125   0.084375 0.3     ]\n",
      "Q values:  tensor([[-7.7972, -7.5408, -7.4046, -7.9696, -7.8373, -6.9875]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19445 765 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2817\n",
      "673 15 True\n",
      "x_t:  1 [0.259375   0.35833333 0.115625   0.51666667]\n",
      "Q values:  tensor([[-7.1111, -7.8179, -7.4026, -7.2943, -7.8670, -6.5225]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22057 267 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  737\n",
      "673 22 True\n",
      "x_t:  2 [0.0375     0.4125     0.059375   0.25833333]\n",
      "Q values:  tensor([[-7.1216, -6.9245, -7.1018, -7.3417, -7.2400, -6.2520]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8920 874 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  835\n",
      "674 0 False\n",
      "x_t:  1 [0.840625   0.3        0.15625    0.44166667]\n",
      "Q values:  tensor([[-5.8589, -5.0772, -5.3770, -6.4784, -6.0081, -5.2157]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9499 256 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 674: ep_len:256 episode reward: total was -81.000000. running mean: -143.203695\n",
      "startIDX:  470\n",
      "674 1 False\n",
      "x_t:  1 [0.859375   0.25833333 0.1375     0.47083333]\n",
      "Q values:  tensor([[-7.4202, -6.6685, -7.2145, -7.4471, -7.7010, -6.7022]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30678 792 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 674: ep_len:792 episode reward: total was -96.700000. running mean: -142.738658\n",
      "startIDX:  1262\n",
      "674 5 False\n",
      "x_t:  2 [0.003125   0.39583333 0.103125   0.27083333]\n",
      "Q values:  tensor([[-6.3763, -5.9071, -5.8403, -6.6733, -6.5302, -5.9448]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12004 723 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 674: ep_len:723 episode reward: total was -110.400000. running mean: -142.415271\n",
      "startIDX:  2566\n",
      "ep 674: ep_len:34 episode reward: total was 26.000000. running mean: -140.731119\n",
      "startIDX:  939\n",
      "674 12 True\n",
      "x_t:  2 [0.865625   0.39166667 0.065625   0.23333333]\n",
      "Q values:  tensor([[-7.5964, -8.1644, -7.9794, -8.3943, -8.7071, -7.5285]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13567 909 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 674: ep_len:909 episode reward: total was -163.200000. running mean: -140.955807\n",
      "startIDX:  1395\n",
      "674 15 False\n",
      "x_t:  3 [0.5375     0.29583333 0.125      0.34166667]\n",
      "Q values:  tensor([[-11.3770, -10.8131,  -9.8564,  -9.0999, -11.1870,  -9.9210]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10389 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 674: ep_len:200 episode reward: total was -50.400000. running mean: -140.050249\n",
      "startIDX:  1634\n",
      "674 22 False\n",
      "x_t:  3 [0.653125   0.32083333 0.1        0.37083333]\n",
      "Q values:  tensor([[-7.5782, -7.3226, -7.9859, -6.6547, -7.3595, -6.7573]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16877 249 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 674: ep_len:249 episode reward: total was 12.200000. running mean: -138.527747\n",
      "startIDX:  2183\n",
      "675 0 True\n",
      "x_t:  1 [0.0125     0.38333333 0.1875     0.49166667]\n",
      "Q values:  tensor([[-9.5351, -9.4344, -9.0462, -9.4420, -9.6648, -8.5722]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22981 1137 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  876\n",
      "675 1 True\n",
      "x_t:  4 [0.003125   0.39583333 0.11875    0.40833333]\n",
      "Q values:  tensor([[-6.7114, -6.0812, -5.9007, -6.4190, -6.1673, -5.6458]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35421 521 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  1125\n",
      "675 5 True\n",
      "x_t:  2 [0.321875   0.37916667 0.040625   0.3       ]\n",
      "Q values:  tensor([[-10.0299, -10.0366,  -9.6759,  -9.2467, -10.0807,  -8.9611]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12046 916 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1864\n",
      "675 10 False\n",
      "x_t:  2 [0.003125   0.40416667 0.065625   0.24583333]\n",
      "Q values:  tensor([[-11.0165,  -9.8130,  -8.9442, -10.2672, -10.8515,  -9.2658]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18141 817 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1887\n",
      "675 12 False\n",
      "x_t:  0 [0.909375   0.40833333 0.075      0.26666667]\n",
      "Q values:  tensor([[ -9.9133, -10.7724, -11.5342, -10.5402, -10.5078,  -9.9637]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23131 1000 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3107\n",
      "startIDX:  2330\n",
      "675 22 False\n",
      "x_t:  1 [0.684375   0.31666667 0.084375   0.4375    ]\n",
      "Q values:  tensor([[-11.3297, -10.2226, -11.4928, -11.2027, -12.2520, -10.3781]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22952 1058 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1402\n",
      "676 0 False\n",
      "x_t:  4 [0.034375   0.38333333 0.1        0.30416667]\n",
      "Q values:  tensor([[-11.3606, -10.7680, -10.5534, -10.6613, -10.3081, -10.3421]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16291 533 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 676: ep_len:533 episode reward: total was -189.400000. running mean: -143.694052\n",
      "startIDX:  628\n",
      "676 1 False\n",
      "x_t:  2 [0.725      0.37916667 0.096875   0.31666667]\n",
      "Q values:  tensor([[-12.4687, -11.6884, -11.5151, -13.0294, -13.3079, -11.9145]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31477 381 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 676: ep_len:381 episode reward: total was -145.000000. running mean: -143.707111\n",
      "startIDX:  575\n",
      "676 5 False\n",
      "x_t:  2 [0.75       0.39583333 0.046875   0.29166667]\n",
      "Q values:  tensor([[-11.5652, -12.9388, -11.1115, -11.6212, -12.2450, -11.5959]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6050 469 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 676: ep_len:469 episode reward: total was -218.500000. running mean: -144.455040\n",
      "startIDX:  291\n",
      "676 10 False\n",
      "x_t:  3 [0.828125   0.3375     0.15625    0.36666667]\n",
      "Q values:  tensor([[-13.0255, -12.5356, -12.1608, -10.7328, -13.7029, -11.7477]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5037 233 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 676: ep_len:233 episode reward: total was -15.300000. running mean: -143.163490\n",
      "startIDX:  1639\n",
      "676 12 False\n",
      "x_t:  1 [0.0375     0.37083333 0.1375     0.35416667]\n",
      "Q values:  tensor([[-15.1698, -14.2241, -15.0423, -14.7303, -15.2504, -14.8789]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19875 255 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 676: ep_len:255 episode reward: total was -169.700000. running mean: -143.428855\n",
      "startIDX:  1984\n",
      "676 15 False\n",
      "x_t:  1 [0.94375  0.2875   0.053125 0.325   ]\n",
      "Q values:  tensor([[-18.9871, -15.8561, -17.0679, -17.0800, -17.1203, -16.4562]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14836 662 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 676: ep_len:662 episode reward: total was -345.100000. running mean: -145.445566\n",
      "startIDX:  2574\n",
      "676 22 False\n",
      "x_t:  3 [0.1        0.24583333 0.059375   0.24583333]\n",
      "Q values:  tensor([[-20.1709, -21.2553, -21.0558, -19.2307, -21.0306, -19.3718]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26184 1236 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 676: ep_len:1236 episode reward: total was -770.300000. running mean: -151.694110\n",
      "startIDX:  1537\n",
      "677 0 False\n",
      "x_t:  3 [0.703125   0.35       0.153125   0.39166667]\n",
      "Q values:  tensor([[-23.7012, -21.2760, -22.2136, -20.8771, -23.2006, -21.1330]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16829 241 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1156\n",
      "startIDX:  2428\n",
      "677 5 False\n",
      "x_t:  2 [0.06875 0.4     0.09375 0.2625 ]\n",
      "Q values:  tensor([[-22.3896, -22.4132, -22.0890, -23.6042, -23.3510, -22.1347]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21559 935 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2595\n",
      "startIDX:  1747\n",
      "677 12 False\n",
      "x_t:  0 [0.68125    0.40833333 0.071875   0.34583333]\n",
      "Q values:  tensor([[-24.3444, -26.9333, -28.1967, -27.0032, -28.7895, -27.0964]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21120 620 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  131\n",
      "677 15 False\n",
      "x_t:  2 [0.25625    0.39583333 0.075      0.34166667]\n",
      "Q values:  tensor([[-30.8223, -32.0609, -29.6072, -34.4730, -31.2588, -30.4271]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2225 855 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2316\n",
      "677 22 True\n",
      "x_t:  2 [0.671875 0.4125   0.084375 0.25    ]\n",
      "Q values:  tensor([[-38.3183, -41.2588, -40.6951, -42.6495, -40.7782, -40.5755]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23661 1448 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  318\n",
      "678 0 True\n",
      "x_t:  3 [0.059375   0.23333333 0.0625     0.23333333]\n",
      "Q values:  tensor([[-37.5604, -35.7397, -36.9929, -36.8280, -35.5046, -36.7022]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4832 1226 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 678: ep_len:1226 episode reward: total was -881.800000. running mean: -175.810639\n",
      "startIDX:  79\n",
      "678 1 False\n",
      "x_t:  3 [0.15625    0.22916667 0.084375   0.29583333]\n",
      "Q values:  tensor([[-31.7384, -31.0345, -30.4156, -27.1442, -29.1771, -30.2175]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25764 207 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 678: ep_len:207 episode reward: total was -130.600000. running mean: -175.358533\n",
      "startIDX:  2762\n",
      "678 5 False\n",
      "x_t:  0 [0.93125    0.3875     0.0625     0.30833333]\n",
      "Q values:  tensor([[-22.3683, -24.0236, -26.0570, -27.7050, -24.4294, -24.9517]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23151 508 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 678: ep_len:508 episode reward: total was -333.900000. running mean: -176.943947\n",
      "startIDX:  2143\n",
      "678 10 False\n",
      "x_t:  0 [0.875      0.39166667 0.09375    0.3625    ]\n",
      "Q values:  tensor([[-19.8252, -21.5148, -22.0910, -22.0693, -22.2192, -21.2896]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19935 541 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 678: ep_len:541 episode reward: total was -358.200000. running mean: -178.756508\n",
      "startIDX:  770\n",
      "678 12 False\n",
      "x_t:  0 [0.915625   0.40833333 0.08125    0.30416667]\n",
      "Q values:  tensor([[-22.8669, -23.8987, -24.4065, -24.4363, -23.6347, -23.1412]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11631 846 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 678: ep_len:846 episode reward: total was -627.600000. running mean: -183.244943\n",
      "startIDX:  1603\n",
      "678 15 False\n",
      "x_t:  2 [0.028125   0.4125     0.065625   0.25416667]\n",
      "Q values:  tensor([[-27.1236, -28.0056, -26.3796, -29.2620, -28.3843, -26.5612]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 11912 703 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 678: ep_len:703 episode reward: total was -507.500000. running mean: -186.487494\n",
      "startIDX:  3014\n",
      "ep 678: ep_len:2 episode reward: total was 0.000000. running mean: -184.622619\n",
      "startIDX:  1439\n",
      "679 0 True\n",
      "x_t:  4 [0.003125 0.4      0.09375  0.275   ]\n",
      "Q values:  tensor([[-33.8794, -30.6893, -33.1729, -31.1523, -30.0201, -30.6767]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16284 503 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  873\n",
      "679 1 False\n",
      "x_t:  4 [0.003125   0.39583333 0.11875    0.4       ]\n",
      "Q values:  tensor([[-34.0391, -33.2094, -34.4707, -33.5174, -32.1664, -32.7165]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35422 536 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  683\n",
      "679 5 True\n",
      "x_t:  3 [0.0625     0.25833333 0.078125   0.31666667]\n",
      "Q values:  tensor([[-44.5554, -43.8881, -47.7043, -41.5994, -43.4947, -44.0854]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8745 1341 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1238\n",
      "679 10 False\n",
      "x_t:  3 [0.075      0.23333333 0.065625   0.24166667]\n",
      "Q values:  tensor([[-39.2439, -37.5749, -39.8516, -35.7972, -37.4836, -36.9716]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14577 1204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  784\n",
      "679 12 False\n",
      "x_t:  0 [0.790625   0.40833333 0.128125   0.30833333]\n",
      "Q values:  tensor([[-31.0256, -32.2822, -32.7093, -33.1499, -35.0542, -32.1417]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11647 850 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2953\n",
      "startIDX:  127\n",
      "679 22 False\n",
      "x_t:  1 [0.75       0.30416667 0.13125    0.4       ]\n",
      "Q values:  tensor([[-23.9436, -21.5090, -24.1462, -23.5177, -24.0257, -22.2394]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1590 669 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  6211.077520608902\n",
      "startIDX:  1749\n",
      "680 0 False\n",
      "x_t:  2 [0.10625    0.40833333 0.115625   0.24583333]\n",
      "Q values:  tensor([[-25.4670, -25.1441, -23.6559, -25.6530, -24.6415, -23.7498]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18409 777 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 680: ep_len:777 episode reward: total was -508.300000. running mean: -209.290005\n",
      "startIDX:  394\n",
      "680 1 False\n",
      "x_t:  1 [0.496875 0.3      0.240625 0.575   ]\n",
      "Q values:  tensor([[-29.9075, -26.3202, -28.1545, -27.8008, -29.1305, -27.5577]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28099 285 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 680: ep_len:285 episode reward: total was -193.900000. running mean: -209.136105\n",
      "startIDX:  736\n",
      "680 5 False\n",
      "x_t:  3 [0.103125   0.26666667 0.08125    0.31666667]\n",
      "Q values:  tensor([[-31.9676, -27.8139, -30.8438, -25.8757, -29.7100, -28.3569]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8760 1321 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 680: ep_len:1321 episode reward: total was -841.300000. running mean: -215.457744\n",
      "startIDX:  1303\n",
      "680 10 False\n",
      "x_t:  3 [0.14375    0.22916667 0.06875    0.27083333]\n",
      "Q values:  tensor([[-24.7352, -28.1622, -25.9264, -23.3470, -27.4793, -23.8324]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14600 1206 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 680: ep_len:1206 episode reward: total was -743.700000. running mean: -220.740167\n",
      "startIDX:  204\n",
      "680 12 False\n",
      "x_t:  3 [0.14375    0.2625     0.0625     0.28333333]\n",
      "Q values:  tensor([[-29.0183, -30.5581, -30.0070, -26.6630, -27.0613, -27.9433]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5681 1409 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 680: ep_len:1409 episode reward: total was -796.700000. running mean: -226.499765\n",
      "startIDX:  921\n",
      "680 15 False\n",
      "x_t:  4 [0.003125   0.4        0.065625   0.29166667]\n",
      "Q values:  tensor([[-31.6701, -29.7181, -31.9247, -32.6146, -29.4062, -29.7823]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9808 656 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 680: ep_len:656 episode reward: total was -236.500000. running mean: -226.599768\n",
      "startIDX:  2843\n",
      "ep 680: ep_len:88 episode reward: total was 60.000000. running mean: -223.733770\n",
      "startIDX:  1206\n",
      "681 0 True\n",
      "x_t:  3 [0.190625   0.25833333 0.078125   0.29583333]\n",
      "Q values:  tensor([[-26.5867, -25.9108, -26.3215, -26.5987, -26.0069, -24.1697]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15196 1267 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  634\n",
      "681 1 True\n",
      "x_t:  2 [0.6375     0.38333333 0.075      0.30416667]\n",
      "Q values:  tensor([[-24.5758, -23.4034, -23.4824, -22.2648, -23.5421, -21.5231]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31493 379 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1055\n",
      "681 5 False\n",
      "x_t:  3 [0.340625   0.25833333 0.0875     0.3125    ]\n",
      "Q values:  tensor([[-29.9286, -27.2788, -26.2746, -25.2218, -26.8844, -26.0583]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10555 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2501\n",
      "681 10 True\n",
      "x_t:  1 [0.096875   0.34583333 0.159375   0.3625    ]\n",
      "Q values:  tensor([[-22.2085, -24.4741, -20.3431, -23.0482, -21.7547, -21.9497]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22550 1188 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  507\n",
      "681 12 False\n",
      "x_t:  3 [0.7875     0.3375     0.0875     0.42083333]\n",
      "Q values:  tensor([[-23.4022, -24.1201, -24.3337, -22.1028, -23.1857, -22.1438]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7722 218 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  338\n",
      "681 15 False\n",
      "x_t:  1 [0.203125   0.37083333 0.1375     0.49583333]\n",
      "Q values:  tensor([[-26.3219, -24.0963, -25.3208, -26.9869, -26.2616, -24.2699]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2766 254 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  140\n",
      "681 22 True\n",
      "x_t:  1 [0.30625    0.34166667 0.096875   0.40833333]\n",
      "Q values:  tensor([[-25.8696, -24.1285, -22.5772, -25.4316, -24.3547, -23.7688]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1637 672 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  662\n",
      "682 0 False\n",
      "x_t:  2 [0.01875    0.40416667 0.1125     0.275     ]\n",
      "Q values:  tensor([[-31.9203, -29.9463, -29.5098, -30.2712, -32.8068, -30.1927]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8874 896 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 682: ep_len:896 episode reward: total was -500.100000. running mean: -235.041497\n",
      "startIDX:  518\n",
      "682 1 False\n",
      "x_t:  1 [0.484375   0.29583333 0.18125    0.47083333]\n",
      "Q values:  tensor([[-34.4356, -33.2541, -34.3544, -34.1844, -34.5916, -34.5186]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30720 768 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 682: ep_len:768 episode reward: total was -430.500000. running mean: -236.996082\n",
      "startIDX:  2271\n",
      "682 5 False\n",
      "x_t:  3 [0.553125   0.30416667 0.14375    0.4       ]\n",
      "Q values:  tensor([[-2.3017, -2.8778, -3.6962, -0.7834, -3.2063, -3.6313]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19915 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 682: ep_len:200 episode reward: total was -6.400000. running mean: -234.690121\n",
      "startIDX:  1911\n",
      "682 10 True\n",
      "x_t:  2 [0.365625   0.4        0.0875     0.24583333]\n",
      "Q values:  tensor([[-29.2323, -29.9497, -32.7145, -28.4398, -30.8820, -31.3894]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18211 834 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 682: ep_len:834 episode reward: total was -471.100000. running mean: -237.054220\n",
      "startIDX:  906\n",
      "682 12 False\n",
      "x_t:  1 [0.646875   0.38333333 0.1625     0.48333333]\n",
      "Q values:  tensor([[-25.0523, -23.7882, -26.5430, -26.1067, -24.4381, -25.3682]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12926 623 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 682: ep_len:623 episode reward: total was -295.200000. running mean: -237.635678\n",
      "startIDX:  1683\n",
      "682 15 False\n",
      "x_t:  1 [0.340625   0.32916667 0.08125    0.3875    ]\n",
      "Q values:  tensor([[-24.5130, -23.0428, -23.8706, -24.9597, -23.8381, -23.5618]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12482 255 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 682: ep_len:255 episode reward: total was -114.200000. running mean: -236.401321\n",
      "startIDX:  2312\n",
      "682 22 True\n",
      "x_t:  1 [0.81875  0.3      0.096875 0.4625  ]\n",
      "Q values:  tensor([[-23.3822, -24.1856, -24.8850, -24.4569, -23.0553, -23.3428]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22938 1071 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 682: ep_len:1071 episode reward: total was -477.200000. running mean: -238.809308\n",
      "startIDX:  1121\n",
      "683 0 True\n",
      "x_t:  2 [0.496875   0.40833333 0.115625   0.3       ]\n",
      "Q values:  tensor([[-22.9126, -24.3811, -25.6800, -23.6322, -23.2596, -22.6854]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12673 350 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  413\n",
      "683 1 False\n",
      "x_t:  0 [0.853125   0.375      0.09375    0.40833333]\n",
      "Q values:  tensor([[-18.2456, -20.7704, -20.7518, -18.7703, -21.1299, -18.7186]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29100 496 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2375\n",
      "683 5 True\n",
      "x_t:  2 [0.225      0.39583333 0.090625   0.27083333]\n",
      "Q values:  tensor([[-22.8747, -21.8843, -22.2173, -21.0710, -21.1175, -19.7695]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21584 988 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  43\n",
      "683 10 True\n",
      "x_t:  3 [0.09375    0.2375     0.065625   0.27083333]\n",
      "Q values:  tensor([[-21.1021, -19.2981, -20.5519, -20.9724, -19.6416, -18.6706]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3592 1093 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1530\n",
      "683 12 False\n",
      "x_t:  2 [0.1125     0.4125     0.08125    0.29166667]\n",
      "Q values:  tensor([[-15.3511, -14.4151, -13.4686, -15.0567, -14.6441, -13.5313]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19395 749 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1798\n",
      "683 15 False\n",
      "x_t:  0 [0.78125    0.39583333 0.09375    0.34583333]\n",
      "Q values:  tensor([[-12.2970, -13.2766, -15.5466, -14.5446, -12.8649, -13.7667]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13382 442 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2961\n",
      "startIDX:  493\n",
      "684 0 False\n",
      "x_t:  3 [0.828125   0.39583333 0.165625   0.425     ]\n",
      "Q values:  tensor([[-13.6064, -13.2310, -13.4257, -11.9688, -12.6985, -12.6675]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 6990 1025 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 684: ep_len:1025 episode reward: total was -295.300000. running mean: -236.918822\n",
      "startIDX:  815\n",
      "684 1 False\n",
      "x_t:  4 [0.171875   0.375      0.078125   0.42083333]\n",
      "Q values:  tensor([[-16.2986, -16.1334, -17.0357, -15.2167, -14.3130, -14.9854]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35445 582 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 684: ep_len:582 episode reward: total was -125.400000. running mean: -235.803633\n",
      "startIDX:  809\n",
      "684 5 False\n",
      "x_t:  4 [0.0875     0.40416667 0.090625   0.39166667]\n",
      "Q values:  tensor([[-14.1538, -14.2475, -14.7240, -13.8107, -12.8872, -13.0712]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10021 611 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 684: ep_len:611 episode reward: total was -169.100000. running mean: -235.136597\n",
      "startIDX:  124\n",
      "684 10 False\n",
      "x_t:  3 [0.165625   0.25416667 0.0875     0.2875    ]\n",
      "Q values:  tensor([[-12.5476, -12.4733, -13.4136, -11.3387, -12.6754, -11.7851]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3612 1049 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 684: ep_len:1049 episode reward: total was -310.400000. running mean: -235.889231\n",
      "startIDX:  1846\n",
      "684 12 False\n",
      "x_t:  0 [0.2625     0.41666667 0.071875   0.30416667]\n",
      "Q values:  tensor([[-10.0743, -11.0081, -11.5061, -11.5014, -12.2465, -10.7626]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 22998 965 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 684: ep_len:965 episode reward: total was -310.100000. running mean: -236.631339\n",
      "startIDX:  2309\n",
      "684 15 True\n",
      "x_t:  3 [0.140625   0.275      0.078125   0.31666667]\n",
      "Q values:  tensor([[-13.8334, -14.4302, -14.5786, -13.9072, -14.0991, -13.4855]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18190 1261 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 684: ep_len:1261 episode reward: total was -367.700000. running mean: -237.942025\n",
      "startIDX:  891\n",
      "684 22 False\n",
      "x_t:  1 [0.25625    0.3375     0.109375   0.40416667]\n",
      "Q values:  tensor([[-16.4897, -14.9136, -18.2268, -15.8152, -15.9874, -15.1635]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9509 252 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 684: ep_len:252 episode reward: total was -76.300000. running mean: -236.325605\n",
      "startIDX:  1635\n",
      "685 0 False\n",
      "x_t:  3 [0.5125     0.32083333 0.115625   0.3625    ]\n",
      "Q values:  tensor([[-14.6662, -14.3437, -15.0600, -13.3356, -14.6532, -13.4515]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16857 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  801\n",
      "685 1 True\n",
      "x_t:  3 [0.10625    0.22916667 0.08125    0.30416667]\n",
      "Q values:  tensor([[-13.1702, -13.2335, -12.8445, -14.0103, -12.8782, -12.6393]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34318 1372 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1166\n",
      "685 5 True\n",
      "x_t:  2 [0.65       0.3875     0.1        0.32916667]\n",
      "Q values:  tensor([[-14.3205, -13.4206, -13.9188, -14.6435, -12.5142, -12.2051]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12091 911 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2534\n",
      "685 10 True\n",
      "x_t:  1 [0.615625   0.29583333 0.0875     0.33333333]\n",
      "Q values:  tensor([[-14.4915, -14.7459, -15.5598, -14.1570, -14.7535, -13.0813]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22499 1148 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  431\n",
      "685 12 True\n",
      "x_t:  3 [0.69375    0.3375     0.14375    0.40833333]\n",
      "Q values:  tensor([[-13.5180, -12.9572, -12.6999, -13.5438, -12.8840, -12.0008]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7729 261 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2904\n",
      "685 15 False\n",
      "x_t:  0 [0.909375   0.40416667 0.0625     0.35      ]\n",
      "Q values:  tensor([[-11.1011, -12.8401, -13.4653, -12.9799, -12.0760, -11.5665]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23070 499 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1644\n",
      "685 22 False\n",
      "x_t:  3 [0.871875   0.35       0.125      0.41666667]\n",
      "Q values:  tensor([[-11.3115, -10.6941, -12.7686,  -9.8530, -10.9266, -10.2545]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16845 227 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  319\n",
      "686 0 True\n",
      "x_t:  3 [0.075      0.22916667 0.059375   0.2375    ]\n",
      "Q values:  tensor([[-15.4214, -13.1052, -15.0436, -13.7179, -13.3901, -13.0539]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4839 1232 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 686: ep_len:1232 episode reward: total was -155.600000. running mean: -228.691863\n",
      "startIDX:  378\n",
      "686 1 False\n",
      "x_t:  1 [0.565625   0.30833333 0.2375     0.5625    ]\n",
      "Q values:  tensor([[-10.4927,  -8.9219,  -9.9728,  -9.8764, -10.2914,  -9.1060]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28102 293 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 686: ep_len:293 episode reward: total was -34.900000. running mean: -226.753945\n",
      "startIDX:  2111\n",
      "686 5 False\n",
      "x_t:  4 [0.378125   0.39583333 0.1375     0.3875    ]\n",
      "Q values:  tensor([[-10.9902, -11.2105, -12.0951, -11.5202, -10.3684, -10.5182]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19497 623 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 686: ep_len:623 episode reward: total was -96.600000. running mean: -225.452405\n",
      "startIDX:  2389\n",
      "686 10 False\n",
      "x_t:  1 [0.7875     0.29166667 0.134375   0.32916667]\n",
      "Q values:  tensor([[-10.4730,  -9.5132, -11.5083, -10.9435, -11.2867,  -9.7438]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22477 1202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 686: ep_len:1202 episode reward: total was -153.900000. running mean: -224.736881\n",
      "startIDX:  1856\n",
      "686 12 False\n",
      "x_t:  0 [0.375      0.41666667 0.0875     0.2875    ]\n",
      "Q values:  tensor([[ -9.0220, -11.0539, -10.2075, -10.3376,  -9.4552,  -9.1427]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23012 951 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 686: ep_len:951 episode reward: total was -107.900000. running mean: -223.568512\n",
      "startIDX:  2408\n",
      "686 15 True\n",
      "x_t:  4 [0.05       0.425      0.10625    0.36666667]\n",
      "Q values:  tensor([[-7.1803, -7.3480, -7.0819, -6.9914, -7.4888, -6.0670]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19254 503 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 686: ep_len:503 episode reward: total was -50.800000. running mean: -221.840827\n",
      "startIDX:  923\n",
      "686 22 True\n",
      "x_t:  1 [0.25625    0.3375     0.109375   0.40416667]\n",
      "Q values:  tensor([[-7.7559, -7.6379, -7.2417, -7.4096, -6.8254, -6.1266]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9509 246 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 686: ep_len:246 episode reward: total was -42.200000. running mean: -220.044419\n",
      "startIDX:  978\n",
      "687 0 True\n",
      "x_t:  2 [0.6875     0.4125     0.1125     0.28333333]\n",
      "Q values:  tensor([[-6.6769, -6.4697, -6.5395, -6.9136, -6.3401, -5.7720]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12647 1148 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1047\n",
      "687 1 True\n",
      "x_t:  3 [0.45     0.2625   0.059375 0.3125  ]\n",
      "Q values:  tensor([[-5.6369, -6.4815, -6.4235, -5.5866, -5.8399, -5.0907]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35976 241 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  294\n",
      "687 5 True\n",
      "x_t:  0 [0.44375    0.39166667 0.06875    0.4       ]\n",
      "Q values:  tensor([[-5.0516, -5.2279, -5.1064, -5.0090, -4.9314, -4.3359]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3612 542 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1762\n",
      "687 10 True\n",
      "x_t:  3 [0.828125   0.33333333 0.165625   0.39583333]\n",
      "Q values:  tensor([[-4.9102, -4.8660, -5.2022, -4.6537, -4.7032, -4.1291]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16404 217 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  823\n",
      "687 12 True\n",
      "x_t:  0 [0.63125    0.4        0.06875    0.37083333]\n",
      "Q values:  tensor([[-4.4573, -4.8493, -4.5909, -4.6190, -4.3868, -3.8655]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11708 685 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2669\n",
      "687 15 True\n",
      "x_t:  2 [0.071875   0.40416667 0.08125    0.34166667]\n",
      "Q values:  tensor([[-4.0240, -4.2986, -4.3443, -4.3874, -3.8503, -3.4886]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21483 864 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2270\n",
      "687 22 True\n",
      "x_t:  1 [0.171875   0.375      0.171875   0.47083333]\n",
      "Q values:  tensor([[-4.5726, -4.2614, -4.6102, -4.7202, -4.5015, -3.8311]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22996 1131 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2272\n",
      "688 0 True\n",
      "x_t:  3 [0.19375    0.25416667 0.065625   0.27083333]\n",
      "Q values:  tensor([[-3.6782, -4.1382, -4.5107, -4.0221, -3.6065, -3.5325]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26129 1586 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 688: ep_len:1586 episode reward: total was -166.600000. running mean: -210.127118\n",
      "startIDX:  528\n",
      "688 1 True\n",
      "x_t:  1 [0.496875   0.29583333 0.171875   0.4625    ]\n",
      "Q values:  tensor([[-3.4380, -3.5461, -3.6615, -3.4627, -3.6549, -2.9528]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30718 748 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 688: ep_len:748 episode reward: total was -68.400000. running mean: -208.709847\n",
      "startIDX:  538\n",
      "688 5 True\n",
      "x_t:  3 [0.2625     0.28333333 0.096875   0.35833333]\n",
      "Q values:  tensor([[-3.3917, -3.7422, -4.1642, -3.7242, -3.3719, -3.0644]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8799 1882 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 688: ep_len:1882 episode reward: total was -205.300000. running mean: -208.675749\n",
      "startIDX:  916\n",
      "688 10 True\n",
      "x_t:  1 [0.315625   0.31666667 0.125      0.37083333]\n",
      "Q values:  tensor([[-3.7319, -4.1161, -4.1011, -4.2958, -3.7721, -3.3265]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11398 1620 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 688: ep_len:1620 episode reward: total was -152.500000. running mean: -208.113991\n",
      "startIDX:  1840\n",
      "688 12 True\n",
      "x_t:  0 [0.203125   0.43333333 0.06875    0.31666667]\n",
      "Q values:  tensor([[-3.3859, -3.7479, -3.6312, -3.6310, -3.3557, -2.8931]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 22987 942 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 688: ep_len:942 episode reward: total was -65.900000. running mean: -206.691851\n",
      "startIDX:  2080\n",
      "688 15 True\n",
      "x_t:  2 [0.4625     0.40833333 0.084375   0.25833333]\n",
      "Q values:  tensor([[-3.8186, -3.9122, -3.7107, -3.6705, -3.6986, -2.9263]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15617 390 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 688: ep_len:390 episode reward: total was -8.600000. running mean: -204.710933\n",
      "startIDX:  913\n",
      "688 22 True\n",
      "x_t:  0 [0.565625   0.40833333 0.06875    0.325     ]\n",
      "Q values:  tensor([[-4.7488, -4.6247, -4.9108, -5.0632, -4.5393, -3.9485]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10470 726 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 688: ep_len:726 episode reward: total was -117.200000. running mean: -203.835823\n",
      "startIDX:  1512\n",
      "689 0 True\n",
      "x_t:  3 [0.284375   0.26666667 0.090625   0.31666667]\n",
      "Q values:  tensor([[-3.4725, -3.3670, -3.5601, -3.4344, -3.3232, -2.8712]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16901 286 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  338\n",
      "689 1 True\n",
      "x_t:  0 [0.91875    0.37083333 0.06875    0.40416667]\n",
      "Q values:  tensor([[-4.2176, -4.1686, -4.1629, -4.0005, -3.8125, -3.4917]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29092 795 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2152\n",
      "689 5 True\n",
      "x_t:  4 [0.375      0.3875     0.153125   0.39166667]\n",
      "Q values:  tensor([[-4.3492, -4.5054, -4.5117, -4.2945, -3.7269, -3.6739]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19498 629 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  706\n",
      "689 10 True\n",
      "x_t:  1 [0.29375    0.32916667 0.065625   0.35      ]\n",
      "Q values:  tensor([[-3.8939, -3.8140, -3.8220, -3.3273, -3.5191, -3.0104]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7134 249 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  237\n",
      "689 12 True\n",
      "x_t:  4 [0.2375     0.39166667 0.096875   0.27916667]\n",
      "Q values:  tensor([[-6.2917, -6.2897, -7.0011, -6.2858, -6.4415, -5.5641]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7277 2178 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2544\n",
      "689 15 True\n",
      "x_t:  3 [0.31875    0.27083333 0.08125    0.28333333]\n",
      "Q values:  tensor([[-7.4094, -6.8736, -6.4717, -6.7638, -7.5656, -5.9370]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19758 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2623\n",
      "689 22 True\n",
      "x_t:  4 [0.29375    0.39583333 0.09375    0.3       ]\n",
      "Q values:  tensor([[-5.0577, -5.1490, -5.0318, -5.2274, -4.7622, -4.3573]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27308 576 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  6318.427836179733\n",
      "startIDX:  1923\n",
      "690 0 True\n",
      "x_t:  1 [0.70625 0.3     0.1125  0.375  ]\n",
      "Q values:  tensor([[-3.8146, -4.3797, -4.6976, -4.1842, -3.9357, -3.6173]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18998 285 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 690: ep_len:285 episode reward: total was -78.800000. running mean: -194.266586\n",
      "startIDX:  630\n",
      "690 1 True\n",
      "x_t:  2 [0.809375   0.38333333 0.071875   0.30833333]\n",
      "Q values:  tensor([[-4.6574, -4.8857, -5.1995, -4.8142, -4.6054, -4.0499]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31465 368 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 690: ep_len:368 episode reward: total was -2.700000. running mean: -192.350920\n",
      "startIDX:  1394\n",
      "690 5 True\n",
      "x_t:  1 [0.06875    0.34583333 0.13125    0.4       ]\n",
      "Q values:  tensor([[-3.6621, -3.8491, -3.6164, -3.5093, -3.7772, -3.0657]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12513 222 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 690: ep_len:222 episode reward: total was -37.400000. running mean: -190.801411\n",
      "startIDX:  2343\n",
      "690 10 True\n",
      "x_t:  1 [0.540625 0.3      0.096875 0.325   ]\n",
      "Q values:  tensor([[-5.7225, -5.2417, -5.1995, -5.1457, -5.1557, -4.5812]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22507 1237 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 690: ep_len:1237 episode reward: total was -178.300000. running mean: -190.676396\n",
      "startIDX:  295\n",
      "690 12 True\n",
      "x_t:  4 [0.390625   0.39166667 0.084375   0.29166667]\n",
      "Q values:  tensor([[-6.1697, -6.4231, -6.3561, -6.6696, -6.4528, -5.6054]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7252 778 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 690: ep_len:778 episode reward: total was -102.100000. running mean: -189.790632\n",
      "startIDX:  292\n",
      "690 15 True\n",
      "x_t:  1 [0.1        0.38333333 0.14375    0.4875    ]\n",
      "Q values:  tensor([[-3.8753, -4.0295, -4.3387, -4.1964, -4.1088, -3.4900]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2759 271 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 690: ep_len:271 episode reward: total was -44.100000. running mean: -188.333726\n",
      "startIDX:  2362\n",
      "690 22 True\n",
      "x_t:  1 [0.0625     0.375      0.16875    0.49166667]\n",
      "Q values:  tensor([[-7.0274, -6.7676, -7.0563, -7.2683, -7.0840, -6.0604]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 23004 1076 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 690: ep_len:1076 episode reward: total was -102.900000. running mean: -187.479389\n",
      "startIDX:  1044\n",
      "691 0 True\n",
      "x_t:  2 [0.4625     0.4        0.05625    0.30416667]\n",
      "Q values:  tensor([[-7.6078, -7.4055, -8.6835, -7.6039, -7.3763, -6.7991]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12682 1128 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  589\n",
      "691 1 True\n",
      "x_t:  2 [0.734375   0.38333333 0.109375   0.3125    ]\n",
      "Q values:  tensor([[-4.8214, -5.0096, -5.3752, -5.1130, -4.7752, -4.0787]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31475 389 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1703\n",
      "691 5 True\n",
      "x_t:  2 [0.61875    0.39583333 0.09375    0.24583333]\n",
      "Q values:  tensor([[-6.7147, -7.2685, -7.1764, -6.8360, -6.7301, -5.9774]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15678 987 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1486\n",
      "691 10 True\n",
      "x_t:  2 [0.2125     0.4        0.090625   0.24166667]\n",
      "Q values:  tensor([[-7.5570, -7.5138, -7.7609, -7.9845, -7.7965, -6.5071]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18184 1236 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  300\n",
      "691 12 False\n",
      "x_t:  4 [0.325      0.38333333 0.1125     0.27916667]\n",
      "Q values:  tensor([[-5.2845, -5.7853, -6.0233, -5.8962, -5.0842, -5.1235]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7264 770 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  762\n",
      "691 15 True\n",
      "x_t:  2 [0.634375   0.40416667 0.09375    0.29583333]\n",
      "Q values:  tensor([[-5.8467, -6.4868, -6.3850, -5.6676, -6.0337, -5.3255]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5992 367 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2806\n",
      "startIDX:  664\n",
      "692 0 True\n",
      "x_t:  1 [0.003125   0.36666667 0.06875    0.4       ]\n",
      "Q values:  tensor([[ -9.9118,  -9.5290, -10.5366, -10.1452, -10.1039,  -8.7051]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9403 1161 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 692: ep_len:1161 episode reward: total was -155.100000. running mean: -178.777176\n",
      "startIDX:  885\n",
      "692 1 False\n",
      "x_t:  4 [0.00625    0.39583333 0.11875    0.4       ]\n",
      "Q values:  tensor([[-6.0787, -6.5664, -6.7159, -6.3760, -5.9790, -6.0471]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35424 533 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 692: ep_len:533 episode reward: total was -47.000000. running mean: -177.459404\n",
      "startIDX:  2850\n",
      "ep 692: ep_len:112 episode reward: total was -96.700000. running mean: -176.651810\n",
      "startIDX:  887\n",
      "692 10 True\n",
      "x_t:  1 [0.546875   0.29166667 0.121875   0.35416667]\n",
      "Q values:  tensor([[-11.4281, -13.1981, -12.8495, -11.1428, -10.8327, -11.1799]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11370 1635 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 692: ep_len:1635 episode reward: total was -272.900000. running mean: -177.614292\n",
      "startIDX:  1756\n",
      "692 12 False\n",
      "x_t:  0 [0.4125     0.41666667 0.1125     0.34583333]\n",
      "Q values:  tensor([[-4.9811, -6.2820, -6.2642, -6.5489, -6.2828, -5.5883]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21153 631 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 692: ep_len:631 episode reward: total was -66.200000. running mean: -176.500149\n",
      "startIDX:  1323\n",
      "692 15 True\n",
      "x_t:  3 [0.371875 0.275    0.09375  0.3     ]\n",
      "Q values:  tensor([[-8.1901, -7.9074, -8.6135, -7.9021, -7.5449, -6.7241]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10425 249 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 692: ep_len:249 episode reward: total was -22.600000. running mean: -174.961148\n",
      "startIDX:  2417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "692 22 True\n",
      "x_t:  2 [0.88125 0.4     0.08125 0.2125 ]\n",
      "Q values:  tensor([[-5.9459, -6.3709, -6.8523, -6.0226, -6.2333, -5.6348]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23628 340 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 692: ep_len:340 episode reward: total was -18.900000. running mean: -173.400536\n",
      "startIDX:  386\n",
      "693 0 True\n",
      "x_t:  3 [0.65625    0.375      0.19375    0.44583333]\n",
      "Q values:  tensor([[-8.2099, -8.8943, -8.8646, -8.7474, -8.3167, -7.8072]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7007 1078 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  869\n",
      "693 1 False\n",
      "x_t:  4 [0.078125   0.3875     0.1375     0.41666667]\n",
      "Q values:  tensor([[-6.9608, -7.0228, -7.4575, -6.9258, -6.3627, -6.5298]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35433 541 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  937\n",
      "693 5 True\n",
      "x_t:  3 [0.734375   0.3125     0.178125   0.40416667]\n",
      "Q values:  tensor([[-5.4436, -4.7635, -5.0438, -5.1078, -4.9598, -4.8835]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10496 235 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  126\n",
      "693 10 True\n",
      "x_t:  3 [0.165625   0.25416667 0.090625   0.2875    ]\n",
      "Q values:  tensor([[-7.9654, -7.3331, -7.9442, -7.4939, -7.9105, -6.9864]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3614 1093 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  18\n",
      "693 12 True\n",
      "x_t:  2 [0.00625    0.40833333 0.08125    0.25416667]\n",
      "Q values:  tensor([[-7.4777, -7.7065, -8.3285, -7.2975, -7.0724, -6.7413]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2927 993 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  679\n",
      "693 15 True\n",
      "x_t:  2 [0.534375   0.40833333 0.09375    0.29166667]\n",
      "Q values:  tensor([[-5.6576, -6.6683, -6.4044, -5.9418, -5.8238, -5.4404]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6009 418 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  972\n",
      "693 22 True\n",
      "x_t:  0 [0.74375    0.40833333 0.115625   0.36666667]\n",
      "Q values:  tensor([[-7.0162, -6.8932, -7.4274, -7.1556, -6.9285, -6.2105]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10544 518 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1668\n",
      "694 0 False\n",
      "x_t:  3 [0.30625    0.275      0.090625   0.31666667]\n",
      "Q values:  tensor([[-2.0962, -1.7417, -2.3622, -1.1774, -2.1256, -2.5779]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16894 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 694: ep_len:200 episode reward: total was 11.800000. running mean: -165.129010\n",
      "startIDX:  95\n",
      "694 1 False\n",
      "x_t:  3 [0.06875    0.225      0.06875    0.26666667]\n",
      "Q values:  tensor([[-10.3537,  -9.6894, -10.9241,  -9.1495, -10.0993,  -9.1999]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25793 216 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 694: ep_len:216 episode reward: total was -26.200000. running mean: -163.739720\n",
      "startIDX:  1401\n",
      "694 5 True\n",
      "x_t:  1 [0.2875     0.325      0.146875   0.37916667]\n",
      "Q values:  tensor([[-5.5489, -5.4681, -5.3974, -5.2137, -6.0982, -4.8024]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12537 230 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 694: ep_len:230 episode reward: total was -54.800000. running mean: -162.650323\n",
      "startIDX:  42\n",
      "694 10 True\n",
      "x_t:  3 [0.0625     0.24166667 0.059375   0.24583333]\n",
      "Q values:  tensor([[-6.9394, -6.9810, -7.4174, -7.0124, -6.4419, -6.5160]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3578 1092 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 694: ep_len:1092 episode reward: total was -120.900000. running mean: -162.232819\n",
      "startIDX:  249\n",
      "694 12 True\n",
      "x_t:  3 [0.34375 0.2875  0.08125 0.3125 ]\n",
      "Q values:  tensor([[-9.1604, -8.9825, -9.8339, -9.2390, -9.3723, -8.5320]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5718 1404 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 694: ep_len:1404 episode reward: total was -151.500000. running mean: -162.125491\n",
      "startIDX:  18\n",
      "694 15 True\n",
      "x_t:  3 [0.534375   0.32083333 0.096875   0.35833333]\n",
      "Q values:  tensor([[-6.0109, -5.9085, -6.1881, -5.6109, -6.2396, -5.9223]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 566 262 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 694: ep_len:262 episode reward: total was -19.200000. running mean: -160.696236\n",
      "startIDX:  2973\n",
      "ep 694: ep_len:24 episode reward: total was 20.000000. running mean: -158.889274\n",
      "startIDX:  1539\n",
      "695 0 False\n",
      "x_t:  3 [0.80625    0.34583333 0.190625   0.42083333]\n",
      "Q values:  tensor([[-4.5802, -4.8729, -4.6184, -4.3005, -4.9416, -4.3788]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16816 234 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  414\n",
      "695 1 False\n",
      "x_t:  0 [0.496875   0.375      0.125      0.49166667]\n",
      "Q values:  tensor([[-5.3498, -5.9478, -6.3438, -5.8011, -5.6044, -5.4432]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29185 531 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2275\n",
      "695 5 False\n",
      "x_t:  3 [0.38125    0.27916667 0.084375   0.34583333]\n",
      "Q values:  tensor([[-5.5521, -5.3722, -5.0243, -4.8684, -5.0199, -4.8761]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19947 208 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2484\n",
      "695 10 True\n",
      "x_t:  1 [0.696875   0.2875     0.115625   0.32916667]\n",
      "Q values:  tensor([[-10.2047, -10.9546, -11.2807, -10.1931, -10.2220,  -9.6150]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22488 1172 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1252\n",
      "695 12 True\n",
      "x_t:  4 [0.059375   0.44166667 0.146875   0.35833333]\n",
      "Q values:  tensor([[-5.9000, -5.1136, -5.7088, -6.1224, -5.4051, -5.0566]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17397 471 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2521\n",
      "695 15 False\n",
      "x_t:  3 [0.4875     0.28333333 0.1        0.325     ]\n",
      "Q values:  tensor([[-6.2240, -5.2678, -6.2507, -5.2190, -6.0280, -5.7760]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19720 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2582\n",
      "695 22 True\n",
      "x_t:  3 [0.0625   0.2375   0.059375 0.2375  ]\n",
      "Q values:  tensor([[-9.5190, -9.2450, -9.3865, -9.7369, -9.2445, -8.3443]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26172 1228 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1249\n",
      "696 0 False\n",
      "x_t:  3 [0.0625     0.24166667 0.06875    0.2625    ]\n",
      "Q values:  tensor([[-10.3752,  -9.7238,  -9.8241,  -9.1697, -10.3098,  -9.2003]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15158 1221 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 696: ep_len:1221 episode reward: total was -169.700000. running mean: -152.318255\n",
      "startIDX:  742\n",
      "696 1 False\n",
      "x_t:  3 [0.296875   0.25833333 0.0875     0.34583333]\n",
      "Q values:  tensor([[-8.6438, -9.0238, -9.1386, -7.6730, -8.7916, -8.0966]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34370 1422 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 696: ep_len:1422 episode reward: total was -247.600000. running mean: -153.271073\n",
      "startIDX:  2820\n",
      "696 5 True\n",
      "x_t:  0 [0.753125   0.39583333 0.103125   0.30833333]\n",
      "Q values:  tensor([[-6.7994, -7.0940, -6.8533, -6.2157, -6.9404, -5.8218]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23189 500 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 696: ep_len:500 episode reward: total was -89.900000. running mean: -152.637362\n",
      "startIDX:  2195\n",
      "696 10 True\n",
      "x_t:  0 [0.7375     0.39166667 0.06875    0.34166667]\n",
      "Q values:  tensor([[-5.2706, -5.1810, -5.9456, -5.5956, -5.0954, -4.9196]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19971 534 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 696: ep_len:534 episode reward: total was -60.400000. running mean: -151.714988\n",
      "startIDX:  290\n",
      "696 12 False\n",
      "x_t:  4 [0.41875    0.3875     0.08125    0.30416667]\n",
      "Q values:  tensor([[-6.9296, -7.7223, -7.2782, -7.1128, -6.1468, -6.4689]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7244 761 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 696: ep_len:761 episode reward: total was -73.300000. running mean: -150.930839\n",
      "startIDX:  2383\n",
      "696 15 False\n",
      "x_t:  4 [0.140625   0.40416667 0.1125     0.34583333]\n",
      "Q values:  tensor([[-5.3790, -5.5383, -5.9857, -5.2806, -5.1329, -5.2465]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19268 516 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 696: ep_len:516 episode reward: total was -51.800000. running mean: -149.939530\n",
      "startIDX:  879\n",
      "696 22 False\n",
      "x_t:  1 [0.184375   0.35416667 0.13125    0.3875    ]\n",
      "Q values:  tensor([[-4.5698, -3.9849, -4.6450, -4.1743, -4.7258, -4.0132]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9503 260 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 696: ep_len:260 episode reward: total was -45.900000. running mean: -148.899135\n",
      "startIDX:  1621\n",
      "697 0 False\n",
      "x_t:  3 [0.603125   0.33333333 0.1375     0.37916667]\n",
      "Q values:  tensor([[-6.4456, -6.5168, -6.8844, -5.8803, -6.4056, -5.9670]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16840 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697 1 True\n",
      "x_t:  1 [0.7875     0.275      0.165625   0.59583333]\n",
      "Q values:  tensor([[-5.7109, -5.4339, -5.4321, -5.2048, -5.5574, -4.9209]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28121 296 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1669\n",
      "697 5 True\n",
      "x_t:  1 [0.65       0.2875     0.1        0.29583333]\n",
      "Q values:  tensor([[-7.5466, -7.1857, -7.0932, -7.4207, -6.6784, -6.6946]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14953 660 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1233\n",
      "697 10 False\n",
      "x_t:  3 [0.115625   0.24166667 0.0625     0.24583333]\n",
      "Q values:  tensor([[-7.5882, -6.8895, -7.1771, -5.9377, -6.6429, -6.6978]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14593 1242 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1991\n",
      "startIDX:  367\n",
      "697 15 True\n",
      "x_t:  1 [0.003125   0.39166667 0.109375   0.47916667]\n",
      "Q values:  tensor([[-5.5554, -5.8217, -6.0747, -5.5170, -5.4825, -5.2259]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2751 232 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  256\n",
      "697 22 False\n",
      "x_t:  3 [0.06875  0.2375   0.053125 0.2375  ]\n",
      "Q values:  tensor([[ -9.7288, -10.7005, -10.9392,  -9.1542,  -9.7138,  -9.3513]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4873 1290 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1853\n",
      "698 0 True\n",
      "x_t:  1 [0.778125   0.29166667 0.13125    0.3875    ]\n",
      "Q values:  tensor([[-6.6454, -7.0359, -6.8980, -6.6014, -6.7396, -6.2213]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19004 1017 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 698: ep_len:1017 episode reward: total was -233.300000. running mean: -146.638511\n",
      "startIDX:  928\n",
      "698 1 False\n",
      "x_t:  4 [0.040625   0.39166667 0.090625   0.40833333]\n",
      "Q values:  tensor([[-6.5390, -6.6001, -6.4276, -6.4991, -5.7361, -5.7987]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35428 511 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 698: ep_len:511 episode reward: total was -74.900000. running mean: -145.921126\n",
      "startIDX:  1460\n",
      "698 5 True\n",
      "x_t:  0 [0.865625   0.39583333 0.1        0.32916667]\n",
      "Q values:  tensor([[-7.3907, -7.1803, -7.3401, -7.4324, -6.8095, -6.4333]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13506 478 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 698: ep_len:478 episode reward: total was -38.100000. running mean: -144.842915\n",
      "startIDX:  1373\n",
      "698 10 False\n",
      "x_t:  4 [0.09375    0.36666667 0.09375    0.27083333]\n",
      "Q values:  tensor([[-8.1751, -7.7551, -7.7281, -7.7933, -6.9966, -7.1273]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15717 544 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 698: ep_len:544 episode reward: total was -65.500000. running mean: -144.049485\n",
      "startIDX:  1638\n",
      "698 12 False\n",
      "x_t:  0 [0.68125    0.40833333 0.071875   0.34583333]\n",
      "Q values:  tensor([[-7.6565, -8.3792, -8.7912, -8.6488, -7.9971, -7.7118]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21120 858 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 698: ep_len:858 episode reward: total was -193.100000. running mean: -144.539991\n",
      "startIDX:  1335\n",
      "698 15 False\n",
      "x_t:  3 [0.85625    0.34583333 0.128125   0.39166667]\n",
      "Q values:  tensor([[-5.2165, -5.5882, -4.9687, -4.7628, -4.8739, -4.8352]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10340 211 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 698: ep_len:211 episode reward: total was 20.200000. running mean: -142.892591\n",
      "startIDX:  414\n",
      "698 22 True\n",
      "x_t:  4 [0.01875    0.41666667 0.084375   0.37083333]\n",
      "Q values:  tensor([[-8.8020, -9.1039, -9.7766, -9.4954, -8.7776, -8.6412]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 6631 882 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 698: ep_len:882 episode reward: total was -123.400000. running mean: -142.697665\n",
      "startIDX:  2005\n",
      "699 0 True\n",
      "x_t:  0 [0.9375     0.4        0.059375   0.35416667]\n",
      "Q values:  tensor([[-9.3164, -9.0842, -9.6914, -8.6095, -8.8045, -8.5137]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20626 854 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  676\n",
      "699 1 True\n",
      "x_t:  3 [0.18125    0.24583333 0.090625   0.32083333]\n",
      "Q values:  tensor([[-12.9756, -13.1873, -14.5391, -14.6176, -12.6060, -12.2775]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34341 1440 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2556\n",
      "699 5 False\n",
      "x_t:  2 [0.425      0.39583333 0.10625    0.275     ]\n",
      "Q values:  tensor([[-9.0982, -9.5580, -8.0210, -9.0774, -9.5831, -8.5788]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21619 824 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1421\n",
      "699 10 False\n",
      "x_t:  4 [0.359375   0.3375     0.06875    0.25833333]\n",
      "Q values:  tensor([[ -9.3487,  -9.8427,  -9.4354, -10.2172,  -8.6398,  -8.6992]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15766 541 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1636\n",
      "699 12 False\n",
      "x_t:  2 [0.125      0.40416667 0.06875    0.29583333]\n",
      "Q values:  tensor([[-11.6899, -13.0740, -11.4748, -11.8549, -12.1034, -11.5813]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19396 694 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  783\n",
      "699 15 True\n",
      "x_t:  2 [0.671875   0.40416667 0.0625     0.2875    ]\n",
      "Q values:  tensor([[ -8.9702, -10.0234,  -9.7766,  -9.2830,  -9.4060,  -8.3369]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5990 347 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2452\n",
      "699 22 False\n",
      "x_t:  2 [0.75625    0.40416667 0.071875   0.25      ]\n",
      "Q values:  tensor([[-7.5151, -7.6376, -7.1560, -7.4299, -7.9363, -7.1707]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23648 331 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  6412.275315284729\n",
      "startIDX:  2040\n",
      "700 0 True\n",
      "x_t:  0 [0.846875   0.4        0.128125   0.35416667]\n",
      "Q values:  tensor([[-11.1819, -12.4166, -11.6797, -11.8618, -10.8523, -10.8030]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20633 822 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 700: ep_len:822 episode reward: total was -144.400000. running mean: -142.139214\n",
      "startIDX:  737\n",
      "700 1 False\n",
      "x_t:  3 [0.0625     0.23333333 0.059375   0.275     ]\n",
      "Q values:  tensor([[-14.1832, -14.0935, -14.1643, -12.2769, -14.1321, -13.1024]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34301 1387 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 700: ep_len:1387 episode reward: total was -295.000000. running mean: -143.667822\n",
      "startIDX:  2385\n",
      "700 5 False\n",
      "x_t:  2 [0.04375    0.40416667 0.109375   0.26666667]\n",
      "Q values:  tensor([[-11.4851, -11.4792, -10.9600, -11.3203, -11.8131, -11.0887]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21554 950 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 700: ep_len:950 episode reward: total was -90.400000. running mean: -143.135143\n",
      "startIDX:  1275\n",
      "700 10 False\n",
      "x_t:  3 [0.378125   0.26666667 0.096875   0.32916667]\n",
      "Q values:  tensor([[-15.1270, -15.2478, -16.7414, -14.1708, -15.8380, -14.9951]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14666 1272 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 700: ep_len:1272 episode reward: total was -310.100000. running mean: -144.804792\n",
      "startIDX:  1898\n",
      "700 12 True\n",
      "x_t:  0 [0.440625   0.41666667 0.0875     0.36666667]\n",
      "Q values:  tensor([[-13.9823, -15.0539, -13.6621, -15.4214, -14.8125, -13.1272]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23022 921 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 700: ep_len:921 episode reward: total was -174.500000. running mean: -145.101744\n",
      "startIDX:  1337\n",
      "700 15 True\n",
      "x_t:  3 [0.296875   0.25416667 0.065625   0.28333333]\n",
      "Q values:  tensor([[-7.5118, -7.6630, -7.3967, -7.2218, -7.4580, -6.3256]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10446 265 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 700: ep_len:265 episode reward: total was -47.800000. running mean: -144.128727\n",
      "startIDX:  41\n",
      "700 22 False\n",
      "x_t:  1 [0.43125    0.32916667 0.096875   0.39583333]\n",
      "Q values:  tensor([[-10.9836,  -9.4860, -11.2083,  -9.9978, -11.0864,  -9.8754]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1625 739 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 700: ep_len:739 episode reward: total was -156.600000. running mean: -144.253439\n",
      "startIDX:  2059\n",
      "701 0 False\n",
      "x_t:  0 [0.80625    0.4        0.115625   0.40416667]\n",
      "Q values:  tensor([[-10.7006, -11.9004, -12.0227, -12.5377, -11.7506, -10.7620]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20729 855 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  352\n",
      "701 1 True\n",
      "x_t:  0 [0.575      0.37916667 0.134375   0.40416667]\n",
      "Q values:  tensor([[-13.4340, -14.2892, -13.2200, -13.3587, -13.1896, -11.9427]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29142 817 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  600\n",
      "701 5 True\n",
      "x_t:  2 [0.859375   0.37083333 0.08125    0.24166667]\n",
      "Q values:  tensor([[ -9.6023, -10.6641, -10.2926,  -9.5183,  -9.3736,  -8.7388]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6022 446 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701 10 False\n",
      "x_t:  2 [0.74375    0.39583333 0.06875    0.25      ]\n",
      "Q values:  tensor([[-7.4585, -7.6703, -7.4231, -7.8972, -8.6516, -7.4520]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12072 344 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  259\n",
      "701 12 False\n",
      "x_t:  3 [0.153125 0.2625   0.06875  0.2875  ]\n",
      "Q values:  tensor([[-14.5065, -13.7024, -13.6129, -12.8581, -14.8244, -13.2963]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5683 1376 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3\n",
      "701 15 False\n",
      "x_t:  3 [0.834375   0.34583333 0.121875   0.4375    ]\n",
      "Q values:  tensor([[-7.6867, -7.9442, -8.1233, -6.7927, -7.5101, -6.8897]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 523 254 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1617\n",
      "701 22 True\n",
      "x_t:  3 [0.778125   0.33333333 0.096875   0.40416667]\n",
      "Q values:  tensor([[-6.7969, -7.7804, -6.8130, -7.1998, -6.7939, -5.9837]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16859 260 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  99\n",
      "702 0 False\n",
      "x_t:  2 [0.73125    0.4125     0.1        0.27916667]\n",
      "Q values:  tensor([[-14.4346, -13.6464, -13.0882, -14.8047, -14.3150, -13.0972]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2332 1089 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 702: ep_len:1089 episode reward: total was -268.800000. running mean: -141.679012\n",
      "startIDX:  969\n",
      "702 1 True\n",
      "x_t:  4 [0.365625   0.36666667 0.0875     0.4125    ]\n",
      "Q values:  tensor([[-9.7022, -8.5114, -8.7130, -8.6625, -9.3130, -8.4394]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35477 496 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 702: ep_len:496 episode reward: total was -124.400000. running mean: -141.506222\n",
      "startIDX:  1283\n",
      "702 5 True\n",
      "x_t:  2 [0.003125   0.4        0.09375    0.26666667]\n",
      "Q values:  tensor([[ -9.8760, -10.1529,  -9.3753, -10.1040, -10.3359,  -9.3857]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12003 710 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 702: ep_len:710 episode reward: total was -125.100000. running mean: -141.342160\n",
      "startIDX:  2457\n",
      "702 10 True\n",
      "x_t:  1 [0.775      0.29166667 0.1375     0.325     ]\n",
      "Q values:  tensor([[-10.7135, -11.3886, -12.1121, -10.8725, -11.1643, -10.6025]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22480 1175 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 702: ep_len:1175 episode reward: total was -249.600000. running mean: -142.424738\n",
      "startIDX:  485\n",
      "702 12 False\n",
      "x_t:  3 [0.159375   0.25833333 0.059375   0.27916667]\n",
      "Q values:  tensor([[-6.4056, -6.8795, -6.4872, -6.1900, -6.4290, -6.2429]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7821 263 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 702: ep_len:263 episode reward: total was -78.100000. running mean: -141.781491\n",
      "startIDX:  1221\n",
      "702 15 False\n",
      "x_t:  3 [0.846875 0.3375   0.096875 0.3875  ]\n",
      "Q values:  tensor([[-6.9314, -7.3683, -6.5476, -5.7231, -7.4244, -5.8352]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10343 263 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 702: ep_len:263 episode reward: total was 37.800000. running mean: -139.985676\n",
      "startIDX:  2281\n",
      "702 22 True\n",
      "x_t:  2 [0.903125   0.37916667 0.04375    0.2       ]\n",
      "Q values:  tensor([[-12.8352, -13.8620, -13.1119, -14.0913, -14.0189, -12.6977]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23625 1439 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 702: ep_len:1439 episode reward: total was -346.400000. running mean: -142.049819\n",
      "startIDX:  1039\n",
      "703 0 True\n",
      "x_t:  1 [0.703125   0.3125     0.146875   0.44166667]\n",
      "Q values:  tensor([[-10.4366, -10.4840, -10.2661,  -9.8381,  -9.6569,  -9.4455]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11962 761 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  422\n",
      "703 1 False\n",
      "x_t:  0 [0.659375   0.375      0.121875   0.40416667]\n",
      "Q values:  tensor([[-6.1673, -7.4643, -6.9380, -7.3546, -7.2771, -6.7571]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29130 506 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2003\n",
      "703 5 True\n",
      "x_t:  3 [0.1        0.25416667 0.1        0.30833333]\n",
      "Q values:  tensor([[-12.8063, -13.1892, -12.0139, -13.1018, -12.0574, -11.6757]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18213 1242 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  945\n",
      "703 10 True\n",
      "x_t:  1 [0.309375   0.32083333 0.075      0.3625    ]\n",
      "Q values:  tensor([[-14.6407, -14.8418, -12.5368, -13.8745, -14.2184, -12.6430]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11402 1612 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  437\n",
      "703 12 True\n",
      "x_t:  3 [0.809375   0.375      0.1625     0.40416667]\n",
      "Q values:  tensor([[-7.3180, -7.0083, -7.5804, -7.0586, -6.9447, -6.4570]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7713 237 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  416\n",
      "703 15 False\n",
      "x_t:  0 [0.603125   0.4125     0.103125   0.34166667]\n",
      "Q values:  tensor([[-8.0024, -9.7820, -8.3378, -9.2381, -8.6095, -8.3273]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3702 451 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  233\n",
      "703 22 False\n",
      "x_t:  2 [0.74375    0.40416667 0.075      0.25      ]\n",
      "Q values:  tensor([[-7.9899, -8.1153, -7.2273, -8.2424, -8.6986, -7.4369]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2290 323 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  638\n",
      "704 0 False\n",
      "x_t:  2 [0.115625   0.4125     0.09375    0.26666667]\n",
      "Q values:  tensor([[-9.4014, -8.3293, -7.4001, -9.0473, -9.3094, -7.6977]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8886 911 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 704: ep_len:911 episode reward: total was -141.200000. running mean: -142.186683\n",
      "startIDX:  1093\n",
      "704 1 False\n",
      "x_t:  3 [0.596875 0.3      0.096875 0.3625  ]\n",
      "Q values:  tensor([[-1.4529, -1.1735, -1.4401,  0.2436, -0.1756, -1.9597]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35942 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 704: ep_len:200 episode reward: total was -16.200000. running mean: -140.926817\n",
      "startIDX:  2610\n",
      "704 5 False\n",
      "x_t:  1 [0.228125   0.35416667 0.175      0.49583333]\n",
      "Q values:  tensor([[-7.8130, -7.4708, -7.7333, -8.0201, -8.4800, -7.5038]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22125 287 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 704: ep_len:287 episode reward: total was -51.200000. running mean: -140.029548\n",
      "startIDX:  1857\n",
      "704 10 False\n",
      "x_t:  2 [0.190625   0.4        0.109375   0.24166667]\n",
      "Q values:  tensor([[ -9.6002,  -9.1016,  -8.9613, -10.8899,  -9.3524,  -9.1109]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18180 834 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 704: ep_len:834 episode reward: total was -156.300000. running mean: -140.192253\n",
      "startIDX:  1017\n",
      "704 12 False\n",
      "x_t:  2 [0.865625   0.39166667 0.065625   0.23333333]\n",
      "Q values:  tensor([[-8.2072, -8.0770, -7.1768, -8.9132, -7.8788, -7.4410]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13567 300 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 704: ep_len:300 episode reward: total was -70.500000. running mean: -139.495330\n",
      "startIDX:  2387\n",
      "704 15 True\n",
      "x_t:  4 [0.146875   0.4        0.10625    0.34583333]\n",
      "Q values:  tensor([[-8.2831, -8.9558, -8.0092, -8.7478, -8.7914, -7.9904]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19269 515 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 704: ep_len:515 episode reward: total was -113.200000. running mean: -139.232377\n",
      "startIDX:  2182\n",
      "704 22 False\n",
      "x_t:  0 [0.884375   0.39583333 0.053125   0.33333333]\n",
      "Q values:  tensor([[ -9.3239, -10.4644,  -9.3950, -10.3638,  -9.8525,  -9.4472]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20700 819 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 704: ep_len:819 episode reward: total was -152.400000. running mean: -139.364053\n",
      "startIDX:  1549\n",
      "705 0 True\n",
      "x_t:  3 [0.846875   0.34583333 0.15       0.425     ]\n",
      "Q values:  tensor([[-11.0247, -10.6683, -10.4470,  -9.4913, -10.7683,  -8.9905]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16812 227 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  623\n",
      "705 1 False\n",
      "x_t:  2 [0.04375  0.3875   0.115625 0.3     ]\n",
      "Q values:  tensor([[-7.4089, -7.3128, -6.4032, -7.4148, -6.9598, -6.8945]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31584 422 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1075\n",
      "705 5 False\n",
      "x_t:  3 [0.121875   0.22916667 0.071875   0.27083333]\n",
      "Q values:  tensor([[-16.4670, -16.6144, -15.4731, -15.0286, -17.0769, -15.1293]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10600 213 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  749\n",
      "705 10 True\n",
      "x_t:  1 [0.228125   0.33333333 0.1125     0.34583333]\n",
      "Q values:  tensor([[ -8.9247,  -9.8823,  -9.6614,  -9.0773, -10.7664,  -8.6893]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7128 224 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705 12 False\n",
      "x_t:  0 [0.840625   0.40833333 0.10625    0.3625    ]\n",
      "Q values:  tensor([[ -9.5002, -10.0248, -10.6224, -10.4975, -10.0539,  -9.5413]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21100 818 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2917\n",
      "705 15 False\n",
      "x_t:  0 [0.85625    0.40416667 0.115625   0.35      ]\n",
      "Q values:  tensor([[ -9.4269, -10.8734, -10.1773, -11.7459, -10.6931,  -9.4645]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23074 497 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  670\n",
      "705 22 False\n",
      "x_t:  2 [0.303125   0.40833333 0.10625    0.2625    ]\n",
      "Q values:  tensor([[-11.6032, -11.5618, -11.3888, -12.6895, -12.4377, -11.4841]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8967 919 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  906\n",
      "706 0 True\n",
      "x_t:  0 [0.6875     0.40416667 0.0875     0.34583333]\n",
      "Q values:  tensor([[-11.3116, -12.6885, -12.6174, -12.0516, -11.5293, -10.9246]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10364 455 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 706: ep_len:455 episode reward: total was -178.700000. running mean: -139.719522\n",
      "startIDX:  622\n",
      "706 1 True\n",
      "x_t:  2 [0.3     0.375   0.08125 0.3125 ]\n",
      "Q values:  tensor([[-11.0998, -10.9455, -11.4015, -11.2777, -11.0096, -10.9557]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31545 399 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 706: ep_len:399 episode reward: total was -190.600000. running mean: -140.228327\n",
      "startIDX:  1517\n",
      "706 5 False\n",
      "x_t:  0 [0.76875    0.39166667 0.103125   0.34583333]\n",
      "Q values:  tensor([[-12.6458, -14.3143, -15.1636, -13.3180, -13.0774, -13.1384]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13521 470 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 706: ep_len:470 episode reward: total was -223.100000. running mean: -141.057044\n",
      "startIDX:  2479\n",
      "706 10 False\n",
      "x_t:  1 [0.55625 0.3     0.14375 0.325  ]\n",
      "Q values:  tensor([[-16.8813, -15.4572, -17.7287, -16.9920, -16.4020, -16.1956]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22503 1164 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 706: ep_len:1164 episode reward: total was -497.700000. running mean: -144.623474\n",
      "startIDX:  905\n",
      "706 12 True\n",
      "x_t:  1 [0.71875    0.36666667 0.1625     0.50416667]\n",
      "Q values:  tensor([[-13.6126, -15.7368, -15.2812, -14.3534, -16.3192, -14.3602]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12922 614 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 706: ep_len:614 episode reward: total was -309.800000. running mean: -146.275239\n",
      "startIDX:  2943\n",
      "706 15 False\n",
      "x_t:  0 [0.840625   0.40416667 0.05625    0.35833333]\n",
      "Q values:  tensor([[-14.4093, -16.7530, -16.8951, -15.3630, -14.7786, -14.8215]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23084 483 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 706: ep_len:483 episode reward: total was -285.800000. running mean: -147.670486\n",
      "startIDX:  2633\n",
      "706 22 True\n",
      "x_t:  4 [0.003125   0.40833333 0.090625   0.29583333]\n",
      "Q values:  tensor([[-17.0998, -17.6029, -17.4028, -16.8846, -16.4576, -16.1789]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27262 544 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 706: ep_len:544 episode reward: total was -225.700000. running mean: -148.450782\n",
      "startIDX:  245\n",
      "707 0 True\n",
      "x_t:  2 [0.715625   0.40833333 0.0625     0.29166667]\n",
      "Q values:  tensor([[-19.8321, -20.8177, -20.3681, -19.1705, -19.5346, -18.3941]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2339 325 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  625\n",
      "707 1 True\n",
      "x_t:  2 [0.646875   0.38333333 0.125      0.30833333]\n",
      "Q values:  tensor([[-23.0121, -22.7666, -25.6179, -22.7375, -23.4730, -20.9623]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31486 378 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1546\n",
      "707 5 True\n",
      "x_t:  1 [0.540625   0.29166667 0.1125     0.29166667]\n",
      "Q values:  tensor([[-22.8791, -22.0824, -23.6711, -21.4180, -23.1768, -21.2010]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14969 734 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1149\n",
      "707 10 True\n",
      "x_t:  2 [0.303125   0.4        0.09375    0.24583333]\n",
      "Q values:  tensor([[-19.9364, -21.6794, -21.4577, -21.8824, -20.8620, -19.6529]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12142 366 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  617\n",
      "707 12 True\n",
      "x_t:  2 [0.003125   0.4125     0.06875    0.25416667]\n",
      "Q values:  tensor([[-19.7151, -19.4393, -20.0257, -21.7864, -18.6177, -18.3093]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9824 994 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1685\n",
      "707 15 False\n",
      "x_t:  1 [0.009375   0.36666667 0.13125    0.40833333]\n",
      "Q values:  tensor([[-24.0251, -23.1019, -26.9360, -25.2630, -26.0095, -25.3736]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12447 230 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1410\n",
      "707 22 True\n",
      "x_t:  3 [0.221875   0.275      0.078125   0.30416667]\n",
      "Q values:  tensor([[-25.5777, -28.4254, -27.6024, -27.8537, -27.9800, -25.3520]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15243 1267 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  269\n",
      "708 0 True\n",
      "x_t:  3 [0.134375   0.24166667 0.059375   0.25416667]\n",
      "Q values:  tensor([[-24.4919, -25.6974, -26.1317, -25.8184, -24.9077, -23.6137]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4862 1250 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 708: ep_len:1250 episode reward: total was -767.300000. running mean: -170.997606\n",
      "startIDX:  937\n",
      "708 1 False\n",
      "x_t:  4 [0.078125   0.3875     0.153125   0.41666667]\n",
      "Q values:  tensor([[-30.5399, -27.7319, -31.8200, -29.4494, -27.7252, -28.3900]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35435 501 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 708: ep_len:501 episode reward: total was -336.100000. running mean: -172.648630\n",
      "startIDX:  2491\n",
      "708 5 True\n",
      "x_t:  2 [0.73125    0.39166667 0.071875   0.27916667]\n",
      "Q values:  tensor([[-33.6984, -33.7429, -37.1559, -34.5786, -34.2056, -34.1853]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21666 868 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 708: ep_len:868 episode reward: total was -516.300000. running mean: -176.085144\n",
      "startIDX:  2065\n",
      "708 10 False\n",
      "x_t:  1 [0.10625    0.34583333 0.1375     0.3625    ]\n",
      "Q values:  tensor([[-28.4521, -26.0766, -28.3150, -26.4642, -28.0179, -26.6138]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18824 279 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 708: ep_len:279 episode reward: total was -161.900000. running mean: -175.943293\n",
      "startIDX:  1681\n",
      "708 12 False\n",
      "x_t:  1 [0.24375    0.34166667 0.071875   0.3625    ]\n",
      "Q values:  tensor([[-34.0733, -32.9115, -35.6468, -35.0450, -35.8486, -33.4941]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19894 228 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 708: ep_len:228 episode reward: total was -96.300000. running mean: -175.146860\n",
      "startIDX:  2502\n",
      "708 15 False\n",
      "x_t:  3 [0.415625   0.27083333 0.065625   0.30833333]\n",
      "Q values:  tensor([[-30.8378, -28.8350, -29.3214, -28.4157, -29.5742, -28.5568]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19740 224 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 708: ep_len:224 episode reward: total was -74.300000. running mean: -174.138391\n",
      "startIDX:  2087\n",
      "708 22 False\n",
      "x_t:  1 [0.371875   0.32916667 0.103125   0.37083333]\n",
      "Q values:  tensor([[-27.4799, -25.3643, -28.9721, -28.9897, -27.8679, -26.0559]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19030 222 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 708: ep_len:222 episode reward: total was -109.900000. running mean: -173.496007\n",
      "startIDX:  2048\n",
      "709 0 False\n",
      "x_t:  0 [0.84375    0.4        0.09375    0.35833333]\n",
      "Q values:  tensor([[-22.9100, -23.5504, -25.1216, -25.6725, -23.4501, -23.2094]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20637 831 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  516\n",
      "709 1 False\n",
      "x_t:  1 [0.79375    0.275      0.125      0.45416667]\n",
      "Q values:  tensor([[-24.5733, -21.7365, -25.9177, -23.7304, -23.6159, -22.6205]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30688 764 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2583\n",
      "709 5 False\n",
      "x_t:  2 [0.159375   0.39166667 0.0625     0.26666667]\n",
      "Q values:  tensor([[-20.2693, -21.1177, -19.5553, -21.3584, -20.5605, -19.6742]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21572 774 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1263\n",
      "709 10 False\n",
      "x_t:  3 [0.1        0.23333333 0.065625   0.25833333]\n",
      "Q values:  tensor([[-16.9498, -17.8982, -18.1359, -15.9712, -17.9297, -16.3756]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14588 1205 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1517\n",
      "709 12 False\n",
      "x_t:  2 [0.75       0.41666667 0.11875    0.29166667]\n",
      "Q values:  tensor([[-16.8908, -15.4050, -15.1356, -16.6975, -15.7815, -15.2406]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19479 788 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  1043\n",
      "709 15 False\n",
      "x_t:  4 [0.209375   0.3875     0.059375   0.29166667]\n",
      "Q values:  tensor([[-16.3310, -14.3214, -15.8255, -15.5750, -13.9162, -13.9469]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9847 612 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2234\n",
      "709 22 True\n",
      "x_t:  1 [0.8375     0.30833333 0.1        0.45      ]\n",
      "Q values:  tensor([[-15.5945, -14.8580, -15.1577, -14.5929, -14.8400, -13.4381]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22937 1107 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  6509.067892074585\n",
      "startIDX:  2339\n",
      "710 0 True\n",
      "x_t:  3 [0.159375 0.25     0.08125  0.2625  ]\n",
      "Q values:  tensor([[-14.7323, -13.5242, -14.5252, -13.5714, -12.9927, -12.8103]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26121 1252 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 710: ep_len:1252 episode reward: total was -373.400000. running mean: -183.167052\n",
      "startIDX:  493\n",
      "710 1 True\n",
      "x_t:  1 [0.734375   0.27916667 0.171875   0.45      ]\n",
      "Q values:  tensor([[-13.2044, -11.8467, -13.3903, -12.1981, -11.8960, -12.0174]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30694 783 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 710: ep_len:783 episode reward: total was -267.700000. running mean: -184.012382\n",
      "startIDX:  2227\n",
      "710 5 False\n",
      "x_t:  3 [0.6875     0.32083333 0.1375     0.42916667]\n",
      "Q values:  tensor([[-14.7899, -13.5686, -15.1956, -12.4987, -13.6927, -12.8155]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19902 211 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 710: ep_len:211 episode reward: total was 45.300000. running mean: -181.719258\n",
      "startIDX:  991\n",
      "710 10 True\n",
      "x_t:  1 [0.853125   0.2875     0.109375   0.32916667]\n",
      "Q values:  tensor([[-16.9837, -16.9068, -17.4267, -17.2312, -16.9833, -16.0376]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11332 1579 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 710: ep_len:1579 episode reward: total was -575.100000. running mean: -185.653065\n",
      "startIDX:  1033\n",
      "710 12 True\n",
      "x_t:  2 [0.79375    0.40833333 0.078125   0.24583333]\n",
      "Q values:  tensor([[-13.6986, -13.3783, -14.9719, -14.3186, -13.6632, -12.7696]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13577 310 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 710: ep_len:310 episode reward: total was -106.400000. running mean: -184.860535\n",
      "startIDX:  2152\n",
      "710 15 True\n",
      "x_t:  2 [0.609375   0.40416667 0.096875   0.26666667]\n",
      "Q values:  tensor([[-13.1297, -13.1911, -12.6119, -12.8430, -12.1058, -12.0009]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15593 338 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 710: ep_len:338 episode reward: total was -115.500000. running mean: -184.166929\n",
      "startIDX:  2462\n",
      "710 22 True\n",
      "x_t:  2 [0.83125    0.40416667 0.078125   0.25833333]\n",
      "Q values:  tensor([[-14.1364, -13.2742, -14.3850, -13.6526, -13.3247, -12.4256]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23636 322 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 710: ep_len:322 episode reward: total was -135.600000. running mean: -183.681260\n",
      "startIDX:  1662\n",
      "711 0 False\n",
      "x_t:  3 [0.334375   0.27083333 0.071875   0.325     ]\n",
      "Q values:  tensor([[ 3.2603,  4.4061,  4.8468, 10.3210,  7.6542,  5.0676]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16891 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  624\n",
      "711 1 False\n",
      "x_t:  2 [0.475      0.3875     0.103125   0.30833333]\n",
      "Q values:  tensor([[-14.1681, -13.4595, -13.1290, -13.2588, -13.9396, -13.5446]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31517 410 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2122\n",
      "711 5 False\n",
      "x_t:  4 [0.0125     0.42083333 0.11875    0.40833333]\n",
      "Q values:  tensor([[-14.5688, -14.1087, -15.3477, -14.3350, -13.3655, -13.7655]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19466 615 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1505\n",
      "711 10 False\n",
      "x_t:  3 [0.928125   0.3125     0.06875    0.41666667]\n",
      "Q values:  tensor([[-15.1165, -14.6713, -15.2052, -13.4112, -14.6538, -13.4656]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16398 338 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1056\n",
      "711 12 False\n",
      "x_t:  3 [0.065625   0.2625     0.0625     0.24583333]\n",
      "Q values:  tensor([[-27.6894, -25.3168, -26.8375, -25.2090, -26.5210, -25.3834]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16373 1382 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2490\n",
      "711 15 False\n",
      "x_t:  3 [0.709375   0.31666667 0.071875   0.36666667]\n",
      "Q values:  tensor([[-1.8860, -0.9290, -0.7018,  4.0559, -0.5457, -1.4734]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19681 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  384\n",
      "711 22 False\n",
      "x_t:  3 [0.15625    0.25416667 0.071875   0.2625    ]\n",
      "Q values:  tensor([[-21.9650, -21.6702, -21.9978, -19.7686, -20.9160, -19.8743]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4899 1227 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1084\n",
      "712 0 True\n",
      "x_t:  1 [0.80625    0.3125     0.171875   0.42916667]\n",
      "Q values:  tensor([[-23.9370, -21.1604, -22.9344, -23.0937, -24.2472, -22.3448]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11952 746 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 712: ep_len:746 episode reward: total was -341.400000. running mean: -190.026605\n",
      "startIDX:  1086\n",
      "712 1 False\n",
      "x_t:  3 [0.58125    0.29166667 0.09375    0.35833333]\n",
      "Q values:  tensor([[ 2.4693,  3.4006,  3.7799, 10.4984,  8.0242,  4.8325]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35945 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 712: ep_len:200 episode reward: total was -19.300000. running mean: -188.319339\n",
      "startIDX:  1246\n",
      "712 5 False\n",
      "x_t:  2 [0.046875   0.39166667 0.08125    0.27916667]\n",
      "Q values:  tensor([[-21.7941, -20.3052, -19.4394, -22.2348, -20.8049, -21.1028]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12010 734 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 712: ep_len:734 episode reward: total was -262.200000. running mean: -189.058145\n",
      "startIDX:  865\n",
      "712 10 False\n",
      "x_t:  0 [0.596875   0.40416667 0.096875   0.29166667]\n",
      "Q values:  tensor([[-19.6949, -20.2079, -20.3269, -20.5875, -21.3717, -19.8906]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8160 489 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 712: ep_len:489 episode reward: total was -204.400000. running mean: -189.211564\n",
      "startIDX:  163\n",
      "712 12 False\n",
      "x_t:  2 [0.771875   0.40416667 0.04375    0.25      ]\n",
      "Q values:  tensor([[-20.2627, -20.4895, -19.3396, -19.7099, -20.2522, -19.4818]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2816 287 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 712: ep_len:287 episode reward: total was -115.600000. running mean: -188.475448\n",
      "startIDX:  1917\n",
      "712 15 False\n",
      "x_t:  1 [0.871875   0.29166667 0.04375    0.30833333]\n",
      "Q values:  tensor([[-26.1459, -24.0285, -27.0144, -24.9603, -25.3242, -24.4282]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14846 704 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 712: ep_len:704 episode reward: total was -306.200000. running mean: -189.652694\n",
      "startIDX:  1944\n",
      "712 22 False\n",
      "x_t:  2 [0.428125   0.40833333 0.09375    0.2625    ]\n",
      "Q values:  tensor([[-23.2087, -23.6269, -23.0699, -24.9168, -24.9380, -23.1369]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18518 761 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 712: ep_len:761 episode reward: total was -284.500000. running mean: -190.601167\n",
      "startIDX:  917\n",
      "713 0 False\n",
      "x_t:  0 [0.75       0.4        0.0625     0.35416667]\n",
      "Q values:  tensor([[-15.9479, -17.3379, -17.1768, -18.7199, -16.6330, -16.7104]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10355 439 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  547\n",
      "713 1 False\n",
      "x_t:  1 [0.428125   0.29166667 0.109375   0.48333333]\n",
      "Q values:  tensor([[-20.3463, -18.7383, -20.1481, -21.2297, -20.1782, -18.8515]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30727 746 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2628\n",
      "713 5 True\n",
      "x_t:  1 [0.025      0.35833333 0.159375   0.50833333]\n",
      "Q values:  tensor([[-13.9165, -15.1474, -15.4639, -16.0079, -15.4653, -13.3733]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22108 270 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1682\n",
      "713 10 True\n",
      "x_t:  3 [0.86875    0.32916667 0.125      0.4       ]\n",
      "Q values:  tensor([[-14.3539, -14.2261, -14.1075, -13.3734, -14.6771, -12.5496]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16401 249 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  771\n",
      "713 12 True\n",
      "x_t:  0 [0.890625   0.4125     0.075      0.30416667]\n",
      "Q values:  tensor([[-16.3785, -16.2264, -17.2789, -16.8965, -16.4094, -15.5043]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11639 834 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  904\n",
      "713 15 False\n",
      "x_t:  3 [0.115625   0.2375     0.046875   0.23333333]\n",
      "Q values:  tensor([[-16.9130, -17.6348, -18.8544, -16.8455, -17.8152, -17.0237]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8519 1231 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  794\n",
      "713 22 False\n",
      "x_t:  2 [0.128125   0.40833333 0.053125   0.2625    ]\n",
      "Q values:  tensor([[-17.2098, -15.7533, -14.5611, -16.3621, -16.0301, -15.4220]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8934 834 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1929\n",
      "714 0 False\n",
      "x_t:  1 [0.675      0.30833333 0.140625   0.3625    ]\n",
      "Q values:  tensor([[-9.5330, -8.6102, -9.5470, -9.1116, -9.8803, -9.0558]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18996 272 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 714: ep_len:272 episode reward: total was -59.400000. running mean: -187.857981\n",
      "startIDX:  317\n",
      "714 1 True\n",
      "x_t:  0 [0.70625    0.375      0.0875     0.40416667]\n",
      "Q values:  tensor([[-12.5425, -13.0373, -12.9242, -12.9792, -13.0226, -11.6080]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29122 818 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 714: ep_len:818 episode reward: total was -135.500000. running mean: -187.334401\n",
      "startIDX:  1946\n",
      "714 5 True\n",
      "x_t:  3 [0.25       0.28333333 0.115625   0.35833333]\n",
      "Q values:  tensor([[-12.9344, -11.9941, -12.5160, -13.2475, -13.1869, -11.4213]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18252 1293 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 714: ep_len:1293 episode reward: total was -204.800000. running mean: -187.509057\n",
      "startIDX:  173\n",
      "714 10 True\n",
      "x_t:  4 [0.496875   0.33333333 0.059375   0.225     ]\n",
      "Q values:  tensor([[-10.1780, -10.7835, -10.4441, -11.4036, -10.4925,  -9.5691]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4657 529 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 714: ep_len:529 episode reward: total was -87.100000. running mean: -186.504967\n",
      "startIDX:  1120\n",
      "714 12 True\n",
      "x_t:  3 [0.3125     0.3        0.090625   0.34583333]\n",
      "Q values:  tensor([[-14.1192, -13.5023, -13.6925, -13.4910, -14.2517, -11.9208]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16427 1393 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 714: ep_len:1393 episode reward: total was -274.700000. running mean: -187.386917\n",
      "startIDX:  2055\n",
      "714 15 False\n",
      "x_t:  1 [0.134375   0.35416667 0.0875     0.325     ]\n",
      "Q values:  tensor([[-10.6275,  -9.4894, -10.4614, -11.4978, -10.6742,  -9.6518]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14939 676 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 714: ep_len:676 episode reward: total was -155.000000. running mean: -187.063048\n",
      "startIDX:  2201\n",
      "714 22 True\n",
      "x_t:  0 [0.890625 0.4      0.0625   0.3375  ]\n",
      "Q values:  tensor([[ -8.9726,  -9.5627,  -9.8409, -10.8070, -10.0700,  -8.8963]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20697 804 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 714: ep_len:804 episode reward: total was -114.700000. running mean: -186.339417\n",
      "startIDX:  1556\n",
      "715 0 True\n",
      "x_t:  3 [0.809375   0.34166667 0.134375   0.4125    ]\n",
      "Q values:  tensor([[-8.2124, -7.3035, -7.3663, -8.0065, -7.5710, -6.5888]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16820 228 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  777\n",
      "715 1 True\n",
      "x_t:  3 [0.09375    0.2375     0.08125    0.29583333]\n",
      "Q values:  tensor([[ -9.6041,  -9.9765, -10.0434,  -9.9366, -10.3829,  -8.7680]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34313 1385 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  714\n",
      "715 5 True\n",
      "x_t:  3 [0.084375   0.25833333 0.0875     0.32083333]\n",
      "Q values:  tensor([[-7.6391, -8.5535, -8.7720, -9.7944, -9.1995, -8.0002]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8756 1327 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  565\n",
      "715 10 True\n",
      "x_t:  2 [0.25       0.39166667 0.059375   0.27083333]\n",
      "Q values:  tensor([[-8.1284, -8.2806, -8.5138, -8.8793, -8.9245, -7.2808]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6622 763 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  228\n",
      "715 12 True\n",
      "x_t:  4 [0.0375     0.40416667 0.109375   0.3       ]\n",
      "Q values:  tensor([[-11.9959, -12.4994, -12.5436, -13.8699, -12.1486, -11.5969]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7301 2205 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1641\n",
      "715 15 True\n",
      "x_t:  1 [0.453125   0.32083333 0.071875   0.38333333]\n",
      "Q values:  tensor([[-6.0605, -5.9240, -6.1090, -6.6724, -6.0940, -5.1689]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12494 280 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2374\n",
      "715 22 True\n",
      "x_t:  1 [0.8375     0.30833333 0.1        0.45      ]\n",
      "Q values:  tensor([[-7.9143, -8.1845, -8.1491, -8.0677, -7.9274, -6.9379]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22937 1026 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  897\n",
      "716 0 False\n",
      "x_t:  0 [0.6375     0.40833333 0.115625   0.35      ]\n",
      "Q values:  tensor([[-5.6013, -6.0945, -5.8232, -6.3114, -6.2408, -5.6644]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10375 454 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 716: ep_len:454 episode reward: total was -41.200000. running mean: -180.105663\n",
      "startIDX:  1105\n",
      "ep 716: ep_len:212 episode reward: total was -46.200000. running mean: -178.766607\n",
      "startIDX:  764\n",
      "716 5 True\n",
      "x_t:  4 [0.578125   0.34583333 0.071875   0.25833333]\n",
      "Q values:  tensor([[-6.0163, -5.9180, -5.8155, -6.1590, -6.2952, -5.3650]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10147 696 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 716: ep_len:696 episode reward: total was -75.000000. running mean: -177.728941\n",
      "startIDX:  2296\n",
      "ep 716: ep_len:1293 episode reward: total was -241.200000. running mean: -178.363651\n",
      "startIDX:  420\n",
      "716 12 True\n",
      "x_t:  3 [0.421875   0.3        0.10625    0.32916667]\n",
      "Q values:  tensor([[-4.6520, -5.1205, -4.7432, -5.1825, -4.9768, -4.2293]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7769 276 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 716: ep_len:276 episode reward: total was -2.400000. running mean: -176.604015\n",
      "startIDX:  1156\n",
      "716 15 True\n",
      "x_t:  4 [0.15       0.39166667 0.09375    0.29166667]\n",
      "Q values:  tensor([[-5.7423, -5.8714, -5.3886, -6.1614, -5.4785, -4.8563]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9838 560 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 716: ep_len:560 episode reward: total was -40.800000. running mean: -175.245975\n",
      "startIDX:  2322\n",
      "716 22 False\n",
      "x_t:  1 [0.815625   0.29166667 0.0875     0.47083333]\n",
      "Q values:  tensor([[-4.5063, -4.2274, -4.5986, -5.0208, -4.8138, -4.2633]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22939 1071 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 716: ep_len:1071 episode reward: total was -100.500000. running mean: -174.498515\n",
      "startIDX:  279\n",
      "717 0 True\n",
      "x_t:  3 [0.0625     0.22916667 0.065625   0.23333333]\n",
      "Q values:  tensor([[-5.5660, -5.8503, -5.8163, -6.3582, -5.9889, -5.2732]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4835 1259 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  307\n",
      "717 1 False\n",
      "x_t:  0 [0.503125   0.375      0.128125   0.45833333]\n",
      "Q values:  tensor([[-4.1670, -4.8014, -4.7983, -4.6165, -4.7600, -4.2041]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29162 855 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2087\n",
      "717 5 True\n",
      "x_t:  4 [0.578125   0.375      0.071875   0.36666667]\n",
      "Q values:  tensor([[-4.5157, -4.6014, -4.9231, -5.1435, -4.8782, -4.1487]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19518 652 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1147\n",
      "717 10 True\n",
      "x_t:  2 [0.803125   0.4        0.084375   0.24583333]\n",
      "Q values:  tensor([[-4.9313, -4.9170, -4.9329, -5.2314, -4.6047, -4.1606]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12060 317 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  116\n",
      "717 12 True\n",
      "x_t:  1 [0.640625   0.32083333 0.078125   0.42083333]\n",
      "Q values:  tensor([[-4.5793, -4.4921, -4.6102, -4.9660, -5.0609, -4.1720]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2238 586 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  448\n",
      "717 15 False\n",
      "x_t:  0 [0.721875 0.4125   0.0875   0.3375  ]\n",
      "Q values:  tensor([[-3.5845, -3.9090, -4.3921, -4.2330, -4.0479, -3.6138]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3685 438 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  818\n",
      "717 22 True\n",
      "x_t:  0 [0.815625   0.39583333 0.065625   0.32916667]\n",
      "Q values:  tensor([[-4.8548, -5.4163, -4.6330, -5.5660, -5.2416, -4.4462]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10416 732 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1676\n",
      "718 0 True\n",
      "x_t:  3 [0.2375 0.275  0.1125 0.3   ]\n",
      "Q values:  tensor([[-4.3435, -3.9955, -3.9584, -4.6089, -4.4222, -3.5678]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16910 209 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 718: ep_len:209 episode reward: total was -46.600000. running mean: -164.415208\n",
      "startIDX:  355\n",
      "718 1 True\n",
      "x_t:  0 [0.740625   0.38333333 0.140625   0.39166667]\n",
      "Q values:  tensor([[-4.8744, -4.4009, -4.6217, -5.5928, -5.0682, -4.3711]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29113 793 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 718: ep_len:793 episode reward: total was -53.000000. running mean: -163.301056\n",
      "startIDX:  574\n",
      "718 5 True\n",
      "x_t:  2 [0.825 0.375 0.1   0.3  ]\n",
      "Q values:  tensor([[-4.4315, -4.7048, -4.2211, -4.8254, -4.6574, -3.7881]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6033 463 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 718: ep_len:463 episode reward: total was -54.200000. running mean: -162.210045\n",
      "startIDX:  2383\n",
      "718 10 True\n",
      "x_t:  1 [0.884375   0.2875     0.1125     0.33333333]\n",
      "Q values:  tensor([[-6.0919, -5.6183, -6.0621, -6.6739, -6.3993, -5.1252]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22468 1202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 718: ep_len:1202 episode reward: total was -137.700000. running mean: -161.964945\n",
      "startIDX:  167\n",
      "718 12 True\n",
      "x_t:  2 [0.796875 0.4125   0.078125 0.2375  ]\n",
      "Q values:  tensor([[-3.8082, -3.9115, -3.8516, -4.5645, -4.4045, -3.4217]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2808 266 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 718: ep_len:266 episode reward: total was -27.500000. running mean: -160.620295\n",
      "startIDX:  970\n",
      "718 15 True\n",
      "x_t:  4 [0.03125    0.3875     0.075      0.30416667]\n",
      "Q values:  tensor([[-4.3262, -4.2478, -4.3730, -4.7660, -4.4194, -3.7967]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9816 639 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 718: ep_len:639 episode reward: total was -38.900000. running mean: -159.403092\n",
      "startIDX:  2787\n",
      "ep 718: ep_len:123 episode reward: total was 95.000000. running mean: -156.859061\n",
      "startIDX:  1417\n",
      "719 0 True\n",
      "x_t:  4 [0.35       0.3625     0.096875   0.28333333]\n",
      "Q values:  tensor([[-4.1339, -5.0895, -4.6700, -5.1415, -4.4772, -4.0641]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16343 535 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  644\n",
      "719 1 True\n",
      "x_t:  2 [0.725      0.38333333 0.109375   0.3125    ]\n",
      "Q values:  tensor([[-4.2103, -4.9307, -4.2807, -5.2859, -4.9672, -4.0275]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31474 369 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1046\n",
      "719 5 False\n",
      "x_t:  3 [0.409375   0.27083333 0.121875   0.32083333]\n",
      "Q values:  tensor([[3.9967, 1.9960, 6.1769, 6.6727, 4.9659, 4.8705]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 10543 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1222\n",
      "719 10 True\n",
      "x_t:  3 [0.15625    0.22916667 0.075      0.27916667]\n",
      "Q values:  tensor([[-5.2657, -4.8329, -5.4662, -5.4216, -5.0134, -4.4073]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14605 1242 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  962\n",
      "719 12 True\n",
      "x_t:  1 [0.103125   0.39583333 0.165625   0.475     ]\n",
      "Q values:  tensor([[-5.0522, -5.1698, -5.1790, -5.5295, -5.6036, -4.4612]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12966 621 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  855\n",
      "719 15 True\n",
      "x_t:  3 [0.171875   0.24166667 0.053125   0.24166667]\n",
      "Q values:  tensor([[-5.4746, -4.9321, -5.4596, -6.2169, -5.6729, -4.8580]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8558 1289 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  13\n",
      "719 22 True\n",
      "x_t:  1 [0.6125     0.32916667 0.1125     0.3875    ]\n",
      "Q values:  tensor([[-4.1151, -4.4899, -4.1014, -4.5292, -4.7297, -3.7272]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1607 751 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  6619.679014444351\n",
      "startIDX:  873\n",
      "720 0 True\n",
      "x_t:  0 [0.8625     0.40416667 0.121875   0.35      ]\n",
      "Q values:  tensor([[-4.6862, -4.9328, -5.2979, -5.4541, -5.2922, -4.2555]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10335 463 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 720: ep_len:463 episode reward: total was -72.000000. running mean: -149.237053\n",
      "startIDX:  31\n",
      "720 1 False\n",
      "x_t:  3 [0.41875    0.26666667 0.11875    0.34583333]\n",
      "Q values:  tensor([[1.8671, 2.9857, 3.5131, 4.5724, 3.4943, 2.7511]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 25698 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 720: ep_len:202 episode reward: total was 13.400000. running mean: -147.610683\n",
      "startIDX:  1030\n",
      "720 5 False\n",
      "x_t:  3 [0.371875   0.2625     0.153125   0.32083333]\n",
      "Q values:  tensor([[1.3317, 1.1047, 2.2100, 2.4422, 2.3065, 0.9755]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 10546 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 720: ep_len:203 episode reward: total was 12.100000. running mean: -146.013576\n",
      "startIDX:  867\n",
      "720 10 True\n",
      "x_t:  0 [0.596875   0.40416667 0.096875   0.29166667]\n",
      "Q values:  tensor([[-4.5196, -4.9913, -5.0189, -5.4945, -4.6518, -4.2847]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8160 473 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 720: ep_len:473 episode reward: total was -65.000000. running mean: -145.203440\n",
      "startIDX:  111\n",
      "720 12 True\n",
      "x_t:  1 [0.684375   0.32916667 0.140625   0.4375    ]\n",
      "Q values:  tensor([[-4.0266, -4.4704, -4.1530, -4.4632, -4.5876, -3.7390]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2231 603 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 720: ep_len:603 episode reward: total was -48.800000. running mean: -144.239406\n",
      "startIDX:  3007\n",
      "ep 720: ep_len:79 episode reward: total was -75.900000. running mean: -143.556011\n",
      "startIDX:  1963\n",
      "720 22 True\n",
      "x_t:  1 [0.08125    0.35416667 0.125      0.39583333]\n",
      "Q values:  tensor([[-3.4669, -3.8130, -3.5915, -3.9927, -3.6243, -3.0793]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18998 269 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 720: ep_len:269 episode reward: total was 38.000000. running mean: -141.740451\n",
      "startIDX:  2327\n",
      "721 0 True\n",
      "x_t:  3 [0.171875   0.25       0.08125    0.26666667]\n",
      "Q values:  tensor([[-4.6467, -5.1742, -5.1627, -5.5566, -4.9537, -4.2258]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26124 1259 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  438\n",
      "721 1 True\n",
      "x_t:  1 [0.590625   0.28333333 0.084375   0.47083333]\n",
      "Q values:  tensor([[-4.3538, -4.8534, -4.6594, -5.3999, -5.1397, -4.0082]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30713 797 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  10\n",
      "721 5 True\n",
      "x_t:  1 [0.434375   0.32916667 0.1625     0.54166667]\n",
      "Q values:  tensor([[-5.4647, -5.3121, -5.6365, -5.9789, -5.3060, -4.8110]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2540 1150 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  958\n",
      "721 10 True\n",
      "x_t:  1 [0.753125   0.28333333 0.128125   0.34166667]\n",
      "Q values:  tensor([[-5.9800, -6.2016, -6.0654, -6.3747, -5.9922, -5.1660]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11342 1577 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  645\n",
      "721 12 True\n",
      "x_t:  2 [0.065625   0.4125     0.05625    0.25416667]\n",
      "Q values:  tensor([[-4.4635, -4.7130, -4.3415, -5.0171, -5.4294, -4.0132]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9836 1008 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2946\n",
      "721 15 True\n",
      "x_t:  0 [0.278125   0.41666667 0.078125   0.3       ]\n",
      "Q values:  tensor([[-3.9501, -3.9179, -3.6854, -4.3771, -3.9248, -3.5130]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23208 550 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  22\n",
      "721 22 True\n",
      "x_t:  1 [0.128125   0.37083333 0.15625    0.40833333]\n",
      "Q values:  tensor([[-3.8692, -4.3753, -4.3705, -4.7177, -4.3463, -3.6146]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1653 762 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1921\n",
      "722 0 True\n",
      "x_t:  1 [0.290625   0.34583333 0.15625    0.375     ]\n",
      "Q values:  tensor([[-4.5826, -4.5816, -4.6220, -4.7182, -4.7520, -3.9708]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18953 246 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 722: ep_len:246 episode reward: total was -5.500000. running mean: -136.584065\n",
      "startIDX:  227\n",
      "722 1 False\n",
      "x_t:  0 [0.515625   0.36666667 0.1125     0.50416667]\n",
      "Q values:  tensor([[-4.7537, -5.5862, -5.4931, -6.2919, -5.7216, -4.8006]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29192 1709 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 722: ep_len:1709 episode reward: total was -210.800000. running mean: -137.326224\n",
      "startIDX:  517\n",
      "722 5 True\n",
      "x_t:  2 [0.09375    0.39166667 0.10625    0.30833333]\n",
      "Q values:  tensor([[-3.9697, -4.1504, -3.9951, -4.1528, -4.3176, -3.4522]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6134 543 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 722: ep_len:543 episode reward: total was -97.200000. running mean: -136.924962\n",
      "startIDX:  2613\n",
      "ep 722: ep_len:8 episode reward: total was -2.900000. running mean: -135.584712\n",
      "startIDX:  138\n",
      "722 12 True\n",
      "x_t:  2 [0.4        0.40833333 0.084375   0.25      ]\n",
      "Q values:  tensor([[-4.2824, -4.6417, -4.3308, -4.9046, -4.3336, -3.8238]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2870 330 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 722: ep_len:330 episode reward: total was -28.800000. running mean: -134.516865\n",
      "startIDX:  2035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "722 15 True\n",
      "x_t:  1 [0.928125   0.29166667 0.06875    0.31666667]\n",
      "Q values:  tensor([[-4.5149, -4.4814, -4.9045, -4.8703, -4.7527, -4.0238]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14837 644 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 722: ep_len:644 episode reward: total was -52.400000. running mean: -133.695697\n",
      "startIDX:  2589\n",
      "722 22 True\n",
      "x_t:  3 [0.346875   0.28333333 0.103125   0.30416667]\n",
      "Q values:  tensor([[-5.5523, -5.3138, -5.5988, -5.9396, -5.7038, -4.7538]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26251 1252 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 722: ep_len:1252 episode reward: total was -105.500000. running mean: -133.413740\n",
      "startIDX:  2129\n",
      "723 0 True\n",
      "x_t:  1 [0.51875    0.33333333 0.225      0.50416667]\n",
      "Q values:  tensor([[-4.7533, -4.7998, -5.3611, -5.4998, -4.9927, -4.3351]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22942 1150 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1142\n",
      "startIDX:  2845\n",
      "startIDX:  1364\n",
      "723 10 True\n",
      "x_t:  4 [0.328125   0.34166667 0.1        0.25833333]\n",
      "Q values:  tensor([[-4.9135, -4.9872, -5.0555, -4.8364, -5.3359, -4.4288]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15762 573 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1320\n",
      "723 12 True\n",
      "x_t:  2 [0.15625    0.40833333 0.103125   0.29583333]\n",
      "Q values:  tensor([[-6.0054, -5.4682, -6.2277, -6.5298, -6.5387, -5.4208]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19401 1011 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  593\n",
      "723 15 True\n",
      "x_t:  1 [0.76875    0.30833333 0.053125   0.27083333]\n",
      "Q values:  tensor([[-4.7571, -4.8391, -4.7977, -5.5148, -4.7557, -4.2349]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5186 690 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2917\n",
      "startIDX:  2018\n",
      "724 0 True\n",
      "x_t:  0 [0.74375    0.4        0.1        0.32916667]\n",
      "Q values:  tensor([[-5.8199, -6.0144, -6.1155, -6.0772, -5.6134, -5.2780]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20657 858 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 724: ep_len:858 episode reward: total was -87.700000. running mean: -128.172881\n",
      "startIDX:  274\n",
      "724 1 True\n",
      "x_t:  0 [0.8375     0.37083333 0.13125    0.40416667]\n",
      "Q values:  tensor([[-7.2680, -7.2849, -7.0480, -7.7460, -7.6411, -6.3703]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29096 1624 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 724: ep_len:1624 episode reward: total was -177.900000. running mean: -128.670152\n",
      "startIDX:  2732\n",
      "724 5 False\n",
      "x_t:  0 [0.825      0.39166667 0.09375    0.32083333]\n",
      "Q values:  tensor([[-4.1558, -5.2030, -5.0218, -5.3680, -4.8656, -4.2740]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23172 756 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 724: ep_len:756 episode reward: total was -111.100000. running mean: -128.494451\n",
      "startIDX:  381\n",
      "724 10 True\n",
      "x_t:  3 [0.734375   0.30416667 0.13125    0.3875    ]\n",
      "Q values:  tensor([[-4.4987, -5.2290, -4.5948, -5.3292, -5.1456, -4.1134]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5048 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 724: ep_len:201 episode reward: total was 35.800000. running mean: -126.851506\n",
      "startIDX:  1844\n",
      "724 12 True\n",
      "x_t:  0 [0.30625    0.42916667 0.103125   0.2625    ]\n",
      "Q values:  tensor([[-6.4180, -5.9725, -6.3472, -6.8543, -6.7255, -5.5114]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23004 970 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 724: ep_len:970 episode reward: total was -111.300000. running mean: -126.695991\n",
      "startIDX:  1619\n",
      "724 15 True\n",
      "x_t:  1 [0.359375   0.33333333 0.115625   0.37916667]\n",
      "Q values:  tensor([[-5.4433, -6.1516, -5.4149, -6.5589, -6.3372, -5.1888]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12484 986 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 724: ep_len:986 episode reward: total was -148.000000. running mean: -126.909031\n",
      "startIDX:  992\n",
      "724 22 True\n",
      "x_t:  0 [0.553125   0.4        0.08125    0.33333333]\n",
      "Q values:  tensor([[-4.8719, -5.4478, -5.2484, -5.2738, -5.1890, -4.5454]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10474 484 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 724: ep_len:484 episode reward: total was -42.800000. running mean: -126.067941\n",
      "startIDX:  1398\n",
      "725 0 True\n",
      "x_t:  4 [0.23125    0.37916667 0.121875   0.275     ]\n",
      "Q values:  tensor([[-5.7646, -5.5142, -5.6623, -6.0022, -5.5885, -5.0200]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16323 550 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  560\n",
      "725 1 True\n",
      "x_t:  2 [0.7625     0.37916667 0.09375    0.32083333]\n",
      "Q values:  tensor([[-7.1328, -7.1880, -7.3099, -7.7325, -7.7219, -6.7228]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31469 1142 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2583\n",
      "725 5 True\n",
      "x_t:  0 [0.93125    0.3875     0.0625     0.30833333]\n",
      "Q values:  tensor([[-7.8350, -7.5479, -8.4184, -8.2845, -8.5379, -7.3837]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23151 1562 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  187\n",
      "725 10 True\n",
      "x_t:  4 [0.496875   0.33333333 0.05625    0.22916667]\n",
      "Q values:  tensor([[-5.3496, -5.6341, -5.5138, -5.9360, -5.5565, -4.8313]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4659 512 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  982\n",
      "725 12 True\n",
      "x_t:  4 [0.128125   0.42083333 0.084375   0.37083333]\n",
      "Q values:  tensor([[-12.8325, -12.8916, -12.9101, -13.1807, -13.5624, -11.0247]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17402 2272 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1484\n",
      "725 15 True\n",
      "x_t:  2 [0.20625    0.40416667 0.05       0.25833333]\n",
      "Q values:  tensor([[-6.0803, -6.2791, -6.4878, -7.0397, -6.3414, -5.5674]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 11939 787 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  176\n",
      "725 22 True\n",
      "x_t:  2 [0.640625   0.40416667 0.059375   0.25833333]\n",
      "Q values:  tensor([[-5.1415, -5.4396, -5.9937, -5.8226, -5.7412, -5.0572]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2309 351 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1529\n",
      "726 0 True\n",
      "x_t:  3 [0.559375 0.3125   0.08125  0.375   ]\n",
      "Q values:  tensor([[-5.9498, -6.0944, -6.0897, -6.8758, -6.3799, -5.2460]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16852 253 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 726: ep_len:253 episode reward: total was -54.400000. running mean: -124.969096\n",
      "startIDX:  545\n",
      "726 1 True\n",
      "x_t:  3 [0.159375   0.24583333 0.075      0.30416667]\n",
      "Q values:  tensor([[-11.6542, -11.9669, -12.3501, -14.0127, -13.1197, -11.0592]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34333 2576 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 726: ep_len:2576 episode reward: total was -326.900000. running mean: -126.988405\n",
      "startIDX:  1061\n",
      "726 5 False\n",
      "x_t:  3 [0.30625    0.25416667 0.090625   0.29583333]\n",
      "Q values:  tensor([[-0.2052,  1.7872,  1.4738,  3.2505,  1.6768,  1.2885]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10563 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 726: ep_len:200 episode reward: total was 38.900000. running mean: -125.329521\n",
      "startIDX:  1113\n",
      "726 10 True\n",
      "x_t:  3 [0.078125 0.225    0.059375 0.25    ]\n",
      "Q values:  tensor([[-5.7010, -6.3365, -6.6643, -6.5905, -6.2560, -5.3042]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14578 1606 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 726: ep_len:1606 episode reward: total was -163.100000. running mean: -125.707226\n",
      "startIDX:  163\n",
      "726 12 True\n",
      "x_t:  2 [0.790625 0.4125   0.075    0.25    ]\n",
      "Q values:  tensor([[-4.0523, -4.0391, -3.8710, -4.5705, -4.0750, -3.5195]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2809 279 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 726: ep_len:279 episode reward: total was -21.800000. running mean: -124.668154\n",
      "startIDX:  1953\n",
      "726 15 False\n",
      "x_t:  1 [0.471875   0.31666667 0.0875     0.30416667]\n",
      "Q values:  tensor([[-4.5356, -4.2153, -4.8464, -5.2728, -5.1192, -4.3124]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14896 723 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 726: ep_len:723 episode reward: total was -136.400000. running mean: -124.785472\n",
      "startIDX:  1624\n",
      "726 22 True\n",
      "x_t:  2 [0.584375   0.40416667 0.046875   0.2625    ]\n",
      "Q values:  tensor([[-5.1556, -5.1035, -5.0600, -5.4744, -5.5407, -4.5114]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18539 1077 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 726: ep_len:1077 episode reward: total was -121.700000. running mean: -124.754618\n",
      "startIDX:  2441\n",
      "startIDX:  726\n",
      "727 1 True\n",
      "x_t:  3 [0.084375   0.23333333 0.0875     0.29583333]\n",
      "Q values:  tensor([[-4.6749, -5.3699, -5.3599, -5.7853, -5.6501, -4.6577]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34310 1392 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2813\n",
      "727 5 True\n",
      "x_t:  0 [0.60625 0.4     0.1     0.3125 ]\n",
      "Q values:  tensor([[-5.2036, -5.0233, -4.9210, -5.1910, -5.3483, -4.4260]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23217 515 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  80\n",
      "727 10 True\n",
      "x_t:  3 [0.428125   0.2875     0.1125     0.34583333]\n",
      "Q values:  tensor([[-4.6290, -4.2236, -4.6191, -3.9741, -4.5103, -3.8223]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3667 1112 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1807\n",
      "727 12 True\n",
      "x_t:  0 [0.89375    0.40416667 0.05625    0.36666667]\n",
      "Q values:  tensor([[-4.4473, -4.2960, -4.2052, -4.3957, -4.4480, -3.6272]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21096 577 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  215\n",
      "727 15 True\n",
      "x_t:  2 [0.203125   0.40833333 0.125      0.3375    ]\n",
      "Q values:  tensor([[-4.9052, -4.4738, -4.8449, -5.0279, -4.9899, -4.1546]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2219 804 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1231\n",
      "727 22 True\n",
      "x_t:  2 [0.778125   0.4125     0.090625   0.24583333]\n",
      "Q values:  tensor([[-4.4836, -4.8460, -4.9625, -4.9092, -4.8107, -4.2097]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12590 326 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1951\n",
      "728 0 False\n",
      "x_t:  0 [0.765625   0.4        0.10625    0.34166667]\n",
      "Q values:  tensor([[-3.3550, -4.0260, -4.0757, -4.4390, -3.9214, -3.5387]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20653 1083 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 728: ep_len:1083 episode reward: total was -122.700000. running mean: -119.652092\n",
      "startIDX:  569\n",
      "728 1 True\n",
      "x_t:  1 [0.65625    0.27083333 0.140625   0.4625    ]\n",
      "Q values:  tensor([[-4.4885, -4.1371, -4.5301, -4.7869, -4.4260, -3.8379]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30701 733 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 728: ep_len:733 episode reward: total was -60.000000. running mean: -119.055571\n",
      "startIDX:  2348\n",
      "728 5 False\n",
      "x_t:  3 [0.078125   0.24583333 0.0875     0.27916667]\n",
      "Q values:  tensor([[2.7460, 1.6545, 3.4412, 3.7821, 3.4946, 3.2178]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 20008 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 728: ep_len:200 episode reward: total was -11.900000. running mean: -117.984015\n",
      "startIDX:  1206\n",
      "728 10 True\n",
      "x_t:  3 [0.384375   0.27083333 0.103125   0.32083333]\n",
      "Q values:  tensor([[-3.5287, -3.7324, -3.9087, -4.1359, -4.0276, -3.4891]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14667 1299 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 728: ep_len:1299 episode reward: total was -115.100000. running mean: -117.955175\n",
      "startIDX:  279\n",
      "728 12 False\n",
      "x_t:  4 [0.428125   0.39583333 0.090625   0.3375    ]\n",
      "Q values:  tensor([[-5.3990, -5.2093, -5.2024, -6.1105, -4.7772, -4.8782]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7234 768 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 728: ep_len:768 episode reward: total was -57.500000. running mean: -117.350623\n",
      "startIDX:  154\n",
      "728 15 False\n",
      "x_t:  1 [0.4375     0.34583333 0.1625     0.52083333]\n",
      "Q values:  tensor([[-3.9244, -3.3901, -4.0113, -4.1554, -3.8859, -3.4162]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2785 1126 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 728: ep_len:1126 episode reward: total was -119.200000. running mean: -117.369117\n",
      "startIDX:  1697\n",
      "728 22 True\n",
      "x_t:  3 [0.60625    0.32083333 0.128125   0.36666667]\n",
      "Q values:  tensor([[-4.8852, -5.2111, -5.4726, -5.7359, -5.6021, -4.5752]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16882 219 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 728: ep_len:219 episode reward: total was 13.300000. running mean: -116.062426\n",
      "startIDX:  2132\n",
      "729 0 True\n",
      "x_t:  1 [0.4375     0.3375     0.1375     0.50833333]\n",
      "Q values:  tensor([[-4.6909, -4.4304, -4.4249, -4.7749, -4.6432, -4.1117]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22952 1152 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  444\n",
      "729 1 True\n",
      "x_t:  1 [0.215625   0.31666667 0.1875     0.5       ]\n",
      "Q values:  tensor([[-5.6043, -5.9166, -6.2406, -6.5433, -6.3624, -5.2203]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30746 812 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1034\n",
      "729 5 True\n",
      "x_t:  2 [0.23125    0.3875     0.06875    0.29166667]\n",
      "Q values:  tensor([[-5.6824, -5.7286, -5.5541, -5.9008, -5.9786, -4.9914]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12034 960 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  118\n",
      "729 10 True\n",
      "x_t:  3 [0.490625   0.29166667 0.103125   0.35833333]\n",
      "Q values:  tensor([[-6.1234, -5.9328, -5.8518, -5.9816, -6.3212, -5.1353]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3672 1089 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  995\n",
      "729 12 True\n",
      "x_t:  2 [0.2625     0.4125     0.065625   0.24583333]\n",
      "Q values:  tensor([[-5.2014, -5.9418, -6.0560, -6.1823, -5.8447, -5.1129]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13657 361 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  464\n",
      "729 15 True\n",
      "x_t:  1 [0.721875   0.3        0.078125   0.27916667]\n",
      "Q values:  tensor([[-5.6876, -6.0716, -5.6613, -6.3004, -5.9304, -4.9694]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5192 769 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2839\n",
      "Time elapsed:  6841.832319974899\n",
      "startIDX:  1391\n",
      "730 0 True\n",
      "x_t:  4 [0.071875   0.39166667 0.121875   0.2875    ]\n",
      "Q values:  tensor([[-5.5208, -5.5580, -5.4071, -6.0793, -5.9760, -4.7505]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16299 530 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 730: ep_len:530 episode reward: total was -25.800000. running mean: -113.124560\n",
      "startIDX:  706\n",
      "730 1 True\n",
      "x_t:  3 [0.6125     0.3        0.1        0.42083333]\n",
      "Q values:  tensor([[-7.9271, -8.2075, -8.5121, -8.6490, -7.7973, -7.2544]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34430 1457 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 730: ep_len:1457 episode reward: total was -97.600000. running mean: -112.969314\n",
      "startIDX:  945\n",
      "730 5 True\n",
      "x_t:  3 [0.090625   0.23333333 0.08125    0.26666667]\n",
      "Q values:  tensor([[-5.7415, -5.9954, -5.9135, -6.1472, -6.3495, -5.1411]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10609 267 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 730: ep_len:267 episode reward: total was -14.100000. running mean: -111.980621\n",
      "startIDX:  183\n",
      "730 10 True\n",
      "x_t:  4 [0.003125   0.3625     0.078125   0.25416667]\n",
      "Q values:  tensor([[-5.6540, -5.4098, -5.9632, -5.8805, -5.9116, -4.9539]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4544 454 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 730: ep_len:454 episode reward: total was -12.900000. running mean: -110.989815\n",
      "startIDX:  783\n",
      "730 12 False\n",
      "x_t:  1 [0.609375   0.34166667 0.209375   0.525     ]\n",
      "Q values:  tensor([[-7.1028, -6.5215, -7.5274, -6.6691, -8.1353, -7.0516]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10346 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 730: ep_len:204 episode reward: total was -32.300000. running mean: -110.202916\n",
      "startIDX:  1972\n",
      "730 15 True\n",
      "x_t:  2 [0.44375    0.40416667 0.0625     0.26666667]\n",
      "Q values:  tensor([[-8.0072, -7.3453, -8.3841, -7.5558, -7.5536, -6.7153]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15623 1063 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 730: ep_len:1063 episode reward: total was -198.800000. running mean: -111.088887\n",
      "startIDX:  74\n",
      "730 22 True\n",
      "x_t:  1 [0.8375     0.30833333 0.11875    0.39583333]\n",
      "Q values:  tensor([[-7.0340, -6.9053, -6.6749, -7.8419, -7.4616, -6.3650]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1583 704 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 730: ep_len:704 episode reward: total was -78.900000. running mean: -110.766998\n",
      "startIDX:  2236\n",
      "731 0 True\n",
      "x_t:  2 [0.4875     0.40833333 0.08125    0.25833333]\n",
      "Q values:  tensor([[-7.1791, -6.6141, -7.1514, -7.1542, -6.8694, -6.2265]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23641 358 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  503\n",
      "731 1 True\n",
      "x_t:  1 [0.65625    0.27083333 0.140625   0.4625    ]\n",
      "Q values:  tensor([[-6.6532, -6.3608, -6.4347, -6.6769, -6.9237, -5.8350]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30701 760 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1863\n",
      "731 5 True\n",
      "x_t:  2 [0.76875    0.39583333 0.06875    0.25416667]\n",
      "Q values:  tensor([[-5.9854, -6.4083, -6.4720, -7.2121, -6.7873, -5.6780]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15657 338 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  713\n",
      "731 10 True\n",
      "x_t:  1 [0.209375   0.33333333 0.096875   0.35416667]\n",
      "Q values:  tensor([[-6.4885, -6.5972, -6.8552, -7.0697, -6.7554, -6.1022]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7126 249 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1918\n",
      "731 12 False\n",
      "x_t:  0 [0.30625    0.42916667 0.103125   0.2625    ]\n",
      "Q values:  tensor([[-7.9520, -9.0743, -9.2836, -9.3310, -8.3118, -8.1256]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23004 904 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731 15 True\n",
      "x_t:  3 [0.234375   0.29583333 0.0875     0.33333333]\n",
      "Q values:  tensor([[-7.5871, -7.8376, -7.5700, -8.0732, -8.4857, -6.7811]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18209 1332 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1858\n",
      "731 22 True\n",
      "x_t:  2 [0.0125     0.4125     0.1125     0.27083333]\n",
      "Q values:  tensor([[-6.8731, -7.2747, -7.4511, -6.9896, -7.1135, -6.5312]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18458 796 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1196\n",
      "732 0 True\n",
      "x_t:  3 [0.478125 0.2875   0.084375 0.3625  ]\n",
      "Q values:  tensor([[-8.6427, -8.7193, -8.8744, -9.6913, -8.9956, -8.3526]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15254 1319 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 732: ep_len:1319 episode reward: total was -129.200000. running mean: -107.501635\n",
      "startIDX:  646\n",
      "732 1 True\n",
      "x_t:  2 [0.11875    0.38333333 0.078125   0.3125    ]\n",
      "Q values:  tensor([[-5.3048, -5.3750, -5.8661, -5.9994, -5.4453, -5.0844]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31574 404 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 732: ep_len:404 episode reward: total was -78.400000. running mean: -107.210618\n",
      "startIDX:  498\n",
      "732 5 True\n",
      "x_t:  2 [0.575      0.40416667 0.121875   0.29583333]\n",
      "Q values:  tensor([[-6.1502, -5.7963, -6.4430, -6.3231, -6.1059, -5.4584]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6068 518 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 732: ep_len:518 episode reward: total was -44.700000. running mean: -106.585512\n",
      "startIDX:  1595\n",
      "732 10 True\n",
      "x_t:  3 [0.4125     0.28333333 0.103125   0.32916667]\n",
      "Q values:  tensor([[-6.2395, -6.5191, -6.5897, -6.3590, -6.1084, -5.4974]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16468 329 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 732: ep_len:329 episode reward: total was -5.400000. running mean: -105.573657\n",
      "startIDX:  855\n",
      "732 12 True\n",
      "x_t:  1 [0.646875   0.38333333 0.1625     0.48333333]\n",
      "Q values:  tensor([[-6.5931, -6.4416, -6.3053, -6.9908, -6.6148, -5.8812]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12926 643 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 732: ep_len:643 episode reward: total was -107.000000. running mean: -105.587921\n",
      "startIDX:  2726\n",
      "732 15 True\n",
      "x_t:  1 [0.1      0.375    0.103125 0.5     ]\n",
      "Q values:  tensor([[-8.0243, -8.8269, -8.6673, -8.3822, -8.9589, -7.5548]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22044 1121 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 732: ep_len:1121 episode reward: total was -149.500000. running mean: -106.027041\n",
      "startIDX:  1324\n",
      "732 22 True\n",
      "x_t:  3 [0.06875  0.2625   0.071875 0.2625  ]\n",
      "Q values:  tensor([[-6.5827, -6.6127, -6.6573, -7.9386, -7.4537, -6.5555]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15200 1294 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 732: ep_len:1294 episode reward: total was -70.300000. running mean: -105.669771\n",
      "startIDX:  1628\n",
      "733 0 False\n",
      "x_t:  3 [0.584375   0.325      0.140625   0.37916667]\n",
      "Q values:  tensor([[-3.7719, -2.8355, -3.6964, -1.9762, -3.3337, -3.4043]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16844 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  605\n",
      "733 1 True\n",
      "x_t:  2 [0.809375   0.37916667 0.09375    0.31666667]\n",
      "Q values:  tensor([[-6.1701, -5.9592, -6.3031, -6.3777, -6.4742, -5.5183]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31462 364 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2808\n",
      "733 5 True\n",
      "x_t:  0 [0.275      0.4        0.078125   0.28333333]\n",
      "Q values:  tensor([[-6.5984, -6.5477, -7.0091, -6.5757, -6.9507, -5.6480]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23282 550 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  498\n",
      "733 10 False\n",
      "x_t:  3 [0.115625   0.23333333 0.0625     0.25416667]\n",
      "Q values:  tensor([[2.1069, 2.2653, 2.7680, 5.2557, 3.0911, 3.0937]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 5171 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  947\n",
      "733 12 True\n",
      "x_t:  1 [0.175 0.375 0.125 0.5  ]\n",
      "Q values:  tensor([[-6.2594, -6.0519, -6.1981, -6.0625, -5.9654, -5.2071]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12959 625 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1432\n",
      "733 15 True\n",
      "x_t:  3 [0.24375    0.25833333 0.075      0.275     ]\n",
      "Q values:  tensor([[-5.5446, -6.0448, -5.8108, -6.5470, -5.8961, -5.1947]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10456 205 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2763\n",
      "733 22 True\n",
      "x_t:  4 [0.43125    0.37916667 0.075      0.3125    ]\n",
      "Q values:  tensor([[-6.2071, -5.9309, -5.9671, -6.5169, -6.0310, -5.4725]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27399 543 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1083\n",
      "734 0 True\n",
      "x_t:  1 [0.4875     0.325      0.0875     0.45416667]\n",
      "Q values:  tensor([[-5.5900, -5.9041, -6.2040, -6.4286, -6.0869, -5.1973]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11987 783 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 734: ep_len:783 episode reward: total was -89.300000. running mean: -102.229293\n",
      "startIDX:  518\n",
      "734 1 True\n",
      "x_t:  1 [0.734375   0.27916667 0.171875   0.45      ]\n",
      "Q values:  tensor([[-5.4537, -5.6470, -5.5290, -6.8622, -5.9717, -5.3909]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30694 761 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 734: ep_len:761 episode reward: total was -72.800000. running mean: -101.935000\n",
      "startIDX:  2812\n",
      "734 5 False\n",
      "x_t:  0 [0.93125  0.3875   0.059375 0.3     ]\n",
      "Q values:  tensor([[-5.9465, -6.2080, -7.2813, -6.9326, -6.5507, -6.0073]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23149 480 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 734: ep_len:480 episode reward: total was -39.700000. running mean: -101.312650\n",
      "startIDX:  636\n",
      "734 10 True\n",
      "x_t:  2 [0.009375 0.4125   0.1125   0.25    ]\n",
      "Q values:  tensor([[-7.1461, -6.5926, -6.7996, -6.4747, -7.3189, -5.8562]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6590 719 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 734: ep_len:719 episode reward: total was -55.500000. running mean: -100.854523\n",
      "startIDX:  2\n",
      "734 12 True\n",
      "x_t:  3 [0.2625     0.28333333 0.1        0.30833333]\n",
      "Q values:  tensor([[ -9.5378, -10.2112, -10.1185, -11.1924, -10.2114,  -8.8452]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5704 2398 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 734: ep_len:2398 episode reward: total was -312.500000. running mean: -102.970978\n",
      "startIDX:  2001\n",
      "734 15 True\n",
      "x_t:  1 [0.78125 0.3     0.08125 0.3    ]\n",
      "Q values:  tensor([[-5.9913, -5.9688, -6.2532, -6.1174, -6.3213, -5.2386]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14856 672 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 734: ep_len:672 episode reward: total was -57.500000. running mean: -102.516268\n",
      "startIDX:  2781\n",
      "734 22 True\n",
      "x_t:  4 [0.259375   0.3875     0.115625   0.30833333]\n",
      "Q values:  tensor([[-5.4773, -5.3910, -5.2849, -5.4480, -5.3034, -4.6658]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27303 499 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 734: ep_len:499 episode reward: total was -57.000000. running mean: -102.061106\n",
      "startIDX:  2361\n",
      "735 0 True\n",
      "x_t:  3 [0.0625     0.23333333 0.059375   0.24166667]\n",
      "Q values:  tensor([[-7.0882, -6.7015, -6.9041, -7.0606, -7.4106, -6.1601]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26092 1235 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  539\n",
      "735 1 True\n",
      "x_t:  1 [0.48125    0.29583333 0.140625   0.47083333]\n",
      "Q values:  tensor([[-5.3101, -5.6052, -6.0327, -5.5707, -5.8981, -4.7575]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30723 766 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1504\n",
      "735 5 True\n",
      "x_t:  0 [0.76875    0.3875     0.1125     0.34166667]\n",
      "Q values:  tensor([[-6.4636, -6.4346, -6.1834, -6.7501, -6.7372, -5.5350]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13518 474 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1601\n",
      "735 10 True\n",
      "x_t:  3 [0.734375   0.31666667 0.1375     0.3875    ]\n",
      "Q values:  tensor([[-4.1818, -4.2633, -4.1655, -4.1994, -4.5166, -3.5233]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16417 295 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1010\n",
      "735 12 True\n",
      "x_t:  2 [0.296875   0.4125     0.078125   0.24583333]\n",
      "Q values:  tensor([[-4.1248, -3.9027, -3.9728, -4.4750, -4.0189, -3.6033]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13652 348 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1744\n",
      "735 15 True\n",
      "x_t:  0 [0.9375     0.40416667 0.053125   0.325     ]\n",
      "Q values:  tensor([[-3.4764, -3.8318, -3.9904, -4.1363, -4.2193, -3.2321]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13362 677 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  27\n",
      "735 22 True\n",
      "x_t:  2 [0.66875    0.40416667 0.059375   0.25416667]\n",
      "Q values:  tensor([[-4.0057, -4.2651, -4.1204, -4.5987, -4.9588, -3.7548]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2305 1071 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  34\n",
      "736 0 True\n",
      "x_t:  1 [0.165625   0.3625     0.1625     0.45833333]\n",
      "Q values:  tensor([[-4.5361, -4.7259, -4.7065, -4.7363, -4.8674, -3.9953]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1681 771 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 736: ep_len:771 episode reward: total was -129.200000. running mean: -99.880303\n",
      "startIDX:  709\n",
      "736 1 True\n",
      "x_t:  3 [0.703125   0.30833333 0.1        0.45833333]\n",
      "Q values:  tensor([[-4.3943, -4.5064, -4.0735, -4.8238, -4.5667, -4.0287]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34443 1459 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 736: ep_len:1459 episode reward: total was -106.100000. running mean: -99.942500\n",
      "startIDX:  1857\n",
      "736 5 True\n",
      "x_t:  2 [0.096875   0.40416667 0.1        0.24166667]\n",
      "Q values:  tensor([[-2.9716, -3.4988, -3.3478, -2.9699, -3.4386, -2.8127]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15763 401 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 736: ep_len:401 episode reward: total was -50.600000. running mean: -99.449075\n",
      "startIDX:  42\n",
      "736 10 True\n",
      "x_t:  3 [0.109375   0.2375     0.065625   0.27916667]\n",
      "Q values:  tensor([[-4.4682, -4.5843, -4.3741, -4.6496, -4.8871, -3.8515]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3597 1116 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 736: ep_len:1116 episode reward: total was -48.000000. running mean: -98.934584\n",
      "startIDX:  560\n",
      "736 12 True\n",
      "x_t:  2 [0.19375 0.4125  0.08125 0.25   ]\n",
      "Q values:  tensor([[-3.8572, -4.2603, -3.5604, -4.6200, -4.1419, -3.4447]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9858 1061 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 736: ep_len:1061 episode reward: total was -35.700000. running mean: -98.302239\n",
      "startIDX:  314\n",
      "736 15 True\n",
      "x_t:  1 [0.115625   0.35416667 0.109375   0.3375    ]\n",
      "Q values:  tensor([[-4.1655, -4.3393, -4.3610, -4.2681, -3.9161, -3.5935]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5273 1517 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 736: ep_len:1517 episode reward: total was -226.100000. running mean: -99.580216\n",
      "startIDX:  189\n",
      "736 22 True\n",
      "x_t:  2 [0.490625   0.40416667 0.065625   0.25833333]\n",
      "Q values:  tensor([[-4.2946, -4.2366, -4.3813, -4.4779, -4.4640, -3.6335]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2335 371 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 736: ep_len:371 episode reward: total was -22.200000. running mean: -98.806414\n",
      "startIDX:  1139\n",
      "737 0 True\n",
      "x_t:  3 [0.69375    0.33333333 0.15       0.40833333]\n",
      "Q values:  tensor([[-4.4324, -4.8534, -4.8362, -5.0784, -4.7492, -4.0014]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15289 1656 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  22\n",
      "737 1 False\n",
      "x_t:  3 [0.4375     0.25833333 0.1        0.35416667]\n",
      "Q values:  tensor([[1.2468, 2.2638, 2.3423, 3.1954, 1.8301, 2.4843]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 25696 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2506\n",
      "737 5 True\n",
      "x_t:  2 [0.115625   0.39583333 0.10625    0.26666667]\n",
      "Q values:  tensor([[-3.5004, -3.8193, -4.2467, -3.7061, -3.8832, -3.4894]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21566 833 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1326\n",
      "737 10 True\n",
      "x_t:  4 [0.021875   0.36666667 0.109375   0.275     ]\n",
      "Q values:  tensor([[-4.2902, -4.5869, -4.3632, -4.4143, -4.2252, -3.5357]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15709 571 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  759\n",
      "737 12 False\n",
      "x_t:  1 [0.1        0.37916667 0.15       0.49583333]\n",
      "Q values:  tensor([[-3.3600, -2.4720, -2.8924, -2.7832, -3.5812, -2.9316]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10312 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1875\n",
      "737 15 True\n",
      "x_t:  2 [0.115625   0.40416667 0.09375    0.28333333]\n",
      "Q values:  tensor([[-4.7266, -5.1583, -5.1594, -5.2253, -5.3627, -4.5071]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15670 1174 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2842\n",
      "startIDX:  1625\n",
      "738 0 True\n",
      "x_t:  3 [0.496875   0.3        0.08125    0.35416667]\n",
      "Q values:  tensor([[-3.1543, -3.5957, -3.3169, -3.5641, -3.4605, -2.9321]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16862 219 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 738: ep_len:219 episode reward: total was -14.100000. running mean: -95.615104\n",
      "startIDX:  347\n",
      "738 1 False\n",
      "x_t:  0 [0.73125    0.37083333 0.09375    0.40416667]\n",
      "Q values:  tensor([[-4.2301, -4.6240, -4.9266, -4.7196, -4.6940, -4.2309]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29120 806 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 738: ep_len:806 episode reward: total was -60.000000. running mean: -95.258953\n",
      "startIDX:  2783\n",
      "738 5 True\n",
      "x_t:  0 [0.8875     0.39583333 0.08125    0.30416667]\n",
      "Q values:  tensor([[-4.9906, -5.0990, -5.2227, -5.3478, -5.0327, -4.4515]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23158 505 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 738: ep_len:505 episode reward: total was -19.100000. running mean: -94.497364\n",
      "startIDX:  981\n",
      "738 10 True\n",
      "x_t:  1 [0.853125   0.2875     0.109375   0.32916667]\n",
      "Q values:  tensor([[-7.5143, -6.5621, -6.7309, -7.3624, -7.7165, -6.1589]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11332 1564 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 738: ep_len:1564 episode reward: total was -108.400000. running mean: -94.636390\n",
      "startIDX:  1241\n",
      "738 12 True\n",
      "x_t:  4 [0.353125   0.35416667 0.053125   0.24166667]\n",
      "Q values:  tensor([[-5.0291, -5.4018, -5.8534, -6.1516, -5.5996, -4.7098]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17495 525 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 738: ep_len:525 episode reward: total was -46.800000. running mean: -94.158026\n",
      "startIDX:  1311\n",
      "738 15 True\n",
      "x_t:  3 [0.084375   0.24166667 0.071875   0.24166667]\n",
      "Q values:  tensor([[-4.1156, -4.0190, -4.3177, -4.0806, -4.3620, -3.5076]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10501 309 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 738: ep_len:309 episode reward: total was -69.200000. running mean: -93.908446\n",
      "startIDX:  969\n",
      "738 22 True\n",
      "x_t:  0 [0.615625   0.4125     0.0625     0.34583333]\n",
      "Q values:  tensor([[-3.8987, -3.8446, -4.0480, -4.1932, -3.9593, -3.4545]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10507 502 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 738: ep_len:502 episode reward: total was -43.800000. running mean: -93.407362\n",
      "startIDX:  370\n",
      "739 0 True\n",
      "x_t:  3 [0.61875    0.32083333 0.071875   0.37083333]\n",
      "Q values:  tensor([[-7.5582, -7.3503, -7.3629, -7.4227, -7.7350, -6.6497]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4972 1277 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  647\n",
      "739 1 False\n",
      "x_t:  2 [0.384375   0.3875     0.115625   0.30416667]\n",
      "Q values:  tensor([[-4.7367, -4.5004, -4.1200, -5.0715, -4.6428, -4.1375]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31529 376 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  259\n",
      "739 5 True\n",
      "x_t:  0 [0.303125 0.4125   0.103125 0.275   ]\n",
      "Q values:  tensor([[-5.5240, -5.1556, -5.2691, -5.3232, -5.3843, -4.5996]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3629 553 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  840\n",
      "739 10 True\n",
      "x_t:  0 [0.603125   0.40416667 0.09375    0.2875    ]\n",
      "Q values:  tensor([[-4.3139, -4.1608, -4.3587, -4.2120, -4.7185, -3.6520]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8157 489 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2003\n",
      "startIDX:  2342\n",
      "739 15 True\n",
      "x_t:  4 [0.215625   0.375      0.06875    0.24583333]\n",
      "Q values:  tensor([[-4.5879, -4.7990, -4.5027, -5.4398, -4.7863, -4.4098]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19329 567 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  711\n",
      "739 22 True\n",
      "x_t:  2 [0.059375   0.40833333 0.09375    0.2625    ]\n",
      "Q values:  tensor([[-6.1571, -5.9967, -6.0302, -6.4135, -6.0133, -5.1625]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8925 868 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  7079.254184484482\n",
      "startIDX:  2233\n",
      "740 0 True\n",
      "x_t:  2 [0.359375   0.40833333 0.096875   0.25416667]\n",
      "Q values:  tensor([[-6.2434, -6.6039, -6.6633, -6.5282, -6.0113, -5.5073]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23661 367 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 740: ep_len:367 episode reward: total was -33.800000. running mean: -89.712755\n",
      "startIDX:  346\n",
      "740 1 True\n",
      "x_t:  1 [0.678125   0.27083333 0.153125   0.60416667]\n",
      "Q values:  tensor([[-5.2541, -5.3424, -4.8730, -5.4362, -5.4487, -4.5369]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28110 309 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 740: ep_len:309 episode reward: total was 1.400000. running mean: -88.801628\n",
      "startIDX:  645\n",
      "740 5 True\n",
      "x_t:  3 [0.146875   0.2625     0.10625    0.33333333]\n",
      "Q values:  tensor([[-8.0297, -8.3346, -8.8321, -8.2553, -8.1699, -7.3511]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8772 1363 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 740: ep_len:1363 episode reward: total was -31.400000. running mean: -88.227611\n",
      "startIDX:  212\n",
      "740 10 True\n",
      "x_t:  4 [0.28125 0.35    0.05    0.2375 ]\n",
      "Q values:  tensor([[-5.7637, -5.8013, -6.1880, -6.7292, -5.7347, -5.1489]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4589 456 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 740: ep_len:456 episode reward: total was -45.500000. running mean: -87.800335\n",
      "startIDX:  603\n",
      "740 12 True\n",
      "x_t:  0 [0.771875   0.4        0.11875    0.40416667]\n",
      "Q values:  tensor([[ -9.5282, -10.0919,  -9.8698,  -9.4584,  -9.9136,  -8.2458]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11735 1975 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 740: ep_len:1975 episode reward: total was -249.100000. running mean: -89.413332\n",
      "startIDX:  2547\n",
      "740 15 False\n",
      "x_t:  2 [0.2        0.40416667 0.125      0.33333333]\n",
      "Q values:  tensor([[-4.8704, -5.7991, -4.3389, -5.2410, -5.3006, -4.3778]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21501 1089 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 740: ep_len:1089 episode reward: total was -155.600000. running mean: -90.075199\n",
      "startIDX:  1337\n",
      "740 22 True\n",
      "x_t:  3 [0.096875   0.25416667 0.075      0.2875    ]\n",
      "Q values:  tensor([[-8.3154, -8.1951, -7.5485, -8.4536, -8.8334, -7.0671]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15209 1291 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 740: ep_len:1291 episode reward: total was -78.700000. running mean: -89.961447\n",
      "startIDX:  739\n",
      "741 0 True\n",
      "x_t:  1 [0.20625    0.35       0.11875    0.39583333]\n",
      "Q values:  tensor([[-4.3033, -4.8666, -4.6597, -4.6652, -5.3456, -3.9986]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9430 282 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  425\n",
      "741 1 True\n",
      "x_t:  0 [0.934375   0.37083333 0.059375   0.40416667]\n",
      "Q values:  tensor([[-6.4059, -6.6847, -6.8125, -6.5783, -6.6846, -5.8132]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29087 489 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1896\n",
      "741 5 True\n",
      "x_t:  2 [0.7375     0.39583333 0.0625     0.24583333]\n",
      "Q values:  tensor([[-5.2640, -5.2007, -5.6494, -5.4036, -5.6425, -4.6965]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15661 322 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1662\n",
      "741 10 True\n",
      "x_t:  3 [0.728125   0.30416667 0.134375   0.39166667]\n",
      "Q values:  tensor([[-4.9217, -5.1278, -5.3428, -5.2127, -5.1919, -4.4699]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16419 272 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  629\n",
      "741 12 True\n",
      "x_t:  2 [0.234375   0.40833333 0.046875   0.25833333]\n",
      "Q values:  tensor([[-6.3559, -6.7700, -6.0303, -6.5833, -7.1080, -5.5294]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9861 1001 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1280\n",
      "741 15 True\n",
      "x_t:  3 [0.753125   0.32916667 0.115625   0.37916667]\n",
      "Q values:  tensor([[-4.7729, -4.8773, -4.9610, -5.3401, -5.1799, -4.3986]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10354 247 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  230\n",
      "741 22 True\n",
      "x_t:  4 [0.021875   0.41666667 0.084375   0.3625    ]\n",
      "Q values:  tensor([[-7.9848, -9.3927, -9.0040, -8.8614, -9.6491, -7.8204]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 6634 2506 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2162\n",
      "742 0 True\n",
      "x_t:  1 [0.85       0.30416667 0.146875   0.54166667]\n",
      "Q values:  tensor([[-5.0976, -5.4822, -5.6099, -5.6204, -5.5250, -4.9342]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22920 1107 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 742: ep_len:1107 episode reward: total was -76.900000. running mean: -87.385250\n",
      "startIDX:  485\n",
      "742 1 True\n",
      "x_t:  1 [0.2        0.325      0.175      0.49583333]\n",
      "Q values:  tensor([[-5.7051, -5.5742, -5.8686, -5.6727, -6.1004, -4.7158]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30749 793 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 742: ep_len:793 episode reward: total was -112.500000. running mean: -87.636398\n",
      "startIDX:  2765\n",
      "742 5 True\n",
      "x_t:  0 [0.821875   0.3875     0.090625   0.31666667]\n",
      "Q values:  tensor([[-5.0558, -5.6727, -5.9136, -5.2854, -5.2149, -4.4958]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23176 524 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 742: ep_len:524 episode reward: total was -23.500000. running mean: -86.995034\n",
      "startIDX:  669\n",
      "742 10 True\n",
      "x_t:  0 [0.596875   0.40416667 0.1        0.29166667]\n",
      "Q values:  tensor([[-4.8459, -5.1197, -4.9093, -5.0731, -5.0220, -4.1569]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8161 761 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 742: ep_len:761 episode reward: total was -51.700000. running mean: -86.642083\n",
      "startIDX:  1673\n",
      "742 12 True\n",
      "x_t:  1 [0.821875   0.3        0.15       0.41666667]\n",
      "Q values:  tensor([[-3.6609, -3.9798, -3.6811, -4.0348, -3.9583, -3.1880]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19953 269 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 742: ep_len:269 episode reward: total was -38.300000. running mean: -86.158663\n",
      "startIDX:  1961\n",
      "742 15 True\n",
      "x_t:  1 [0.49375    0.30833333 0.065625   0.30416667]\n",
      "Q values:  tensor([[-4.1738, -4.5728, -4.2930, -4.5296, -3.9859, -3.7220]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14894 703 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 742: ep_len:703 episode reward: total was -144.400000. running mean: -86.741076\n",
      "startIDX:  2159\n",
      "742 22 False\n",
      "x_t:  0 [0.653125   0.40833333 0.071875   0.325     ]\n",
      "Q values:  tensor([[-3.5938, -4.3550, -4.1766, -4.3203, -4.2006, -3.6417]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20779 860 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 742: ep_len:860 episode reward: total was -75.300000. running mean: -86.626665\n",
      "startIDX:  2321\n",
      "743 0 True\n",
      "x_t:  3 [0.534375   0.3        0.08125    0.34583333]\n",
      "Q values:  tensor([[-4.9175, -5.3179, -5.3661, -5.6466, -5.5099, -4.7024]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26195 1315 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  606\n",
      "743 1 True\n",
      "x_t:  4 [0.365625   0.36666667 0.0875     0.4125    ]\n",
      "Q values:  tensor([[-6.2289, -6.7771, -6.5155, -6.5770, -6.5940, -5.4651]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35477 2400 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2782\n",
      "743 5 False\n",
      "x_t:  0 [0.940625 0.3875   0.05     0.3125  ]\n",
      "Q values:  tensor([[-3.2523, -3.8903, -3.6565, -3.7821, -4.1109, -3.2603]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23148 508 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  573\n",
      "743 10 True\n",
      "x_t:  2 [0.409375   0.4        0.0875     0.25833333]\n",
      "Q values:  tensor([[-4.0071, -4.6911, -3.9377, -4.3318, -4.4300, -3.5971]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6650 771 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  23\n",
      "743 12 False\n",
      "x_t:  2 [0.803125   0.40833333 0.0875     0.24583333]\n",
      "Q values:  tensor([[-3.9065, -4.1997, -3.3046, -4.2972, -4.5532, -3.4098]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2806 931 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  236\n",
      "743 15 True\n",
      "x_t:  2 [0.096875   0.40416667 0.08125    0.34166667]\n",
      "Q values:  tensor([[-4.5455, -4.5066, -4.3216, -4.5075, -4.8838, -3.7909]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2205 771 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2947\n",
      "startIDX:  585\n",
      "744 0 True\n",
      "x_t:  2 [0.115625   0.4125     0.09375    0.26666667]\n",
      "Q values:  tensor([[-3.3754, -3.9289, -4.0322, -3.8816, -3.7910, -3.1642]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8886 939 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 744: ep_len:939 episode reward: total was -23.100000. running mean: -85.415099\n",
      "startIDX:  661\n",
      "744 1 False\n",
      "x_t:  2 [0.621875   0.37916667 0.071875   0.31666667]\n",
      "Q values:  tensor([[-4.2174, -4.0788, -3.4973, -4.3542, -4.3033, -3.5472]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31494 356 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 744: ep_len:356 episode reward: total was -39.600000. running mean: -84.956948\n",
      "startIDX:  746\n",
      "744 5 True\n",
      "x_t:  3 [0.065625   0.25833333 0.071875   0.31666667]\n",
      "Q values:  tensor([[-4.4191, -4.8106, -4.3965, -4.9974, -4.7910, -4.0507]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8748 1303 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 744: ep_len:1303 episode reward: total was -59.500000. running mean: -84.702378\n",
      "startIDX:  2012\n",
      "744 10 False\n",
      "x_t:  1 [0.559375   0.29166667 0.0625     0.34583333]\n",
      "Q values:  tensor([[-3.1716, -3.0773, -3.6189, -3.4649, -3.3636, -3.0995]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18887 331 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 744: ep_len:331 episode reward: total was -18.800000. running mean: -84.043355\n",
      "startIDX:  956\n",
      "744 12 True\n",
      "x_t:  2 [0.03125    0.41666667 0.11875    0.25      ]\n",
      "Q values:  tensor([[-4.1869, -4.5070, -4.2034, -4.6407, -4.6029, -3.7846]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13688 966 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 744: ep_len:966 episode reward: total was -123.600000. running mean: -84.438921\n",
      "startIDX:  1508\n",
      "744 15 True\n",
      "x_t:  1 [0.03125    0.36666667 0.1375     0.4       ]\n",
      "Q values:  tensor([[-4.3109, -4.9239, -4.5332, -4.7850, -4.8318, -4.0670]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12451 1027 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 744: ep_len:1027 episode reward: total was -80.800000. running mean: -84.402532\n",
      "startIDX:  1736\n",
      "744 22 False\n",
      "x_t:  3 [0.653125   0.32083333 0.1        0.37083333]\n",
      "Q values:  tensor([[2.1317, 2.8059, 4.0630, 4.2224, 2.8666, 4.0134]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 16877 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 744: ep_len:200 episode reward: total was 1.900000. running mean: -83.539506\n",
      "startIDX:  715\n",
      "745 0 True\n",
      "x_t:  1 [0.696875   0.30416667 0.078125   0.4375    ]\n",
      "Q values:  tensor([[-3.0950, -3.3545, -3.3383, -3.3442, -3.2645, -2.7764]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9481 317 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  17\n",
      "745 1 True\n",
      "x_t:  3 [0.228125   0.23333333 0.075      0.30416667]\n",
      "Q values:  tensor([[-4.4324, -4.2475, -4.1440, -4.5047, -4.1922, -3.6043]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25745 242 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1145\n",
      "745 5 True\n",
      "x_t:  2 [0.23125    0.3875     0.06875    0.29166667]\n",
      "Q values:  tensor([[-4.5815, -4.6768, -4.2740, -4.6961, -5.0421, -4.0531]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12034 892 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1923\n",
      "745 10 True\n",
      "x_t:  2 [0.446875   0.40416667 0.084375   0.24583333]\n",
      "Q values:  tensor([[-5.7308, -5.5431, -5.4662, -5.7433, -5.6116, -4.5612]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18225 832 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  276\n",
      "745 12 True\n",
      "x_t:  3 [0.790625   0.34583333 0.109375   0.41666667]\n",
      "Q values:  tensor([[-4.4426, -4.6712, -4.3189, -4.6793, -4.6202, -3.7539]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7721 1028 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  507\n",
      "745 15 True\n",
      "x_t:  1 [0.634375 0.3      0.1      0.2875  ]\n",
      "Q values:  tensor([[-4.1554, -4.9037, -4.3148, -4.9355, -4.8520, -3.9379]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5203 729 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1702\n",
      "745 22 True\n",
      "x_t:  3 [0.796875   0.34166667 0.121875   0.41666667]\n",
      "Q values:  tensor([[-3.4232, -3.4576, -3.4501, -3.5453, -3.3440, -3.0108]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16853 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2315\n",
      "ep 746: ep_len:1325 episode reward: total was -97.000000. running mean: -81.257555\n",
      "startIDX:  596\n",
      "746 1 False\n",
      "x_t:  2 [0.728125   0.37916667 0.0625     0.31666667]\n",
      "Q values:  tensor([[-4.6154, -5.4224, -4.1535, -5.2034, -4.7158, -4.2724]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31479 398 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 746: ep_len:398 episode reward: total was -1.100000. running mean: -80.455980\n",
      "startIDX:  1301\n",
      "746 5 True\n",
      "x_t:  2 [0.321875   0.37916667 0.040625   0.3       ]\n",
      "Q values:  tensor([[-4.9775, -5.3407, -5.0973, -5.0771, -5.2551, -4.4585]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12046 717 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 746: ep_len:717 episode reward: total was -43.200000. running mean: -80.083420\n",
      "startIDX:  1115\n",
      "746 10 True\n",
      "x_t:  2 [0.725  0.4    0.0875 0.25  ]\n",
      "Q values:  tensor([[-5.5782, -5.7182, -5.8537, -5.8136, -5.7536, -4.9450]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12073 347 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 746: ep_len:347 episode reward: total was -4.200000. running mean: -79.324586\n",
      "startIDX:  24\n",
      "746 12 True\n",
      "x_t:  1 [0.7     0.325   0.14375 0.425  ]\n",
      "Q values:  tensor([[-4.7528, -5.0673, -4.8123, -5.6065, -5.0208, -4.2347]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2230 637 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 746: ep_len:637 episode reward: total was -90.200000. running mean: -79.433340\n",
      "startIDX:  1919\n",
      "746 15 False\n",
      "x_t:  1 [0.775      0.3        0.053125   0.30416667]\n",
      "Q values:  tensor([[-4.9639, -4.1938, -4.9038, -4.6250, -5.0515, -4.2396]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14858 726 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 746: ep_len:726 episode reward: total was -106.600000. running mean: -79.705006\n",
      "startIDX:  2477\n",
      "746 22 True\n",
      "x_t:  3 [0.225      0.275      0.10625    0.27083333]\n",
      "Q values:  tensor([[-6.1828, -6.4904, -5.7213, -6.2723, -6.4329, -5.5504]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26226 1309 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 746: ep_len:1309 episode reward: total was -39.400000. running mean: -79.301956\n",
      "startIDX:  118\n",
      "747 0 True\n",
      "x_t:  1 [0.85       0.3        0.146875   0.42916667]\n",
      "Q values:  tensor([[-6.2332, -6.4406, -6.0490, -6.9301, -6.7420, -5.6875]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1609 695 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  479\n",
      "747 1 True\n",
      "x_t:  2 [0.496875   0.38333333 0.103125   0.30833333]\n",
      "Q values:  tensor([[-6.0932, -6.0822, -5.8605, -6.6395, -6.1822, -5.9518]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31511 1185 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1668\n",
      "747 5 True\n",
      "x_t:  1 [0.1625     0.33333333 0.134375   0.31666667]\n",
      "Q values:  tensor([[-6.5127, -6.6825, -6.2308, -6.8429, -6.7299, -5.7381]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 15022 687 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1217\n",
      "747 10 True\n",
      "x_t:  3 [0.134375   0.225      0.0625     0.27083333]\n",
      "Q values:  tensor([[-7.1422, -6.9373, -7.2940, -7.6875, -6.5112, -6.2069]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14598 1253 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  725\n",
      "747 12 True\n",
      "x_t:  0 [0.696875   0.41666667 0.0625     0.29166667]\n",
      "Q values:  tensor([[-6.6139, -6.9358, -6.8225, -6.9650, -7.1900, -5.8947]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11667 899 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  946\n",
      "747 15 True\n",
      "x_t:  4 [0.425      0.37083333 0.06875    0.27916667]\n",
      "Q values:  tensor([[-7.5198, -7.5690, -6.8272, -7.3508, -7.0067, -6.2043]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9894 697 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  560\n",
      "747 22 True\n",
      "x_t:  3 [0.521875   0.29166667 0.08125    0.33333333]\n",
      "Q values:  tensor([[-4.4382, -4.8380, -4.7338, -4.8177, -4.9341, -4.2712]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7108 240 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  506\n",
      "748 0 True\n",
      "x_t:  3 [0.671875   0.37916667 0.18125    0.4375    ]\n",
      "Q values:  tensor([[-6.9083, -6.9586, -6.7988, -6.9339, -7.0825, -5.8954]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7004 1014 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 748: ep_len:1014 episode reward: total was -67.200000. running mean: -78.786561\n",
      "startIDX:  827\n",
      "ep 748: ep_len:838 episode reward: total was -119.900000. running mean: -79.197695\n",
      "startIDX:  1058\n",
      "748 5 False\n",
      "x_t:  3 [0.240625 0.25     0.121875 0.3     ]\n",
      "Q values:  tensor([[3.7115, 3.6445, 4.6632, 7.8102, 2.7977, 3.0568]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 10572 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 748: ep_len:200 episode reward: total was -11.000000. running mean: -78.515718\n",
      "startIDX:  33\n",
      "748 10 True\n",
      "x_t:  3 [0.2125     0.25833333 0.084375   0.29583333]\n",
      "Q values:  tensor([[-7.4656, -7.4282, -6.4895, -8.1876, -7.5585, -6.4517]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3624 1120 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 748: ep_len:1120 episode reward: total was -45.500000. running mean: -78.185561\n",
      "startIDX:  736\n",
      "748 12 True\n",
      "x_t:  0 [0.7875     0.40416667 0.053125   0.30416667]\n",
      "Q values:  tensor([[-4.9771, -4.9711, -5.1188, -5.5440, -5.3422, -4.6110]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11653 875 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 748: ep_len:875 episode reward: total was -78.100000. running mean: -78.184705\n",
      "startIDX:  2024\n",
      "748 15 True\n",
      "x_t:  1 [0.471875   0.31666667 0.0875     0.30416667]\n",
      "Q values:  tensor([[-5.5737, -5.8547, -5.5780, -6.1395, -5.5362, -5.0922]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14896 684 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 748: ep_len:684 episode reward: total was -81.600000. running mean: -78.218858\n",
      "startIDX:  1160\n",
      "748 22 False\n",
      "x_t:  2 [0.540625   0.40833333 0.05       0.25833333]\n",
      "Q values:  tensor([[-6.6024, -6.6158, -5.6918, -6.6170, -6.8760, -5.7568]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12634 1058 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 748: ep_len:1058 episode reward: total was -142.300000. running mean: -78.859670\n",
      "startIDX:  1092\n",
      "749 0 False\n",
      "x_t:  1 [0.671875   0.31666667 0.15625    0.45416667]\n",
      "Q values:  tensor([[-5.0467, -4.6753, -5.7642, -5.1416, -4.8434, -4.7736]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11967 749 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  1009\n",
      "749 1 True\n",
      "x_t:  3 [0.440625   0.2625     0.0625     0.31666667]\n",
      "Q values:  tensor([[-5.9664, -5.8680, -6.1364, -6.1620, -6.0385, -5.3287]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35977 268 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  288\n",
      "749 5 True\n",
      "x_t:  0 [0.346875   0.40416667 0.0625     0.2875    ]\n",
      "Q values:  tensor([[-5.0023, -4.7108, -4.9169, -4.7381, -5.0447, -4.2347]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3624 534 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1394\n",
      "749 10 True\n",
      "x_t:  4 [0.525   0.3375  0.06875 0.2375 ]\n",
      "Q values:  tensor([[-4.9826, -5.6829, -5.4419, -5.0998, -5.5750, -4.5036]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15806 584 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  321\n",
      "749 12 True\n",
      "x_t:  4 [0.30625    0.38333333 0.0625     0.27916667]\n",
      "Q values:  tensor([[-4.9661, -4.9531, -5.1841, -5.0551, -5.0697, -4.5827]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7269 765 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2496\n",
      "749 15 False\n",
      "x_t:  3 [0.571875   0.30416667 0.121875   0.35833333]\n",
      "Q values:  tensor([[1.5693, 2.0510, 2.2775, 4.6316, 2.3724, 1.4458]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 19699 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1093\n",
      "749 22 True\n",
      "x_t:  1 [0.584375   0.32916667 0.159375   0.49583333]\n",
      "Q values:  tensor([[-5.6829, -5.6426, -5.8182, -5.9218, -5.8902, -5.0756]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11940 762 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  7336.419253587723\n",
      "startIDX:  1617\n",
      "750 0 True\n",
      "x_t:  3 [0.621875   0.32916667 0.121875   0.38333333]\n",
      "Q values:  tensor([[-3.7609, -3.7982, -4.0618, -3.8202, -4.1093, -3.3887]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16839 205 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 750: ep_len:205 episode reward: total was -8.300000. running mean: -76.255411\n",
      "startIDX:  665\n",
      "750 1 True\n",
      "x_t:  3 [0.059375   0.23333333 0.05625    0.27916667]\n",
      "Q values:  tensor([[-6.8841, -7.6828, -7.8323, -7.9389, -7.2512, -6.6278]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34299 1395 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 750: ep_len:1395 episode reward: total was -26.400000. running mean: -75.756857\n",
      "startIDX:  3016\n",
      "ep 750: ep_len:31 episode reward: total was -29.900000. running mean: -75.298289\n",
      "startIDX:  717\n",
      "750 10 True\n",
      "x_t:  0 [0.896875   0.4        0.096875   0.32916667]\n",
      "Q values:  tensor([[-4.9463, -5.5337, -4.9468, -5.6188, -5.6148, -4.6316]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8107 742 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 750: ep_len:742 episode reward: total was -60.800000. running mean: -75.153306\n",
      "startIDX:  1314\n",
      "750 12 True\n",
      "x_t:  2 [0.246875   0.40833333 0.1        0.2875    ]\n",
      "Q values:  tensor([[-6.5343, -6.9882, -6.8410, -6.9300, -7.4612, -5.8137]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19413 1010 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 750: ep_len:1010 episode reward: total was -120.800000. running mean: -75.609773\n",
      "startIDX:  441\n",
      "750 15 True\n",
      "x_t:  0 [0.45625 0.4125  0.0875  0.35   ]\n",
      "Q values:  tensor([[-4.4736, -5.1924, -4.6786, -5.1434, -4.7302, -4.1431]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3728 471 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 750: ep_len:471 episode reward: total was -89.200000. running mean: -75.745675\n",
      "startIDX:  1694\n",
      "750 22 True\n",
      "x_t:  3 [0.515625   0.30416667 0.08125    0.34583333]\n",
      "Q values:  tensor([[-4.0700, -4.1455, -4.3831, -4.3434, -4.5191, -3.7415]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16898 233 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 750: ep_len:233 episode reward: total was -20.400000. running mean: -75.192218\n",
      "startIDX:  1102\n",
      "751 0 True\n",
      "x_t:  2 [0.1625     0.40416667 0.11875    0.30416667]\n",
      "Q values:  tensor([[-4.2440, -4.8680, -4.2368, -4.5903, -4.8056, -3.9964]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12729 391 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  416\n",
      "751 1 True\n",
      "x_t:  0 [0.73125    0.37083333 0.09375    0.40416667]\n",
      "Q values:  tensor([[-5.7837, -5.8122, -6.3065, -6.3665, -6.2848, -5.3683]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29120 505 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2306\n",
      "751 5 False\n",
      "x_t:  3 [0.265625   0.26666667 0.1        0.32083333]\n",
      "Q values:  tensor([[3.3992, 3.9963, 4.1232, 5.8144, 2.9574, 4.3720]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 19964 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  410\n",
      "751 10 True\n",
      "x_t:  3 [0.3125     0.25833333 0.10625    0.3125    ]\n",
      "Q values:  tensor([[-4.6464, -4.7413, -4.6103, -4.8040, -4.7669, -4.0546]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5113 214 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  830\n",
      "751 12 True\n",
      "x_t:  0 [0.753125   0.41666667 0.08125    0.29166667]\n",
      "Q values:  tensor([[-5.2555, -5.9110, -5.6933, -5.4010, -5.4183, -4.9056]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11658 646 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  724\n",
      "751 15 True\n",
      "x_t:  2 [0.728125   0.40416667 0.0875     0.29583333]\n",
      "Q values:  tensor([[-4.4861, -4.6239, -4.0222, -4.6032, -4.2788, -3.7407]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5980 381 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2792\n",
      "startIDX:  1581\n",
      "752 0 True\n",
      "x_t:  2 [0.184375 0.4      0.059375 0.2625  ]\n",
      "Q values:  tensor([[-7.9200, -7.7779, -8.0126, -8.2751, -7.6436, -6.7244]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18416 1010 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 752: ep_len:1010 episode reward: total was -160.700000. running mean: -72.613493\n",
      "startIDX:  615\n",
      "752 1 True\n",
      "x_t:  2 [0.465625   0.37916667 0.096875   0.31666667]\n",
      "Q values:  tensor([[-4.8005, -4.9404, -4.7783, -4.5848, -5.1863, -4.2067]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31518 411 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 752: ep_len:411 episode reward: total was -51.400000. running mean: -72.401358\n",
      "startIDX:  226\n",
      "752 5 True\n",
      "x_t:  0 [0.790625   0.38333333 0.065625   0.375     ]\n",
      "Q values:  tensor([[-6.2095, -7.1947, -6.2372, -7.3965, -6.6417, -5.9886]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3573 737 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 752: ep_len:737 episode reward: total was -82.900000. running mean: -72.506345\n",
      "startIDX:  1146\n",
      "752 10 True\n",
      "x_t:  2 [0.759375   0.39583333 0.053125   0.25      ]\n",
      "Q values:  tensor([[-6.2631, -6.4812, -6.6794, -6.3941, -6.1889, -5.9129]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12071 328 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 752: ep_len:328 episode reward: total was -27.300000. running mean: -72.054281\n",
      "startIDX:  25\n",
      "752 12 True\n",
      "x_t:  2 [0.803125   0.40833333 0.0875     0.24583333]\n",
      "Q values:  tensor([[-6.5644, -6.4949, -6.6347, -7.1905, -6.7600, -5.9942]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2806 928 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 752: ep_len:928 episode reward: total was -139.400000. running mean: -72.727739\n",
      "startIDX:  396\n",
      "752 15 False\n",
      "x_t:  0 [0.765625   0.40416667 0.0625     0.34583333]\n",
      "Q values:  tensor([[-4.9748, -5.9239, -5.6248, -6.2827, -5.7042, -5.2385]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3680 448 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 752: ep_len:448 episode reward: total was -41.300000. running mean: -72.413461\n",
      "startIDX:  2812\n",
      "ep 752: ep_len:97 episode reward: total was 21.000000. running mean: -71.479327\n",
      "startIDX:  3\n",
      "753 0 True\n",
      "x_t:  2 [0.71875    0.40416667 0.103125   0.29166667]\n",
      "Q values:  tensor([[-8.4341, -8.5434, -8.9186, -8.8575, -8.2979, -7.5666]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2335 1129 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1050\n",
      "753 1 True\n",
      "x_t:  3 [0.803125   0.3        0.103125   0.42083333]\n",
      "Q values:  tensor([[-7.0416, -7.4645, -7.8140, -7.5287, -7.5990, -6.8244]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35907 212 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  168\n",
      "753 5 False\n",
      "x_t:  2 [0.33125    0.3875     0.1875     0.44166667]\n",
      "Q values:  tensor([[-6.0235, -6.2648, -5.4008, -6.3549, -6.4828, -5.6443]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2085 843 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1486\n",
      "753 10 True\n",
      "x_t:  3 [0.553125   0.3        0.125      0.35833333]\n",
      "Q values:  tensor([[-5.9108, -6.9157, -6.4307, -6.9788, -6.9534, -5.7619]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16445 377 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  382\n",
      "753 12 False\n",
      "x_t:  4 [0.028125   0.40833333 0.078125   0.29166667]\n",
      "Q values:  tensor([[-6.6981, -6.8883, -7.0586, -6.9772, -6.2242, -6.2384]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7304 756 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  0\n",
      "753 15 False\n",
      "x_t:  3 [0.428125   0.30416667 0.084375   0.35416667]\n",
      "Q values:  tensor([[-5.4266, -5.9544, -6.2201, -5.2402, -5.6465, -5.2623]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 586 286 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  2973\n",
      "startIDX:  177\n",
      "754 0 True\n",
      "x_t:  2 [0.528125   0.40416667 0.11875    0.30833333]\n",
      "Q values:  tensor([[-7.2821, -7.4153, -7.7279, -7.5705, -7.5559, -6.5750]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2363 367 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 754: ep_len:367 episode reward: total was -25.200000. running mean: -71.073159\n",
      "startIDX:  776\n",
      "754 1 True\n",
      "x_t:  3 [0.1        0.23333333 0.075      0.3       ]\n",
      "Q values:  tensor([[-8.5067, -8.6673, -8.7277, -8.8981, -8.4432, -7.9294]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34315 1390 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 754: ep_len:1390 episode reward: total was -154.900000. running mean: -71.911427\n",
      "startIDX:  2865\n",
      "ep 754: ep_len:104 episode reward: total was -69.800000. running mean: -71.890313\n",
      "startIDX:  948\n",
      "754 10 True\n",
      "x_t:  2 [0.703125 0.4      0.0875   0.25    ]\n",
      "Q values:  tensor([[-11.4193, -12.1087, -10.9677, -11.9590, -11.5919, -10.0924]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12078 1949 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 754: ep_len:1949 episode reward: total was -329.200000. running mean: -74.463410\n",
      "startIDX:  1250\n",
      "754 12 True\n",
      "x_t:  4 [0.1625     0.42083333 0.125      0.36666667]\n",
      "Q values:  tensor([[-6.9633, -7.5487, -6.9149, -6.9955, -7.2450, -6.4384]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17406 477 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 754: ep_len:477 episode reward: total was -55.600000. running mean: -74.274776\n",
      "startIDX:  236\n",
      "754 15 True\n",
      "x_t:  2 [0.01875    0.4125     0.115625   0.33333333]\n",
      "Q values:  tensor([[-8.0828, -8.1151, -8.1012, -8.2277, -7.3073, -7.5257]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2196 771 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 754: ep_len:771 episode reward: total was -74.800000. running mean: -74.280028\n",
      "startIDX:  1328\n",
      "754 22 True\n",
      "x_t:  3 [0.196875   0.27083333 0.08125    0.30833333]\n",
      "Q values:  tensor([[-8.1491, -8.4585, -8.7795, -9.3152, -8.8691, -7.7829]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15238 1334 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 754: ep_len:1334 episode reward: total was -186.900000. running mean: -75.406228\n",
      "startIDX:  203\n",
      "755 0 False\n",
      "x_t:  2 [0.4625     0.4125     0.1        0.29583333]\n",
      "Q values:  tensor([[-6.7110, -7.0865, -6.2393, -7.0428, -6.7963, -6.3173]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2373 354 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  58\n",
      "755 1 False\n",
      "x_t:  3 [0.346875   0.25833333 0.08125    0.31666667]\n",
      "Q values:  tensor([[3.1716, 4.0188, 2.6814, 5.3704, 2.1098, 2.6207]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 25717 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2841\n",
      "startIDX:  874\n",
      "755 10 False\n",
      "x_t:  0 [0.80625    0.39166667 0.071875   0.31666667]\n",
      "Q values:  tensor([[-6.3230, -6.8005, -6.7801, -7.0484, -6.8123, -6.4244]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8121 457 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  809\n",
      "755 12 False\n",
      "x_t:  0 [0.790625   0.40833333 0.128125   0.30833333]\n",
      "Q values:  tensor([[-6.2967, -6.8242, -6.6678, -6.9804, -7.1500, -6.4539]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11647 644 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1398\n",
      "755 15 False\n",
      "x_t:  3 [0.490625   0.29166667 0.103125   0.325     ]\n",
      "Q values:  tensor([[1.9057, 2.3588, 2.4905, 5.7032, 2.5397, 1.9620]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 10402 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1015\n",
      "755 22 False\n",
      "x_t:  0 [0.640625   0.40833333 0.06875    0.35416667]\n",
      "Q values:  tensor([[-6.6645, -7.1034, -7.5157, -7.3952, -8.0175, -6.7427]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10517 480 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  263\n",
      "756 0 True\n",
      "x_t:  3 [0.475      0.29583333 0.075      0.34166667]\n",
      "Q values:  tensor([[-8.7035, -9.3892, -9.0177, -8.3607, -8.6664, -7.8168]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4948 1295 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 756: ep_len:1295 episode reward: total was -144.700000. running mean: -75.340139\n",
      "startIDX:  70\n",
      "756 1 False\n",
      "x_t:  3 [0.26875    0.22916667 0.08125    0.325     ]\n",
      "Q values:  tensor([[3.1157, 3.8970, 3.9932, 5.4200, 2.5750, 4.2301]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 25733 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 756: ep_len:200 episode reward: total was -30.500000. running mean: -74.891737\n",
      "startIDX:  520\n",
      "756 5 True\n",
      "x_t:  2 [0.321875   0.39166667 0.096875   0.30416667]\n",
      "Q values:  tensor([[-7.9882, -7.8751, -8.2015, -8.4342, -8.2213, -7.0221]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6102 532 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 756: ep_len:532 episode reward: total was -37.000000. running mean: -74.512820\n",
      "startIDX:  1159\n",
      "756 10 True\n",
      "x_t:  2 [0.384375   0.39583333 0.090625   0.24583333]\n",
      "Q values:  tensor([[-6.7573, -7.4569, -6.5905, -7.2604, -6.5454, -5.8979]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12129 354 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 756: ep_len:354 episode reward: total was -67.900000. running mean: -74.446692\n",
      "startIDX:  1204\n",
      "756 12 False\n",
      "x_t:  3 [0.70625    0.3625     0.14375    0.42916667]\n",
      "Q values:  tensor([[-7.5678, -7.9203, -8.0675, -7.3780, -8.2145, -7.4544]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17858 733 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 756: ep_len:733 episode reward: total was -114.500000. running mean: -74.847225\n",
      "startIDX:  2129\n",
      "756 15 True\n",
      "x_t:  2 [0.60625  0.4125   0.078125 0.25    ]\n",
      "Q values:  tensor([[-7.5516, -7.5351, -7.3762, -7.6186, -7.2319, -6.8196]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15597 349 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 756: ep_len:349 episode reward: total was -27.500000. running mean: -74.373752\n",
      "startIDX:  1436\n",
      "756 22 True\n",
      "x_t:  4 [0.55625    0.36666667 0.05       0.3       ]\n",
      "Q values:  tensor([[-8.3745, -7.6891, -7.5733, -7.8354, -8.5749, -6.7293]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16431 600 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 756: ep_len:600 episode reward: total was -70.000000. running mean: -74.330015\n",
      "startIDX:  2204\n",
      "757 0 True\n",
      "x_t:  1 [0.484375   0.33333333 0.10625    0.5125    ]\n",
      "Q values:  tensor([[-8.2535, -7.9243, -8.1680, -7.9176, -7.9365, -7.1103]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22949 1120 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  789\n",
      "757 1 True\n",
      "x_t:  3 [0.059375   0.23333333 0.05625    0.27916667]\n",
      "Q values:  tensor([[-10.4055, -11.2396, -10.9828, -10.7598, -11.3581,  -9.5687]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34299 1368 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2900\n",
      "startIDX:  2130\n",
      "757 10 True\n",
      "x_t:  0 [0.809375   0.3875     0.103125   0.35416667]\n",
      "Q values:  tensor([[-8.2671, -7.9850, -7.7310, -7.9486, -8.5370, -7.3979]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19950 567 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1144\n",
      "757 12 False\n",
      "x_t:  3 [0.79375    0.37916667 0.165625   0.4375    ]\n",
      "Q values:  tensor([[-10.5118, -10.1517, -10.8657,  -8.7918, -10.7788,  -8.8889]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16495 1424 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  163\n",
      "757 15 True\n",
      "x_t:  2 [0.48125  0.4      0.071875 0.35    ]\n",
      "Q values:  tensor([[-7.3208, -6.9551, -7.2088, -7.1564, -7.3164, -6.3144]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2252 841 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  131\n",
      "757 22 False\n",
      "x_t:  1 [0.6125     0.32083333 0.146875   0.3875    ]\n",
      "Q values:  tensor([[-6.7605, -5.8068, -6.6269, -6.0809, -6.1522, -5.8449]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1605 679 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1528\n",
      "758 0 True\n",
      "x_t:  3 [0.809375   0.34166667 0.134375   0.4125    ]\n",
      "Q values:  tensor([[-5.7323, -5.9668, -5.6340, -5.9937, -5.8060, -5.1858]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16820 243 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 758: ep_len:243 episode reward: total was -1.200000. running mean: -75.525796\n",
      "startIDX:  771\n",
      "758 1 True\n",
      "x_t:  3 [0.09375    0.2375     0.08125    0.29583333]\n",
      "Q values:  tensor([[-8.0439, -8.4644, -8.1896, -7.8144, -8.5866, -7.1759]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34312 1368 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 758: ep_len:1368 episode reward: total was -96.300000. running mean: -75.733538\n",
      "startIDX:  1385\n",
      "758 5 True\n",
      "x_t:  1 [0.678125 0.2875   0.109375 0.3875  ]\n",
      "Q values:  tensor([[-5.2810, -5.4128, -4.7493, -5.1869, -5.1133, -4.3257]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12576 255 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 758: ep_len:255 episode reward: total was -42.700000. running mean: -75.403202\n",
      "startIDX:  1652\n",
      "758 10 True\n",
      "x_t:  3 [0.340625   0.2625     0.090625   0.30833333]\n",
      "Q values:  tensor([[-6.2184, -6.1524, -6.2643, -5.4827, -5.6324, -5.1163]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16487 301 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 758: ep_len:301 episode reward: total was -44.200000. running mean: -75.091170\n",
      "startIDX:  1086\n",
      "758 12 True\n",
      "x_t:  3 [0.1875     0.29166667 0.103125   0.3125    ]\n",
      "Q values:  tensor([[-6.0593, -6.8452, -6.4100, -6.4115, -6.5442, -5.9624]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16406 1403 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 758: ep_len:1403 episode reward: total was -72.800000. running mean: -75.068259\n",
      "startIDX:  2817\n",
      "758 15 True\n",
      "x_t:  0 [0.396875   0.41666667 0.109375   0.35416667]\n",
      "Q values:  tensor([[-6.5136, -6.8580, -5.8715, -6.3619, -6.7088, -5.6623]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23143 794 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 758: ep_len:794 episode reward: total was -95.500000. running mean: -75.272576\n",
      "startIDX:  1072\n",
      "758 22 True\n",
      "x_t:  2 [0.846875   0.39583333 0.065625   0.23333333]\n",
      "Q values:  tensor([[-6.0212, -6.3424, -5.8579, -6.2234, -5.8740, -5.3515]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12582 1085 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 758: ep_len:1085 episode reward: total was -150.800000. running mean: -76.027850\n",
      "startIDX:  1438\n",
      "759 0 True\n",
      "x_t:  4 [0.5        0.3625     0.071875   0.27083333]\n",
      "Q values:  tensor([[-5.0618, -5.5087, -5.4053, -5.2240, -5.3609, -4.5155]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16372 540 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  354\n",
      "759 1 True\n",
      "x_t:  1 [0.565625   0.30833333 0.2375     0.5625    ]\n",
      "Q values:  tensor([[-4.5385, -4.4543, -4.3896, -4.3908, -4.5174, -3.7954]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28102 302 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  771\n",
      "759 5 True\n",
      "x_t:  4 [0.2375   0.4      0.134375 0.375   ]\n",
      "Q values:  tensor([[-4.3516, -4.5323, -4.0300, -3.9898, -4.0583, -3.4854]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10044 649 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2025\n",
      "759 10 True\n",
      "x_t:  1 [0.33125    0.3125     0.1        0.34583333]\n",
      "Q values:  tensor([[-5.9862, -5.5406, -5.9323, -6.0355, -5.9725, -5.0005]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18856 312 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  848\n",
      "759 12 True\n",
      "x_t:  0 [0.88125    0.40833333 0.053125   0.3       ]\n",
      "Q values:  tensor([[-4.7425, -4.8988, -5.3191, -4.7796, -5.4195, -4.1474]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11641 631 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2865\n",
      "759 15 True\n",
      "x_t:  1 [0.121875   0.37083333 0.121875   0.50416667]\n",
      "Q values:  tensor([[-3.4220, -3.6260, -3.4652, -3.3428, -3.3495, -2.9740]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22046 231 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  528\n",
      "759 22 True\n",
      "x_t:  4 [0.009375   0.42916667 0.090625   0.35416667]\n",
      "Q values:  tensor([[-4.8971, -4.9072, -4.7434, -4.7811, -4.7984, -4.1259]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 6655 805 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  7542.752853631973\n",
      "startIDX:  124\n",
      "760 0 True\n",
      "x_t:  1 [0.734375   0.30833333 0.16875    0.42083333]\n",
      "Q values:  tensor([[-4.1833, -4.9329, -4.5285, -4.5016, -4.5341, -4.0399]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1622 708 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 760: ep_len:708 episode reward: total was -41.600000. running mean: -72.559553\n",
      "startIDX:  71\n",
      "760 1 False\n",
      "x_t:  3 [0.246875   0.24166667 0.09375    0.32083333]\n",
      "Q values:  tensor([[1.7619, 2.7859, 2.8874, 3.4926, 1.5180, 1.8993]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 25737 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 760: ep_len:200 episode reward: total was -34.500000. running mean: -72.178958\n",
      "startIDX:  2376\n",
      "760 5 False\n",
      "x_t:  3 [0.0625     0.23333333 0.053125   0.26666667]\n",
      "Q values:  tensor([[2.1816, 2.1925, 2.3824, 2.5660, 1.0223, 2.4814]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 20021 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 760: ep_len:200 episode reward: total was -30.400000. running mean: -71.761168\n",
      "startIDX:  978\n",
      "760 10 True\n",
      "x_t:  1 [0.6375     0.28333333 0.06875    0.34166667]\n",
      "Q values:  tensor([[-4.5832, -5.3523, -4.5923, -4.5927, -4.7289, -4.0671]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11362 1598 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 760: ep_len:1598 episode reward: total was -148.400000. running mean: -72.527557\n",
      "startIDX:  806\n",
      "760 12 True\n",
      "x_t:  0 [0.89375    0.4125     0.078125   0.30416667]\n",
      "Q values:  tensor([[-3.9936, -4.1622, -3.7064, -4.2271, -4.0774, -3.4635]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11640 662 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 760: ep_len:662 episode reward: total was -31.900000. running mean: -72.121281\n",
      "startIDX:  1753\n",
      "760 15 True\n",
      "x_t:  0 [0.671875   0.40416667 0.11875    0.3375    ]\n",
      "Q values:  tensor([[-4.6024, -4.6543, -4.2875, -4.3277, -4.5242, -3.9608]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13399 471 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 760: ep_len:471 episode reward: total was -53.000000. running mean: -71.930068\n",
      "startIDX:  1360\n",
      "760 22 True\n",
      "x_t:  3 [0.1        0.25416667 0.0625     0.27916667]\n",
      "Q values:  tensor([[-3.8718, -3.7250, -3.6930, -3.9519, -3.8820, -3.2736]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15207 1271 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 760: ep_len:1271 episode reward: total was -25.100000. running mean: -71.461768\n",
      "startIDX:  1016\n",
      "761 0 True\n",
      "x_t:  1 [0.515625   0.32916667 0.14375    0.45416667]\n",
      "Q values:  tensor([[-3.3969, -3.0516, -3.0082, -3.2778, -3.0924, -2.7322]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11983 807 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  760\n",
      "761 1 True\n",
      "x_t:  3 [0.578125   0.3        0.11875    0.42916667]\n",
      "Q values:  tensor([[-3.3846, -3.8290, -3.7827, -3.2918, -3.1593, -3.0109]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34427 1407 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  23\n",
      "761 5 True\n",
      "x_t:  0 [0.6625     0.39166667 0.0875     0.38333333]\n",
      "Q values:  tensor([[-3.3832, -4.1235, -3.7404, -3.7595, -3.9846, -3.1813]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3585 1664 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1868\n",
      "761 10 True\n",
      "x_t:  2 [0.01875    0.39583333 0.05625    0.25      ]\n",
      "Q values:  tensor([[-3.0436, -3.3061, -3.3526, -3.2134, -3.2765, -2.8445]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18145 818 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1314\n",
      "761 12 True\n",
      "x_t:  3 [0.4125     0.3        0.09375    0.34583333]\n",
      "Q values:  tensor([[-4.1588, -4.7450, -4.3652, -4.5480, -4.7130, -3.7489]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17905 256 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3021\n",
      "startIDX:  2410\n",
      "761 22 True\n",
      "x_t:  2 [0.521875   0.40833333 0.103125   0.25      ]\n",
      "Q values:  tensor([[-3.6893, -3.8268, -3.6842, -3.3988, -3.5702, -3.0877]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23683 375 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1668\n",
      "762 0 False\n",
      "x_t:  3 [0.353125   0.28333333 0.103125   0.33333333]\n",
      "Q values:  tensor([[2.4183, 3.1737, 2.9758, 4.0887, 1.9944, 3.3181]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 16886 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 762: ep_len:200 episode reward: total was -3.300000. running mean: -70.443310\n",
      "startIDX:  612\n",
      "762 1 True\n",
      "x_t:  2 [0.478125   0.38333333 0.115625   0.31666667]\n",
      "Q values:  tensor([[-3.9167, -3.8136, -3.9842, -3.9723, -3.5995, -3.2800]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31513 392 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 762: ep_len:392 episode reward: total was -48.400000. running mean: -70.222877\n",
      "startIDX:  938\n",
      "762 5 True\n",
      "x_t:  3 [0.059375   0.22916667 0.075      0.25      ]\n",
      "Q values:  tensor([[-4.1627, -3.8837, -3.8926, -4.0048, -4.0352, -3.2612]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10622 292 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 762: ep_len:292 episode reward: total was -150.500000. running mean: -71.025648\n",
      "startIDX:  1652\n",
      "762 10 True\n",
      "x_t:  3 [0.81875 0.3125  0.1125  0.4    ]\n",
      "Q values:  tensor([[-4.2900, -4.0779, -4.1117, -4.0647, -4.1493, -3.3742]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16409 264 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 762: ep_len:264 episode reward: total was -17.600000. running mean: -70.491391\n",
      "startIDX:  1274\n",
      "762 12 True\n",
      "x_t:  4 [0.390625   0.38333333 0.078125   0.30416667]\n",
      "Q values:  tensor([[-3.7368, -4.0337, -3.9581, -3.7387, -3.7492, -3.2720]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17442 477 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 762: ep_len:477 episode reward: total was -43.100000. running mean: -70.217477\n",
      "startIDX:  87\n",
      "762 15 True\n",
      "x_t:  3 [0.734375   0.33333333 0.090625   0.40833333]\n",
      "Q values:  tensor([[-4.0295, -4.2543, -4.4047, -4.3629, -3.8412, -3.4494]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 537 222 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 762: ep_len:222 episode reward: total was -16.400000. running mean: -69.679303\n",
      "startIDX:  2341\n",
      "762 22 True\n",
      "x_t:  1 [0.815625   0.29166667 0.0875     0.47083333]\n",
      "Q values:  tensor([[-3.4114, -3.6684, -3.6163, -3.7545, -3.6071, -3.0916]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22939 1039 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 762: ep_len:1039 episode reward: total was -72.500000. running mean: -69.707510\n",
      "startIDX:  2230\n",
      "763 0 True\n",
      "x_t:  2 [0.253125   0.40416667 0.059375   0.26666667]\n",
      "Q values:  tensor([[-3.6605, -4.1265, -3.6694, -3.8515, -3.5537, -3.0735]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23677 383 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  548\n",
      "763 1 True\n",
      "x_t:  2 [0.090625 0.3875   0.08125  0.3     ]\n",
      "Q values:  tensor([[-4.0513, -4.5235, -4.0298, -4.5216, -4.3190, -3.6951]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31578 1153 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2484\n",
      "763 5 True\n",
      "x_t:  1 [0.51875    0.31666667 0.20625    0.5       ]\n",
      "Q values:  tensor([[-4.1775, -4.6644, -4.4465, -4.2628, -4.5501, -3.8319]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22152 1115 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1066\n",
      "763 10 True\n",
      "x_t:  2 [0.76875    0.39583333 0.046875   0.25      ]\n",
      "Q values:  tensor([[-4.3652, -4.3976, -4.7154, -4.3502, -4.4994, -3.7977]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12070 380 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  830\n",
      "763 12 True\n",
      "x_t:  0 [0.728125   0.40833333 0.1125     0.40416667]\n",
      "Q values:  tensor([[-4.4442, -4.4799, -4.4031, -3.9872, -4.5809, -3.6881]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11723 688 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  451\n",
      "763 15 True\n",
      "x_t:  0 [0.903125   0.39583333 0.0625     0.35      ]\n",
      "Q values:  tensor([[-5.9043, -5.6943, -5.8751, -5.9275, -5.1702, -4.7258]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3657 417 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2870\n",
      "startIDX:  9\n",
      "764 0 True\n",
      "x_t:  2 [0.8        0.4125     0.0875     0.27083333]\n",
      "Q values:  tensor([[-5.8330, -6.0272, -5.2388, -6.0885, -5.8193, -4.9404]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2322 1100 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 764: ep_len:1100 episode reward: total was -164.900000. running mean: -70.321353\n",
      "startIDX:  402\n",
      "764 1 True\n",
      "x_t:  0 [0.65625    0.37916667 0.09375    0.40833333]\n",
      "Q values:  tensor([[-5.2319, -5.5880, -5.8257, -5.5500, -5.7413, -4.6084]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29134 521 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 764: ep_len:521 episode reward: total was -31.100000. running mean: -69.929140\n",
      "startIDX:  1250\n",
      "764 5 True\n",
      "x_t:  2 [0.003125   0.39583333 0.103125   0.27083333]\n",
      "Q values:  tensor([[-4.6729, -5.1163, -5.1539, -4.6525, -4.7683, -4.0987]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12004 727 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 764: ep_len:727 episode reward: total was -26.300000. running mean: -69.492848\n",
      "startIDX:  980\n",
      "764 10 True\n",
      "x_t:  1 [0.834375   0.27916667 0.059375   0.3375    ]\n",
      "Q values:  tensor([[-7.4386, -7.2659, -7.8144, -7.2832, -7.5540, -6.6324]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11336 1580 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 764: ep_len:1580 episode reward: total was -82.400000. running mean: -69.621920\n",
      "startIDX:  1897\n",
      "764 12 True\n",
      "x_t:  0 [0.55       0.40416667 0.103125   0.3375    ]\n",
      "Q values:  tensor([[-6.2276, -6.2610, -6.7376, -6.4809, -6.5260, -5.6593]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23049 955 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 764: ep_len:955 episode reward: total was -93.000000. running mean: -69.855701\n",
      "startIDX:  2353\n",
      "764 15 True\n",
      "x_t:  3 [0.80625    0.32916667 0.09375    0.3875    ]\n",
      "Q values:  tensor([[-6.0018, -6.8856, -6.6102, -6.4468, -6.4467, -5.5746]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19666 722 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 764: ep_len:722 episode reward: total was -65.000000. running mean: -69.807144\n",
      "startIDX:  2490\n",
      "764 22 True\n",
      "x_t:  3 [0.771875   0.32916667 0.09375    0.38333333]\n",
      "Q values:  tensor([[-7.3239, -7.4393, -7.1502, -7.2767, -7.1829, -5.9018]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26316 1338 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 764: ep_len:1338 episode reward: total was -143.100000. running mean: -70.540072\n",
      "startIDX:  1498\n",
      "765 0 True\n",
      "x_t:  2 [0.184375 0.4      0.059375 0.2625  ]\n",
      "Q values:  tensor([[-6.3956, -6.4276, -5.7872, -6.3485, -6.2561, -5.2039]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18416 1051 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  847\n",
      "765 1 True\n",
      "x_t:  4 [0.153125   0.37083333 0.08125    0.42083333]\n",
      "Q values:  tensor([[-4.4619, -4.9059, -4.6121, -4.7651, -4.6254, -3.9813]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35443 538 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1734\n",
      "765 5 True\n",
      "x_t:  1 [0.65       0.29583333 0.096875   0.29583333]\n",
      "Q values:  tensor([[-4.8336, -5.1701, -4.5736, -5.4006, -4.7187, -4.0908]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14954 614 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1487\n",
      "765 10 True\n",
      "x_t:  2 [0.01875    0.39583333 0.05625    0.25      ]\n",
      "Q values:  tensor([[-5.7945, -6.0140, -5.9205, -5.7045, -6.3667, -5.0381]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18145 1191 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  402\n",
      "765 12 True\n",
      "x_t:  3 [0.846875   0.3625     0.13125    0.42083333]\n",
      "Q values:  tensor([[-4.4010, -4.7903, -4.2504, -4.7870, -4.5165, -4.1011]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7712 255 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1738\n",
      "765 15 True\n",
      "x_t:  0 [0.30625    0.41666667 0.071875   0.27916667]\n",
      "Q values:  tensor([[-4.7306, -5.2029, -5.3427, -4.8624, -4.8536, -4.2844]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13459 729 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1037\n",
      "765 22 True\n",
      "x_t:  0 [0.90625    0.4        0.05       0.33333333]\n",
      "Q values:  tensor([[-4.1238, -4.3530, -4.3221, -4.5075, -4.3132, -3.6495]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10403 419 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1905\n",
      "766 0 True\n",
      "x_t:  1 [0.41875    0.33333333 0.15625    0.38333333]\n",
      "Q values:  tensor([[-4.9323, -5.4694, -5.4559, -5.1312, -5.1805, -4.3780]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18967 253 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 766: ep_len:253 episode reward: total was -67.400000. running mean: -70.890659\n",
      "startIDX:  255\n",
      "766 1 False\n",
      "x_t:  2 [0.303125   0.36666667 0.075      0.4375    ]\n",
      "Q values:  tensor([[-4.9269, -5.1383, -4.2253, -5.3787, -5.3732, -4.2459]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27473 850 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 766: ep_len:850 episode reward: total was -51.400000. running mean: -70.695752\n",
      "startIDX:  786\n",
      "766 5 True\n",
      "x_t:  4 [0.546875   0.35416667 0.0875     0.32916667]\n",
      "Q values:  tensor([[-5.8169, -6.4112, -5.7920, -6.4859, -6.3095, -5.2847]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10094 662 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 766: ep_len:662 episode reward: total was -19.600000. running mean: -70.184795\n",
      "startIDX:  2460\n",
      "766 10 True\n",
      "x_t:  1 [0.778125   0.29166667 0.1375     0.32916667]\n",
      "Q values:  tensor([[-6.7851, -7.2714, -6.9461, -7.2629, -6.8254, -5.9123]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22479 1171 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 766: ep_len:1171 episode reward: total was -105.300000. running mean: -70.535947\n",
      "startIDX:  1635\n",
      "766 12 True\n",
      "x_t:  0 [0.640625   0.42083333 0.10625    0.33333333]\n",
      "Q values:  tensor([[-7.4651, -8.1368, -7.0028, -6.8477, -7.4747, -6.3423]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21126 1562 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 766: ep_len:1562 episode reward: total was -189.400000. running mean: -71.724587\n",
      "startIDX:  1079\n",
      "766 15 True\n",
      "x_t:  4 [0.18125    0.38333333 0.06875    0.29583333]\n",
      "Q values:  tensor([[-5.6875, -5.3614, -5.3039, -5.4478, -5.5753, -4.4398]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9844 577 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 766: ep_len:577 episode reward: total was -5.700000. running mean: -71.064341\n",
      "startIDX:  1354\n",
      "766 22 True\n",
      "x_t:  3 [0.240625   0.275      0.071875   0.30833333]\n",
      "Q values:  tensor([[-7.5739, -7.8816, -7.0770, -8.0973, -7.8316, -6.5450]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15245 1323 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 766: ep_len:1323 episode reward: total was -104.800000. running mean: -71.401698\n",
      "startIDX:  1525\n",
      "767 0 True\n",
      "x_t:  3 [0.83125    0.35       0.165625   0.41666667]\n",
      "Q values:  tensor([[-4.8742, -5.1417, -4.9043, -5.4071, -5.1876, -4.2358]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16813 239 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  932\n",
      "767 1 True\n",
      "x_t:  4 [0.10625    0.37916667 0.08125    0.3625    ]\n",
      "Q values:  tensor([[-5.8188, -5.8119, -5.9527, -6.6768, -5.7804, -4.9753]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35546 561 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1327\n",
      "767 5 False\n",
      "x_t:  0 [0.76875    0.39166667 0.103125   0.34583333]\n",
      "Q values:  tensor([[-5.3118, -6.1677, -5.9504, -6.0062, -6.1113, -5.3775]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13521 763 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2091\n",
      "767 10 True\n",
      "x_t:  1 [0.1875  0.325   0.06875 0.375  ]\n",
      "Q values:  tensor([[-4.9266, -4.7942, -4.9834, -4.6915, -5.0939, -4.1852]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18832 270 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  344\n",
      "767 12 True\n",
      "x_t:  3 [0.58125    0.3125     0.065625   0.36666667]\n",
      "Q values:  tensor([[-7.2542, -6.4690, -6.9086, -7.0432, -6.0175, -5.9291]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7748 987 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2898\n",
      "767 15 True\n",
      "x_t:  0 [0.465625   0.40416667 0.159375   0.49166667]\n",
      "Q values:  tensor([[-4.4206, -4.3817, -4.2521, -4.6176, -4.3246, -3.7731]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23232 580 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1868\n",
      "767 22 True\n",
      "x_t:  2 [0.16875    0.40833333 0.09375    0.27916667]\n",
      "Q values:  tensor([[-5.6375, -6.0463, -5.9524, -6.1262, -5.8229, -4.9349]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18480 797 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1600\n",
      "768 0 True\n",
      "x_t:  2 [0.165625   0.40416667 0.059375   0.25416667]\n",
      "Q values:  tensor([[-6.6681, -7.1516, -6.7105, -6.6629, -7.1179, -5.9672]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18414 1020 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 768: ep_len:1020 episode reward: total was -110.600000. running mean: -71.892741\n",
      "startIDX:  563\n",
      "768 1 True\n",
      "x_t:  2 [0.003125   0.3875     0.09375    0.30416667]\n",
      "Q values:  tensor([[-6.5543, -6.6257, -6.8447, -6.6008, -7.0986, -5.6614]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31592 1192 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 768: ep_len:1192 episode reward: total was -147.200000. running mean: -72.645813\n",
      "startIDX:  1490\n",
      "768 5 True\n",
      "x_t:  0 [0.76875    0.39166667 0.115625   0.3375    ]\n",
      "Q values:  tensor([[-4.7603, -4.8878, -4.9245, -4.9764, -4.8614, -4.1820]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13519 489 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 768: ep_len:489 episode reward: total was -26.000000. running mean: -72.179355\n",
      "startIDX:  2548\n",
      "ep 768: ep_len:43 episode reward: total was 22.100000. running mean: -71.236562\n",
      "startIDX:  1337\n",
      "768 12 True\n",
      "x_t:  3 [0.728125   0.35416667 0.125      0.44583333]\n",
      "Q values:  tensor([[-4.8362, -5.3701, -5.0949, -5.1058, -4.7300, -4.2499]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17856 222 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 768: ep_len:222 episode reward: total was 36.000000. running mean: -70.164196\n",
      "startIDX:  1374\n",
      "768 15 True\n",
      "x_t:  3 [0.0625     0.24166667 0.06875    0.23333333]\n",
      "Q values:  tensor([[-5.1954, -5.5208, -5.7901, -5.3494, -4.9857, -4.8234]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10507 276 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 768: ep_len:276 episode reward: total was -88.100000. running mean: -70.343554\n",
      "startIDX:  2081\n",
      "768 22 True\n",
      "x_t:  1 [0.44375    0.32916667 0.128125   0.3625    ]\n",
      "Q values:  tensor([[-5.2764, -5.1324, -5.0201, -5.2739, -5.5230, -4.4507]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19038 234 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 768: ep_len:234 episode reward: total was -27.100000. running mean: -69.911118\n",
      "startIDX:  1709\n",
      "769 0 True\n",
      "x_t:  1 [0.5375  0.325   0.13125 0.3625 ]\n",
      "Q values:  tensor([[-6.7991, -7.1334, -6.9304, -6.8663, -6.6770, -5.8803]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18976 1080 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1102\n",
      "769 1 False\n",
      "x_t:  3 [0.5125     0.2875     0.096875   0.33333333]\n",
      "Q values:  tensor([[2.8183, 2.8300, 3.0426, 5.5290, 2.5461, 2.0392]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 35956 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2007\n",
      "769 5 True\n",
      "x_t:  3 [0.178125   0.25833333 0.084375   0.325     ]\n",
      "Q values:  tensor([[-8.6061, -8.8018, -8.1044, -9.1427, -8.2372, -7.5912]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18234 1254 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1355\n",
      "769 10 True\n",
      "x_t:  4 [0.10625    0.36666667 0.1        0.25833333]\n",
      "Q values:  tensor([[-5.0423, -5.6213, -6.0037, -5.5587, -5.6000, -5.0976]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15722 544 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  290\n",
      "769 12 True\n",
      "x_t:  4 [0.003125   0.44166667 0.13125    0.37083333]\n",
      "Q values:  tensor([[-6.4880, -6.9384, -7.2781, -6.4887, -6.7122, -6.1828]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7184 775 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  597\n",
      "769 15 True\n",
      "x_t:  1 [0.796875   0.3        0.084375   0.27916667]\n",
      "Q values:  tensor([[-6.6573, -7.4320, -6.1071, -7.4169, -6.6351, -5.7070]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5181 691 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1311\n",
      "769 22 True\n",
      "x_t:  3 [0.109375   0.26666667 0.075      0.28333333]\n",
      "Q values:  tensor([[-8.9048, -8.1487, -8.4684, -8.0866, -8.7112, -7.1286]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15214 1306 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  7780.346793889999\n",
      "startIDX:  2558\n",
      "ep 770: ep_len:13 episode reward: total was 5.000000. running mean: -68.062556\n",
      "startIDX:  797\n",
      "770 1 True\n",
      "x_t:  3 [0.09375    0.2375     0.08125    0.29583333]\n",
      "Q values:  tensor([[-9.4068, -9.3797, -9.8578, -9.3519, -9.5850, -8.2905]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34313 1365 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 770: ep_len:1365 episode reward: total was -84.800000. running mean: -68.229930\n",
      "startIDX:  619\n",
      "770 5 False\n",
      "x_t:  2 [0.4375     0.39166667 0.078125   0.3125    ]\n",
      "Q values:  tensor([[-5.3919, -5.6716, -4.3112, -5.7869, -5.1119, -4.3248]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6089 472 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 770: ep_len:472 episode reward: total was -69.600000. running mean: -68.243631\n",
      "startIDX:  2043\n",
      "770 10 True\n",
      "x_t:  1 [0.1        0.3375     0.125      0.37916667]\n",
      "Q values:  tensor([[-4.8816, -5.0146, -4.9779, -4.7686, -5.1497, -4.2564]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18821 289 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 770: ep_len:289 episode reward: total was -35.200000. running mean: -67.913195\n",
      "startIDX:  533\n",
      "770 12 True\n",
      "x_t:  2 [0.003125   0.41666667 0.1        0.24583333]\n",
      "Q values:  tensor([[-6.8021, -6.3382, -6.6175, -7.1357, -6.9931, -5.6311]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9828 1043 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 770: ep_len:1043 episode reward: total was 6.100000. running mean: -67.173063\n",
      "startIDX:  1270\n",
      "770 15 True\n",
      "x_t:  3 [0.915625   0.35       0.078125   0.38333333]\n",
      "Q values:  tensor([[-4.2148, -4.2917, -4.4165, -4.3215, -4.7217, -3.4890]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10334 234 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 770: ep_len:234 episode reward: total was 41.000000. running mean: -66.091332\n",
      "startIDX:  1161\n",
      "770 22 True\n",
      "x_t:  1 [0.3875     0.3375     0.121875   0.50833333]\n",
      "Q values:  tensor([[-4.9586, -5.4950, -5.1688, -5.0048, -5.3387, -4.4788]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11956 735 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 770: ep_len:735 episode reward: total was -78.500000. running mean: -66.215419\n",
      "startIDX:  2456\n",
      "startIDX:  212\n",
      "771 1 True\n",
      "x_t:  2 [0.128125   0.36666667 0.15       0.44583333]\n",
      "Q values:  tensor([[-4.7694, -4.6526, -4.6198, -4.8143, -4.3244, -3.8348]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27453 860 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2235\n",
      "771 5 True\n",
      "x_t:  2 [0.221875 0.4      0.090625 0.2625  ]\n",
      "Q values:  tensor([[-4.5101, -4.4661, -4.5107, -4.1895, -4.0756, -3.6481]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21583 1070 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  216\n",
      "771 10 True\n",
      "x_t:  4 [0.271875   0.35       0.0625     0.23333333]\n",
      "Q values:  tensor([[-3.7313, -3.5364, -3.3956, -3.7859, -3.5693, -2.9630]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4727 532 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1571\n",
      "771 12 True\n",
      "x_t:  2 [0.2875     0.40833333 0.090625   0.3       ]\n",
      "Q values:  tensor([[-3.9750, -4.3912, -4.2910, -4.3937, -4.4204, -3.4266]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19420 747 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1762\n",
      "771 15 True\n",
      "x_t:  0 [0.8375     0.40833333 0.1125     0.325     ]\n",
      "Q values:  tensor([[-3.7589, -3.6907, -3.6411, -3.7218, -3.5312, -2.9502]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13374 441 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  1240\n",
      "771 22 True\n",
      "x_t:  2 [0.6125     0.40833333 0.05       0.25833333]\n",
      "Q values:  tensor([[-3.0300, -3.4345, -3.4004, -3.0109, -3.2257, -2.6639]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12621 333 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2092\n",
      "772 0 True\n",
      "x_t:  0 [0.66875    0.39583333 0.1        0.37916667]\n",
      "Q values:  tensor([[-4.1588, -3.9643, -3.9897, -4.2063, -4.0801, -3.3989]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20702 843 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 772: ep_len:843 episode reward: total was -70.900000. running mean: -63.574107\n",
      "startIDX:  908\n",
      "772 1 True\n",
      "x_t:  4 [0.046875   0.38333333 0.1        0.425     ]\n",
      "Q values:  tensor([[-3.6854, -3.7375, -3.4892, -3.4286, -3.9377, -2.9738]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35430 520 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 772: ep_len:520 episode reward: total was 3.100000. running mean: -62.907366\n",
      "startIDX:  180\n",
      "772 5 True\n",
      "x_t:  2 [0.003125   0.39583333 0.1        0.40416667]\n",
      "Q values:  tensor([[-2.8474, -2.7678, -2.7023, -2.9802, -2.9033, -2.3864]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2051 841 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 772: ep_len:841 episode reward: total was -46.100000. running mean: -62.739292\n",
      "startIDX:  627\n",
      "772 10 True\n",
      "x_t:  2 [0.7625     0.39583333 0.090625   0.26666667]\n",
      "Q values:  tensor([[-3.0500, -2.9748, -2.6363, -3.0224, -3.0871, -2.5201]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6710 783 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 772: ep_len:783 episode reward: total was -92.600000. running mean: -63.037900\n",
      "startIDX:  239\n",
      "772 12 True\n",
      "x_t:  3 [0.14375    0.2625     0.0625     0.28333333]\n",
      "Q values:  tensor([[-4.1761, -4.0803, -3.8939, -3.9862, -4.0725, -3.3193]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5681 1386 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 772: ep_len:1386 episode reward: total was -57.400000. running mean: -62.981521\n",
      "startIDX:  665\n",
      "772 15 True\n",
      "x_t:  3 [0.41875    0.31666667 0.1        0.425     ]\n",
      "Q values:  tensor([[-3.3801, -2.8692, -2.9745, -3.4091, -3.4342, -2.7953]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8625 1738 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 772: ep_len:1738 episode reward: total was -156.300000. running mean: -63.914705\n",
      "startIDX:  800\n",
      "772 22 True\n",
      "x_t:  1 [0.009375   0.35833333 0.140625   0.4125    ]\n",
      "Q values:  tensor([[-3.2361, -3.2294, -3.0963, -3.4650, -3.4359, -2.7333]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9483 1122 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 772: ep_len:1122 episode reward: total was -126.400000. running mean: -64.539558\n",
      "startIDX:  2012\n",
      "773 0 True\n",
      "x_t:  0 [0.66875    0.4        0.08125    0.36666667]\n",
      "Q values:  tensor([[-3.0804, -3.1007, -3.1262, -2.9623, -3.0641, -2.6450]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20692 869 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  451\n",
      "773 1 True\n",
      "x_t:  1 [0.015625   0.325      0.18125    0.54166667]\n",
      "Q values:  tensor([[-3.5979, -3.7856, -3.3334, -3.7429, -3.5836, -2.8738]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30764 840 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1949\n",
      "773 5 True\n",
      "x_t:  3 [0.5        0.32083333 0.134375   0.4375    ]\n",
      "Q values:  tensor([[-3.7602, -3.7436, -3.7238, -3.4734, -3.6344, -2.9798]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18297 1328 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2569\n",
      "startIDX:  702\n",
      "773 12 True\n",
      "x_t:  0 [0.878125   0.41666667 0.053125   0.29166667]\n",
      "Q values:  tensor([[-3.6106, -3.6138, -3.6092, -3.4358, -3.7167, -2.9314]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11643 882 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  391\n",
      "773 15 True\n",
      "x_t:  0 [0.43125    0.40833333 0.09375    0.47916667]\n",
      "Q values:  tensor([[-3.5990, -3.5811, -3.5699, -3.8085, -3.7886, -2.9188]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3831 534 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2494\n",
      "773 22 True\n",
      "x_t:  4 [0.471875   0.37916667 0.0875     0.32083333]\n",
      "Q values:  tensor([[-5.3786, -5.0527, -4.7964, -4.8769, -5.4227, -4.2667]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27347 1868 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2507\n",
      "ep 774: ep_len:39 episode reward: total was 31.000000. running mean: -65.906663\n",
      "startIDX:  835\n",
      "774 1 True\n",
      "x_t:  3 [0.5125     0.2875     0.096875   0.33333333]\n",
      "Q values:  tensor([[-4.1592, -3.9972, -4.0152, -4.4447, -4.4913, -3.5321]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35956 797 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 774: ep_len:797 episode reward: total was -135.600000. running mean: -66.603596\n",
      "startIDX:  241\n",
      "774 5 True\n",
      "x_t:  1 [0.746875 0.2875   0.125    0.5875  ]\n",
      "Q values:  tensor([[-3.6676, -3.5590, -3.8524, -3.6782, -3.5342, -2.9961]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2560 234 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 774: ep_len:234 episode reward: total was -45.000000. running mean: -66.387560\n",
      "startIDX:  373\n",
      "774 10 True\n",
      "x_t:  3 [0.703125   0.3        0.134375   0.37916667]\n",
      "Q values:  tensor([[-4.4007, -3.9843, -3.8941, -4.0371, -4.4494, -3.3443]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5052 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 774: ep_len:200 episode reward: total was 29.900000. running mean: -65.424685\n",
      "startIDX:  787\n",
      "774 12 True\n",
      "x_t:  0 [0.9125     0.40416667 0.08125    0.3125    ]\n",
      "Q values:  tensor([[-4.8078, -4.1966, -4.5038, -4.8951, -4.8393, -3.8861]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11630 833 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 774: ep_len:833 episode reward: total was -39.100000. running mean: -65.161438\n",
      "startIDX:  2012\n",
      "774 15 True\n",
      "x_t:  2 [0.371875   0.4125     0.096875   0.25833333]\n",
      "Q values:  tensor([[-6.1181, -6.0315, -5.5299, -6.0709, -6.0077, -4.8086]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15631 1053 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 774: ep_len:1053 episode reward: total was -163.700000. running mean: -66.146823\n",
      "startIDX:  682\n",
      "774 22 True\n",
      "x_t:  2 [0.140625   0.40416667 0.071875   0.2625    ]\n",
      "Q values:  tensor([[-4.4321, -4.6177, -4.7364, -4.6546, -4.8189, -3.9420]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8937 913 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 774: ep_len:913 episode reward: total was -37.900000. running mean: -65.864355\n",
      "startIDX:  798\n",
      "775 0 True\n",
      "x_t:  0 [0.69375    0.4        0.109375   0.40416667]\n",
      "Q values:  tensor([[-5.3191, -5.0774, -5.1311, -4.9034, -5.1037, -4.2825]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10428 745 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  625\n",
      "775 1 True\n",
      "x_t:  2 [0.646875   0.38333333 0.125      0.30833333]\n",
      "Q values:  tensor([[-5.4892, -5.0548, -5.3552, -5.1808, -5.4689, -4.4628]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31486 364 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2618\n",
      "775 5 True\n",
      "x_t:  0 [0.53125    0.39583333 0.103125   0.30416667]\n",
      "Q values:  tensor([[-6.1138, -5.6689, -6.0427, -5.5043, -5.8333, -4.7995]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23230 819 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  841\n",
      "775 10 True\n",
      "x_t:  0 [0.821875   0.3875     0.109375   0.32916667]\n",
      "Q values:  tensor([[-4.5658, -5.2357, -4.7638, -5.0295, -5.3277, -4.0965]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8114 464 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  529\n",
      "775 12 True\n",
      "x_t:  2 [0.003125   0.41666667 0.1        0.24583333]\n",
      "Q values:  tensor([[-5.9675, -6.1668, -6.4395, -6.7599, -6.3868, -5.3955]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9828 1052 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1805\n",
      "775 15 True\n",
      "x_t:  0 [0.590625   0.40833333 0.11875    0.34583333]\n",
      "Q values:  tensor([[-5.4931, -5.2116, -5.4245, -5.4812, -5.4846, -4.5368]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13412 451 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1339\n",
      "775 22 True\n",
      "x_t:  3 [0.1        0.25416667 0.05625    0.275     ]\n",
      "Q values:  tensor([[-6.8975, -6.9279, -7.1264, -7.7312, -7.0261, -6.2732]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15206 1276 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2007\n",
      "776 0 True\n",
      "x_t:  0 [0.84375    0.4        0.09375    0.35833333]\n",
      "Q values:  tensor([[-7.3810, -6.7499, -6.5000, -6.4865, -6.9907, -5.7432]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20637 857 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 776: ep_len:857 episode reward: total was -28.300000. running mean: -66.085590\n",
      "startIDX:  556\n",
      "776 1 True\n",
      "x_t:  2 [0.553125   0.38333333 0.125      0.31666667]\n",
      "Q values:  tensor([[-9.1388, -7.9856, -8.8098, -8.0407, -8.8262, -7.5554]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31500 1147 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 776: ep_len:1147 episode reward: total was -116.700000. running mean: -66.591734\n",
      "startIDX:  695\n",
      "776 5 True\n",
      "x_t:  4 [0.003125   0.375      0.1        0.27916667]\n",
      "Q values:  tensor([[-11.0238, -10.2581, -10.2408, -11.1870, -10.6613,  -9.3901]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10281 2079 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 776: ep_len:2079 episode reward: total was -286.200000. running mean: -68.787817\n",
      "startIDX:  1944\n",
      "776 10 True\n",
      "x_t:  1 [0.75625    0.27916667 0.09375    0.3375    ]\n",
      "Q values:  tensor([[-5.0069, -5.0765, -5.4338, -4.9377, -5.5080, -4.7287]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18918 387 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 776: ep_len:387 episode reward: total was -134.800000. running mean: -69.447939\n",
      "startIDX:  1474\n",
      "776 12 False\n",
      "x_t:  3 [0.19375    0.2625     0.08125    0.28333333]\n",
      "Q values:  tensor([[3.1433, 6.0801, 3.7588, 8.4899, 3.7588, 2.1910]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 17959 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 776: ep_len:200 episode reward: total was -27.000000. running mean: -69.023459\n",
      "startIDX:  1156\n",
      "776 15 True\n",
      "x_t:  4 [0.2875     0.375      0.084375   0.29583333]\n",
      "Q values:  tensor([[-4.8328, -4.8097, -4.8215, -5.2465, -5.1648, -4.3661]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9862 579 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 776: ep_len:579 episode reward: total was -53.500000. running mean: -68.868225\n",
      "startIDX:  186\n",
      "776 22 True\n",
      "x_t:  3 [0.3625     0.28333333 0.075      0.31666667]\n",
      "Q values:  tensor([[-11.6440, -10.8392, -10.9568, -11.0345, -12.0640,  -9.5153]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4952 1679 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 776: ep_len:1679 episode reward: total was -194.000000. running mean: -70.119543\n",
      "startIDX:  1905\n",
      "777 0 True\n",
      "x_t:  1 [0.003125 0.375    0.146875 0.4125  ]\n",
      "Q values:  tensor([[-5.2493, -5.0276, -5.2827, -5.1095, -5.3070, -4.4705]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18923 245 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1198\n",
      "startIDX:  2185\n",
      "777 5 True\n",
      "x_t:  4 [0.240625   0.42083333 0.1625     0.39583333]\n",
      "Q values:  tensor([[-6.3586, -5.8108, -5.9298, -6.6560, -6.0109, -5.3713]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19487 578 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  135\n",
      "777 10 True\n",
      "x_t:  4 [0.003125   0.36666667 0.078125   0.25      ]\n",
      "Q values:  tensor([[-6.0840, -6.4641, -5.8459, -6.1046, -5.9891, -5.1828]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4543 488 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  993\n",
      "777 12 True\n",
      "x_t:  2 [0.559375   0.4125     0.096875   0.24583333]\n",
      "Q values:  tensor([[-5.2253, -4.9604, -4.9626, -5.2180, -5.4751, -4.7189]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13610 333 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  304\n",
      "777 15 True\n",
      "x_t:  0 [0.903125   0.40416667 0.0625     0.33333333]\n",
      "Q values:  tensor([[-6.3224, -6.9135, -6.5183, -6.7156, -7.0918, -5.8878]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3656 726 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2910\n",
      "startIDX:  1533\n",
      "778 0 True\n",
      "x_t:  3 [0.846875   0.34583333 0.15       0.425     ]\n",
      "Q values:  tensor([[-5.6158, -5.4546, -5.4318, -5.4971, -5.8882, -5.0051]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16812 228 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 778: ep_len:228 episode reward: total was 41.300000. running mean: -66.526776\n",
      "startIDX:  849\n",
      "778 1 True\n",
      "x_t:  4 [0.2375     0.37083333 0.090625   0.4125    ]\n",
      "Q values:  tensor([[-6.7307, -6.1939, -6.5237, -6.5201, -6.6203, -5.8985]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35455 551 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 778: ep_len:551 episode reward: total was -27.400000. running mean: -66.135508\n",
      "startIDX:  611\n",
      "778 5 True\n",
      "x_t:  3 [0.06875    0.2625     0.08125    0.31666667]\n",
      "Q values:  tensor([[-11.7587, -11.3839, -11.7917, -11.3007, -11.2899, -10.1692]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8750 1833 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 778: ep_len:1833 episode reward: total was -234.400000. running mean: -67.818153\n",
      "startIDX:  814\n",
      "778 10 True\n",
      "x_t:  0 [0.578125   0.39583333 0.071875   0.3       ]\n",
      "Q values:  tensor([[-4.9751, -5.2737, -5.2804, -4.8401, -4.9630, -4.2947]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8215 542 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 778: ep_len:542 episode reward: total was -93.500000. running mean: -68.074971\n",
      "startIDX:  1244\n",
      "778 12 True\n",
      "x_t:  4 [0.403125 0.375    0.084375 0.3125  ]\n",
      "Q values:  tensor([[-4.4646, -4.8293, -4.1748, -4.2893, -4.3592, -3.7621]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17450 520 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 778: ep_len:520 episode reward: total was -69.300000. running mean: -68.087222\n",
      "startIDX:  96\n",
      "778 15 True\n",
      "x_t:  3 [0.834375   0.34583333 0.121875   0.4375    ]\n",
      "Q values:  tensor([[-5.1655, -5.8029, -5.9857, -5.9519, -5.6975, -4.7579]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 523 211 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 778: ep_len:211 episode reward: total was -38.200000. running mean: -67.788349\n",
      "startIDX:  2644\n",
      "778 22 True\n",
      "x_t:  4 [0.415625   0.37916667 0.09375    0.3125    ]\n",
      "Q values:  tensor([[-5.5953, -5.6460, -5.1926, -5.2856, -5.6816, -4.9803]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27331 582 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 778: ep_len:582 episode reward: total was -43.300000. running mean: -67.543466\n",
      "startIDX:  1841\n",
      "779 0 True\n",
      "x_t:  2 [0.0125     0.4125     0.1125     0.24166667]\n",
      "Q values:  tensor([[-4.8658, -4.6629, -4.8095, -4.5723, -5.1488, -4.3402]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18395 727 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  181\n",
      "779 1 False\n",
      "x_t:  2 [0.334375 0.375    0.146875 0.425   ]\n",
      "Q values:  tensor([[-5.8221, -5.4487, -4.9873, -5.7179, -6.0425, -5.0985]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27480 894 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1757\n",
      "779 5 True\n",
      "x_t:  2 [0.71875    0.39583333 0.08125    0.24583333]\n",
      "Q values:  tensor([[-5.6997, -5.3693, -5.5149, -5.7456, -5.2150, -4.8197]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15662 947 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2227\n",
      "779 10 True\n",
      "x_t:  0 [0.525      0.39583333 0.078125   0.30416667]\n",
      "Q values:  tensor([[-4.8197, -5.3307, -4.9583, -4.8930, -4.9450, -4.2781]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20033 543 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  39\n",
      "779 12 False\n",
      "x_t:  1 [0.790625 0.3125   0.078125 0.425   ]\n",
      "Q values:  tensor([[-4.4681, -3.9289, -4.1092, -4.3736, -4.5131, -3.9829]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2226 653 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  13\n",
      "779 15 False\n",
      "x_t:  3 [0.353125   0.29166667 0.065625   0.325     ]\n",
      "Q values:  tensor([[-4.4990, -4.0831, -4.2248, -3.5361, -4.0338, -3.8274]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 603 296 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  769\n",
      "779 22 True\n",
      "x_t:  2 [0.671875   0.40833333 0.0875     0.27083333]\n",
      "Q values:  tensor([[-6.6740, -6.4354, -6.0466, -6.4018, -6.6171, -5.8319]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9027 888 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  8020.2478494644165\n",
      "startIDX:  1563\n",
      "780 0 True\n",
      "x_t:  3 [0.765625   0.32916667 0.10625    0.4125    ]\n",
      "Q values:  tensor([[-4.7379, -4.8955, -5.1890, -4.8311, -4.8152, -4.3911]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16825 234 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 780: ep_len:234 episode reward: total was -8.300000. running mean: -70.138518\n",
      "startIDX:  572\n",
      "780 1 True\n",
      "x_t:  2 [0.378125   0.38333333 0.096875   0.30833333]\n",
      "Q values:  tensor([[-4.7158, -4.8222, -4.6318, -4.7903, -5.0937, -4.4507]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31532 425 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 780: ep_len:425 episode reward: total was -81.400000. running mean: -70.251133\n",
      "startIDX:  2153\n",
      "780 5 False\n",
      "x_t:  4 [0.078125   0.41666667 0.159375   0.42916667]\n",
      "Q values:  tensor([[-4.9752, -4.9899, -5.0937, -4.8697, -4.1617, -4.3855]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19473 605 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 780: ep_len:605 episode reward: total was -81.100000. running mean: -70.359622\n",
      "startIDX:  2103\n",
      "780 10 False\n",
      "x_t:  0 [0.871875   0.39166667 0.10625    0.34583333]\n",
      "Q values:  tensor([[-5.2594, -5.5546, -5.6740, -5.4341, -6.0927, -5.3396]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19936 565 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 780: ep_len:565 episode reward: total was -60.300000. running mean: -70.259025\n",
      "startIDX:  837\n",
      "780 12 True\n",
      "x_t:  0 [0.603125   0.41666667 0.078125   0.32083333]\n",
      "Q values:  tensor([[-6.3772, -6.2005, -5.8182, -6.5118, -5.9122, -5.5669]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11687 663 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 780: ep_len:663 episode reward: total was -144.800000. running mean: -71.004435\n",
      "startIDX:  1960\n",
      "780 15 True\n",
      "x_t:  1 [0.871875   0.29166667 0.04375    0.30833333]\n",
      "Q values:  tensor([[-7.2498, -6.4093, -7.0775, -6.2855, -6.2620, -6.0316]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14846 685 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 780: ep_len:685 episode reward: total was -160.100000. running mean: -71.895391\n",
      "startIDX:  1010\n",
      "780 22 True\n",
      "x_t:  0 [0.76875    0.40833333 0.075      0.3125    ]\n",
      "Q values:  tensor([[-5.9831, -5.8508, -5.9447, -5.6854, -6.0654, -5.3504]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10426 442 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 780: ep_len:442 episode reward: total was -104.800000. running mean: -72.224437\n",
      "startIDX:  92\n",
      "781 0 False\n",
      "x_t:  1 [0.853125   0.3        0.1        0.43333333]\n",
      "Q values:  tensor([[-6.6061, -6.0456, -6.6003, -6.6134, -6.5588, -6.1066]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1614 699 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  592\n",
      "781 1 False\n",
      "x_t:  2 [0.475      0.39166667 0.1125     0.30416667]\n",
      "Q values:  tensor([[-7.6449, -7.0847, -6.3204, -6.6515, -6.9300, -6.4016]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31516 408 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2315\n",
      "781 5 True\n",
      "x_t:  3 [0.18125    0.25833333 0.1125     0.3       ]\n",
      "Q values:  tensor([[-15.4409, -17.6231, -18.1393, -17.3709, -18.1274, -17.7268]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19981 207 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  116\n",
      "781 10 False\n",
      "x_t:  3 [0.10625    0.24166667 0.06875    0.275     ]\n",
      "Q values:  tensor([[-8.8391, -7.8480, -8.5301, -7.6393, -8.8089, -7.8868]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3596 1051 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  43\n",
      "781 12 False\n",
      "x_t:  1 [0.8875     0.30833333 0.109375   0.42916667]\n",
      "Q values:  tensor([[-8.4539, -7.8469, -9.2003, -8.7052, -7.8841, -8.1620]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2216 639 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1281\n",
      "781 15 False\n",
      "x_t:  3 [0.209375 0.25     0.0625   0.2625  ]\n",
      "Q values:  tensor([[-13.2857, -11.5508, -12.9522, -10.8404, -13.8809, -11.0938]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10467 288 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  657\n",
      "781 22 True\n",
      "x_t:  2 [0.1875     0.40833333 0.0625     0.2625    ]\n",
      "Q values:  tensor([[-6.9854, -8.4855, -7.7067, -8.2317, -7.3101, -7.1575]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8945 913 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1501\n",
      "782 0 True\n",
      "x_t:  3 [0.69375    0.34166667 0.153125   0.39166667]\n",
      "Q values:  tensor([[-19.2931, -20.5914, -21.0371, -20.9811, -20.1348, -20.1433]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16831 255 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 782: ep_len:255 episode reward: total was -78.000000. running mean: -84.123913\n",
      "startIDX:  571\n",
      "782 1 True\n",
      "x_t:  1 [0.859375   0.25833333 0.1375     0.46666667]\n",
      "Q values:  tensor([[-12.7558, -12.4185, -12.8151, -11.8697, -13.1920, -11.4109]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30677 728 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 782: ep_len:728 episode reward: total was -513.900000. running mean: -88.421674\n",
      "startIDX:  1842\n",
      "782 5 True\n",
      "x_t:  2 [0.40625    0.4        0.08125    0.24583333]\n",
      "Q values:  tensor([[-16.6110, -17.3407, -17.2769, -16.1948, -17.6502, -16.8105]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15712 368 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 782: ep_len:368 episode reward: total was -255.700000. running mean: -90.094457\n",
      "startIDX:  736\n",
      "782 10 False\n",
      "x_t:  1 [0.053125 0.35     0.084375 0.375   ]\n",
      "Q values:  tensor([[-34.0004, -31.3256, -33.5973, -35.5977, -34.5416, -34.1758]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7110 221 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 782: ep_len:221 episode reward: total was -183.300000. running mean: -91.026512\n",
      "startIDX:  1539\n",
      "782 12 False\n",
      "x_t:  2 [0.08125    0.40833333 0.10625    0.29166667]\n",
      "Q values:  tensor([[-24.0696, -26.0315, -22.4190, -23.7010, -23.1529, -23.5752]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19392 765 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 782: ep_len:765 episode reward: total was -541.400000. running mean: -95.530247\n",
      "startIDX:  3157\n",
      "ep 782: ep_len:4 episode reward: total was 0.000000. running mean: -94.574945\n",
      "startIDX:  2369\n",
      "782 22 False\n",
      "x_t:  1 [0.590625   0.33333333 0.16875    0.4375    ]\n",
      "Q values:  tensor([[-22.6340, -21.9132, -22.0136, -22.3994, -23.0014, -22.8768]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22957 1038 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 782: ep_len:1038 episode reward: total was -805.400000. running mean: -101.683195\n",
      "startIDX:  1868\n",
      "783 0 False\n",
      "x_t:  1 [0.540625   0.32083333 0.15       0.3625    ]\n",
      "Q values:  tensor([[-35.3523, -34.2149, -35.4721, -35.4276, -36.2482, -35.1295]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18980 289 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  618\n",
      "783 1 False\n",
      "x_t:  2 [0.796875   0.37916667 0.075      0.30416667]\n",
      "Q values:  tensor([[-33.7300, -35.4228, -32.3992, -33.3242, -33.3097, -33.0531]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31467 379 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2106\n",
      "783 5 True\n",
      "x_t:  4 [0.078125   0.41666667 0.159375   0.42916667]\n",
      "Q values:  tensor([[-20.1038, -22.9051, -21.2207, -20.5372, -19.7643, -20.6771]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19473 627 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1023\n",
      "783 10 True\n",
      "x_t:  1 [0.5375 0.3    0.075  0.35  ]\n",
      "Q values:  tensor([[-37.7449, -33.1942, -33.4024, -33.2324, -33.9410, -34.5990]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11374 1568 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1499\n",
      "783 12 False\n",
      "x_t:  2 [0.078125 0.4125   0.1      0.2875  ]\n",
      "Q values:  tensor([[-29.4879, -30.9471, -27.7772, -29.4499, -29.2327, -27.9735]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19391 773 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2472\n",
      "783 15 False\n",
      "x_t:  3 [0.728125   0.32083333 0.06875    0.37083333]\n",
      "Q values:  tensor([[-27.9086, -28.4639, -30.8240, -27.7984, -30.6615, -30.1229]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19679 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2330\n",
      "783 22 True\n",
      "x_t:  1 [0.84375    0.30416667 0.115625   0.4625    ]\n",
      "Q values:  tensor([[-35.4519, -36.0820, -35.2697, -35.2435, -36.6028, -34.4886]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22936 1075 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  758\n",
      "784 0 False\n",
      "x_t:  1 [0.146875   0.35833333 0.128125   0.38333333]\n",
      "Q values:  tensor([[-28.8813, -26.6254, -28.9947, -27.7077, -27.9832, -27.8673]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9425 258 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 784: ep_len:258 episode reward: total was -187.200000. running mean: -126.371842\n",
      "startIDX:  424\n",
      "784 1 False\n",
      "x_t:  0 [0.934375   0.37083333 0.059375   0.40416667]\n",
      "Q values:  tensor([[-26.6361, -29.0289, -27.6260, -28.4415, -26.9845, -27.2217]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29087 471 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 784: ep_len:471 episode reward: total was -286.400000. running mean: -127.972124\n",
      "startIDX:  538\n",
      "784 5 False\n",
      "x_t:  2 [0.859375   0.37083333 0.08125    0.24166667]\n",
      "Q values:  tensor([[-25.3379, -25.7255, -24.1121, -26.1977, -25.2199, -24.1708]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6022 478 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 784: ep_len:478 episode reward: total was -255.600000. running mean: -129.248402\n",
      "startIDX:  2557\n",
      "ep 784: ep_len:39 episode reward: total was 25.000000. running mean: -127.705918\n",
      "startIDX:  1893\n",
      "784 12 False\n",
      "x_t:  0 [0.359375   0.41666667 0.075      0.275     ]\n",
      "Q values:  tensor([[-19.7645, -20.8487, -21.7903, -20.7558, -21.6765, -20.8151]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23009 929 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 784: ep_len:929 episode reward: total was -412.600000. running mean: -130.554859\n",
      "startIDX:  823\n",
      "784 15 True\n",
      "x_t:  3 [0.090625   0.23333333 0.059375   0.23333333]\n",
      "Q values:  tensor([[-26.2910, -26.9521, -23.5167, -26.0207, -26.6508, -23.5752]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8508 1248 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 784: ep_len:1248 episode reward: total was -550.900000. running mean: -134.758311\n",
      "startIDX:  2836\n",
      "ep 784: ep_len:86 episode reward: total was 50.000000. running mean: -132.910727\n",
      "startIDX:  21\n",
      "785 0 False\n",
      "x_t:  1 [0.321875 0.3375   0.16875  0.4375  ]\n",
      "Q values:  tensor([[-18.5254, -17.2645, -17.4862, -18.9498, -19.2584, -17.3078]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1665 786 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  610\n",
      "785 1 False\n",
      "x_t:  2 [0.7625     0.37916667 0.09375    0.32083333]\n",
      "Q values:  tensor([[-18.4497, -18.6463, -16.9129, -19.2174, -18.1775, -17.1128]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31469 374 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  204\n",
      "785 5 True\n",
      "x_t:  1 [0.2        0.3375     0.134375   0.53333333]\n",
      "Q values:  tensor([[-17.9158, -15.7565, -16.1418, -18.0302, -16.4649, -15.7343]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2526 226 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  57\n",
      "785 10 False\n",
      "x_t:  3 [0.0625     0.2375     0.0625     0.25416667]\n",
      "Q values:  tensor([[-13.5843, -12.8570, -13.2953, -12.7740, -13.7897, -12.8501]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3579 1076 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  818\n",
      "785 12 True\n",
      "x_t:  0 [0.790625   0.40833333 0.128125   0.30833333]\n",
      "Q values:  tensor([[-13.9523, -15.0803, -13.5023, -13.5511, -14.8366, -12.5268]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11647 668 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  264\n",
      "785 15 False\n",
      "x_t:  2 [0.009375   0.40416667 0.11875    0.33333333]\n",
      "Q values:  tensor([[-12.8455, -13.3800, -11.3945, -12.7290, -13.0356, -11.4944]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2195 759 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  503\n",
      "785 22 True\n",
      "x_t:  4 [0.021875   0.41666667 0.0875     0.375     ]\n",
      "Q values:  tensor([[-12.7822, -12.7204, -10.5755, -11.6260, -12.3537, -10.6762]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 6646 852 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1961\n",
      "786 0 False\n",
      "x_t:  1 [0.321875   0.35       0.240625   0.50416667]\n",
      "Q values:  tensor([[-18.7596, -16.3612, -17.9809, -16.9217, -18.5728, -16.6817]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22957 2235 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 786: ep_len:2235 episode reward: total was -598.000000. running mean: -141.078693\n",
      "startIDX:  591\n",
      "786 1 False\n",
      "x_t:  2 [0.553125   0.39583333 0.121875   0.3       ]\n",
      "Q values:  tensor([[-10.2235, -10.1631,  -8.8257, -10.1578, -10.1926,  -8.8627]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31501 404 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 786: ep_len:404 episode reward: total was -55.700000. running mean: -140.224906\n",
      "startIDX:  679\n",
      "786 5 False\n",
      "x_t:  3 [0.0625     0.25833333 0.075      0.3125    ]\n",
      "Q values:  tensor([[-10.5575,  -9.4366,  -9.6356,  -8.3214, -10.1950,  -8.8498]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8746 1338 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 786: ep_len:1338 episode reward: total was -262.400000. running mean: -141.446657\n",
      "startIDX:  2125\n",
      "786 10 True\n",
      "x_t:  0 [0.5625     0.3875     0.065625   0.30833333]\n",
      "Q values:  tensor([[-8.7164, -8.3743, -7.1160, -8.5037, -8.5130, -7.4074]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20022 579 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 786: ep_len:579 episode reward: total was -91.600000. running mean: -140.948190\n",
      "startIDX:  134\n",
      "786 12 True\n",
      "x_t:  2 [0.80625    0.41666667 0.06875    0.23333333]\n",
      "Q values:  tensor([[-9.7516, -9.1560, -8.3466, -9.6626, -9.6078, -8.1725]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2807 296 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 786: ep_len:296 episode reward: total was -42.700000. running mean: -139.965708\n",
      "startIDX:  1772\n",
      "786 15 True\n",
      "x_t:  0 [0.7625     0.40416667 0.109375   0.33333333]\n",
      "Q values:  tensor([[-8.8663, -8.0452, -7.6924, -8.1160, -7.6660, -7.1913]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13387 455 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 786: ep_len:455 episode reward: total was -45.000000. running mean: -139.016051\n",
      "startIDX:  1159\n",
      "786 22 True\n",
      "x_t:  1 [0.29375    0.35833333 0.209375   0.5       ]\n",
      "Q values:  tensor([[-6.8241, -6.1877, -6.0313, -6.6957, -6.8245, -6.0728]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11960 734 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 786: ep_len:734 episode reward: total was -109.100000. running mean: -138.716890\n",
      "startIDX:  1502\n",
      "787 0 True\n",
      "x_t:  3 [0.584375   0.31666667 0.1        0.36666667]\n",
      "Q values:  tensor([[-9.1899, -9.0753, -8.5389, -8.7102, -9.2547, -7.6453]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16848 269 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  660\n",
      "787 1 False\n",
      "x_t:  2 [0.8125     0.37916667 0.071875   0.31666667]\n",
      "Q values:  tensor([[-8.0707, -8.0419, -6.8392, -7.3554, -8.0049, -6.8811]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31464 340 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  10\n",
      "787 5 False\n",
      "x_t:  2 [0.04375    0.3875     0.19375    0.42083333]\n",
      "Q values:  tensor([[-8.0147, -6.8980, -6.6982, -7.2976, -8.4004, -6.7300]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2060 931 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  518\n",
      "787 10 False\n",
      "x_t:  2 [0.003125   0.40833333 0.103125   0.25      ]\n",
      "Q values:  tensor([[-8.1669, -7.1478, -5.9714, -7.5302, -7.2245, -6.5261]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6586 760 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1266\n",
      "787 12 True\n",
      "x_t:  3 [0.596875   0.3375     0.128125   0.39583333]\n",
      "Q values:  tensor([[-7.5815, -7.2691, -6.9111, -6.6294, -7.9708, -6.5313]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17874 719 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1945\n",
      "787 15 False\n",
      "x_t:  1 [0.609375   0.30416667 0.078125   0.3125    ]\n",
      "Q values:  tensor([[-8.3380, -6.9220, -7.6575, -7.8068, -8.1578, -7.0103]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14880 711 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2281\n",
      "787 22 False\n",
      "x_t:  1 [0.33125    0.35416667 0.16875    0.45      ]\n",
      "Q values:  tensor([[-9.0951, -7.8385, -8.5962, -9.0896, -8.9801, -8.0586]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22981 1110 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2283\n",
      "788 0 False\n",
      "x_t:  2 [0.909375   0.3875     0.05625    0.18333333]\n",
      "Q values:  tensor([[-8.6776, -7.9275, -7.2137, -7.9107, -8.6548, -7.2461]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23571 303 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 788: ep_len:303 episode reward: total was -57.800000. running mean: -136.243639\n",
      "startIDX:  435\n",
      "788 1 False\n",
      "x_t:  1 [0.765625   0.275      0.15625    0.45416667]\n",
      "Q values:  tensor([[-7.7671, -6.9254, -7.4434, -7.6699, -7.4105, -7.2026]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30689 803 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 788: ep_len:803 episode reward: total was -108.700000. running mean: -135.968203\n",
      "startIDX:  611\n",
      "788 5 False\n",
      "x_t:  2 [0.853125   0.375      0.0625     0.28333333]\n",
      "Q values:  tensor([[-8.3681, -7.9611, -7.1517, -7.8227, -8.2619, -7.3240]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6028 447 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 788: ep_len:447 episode reward: total was -86.100000. running mean: -135.469521\n",
      "startIDX:  431\n",
      "788 10 False\n",
      "x_t:  3 [0.35       0.25416667 0.078125   0.3125    ]\n",
      "Q values:  tensor([[-1.2972, -0.4546, -1.7746,  0.2486, -1.1423, -1.3005]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5108 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 788: ep_len:201 episode reward: total was -38.000000. running mean: -134.494826\n",
      "startIDX:  788\n",
      "788 12 False\n",
      "x_t:  1 [0.75     0.325    0.128125 0.5375  ]\n",
      "Q values:  tensor([[-10.5279,  -9.5328, -10.1223,  -9.7246, -11.0512,  -9.6355]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10352 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 788: ep_len:200 episode reward: total was -52.500000. running mean: -133.674877\n",
      "startIDX:  898\n",
      "788 15 False\n",
      "x_t:  3 [0.065625   0.23333333 0.059375   0.2375    ]\n",
      "Q values:  tensor([[-10.7323, -10.6057,  -9.6190,  -9.4779,  -9.6137,  -9.7031]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8498 1221 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 788: ep_len:1221 episode reward: total was -236.400000. running mean: -134.702129\n",
      "startIDX:  1019\n",
      "788 22 True\n",
      "x_t:  1 [0.75     0.325    0.178125 0.475   ]\n",
      "Q values:  tensor([[-13.6564, -12.0444, -12.3141, -12.8914, -12.8285, -11.8896]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11925 1177 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 788: ep_len:1177 episode reward: total was -303.100000. running mean: -136.386107\n",
      "startIDX:  1539\n",
      "789 0 False\n",
      "x_t:  3 [0.43125    0.3125     0.1125     0.34583333]\n",
      "Q values:  tensor([[-8.7817, -8.3073, -8.0911, -7.5020, -9.0746, -7.7314]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16868 255 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  697\n",
      "789 1 True\n",
      "x_t:  3 [0.078125   0.22916667 0.06875    0.29166667]\n",
      "Q values:  tensor([[-12.6176, -11.8592, -12.8697, -10.3778, -12.3578, -11.6111]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34307 1415 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  2425\n",
      "789 5 False\n",
      "x_t:  2 [0.003125   0.40416667 0.071875   0.25416667]\n",
      "Q values:  tensor([[-10.9837,  -9.9503,  -9.2912,  -9.8182, -10.9180,  -9.3415]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21544 944 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1750\n",
      "789 10 True\n",
      "x_t:  3 [0.721875   0.29583333 0.071875   0.37916667]\n",
      "Q values:  tensor([[-9.7590, -9.1369, -9.4216, -9.0555, -8.9525, -8.5014]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16423 224 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1337\n",
      "789 12 True\n",
      "x_t:  3 [0.671875   0.33333333 0.084375   0.41666667]\n",
      "Q values:  tensor([[-7.9331, -8.8566, -8.1863, -9.4112, -8.2843, -7.5933]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17866 222 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3042\n",
      "startIDX:  372\n",
      "789 22 False\n",
      "x_t:  3 [0.253125 0.275    0.084375 0.275   ]\n",
      "Q values:  tensor([[-13.2589, -12.2357, -12.0678, -10.9096, -12.7224, -11.4029]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4928 1255 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  8234.888325929642\n",
      "startIDX:  2201\n",
      "790 0 True\n",
      "x_t:  1 [0.665625 0.3125   0.115625 0.5125  ]\n",
      "Q values:  tensor([[-14.9955, -13.9905, -14.4296, -14.5541, -15.1226, -13.0818]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22935 1111 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 790: ep_len:1111 episode reward: total was -189.400000. running mean: -133.551828\n",
      "startIDX:  21\n",
      "790 1 True\n",
      "x_t:  3 [0.2375     0.24166667 0.078125   0.30833333]\n",
      "Q values:  tensor([[-8.8531, -9.1412, -8.6740, -8.5799, -9.9244, -8.0834]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25742 223 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 790: ep_len:223 episode reward: total was -43.200000. running mean: -132.648310\n",
      "startIDX:  680\n",
      "790 5 True\n",
      "x_t:  3 [0.075      0.25833333 0.08125    0.31666667]\n",
      "Q values:  tensor([[-11.5582, -11.2299, -11.1601, -11.1363, -11.1478,  -9.9804]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8751 1345 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 790: ep_len:1345 episode reward: total was -173.300000. running mean: -133.054827\n",
      "startIDX:  174\n",
      "790 10 False\n",
      "x_t:  2 [0.16875 0.4     0.09375 0.2625 ]\n",
      "Q values:  tensor([[-13.2739, -12.6346, -11.3825, -13.4128, -13.7393, -11.5337]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6611 1481 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 790: ep_len:1481 episode reward: total was -330.700000. running mean: -135.031278\n",
      "startIDX:  1470\n",
      "790 12 True\n",
      "x_t:  3 [0.11875    0.25       0.075      0.27083333]\n",
      "Q values:  tensor([[-9.3935, -9.3883, -8.8324, -9.7092, -9.5388, -8.2131]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17978 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 790: ep_len:204 episode reward: total was -61.200000. running mean: -134.292966\n",
      "startIDX:  2947\n",
      "790 15 True\n",
      "x_t:  0 [0.490625   0.4125     0.096875   0.37083333]\n",
      "Q values:  tensor([[-10.0913,  -8.6906,  -8.4993,  -9.1387,  -9.2494,  -8.0314]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23130 520 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 790: ep_len:520 episode reward: total was -81.500000. running mean: -133.765036\n",
      "startIDX:  389\n",
      "790 22 True\n",
      "x_t:  4 [0.003125   0.425      0.090625   0.34583333]\n",
      "Q values:  tensor([[-8.9126, -8.7545, -8.7471, -8.2655, -8.9235, -7.7303]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 6670 916 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 790: ep_len:916 episode reward: total was -140.800000. running mean: -133.835386\n",
      "startIDX:  2096\n",
      "791 0 True\n",
      "x_t:  0 [0.725      0.40416667 0.09375    0.3875    ]\n",
      "Q values:  tensor([[-8.2170, -7.2000, -7.5369, -7.7372, -7.9864, -6.8555]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20711 843 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  242\n",
      "791 1 False\n",
      "x_t:  2 [0.134375   0.3625     0.140625   0.44583333]\n",
      "Q values:  tensor([[-10.0165,  -8.8872,  -7.6589,  -8.7487,  -9.7240,  -7.9376]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27450 847 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1410\n",
      "791 5 True\n",
      "x_t:  1 [0.003125   0.34583333 0.084375   0.41666667]\n",
      "Q values:  tensor([[-5.9304, -6.1670, -5.8337, -6.3083, -5.9278, -5.2986]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12505 203 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  446\n",
      "791 10 True\n",
      "x_t:  3 [0.29375    0.24583333 0.08125    0.30416667]\n",
      "Q values:  tensor([[-10.5584,  -9.8995,  -9.6424, -10.0653, -11.4397,  -9.3144]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5120 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1212\n",
      "791 12 True\n",
      "x_t:  4 [0.35       0.39583333 0.1        0.32916667]\n",
      "Q values:  tensor([[-6.9388, -6.4260, -7.0907, -6.5604, -7.0435, -5.6537]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17432 518 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  611\n",
      "791 15 True\n",
      "x_t:  1 [0.878125   0.29583333 0.075      0.27083333]\n",
      "Q values:  tensor([[-7.4228, -7.7644, -7.0721, -7.2986, -7.3895, -6.6898]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5169 667 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2186\n",
      "791 22 True\n",
      "x_t:  0 [0.83125    0.40416667 0.04375    0.32083333]\n",
      "Q values:  tensor([[-6.3314, -6.0208, -5.6411, -6.5247, -6.3199, -5.2846]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20716 823 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1545\n",
      "792 0 True\n",
      "x_t:  3 [0.478125 0.3      0.075    0.35    ]\n",
      "Q values:  tensor([[-6.8596, -6.1280, -6.3386, -6.1034, -6.8682, -5.6595]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16864 260 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 792: ep_len:260 episode reward: total was -75.400000. running mean: -127.637053\n",
      "startIDX:  438\n",
      "792 1 True\n",
      "x_t:  1 [0.61875    0.2875     0.178125   0.45416667]\n",
      "Q values:  tensor([[-6.8658, -7.1213, -6.4410, -6.9672, -6.9020, -5.9750]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30704 813 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 792: ep_len:813 episode reward: total was -8.600000. running mean: -126.446683\n",
      "startIDX:  1594\n",
      "792 5 True\n",
      "x_t:  1 [0.890625   0.27916667 0.05       0.325     ]\n",
      "Q values:  tensor([[-6.9328, -6.6915, -6.4170, -6.7895, -6.3330, -5.6728]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14923 679 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 792: ep_len:679 episode reward: total was -28.300000. running mean: -125.465216\n",
      "startIDX:  2497\n",
      "792 10 True\n",
      "x_t:  1 [0.684375 0.2875   0.128125 0.325   ]\n",
      "Q values:  tensor([[-6.7449, -5.9736, -6.0311, -5.5324, -6.1823, -5.1776]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22489 1166 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 792: ep_len:1166 episode reward: total was -61.600000. running mean: -124.826564\n",
      "startIDX:  1484\n",
      "792 12 True\n",
      "x_t:  2 [0.1625     0.41666667 0.115625   0.27916667]\n",
      "Q values:  tensor([[-6.5236, -6.0755, -5.8205, -5.7530, -6.2528, -4.9345]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19405 781 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 792: ep_len:781 episode reward: total was -93.600000. running mean: -124.514298\n",
      "startIDX:  12\n",
      "792 15 True\n",
      "x_t:  3 [0.8375     0.36666667 0.159375   0.42083333]\n",
      "Q values:  tensor([[-5.7464, -5.7017, -5.2747, -5.3349, -5.5188, -4.7760]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 519 243 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 792: ep_len:243 episode reward: total was 19.100000. running mean: -123.078155\n",
      "startIDX:  2545\n",
      "792 22 True\n",
      "x_t:  4 [0.403125   0.39166667 0.1        0.31666667]\n",
      "Q values:  tensor([[-6.6100, -6.1127, -6.1787, -5.8958, -6.7408, -5.4187]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27406 1865 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 792: ep_len:1865 episode reward: total was -221.200000. running mean: -124.059374\n",
      "startIDX:  1003\n",
      "793 0 False\n",
      "x_t:  2 [0.484375   0.40833333 0.084375   0.29583333]\n",
      "Q values:  tensor([[-5.3306, -5.1479, -4.2906, -5.2701, -5.0319, -4.4309]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12678 1167 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  14\n",
      "793 1 False\n",
      "x_t:  3 [0.5125     0.26666667 0.09375    0.37916667]\n",
      "Q values:  tensor([[-4.3281, -4.1995, -3.4222, -3.4066, -4.2542, -3.6115]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25685 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  563\n",
      "793 5 True\n",
      "x_t:  2 [0.665625   0.4        0.103125   0.29583333]\n",
      "Q values:  tensor([[-4.8759, -4.5967, -4.8472, -4.8807, -4.5997, -4.1212]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6058 484 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1486\n",
      "793 10 True\n",
      "x_t:  3 [0.546875 0.2875   0.071875 0.35    ]\n",
      "Q values:  tensor([[-4.5507, -4.6353, -4.0606, -3.9271, -4.5493, -3.6393]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16450 368 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "793 12 True\n",
      "x_t:  3 [0.084375   0.26666667 0.084375   0.29166667]\n",
      "Q values:  tensor([[-4.0834, -4.0236, -4.0214, -3.7241, -4.4628, -3.4363]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16377 1393 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  531\n",
      "793 15 True\n",
      "x_t:  1 [0.29375    0.3375     0.103125   0.31666667]\n",
      "Q values:  tensor([[-5.1189, -4.4561, -4.9218, -4.6465, -4.5297, -3.8321]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5253 771 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2793\n",
      "startIDX:  70\n",
      "794 0 True\n",
      "x_t:  1 [0.8875     0.29166667 0.109375   0.43333333]\n",
      "Q values:  tensor([[-4.3239, -3.8232, -4.1742, -3.8756, -3.9570, -3.5617]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1606 711 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 794: ep_len:711 episode reward: total was -20.400000. running mean: -118.222319\n",
      "startIDX:  1159\n",
      "ep 794: ep_len:24 episode reward: total was -22.900000. running mean: -117.269096\n",
      "startIDX:  2031\n",
      "794 5 True\n",
      "x_t:  3 [0.84375    0.33333333 0.10625    0.45      ]\n",
      "Q values:  tensor([[-6.8389, -6.1418, -6.7024, -5.9688, -6.7331, -5.6078]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19887 2048 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 794: ep_len:2048 episode reward: total was -279.600000. running mean: -118.892405\n",
      "startIDX:  1969\n",
      "794 10 True\n",
      "x_t:  1 [0.003125   0.35833333 0.10625    0.40416667]\n",
      "Q values:  tensor([[-4.3648, -4.0491, -4.0713, -4.3184, -4.1914, -3.4780]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18807 312 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 794: ep_len:312 episode reward: total was -27.800000. running mean: -117.981481\n",
      "startIDX:  136\n",
      "794 12 True\n",
      "x_t:  2 [0.790625   0.40833333 0.034375   0.24166667]\n",
      "Q values:  tensor([[-4.3464, -4.1543, -4.2208, -4.0272, -4.2286, -3.2496]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2814 300 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 794: ep_len:300 episode reward: total was -18.300000. running mean: -116.984666\n",
      "startIDX:  2284\n",
      "794 15 True\n",
      "x_t:  3 [0.615625   0.33333333 0.075      0.40416667]\n",
      "Q values:  tensor([[-5.9513, -5.5081, -5.4988, -5.8034, -6.2400, -4.8915]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18264 1286 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 794: ep_len:1286 episode reward: total was -125.500000. running mean: -117.069819\n",
      "startIDX:  1434\n",
      "794 22 True\n",
      "x_t:  4 [0.09375    0.38333333 0.084375   0.3       ]\n",
      "Q values:  tensor([[-4.6658, -4.2180, -4.4742, -4.5205, -4.7111, -3.7840]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16339 565 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 794: ep_len:565 episode reward: total was -88.100000. running mean: -116.780121\n",
      "startIDX:  1829\n",
      "795 0 True\n",
      "x_t:  2 [0.003125   0.4125     0.04375    0.24583333]\n",
      "Q values:  tensor([[-5.1824, -4.9674, -5.0331, -5.0727, -5.4016, -4.2819]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18389 722 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  565\n",
      "795 1 True\n",
      "x_t:  1 [0.325  0.3125 0.2125 0.4875]\n",
      "Q values:  tensor([[-4.5496, -4.2275, -4.7524, -4.5160, -4.5986, -3.9701]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30734 751 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2344\n",
      "795 5 True\n",
      "x_t:  2 [0.003125   0.39583333 0.071875   0.27083333]\n",
      "Q values:  tensor([[-5.1748, -4.8144, -4.2600, -4.7464, -4.8707, -4.2830]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21546 972 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  53\n",
      "795 10 True\n",
      "x_t:  4 [0.384375   0.34166667 0.06875    0.2375    ]\n",
      "Q values:  tensor([[-7.3268, -7.1102, -7.7209, -7.3478, -7.7757, -6.2375]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4704 1650 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  93\n",
      "795 12 True\n",
      "x_t:  1 [0.81875  0.3125   0.109375 0.425   ]\n",
      "Q values:  tensor([[-5.1823, -4.4986, -4.8378, -5.0602, -4.7578, -4.1730]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2223 616 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2178\n",
      "795 15 True\n",
      "x_t:  2 [0.60625  0.4125   0.078125 0.25    ]\n",
      "Q values:  tensor([[-5.2973, -4.8745, -4.7101, -4.7583, -5.0007, -4.2726]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15597 321 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  28\n",
      "795 22 True\n",
      "x_t:  1 [0.590625   0.31666667 0.06875    0.39166667]\n",
      "Q values:  tensor([[-6.5068, -6.2368, -6.1947, -6.2203, -6.1861, -5.2833]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1610 729 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1010\n",
      "796 0 False\n",
      "x_t:  1 [0.6875     0.3125     0.1625     0.44583333]\n",
      "Q values:  tensor([[-5.2819, -4.4545, -5.2031, -5.2708, -5.1903, -4.5212]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11963 794 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 796: ep_len:794 episode reward: total was -49.600000. running mean: -114.247198\n",
      "startIDX:  710\n",
      "796 1 True\n",
      "x_t:  3 [0.303125   0.2625     0.0875     0.34583333]\n",
      "Q values:  tensor([[-9.2649, -8.5567, -8.2936, -7.9080, -8.6536, -7.3137]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34371 1411 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 796: ep_len:1411 episode reward: total was -143.300000. running mean: -114.537726\n",
      "startIDX:  945\n",
      "796 5 True\n",
      "x_t:  3 [0.1875     0.24166667 0.096875   0.27916667]\n",
      "Q values:  tensor([[-5.3739, -5.1816, -4.7053, -4.9499, -5.2459, -4.3377]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10585 268 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 796: ep_len:268 episode reward: total was -119.900000. running mean: -114.591348\n",
      "startIDX:  874\n",
      "796 10 True\n",
      "x_t:  0 [0.58125 0.4     0.05625 0.2875 ]\n",
      "Q values:  tensor([[-5.5721, -5.2646, -5.1027, -5.3982, -4.9622, -4.5742]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8169 480 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 796: ep_len:480 episode reward: total was -80.200000. running mean: -114.247435\n",
      "startIDX:  1729\n",
      "796 12 True\n",
      "x_t:  1 [0.39375    0.32916667 0.159375   0.37083333]\n",
      "Q values:  tensor([[-4.6501, -4.7800, -4.3038, -4.7086, -4.6282, -4.1682]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19913 217 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 796: ep_len:217 episode reward: total was -74.600000. running mean: -113.850961\n",
      "startIDX:  1669\n",
      "796 15 True\n",
      "x_t:  1 [0.43125 0.325   0.08125 0.375  ]\n",
      "Q values:  tensor([[-5.1480, -4.9341, -4.8394, -4.9905, -5.1470, -4.3507]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12492 270 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 796: ep_len:270 episode reward: total was -44.400000. running mean: -113.156451\n",
      "startIDX:  899\n",
      "796 22 True\n",
      "x_t:  1 [0.1625   0.3625   0.146875 0.3875  ]\n",
      "Q values:  tensor([[-5.4549, -5.0259, -5.2494, -5.2698, -5.2815, -4.4443]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9501 255 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 796: ep_len:255 episode reward: total was -62.600000. running mean: -112.650886\n",
      "startIDX:  1208\n",
      "797 0 True\n",
      "x_t:  4 [0.153125   0.3875     0.10625    0.27916667]\n",
      "Q values:  tensor([[-10.3691,  -9.7229, -10.4223, -10.3117,  -9.8591,  -8.5059]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16308 1825 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  436\n",
      "797 1 True\n",
      "x_t:  1 [0.484375   0.29166667 0.11875    0.48333333]\n",
      "Q values:  tensor([[-7.8589, -6.8570, -7.1085, -7.5177, -7.3749, -6.1289]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30724 808 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1186\n",
      "797 5 True\n",
      "x_t:  2 [0.003125   0.39583333 0.1        0.26666667]\n",
      "Q values:  tensor([[-5.9967, -6.0787, -5.3511, -5.2973, -5.7592, -5.1964]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12005 743 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  994\n",
      "797 10 True\n",
      "x_t:  1 [0.75       0.28333333 0.10625    0.34166667]\n",
      "Q values:  tensor([[-11.3792,  -9.5655, -10.0565,  -9.8954,  -9.4408,  -8.7066]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11345 1561 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  165\n",
      "797 12 True\n",
      "x_t:  2 [0.51875    0.40833333 0.059375   0.25      ]\n",
      "Q values:  tensor([[-6.0845, -6.5916, -6.0196, -6.2698, -6.8212, -5.4915]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2854 282 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2889\n",
      "797 15 True\n",
      "x_t:  0 [0.85       0.40833333 0.1        0.36666667]\n",
      "Q values:  tensor([[-6.6238, -6.5182, -6.0347, -5.9297, -6.0018, -5.2087]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23077 522 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1332\n",
      "797 22 True\n",
      "x_t:  3 [0.1125     0.26666667 0.078125   0.28333333]\n",
      "Q values:  tensor([[-10.2770,  -9.0209,  -8.2689,  -9.0977,  -9.7418,  -7.9540]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15215 1273 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1577\n",
      "798 0 True\n",
      "x_t:  1 [0.1        0.35416667 0.090625   0.41666667]\n",
      "Q values:  tensor([[-7.1457, -7.6793, -7.3598, -7.4420, -7.6601, -6.4600]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18932 1284 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 798: ep_len:1284 episode reward: total was -268.500000. running mean: -112.798253\n",
      "startIDX:  180\n",
      "798 1 False\n",
      "x_t:  2 [0.03125    0.37083333 0.15       0.44166667]\n",
      "Q values:  tensor([[-6.6814, -5.3458, -4.8966, -5.7241, -6.0804, -5.0212]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27440 867 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 798: ep_len:867 episode reward: total was -94.700000. running mean: -112.617271\n",
      "startIDX:  2052\n",
      "798 5 True\n",
      "x_t:  3 [0.1375     0.25416667 0.1125     0.325     ]\n",
      "Q values:  tensor([[-8.3120, -7.9086, -8.6723, -7.8524, -7.9965, -6.8990]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18222 1224 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 798: ep_len:1224 episode reward: total was -128.200000. running mean: -112.773098\n",
      "startIDX:  1338\n",
      "798 10 True\n",
      "x_t:  4 [0.165625   0.35416667 0.05       0.28333333]\n",
      "Q values:  tensor([[-5.7863, -5.7758, -5.6008, -5.6823, -5.8596, -5.0728]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15727 585 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 798: ep_len:585 episode reward: total was -129.900000. running mean: -112.944367\n",
      "startIDX:  827\n",
      "798 12 True\n",
      "x_t:  0 [0.753125   0.41666667 0.08125    0.29166667]\n",
      "Q values:  tensor([[-7.0972, -6.6475, -6.4244, -6.5722, -7.3024, -6.0172]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11658 649 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 798: ep_len:649 episode reward: total was -90.000000. running mean: -112.714923\n",
      "startIDX:  3056\n",
      "ep 798: ep_len:57 episode reward: total was 45.000000. running mean: -111.137774\n",
      "startIDX:  162\n",
      "798 22 False\n",
      "x_t:  2 [0.803125   0.40416667 0.046875   0.25      ]\n",
      "Q values:  tensor([[-5.3956, -4.6175, -4.4338, -4.9802, -4.8488, -4.4468]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2283 339 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 798: ep_len:339 episode reward: total was -12.400000. running mean: -110.150396\n",
      "startIDX:  879\n",
      "799 0 True\n",
      "x_t:  0 [0.765625   0.40416667 0.096875   0.35      ]\n",
      "Q values:  tensor([[-7.0070, -6.7509, -6.5059, -6.4116, -6.3412, -5.6242]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10354 473 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  984\n",
      "799 1 True\n",
      "x_t:  3 [0.628125   0.29583333 0.103125   0.3625    ]\n",
      "Q values:  tensor([[-6.8869, -6.2956, -6.0974, -6.4854, -6.6688, -5.6660]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35936 248 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2107\n",
      "799 5 True\n",
      "x_t:  4 [0.56875 0.35    0.06875 0.2625 ]\n",
      "Q values:  tensor([[-6.6965, -6.6976, -6.8234, -6.4364, -6.7253, -5.7962]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19579 664 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2489\n",
      "799 10 False\n",
      "x_t:  1 [0.4625     0.3125     0.128125   0.32916667]\n",
      "Q values:  tensor([[-6.3448, -5.9166, -7.0660, -6.3294, -6.5671, -5.9323]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22513 1191 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  310\n",
      "799 12 True\n",
      "x_t:  4 [0.28125  0.425    0.146875 0.375   ]\n",
      "Q values:  tensor([[-6.2247, -5.9125, -5.9060, -5.7644, -5.9913, -5.2555]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7211 750 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1818\n",
      "799 15 True\n",
      "x_t:  0 [0.5875     0.40833333 0.109375   0.34583333]\n",
      "Q values:  tensor([[-6.2741, -6.3186, -6.9033, -6.5374, -5.9272, -5.5375]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13413 444 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2262\n",
      "799 22 True\n",
      "x_t:  2 [0.684375   0.40833333 0.103125   0.25416667]\n",
      "Q values:  tensor([[-7.3054, -6.6198, -7.0683, -6.7770, -7.1297, -6.3156]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23657 1444 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  8484.16886472702\n",
      "startIDX:  2243\n",
      "800 0 True\n",
      "x_t:  2 [0.340625   0.40833333 0.046875   0.25833333]\n",
      "Q values:  tensor([[-6.1311, -6.2178, -6.2851, -5.9150, -5.9077, -5.3780]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23666 361 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 800: ep_len:361 episode reward: total was -76.700000. running mean: -108.876322\n",
      "startIDX:  159\n",
      "800 1 True\n",
      "x_t:  0 [0.734375   0.375      0.146875   0.39583333]\n",
      "Q values:  tensor([[-11.1372, -10.3576, -10.3207, -10.2593,  -9.9882,  -9.2922]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29114 1723 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 800: ep_len:1723 episode reward: total was -271.000000. running mean: -110.497558\n",
      "startIDX:  2712\n",
      "800 5 True\n",
      "x_t:  0 [0.4375   0.4      0.059375 0.3125  ]\n",
      "Q values:  tensor([[-7.6195, -6.5569, -6.9817, -6.9576, -6.9765, -6.0224]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23252 804 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 800: ep_len:804 episode reward: total was -178.400000. running mean: -111.176583\n",
      "startIDX:  726\n",
      "800 10 True\n",
      "x_t:  1 [0.003125   0.3625     0.13125    0.37916667]\n",
      "Q values:  tensor([[-7.9544, -7.6355, -7.5839, -7.9171, -7.0010, -6.8210]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7106 224 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 800: ep_len:224 episode reward: total was -23.200000. running mean: -110.296817\n",
      "startIDX:  227\n",
      "800 12 True\n",
      "x_t:  3 [0.384375   0.29583333 0.10625    0.32916667]\n",
      "Q values:  tensor([[-9.0915, -8.9625, -9.4678, -8.9793, -9.4530, -8.0887]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5724 1422 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 800: ep_len:1422 episode reward: total was -200.800000. running mean: -111.201849\n",
      "startIDX:  2871\n",
      "800 15 True\n",
      "x_t:  0 [0.28125    0.425      0.075      0.27083333]\n",
      "Q values:  tensor([[-7.1449, -7.5323, -7.0961, -6.7764, -6.9448, -6.3339]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23162 559 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 800: ep_len:559 episode reward: total was -92.600000. running mean: -111.015830\n",
      "startIDX:  1961\n",
      "800 22 True\n",
      "x_t:  1 [0.39375    0.325      0.08125    0.37083333]\n",
      "Q values:  tensor([[-6.8928, -6.2705, -6.3308, -6.1624, -6.3266, -5.5003]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19031 292 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 800: ep_len:292 episode reward: total was -95.900000. running mean: -110.864672\n",
      "startIDX:  318\n",
      "801 0 True\n",
      "x_t:  3 [0.065625   0.23333333 0.0625     0.22916667]\n",
      "Q values:  tensor([[-7.6821, -7.9383, -7.6008, -7.0015, -7.7271, -6.6120]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4836 1217 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1008\n",
      "801 1 False\n",
      "x_t:  3 [0.65       0.3        0.1125     0.36666667]\n",
      "Q values:  tensor([[-8.0273, -7.1850, -7.4821, -6.3328, -7.2745, -6.5563]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35931 225 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  723\n",
      "801 5 True\n",
      "x_t:  3 [0.08125    0.2625     0.090625   0.31666667]\n",
      "Q values:  tensor([[-9.6452, -8.0736, -8.1075, -7.5104, -8.2567, -7.3851]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8754 1318 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  47\n",
      "801 10 False\n",
      "x_t:  3 [0.303125   0.2625     0.08125    0.33333333]\n",
      "Q values:  tensor([[-7.8349, -7.7564, -7.3600, -7.0630, -7.6029, -7.1363]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3646 1110 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  940\n",
      "801 12 True\n",
      "x_t:  1 [0.11875    0.39583333 0.159375   0.475     ]\n",
      "Q values:  tensor([[-6.4943, -6.7080, -6.2819, -6.5089, -6.0502, -5.3313]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12965 624 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1129\n",
      "801 15 False\n",
      "x_t:  4 [0.21875    0.37916667 0.103125   0.3       ]\n",
      "Q values:  tensor([[-7.0399, -6.4617, -6.0843, -6.2120, -5.8077, -5.8163]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9852 570 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  680\n",
      "801 22 True\n",
      "x_t:  2 [0.05       0.40416667 0.065625   0.25833333]\n",
      "Q values:  tensor([[-8.5350, -8.4247, -8.1148, -7.8315, -8.2727, -7.1187]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8923 889 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2350\n",
      "802 0 False\n",
      "x_t:  3 [0.2125     0.25416667 0.078125   0.2875    ]\n",
      "Q values:  tensor([[-9.6105, -8.7882, -9.6765, -8.6374, -9.5123, -8.6726]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26134 1239 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 802: ep_len:1239 episode reward: total was -137.300000. running mean: -110.771520\n",
      "startIDX:  782\n",
      "802 1 True\n",
      "x_t:  3 [0.29375    0.27083333 0.13125    0.35833333]\n",
      "Q values:  tensor([[-10.5533, -10.6706, -10.3324, -10.6894, -10.6841,  -9.1657]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34380 1393 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 802: ep_len:1393 episode reward: total was -168.800000. running mean: -111.351804\n",
      "startIDX:  1119\n",
      "802 5 False\n",
      "x_t:  3 [0.059375   0.22083333 0.059375   0.25416667]\n",
      "Q values:  tensor([[-18.3668, -16.4333, -17.5589, -15.6422, -17.0251, -16.1749]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10623 200 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 802: ep_len:200 episode reward: total was -6.500000. running mean: -110.303286\n",
      "startIDX:  2354\n",
      "802 10 False\n",
      "x_t:  1 [0.296875   0.32083333 0.06875    0.34583333]\n",
      "Q values:  tensor([[-7.5479, -6.9655, -7.5964, -7.3606, -7.4369, -7.0323]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22534 1250 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 802: ep_len:1250 episode reward: total was -87.500000. running mean: -110.075253\n",
      "startIDX:  92\n",
      "802 12 False\n",
      "x_t:  2 [0.365625   0.40416667 0.053125   0.25      ]\n",
      "Q values:  tensor([[-7.0084, -7.2188, -6.1098, -7.4020, -6.7947, -6.2669]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2876 935 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 802: ep_len:935 episode reward: total was -126.200000. running mean: -110.236501\n",
      "startIDX:  1863\n",
      "802 15 True\n",
      "x_t:  1 [0.715625   0.29583333 0.10625    0.30833333]\n",
      "Q values:  tensor([[-6.4551, -6.4470, -6.2021, -6.4679, -6.0767, -5.5309]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14862 742 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 802: ep_len:742 episode reward: total was 22.900000. running mean: -108.905136\n",
      "startIDX:  2946\n",
      "ep 802: ep_len:37 episode reward: total was 25.000000. running mean: -107.566085\n",
      "startIDX:  502\n",
      "803 0 True\n",
      "x_t:  3 [0.7875     0.375      0.115625   0.44166667]\n",
      "Q values:  tensor([[-5.7414, -5.8994, -5.3599, -5.9282, -5.7338, -4.9688]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 6998 1021 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  911\n",
      "803 1 False\n",
      "x_t:  4 [0.078125   0.3875     0.153125   0.41666667]\n",
      "Q values:  tensor([[-5.2150, -4.7619, -4.6010, -4.8196, -4.2628, -4.2954]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35435 505 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2379\n",
      "803 5 True\n",
      "x_t:  1 [0.703125   0.29583333 0.146875   0.5125    ]\n",
      "Q values:  tensor([[-6.2503, -5.8013, -5.6494, -5.6329, -5.6482, -4.9365]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22169 1269 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  260\n",
      "803 10 True\n",
      "x_t:  4 [0.015625   0.35833333 0.0625     0.25833333]\n",
      "Q values:  tensor([[-5.7184, -4.8943, -5.8371, -4.8506, -5.0649, -4.5580]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4546 434 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1537\n",
      "803 12 True\n",
      "x_t:  2 [0.246875 0.4125   0.084375 0.2875  ]\n",
      "Q values:  tensor([[-5.3210, -4.9167, -5.2884, -4.4124, -4.9025, -4.4011]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 19412 741 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1896\n",
      "803 15 True\n",
      "x_t:  1 [0.715625   0.29583333 0.10625    0.30833333]\n",
      "Q values:  tensor([[-5.3556, -5.6647, -5.1499, -5.2094, -5.4820, -4.5293]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14862 727 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2890\n",
      "startIDX:  2473\n",
      "ep 804: ep_len:52 episode reward: total was 34.000000. running mean: -103.375987\n",
      "startIDX:  1160\n",
      "ep 804: ep_len:24 episode reward: total was 18.000000. running mean: -102.162227\n",
      "startIDX:  607\n",
      "804 5 True\n",
      "x_t:  2 [0.046875   0.3875     0.090625   0.31666667]\n",
      "Q values:  tensor([[-4.8981, -4.9006, -4.3793, -4.5532, -4.6919, -3.9969]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6138 493 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 804: ep_len:493 episode reward: total was -170.600000. running mean: -102.846605\n",
      "startIDX:  2499\n",
      "ep 804: ep_len:1206 episode reward: total was -173.400000. running mean: -103.552139\n",
      "startIDX:  904\n",
      "804 12 True\n",
      "x_t:  2 [0.546875   0.40833333 0.09375    0.25      ]\n",
      "Q values:  tensor([[-4.8716, -5.1461, -4.9953, -4.8445, -4.9502, -4.3343]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13614 964 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 804: ep_len:964 episode reward: total was -197.400000. running mean: -104.490618\n",
      "startIDX:  775\n",
      "804 15 False\n",
      "x_t:  3 [0.140625 0.2375   0.0625   0.2375  ]\n",
      "Q values:  tensor([[-6.9789, -6.0702, -6.5481, -5.2254, -7.0636, -5.8204]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8534 1650 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 804: ep_len:1650 episode reward: total was -252.800000. running mean: -105.973711\n",
      "startIDX:  2821\n",
      "ep 804: ep_len:96 episode reward: total was 5.100000. running mean: -104.862974\n",
      "startIDX:  2201\n",
      "805 0 True\n",
      "x_t:  1 [0.325    0.35     0.240625 0.5     ]\n",
      "Q values:  tensor([[-8.1263, -7.4223, -7.3562, -6.7495, -7.1436, -6.3878]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22956 1122 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  559\n",
      "805 1 True\n",
      "x_t:  1 [0.428125   0.29583333 0.1125     0.475     ]\n",
      "Q values:  tensor([[-6.9092, -6.7632, -6.6389, -6.0922, -6.5123, -5.7646]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30728 748 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1574\n",
      "805 5 True\n",
      "x_t:  1 [0.515625   0.29583333 0.065625   0.2875    ]\n",
      "Q values:  tensor([[-7.3355, -6.9796, -6.8196, -6.8943, -6.9087, -6.0630]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14977 721 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  289\n",
      "805 10 False\n",
      "x_t:  3 [0.609375   0.3        0.103125   0.34583333]\n",
      "Q values:  tensor([[-8.0779, -7.3491, -7.3472, -6.7351, -8.4881, -7.1244]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5066 263 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  362\n",
      "805 12 True\n",
      "x_t:  4 [0.3875     0.39166667 0.084375   0.28333333]\n",
      "Q values:  tensor([[-7.3932, -7.6004, -6.8380, -7.2442, -7.4063, -6.1574]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7253 748 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2960\n",
      "startIDX:  345\n",
      "805 22 True\n",
      "x_t:  3 [0.24375    0.26666667 0.090625   0.28333333]\n",
      "Q values:  tensor([[-9.0263, -8.1594, -8.4700, -7.5904, -7.6205, -6.7926]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4926 1272 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1931\n",
      "806 0 True\n",
      "x_t:  1 [0.41875    0.32916667 0.153125   0.3875    ]\n",
      "Q values:  tensor([[-7.5106, -7.7448, -7.5676, -6.8369, -7.6257, -6.4199]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18966 263 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 806: ep_len:263 episode reward: total was -74.200000. running mean: -104.155855\n",
      "startIDX:  476\n",
      "806 1 True\n",
      "x_t:  1 [0.590625   0.28333333 0.190625   0.46666667]\n",
      "Q values:  tensor([[-8.2316, -8.0771, -7.6357, -7.5579, -8.0071, -6.9196]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30707 788 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 806: ep_len:788 episode reward: total was -54.100000. running mean: -103.655297\n",
      "startIDX:  713\n",
      "806 5 True\n",
      "x_t:  4 [0.60625    0.34583333 0.0625     0.28333333]\n",
      "Q values:  tensor([[-13.1555, -12.8110, -12.8389, -11.9866, -13.0734, -11.4587]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10125 1988 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 806: ep_len:1988 episode reward: total was -246.100000. running mean: -105.079744\n",
      "startIDX:  1507\n",
      "806 10 True\n",
      "x_t:  3 [0.734375   0.31666667 0.1375     0.3875    ]\n",
      "Q values:  tensor([[-7.5587, -6.4928, -7.0550, -6.4695, -7.1428, -6.0552]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16417 337 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 806: ep_len:337 episode reward: total was 55.000000. running mean: -103.478946\n",
      "startIDX:  1942\n",
      "ep 806: ep_len:74 episode reward: total was -49.400000. running mean: -102.938157\n",
      "startIDX:  700\n",
      "806 15 True\n",
      "x_t:  3 [0.0625     0.23333333 0.04375    0.225     ]\n",
      "Q values:  tensor([[-10.1828,  -9.8269, -10.2399,  -9.8294,  -9.5987,  -8.7252]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8492 1664 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 806: ep_len:1664 episode reward: total was -88.400000. running mean: -102.792775\n",
      "startIDX:  732\n",
      "806 22 True\n",
      "x_t:  2 [0.15       0.40416667 0.096875   0.26666667]\n",
      "Q values:  tensor([[-8.1554, -7.1137, -7.0695, -7.6029, -7.0198, -6.4601]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8941 882 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 806: ep_len:882 episode reward: total was -34.300000. running mean: -102.107847\n",
      "startIDX:  194\n",
      "807 0 True\n",
      "x_t:  2 [0.4375     0.40833333 0.11875    0.3       ]\n",
      "Q values:  tensor([[-7.2601, -7.6554, -7.3997, -7.2257, -7.5664, -6.3010]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2375 374 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  134\n",
      "807 1 True\n",
      "x_t:  2 [0.596875   0.3625     0.096875   0.44166667]\n",
      "Q values:  tensor([[-6.6253, -7.1241, -6.7492, -6.4829, -6.8909, -5.7261]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27515 941 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2081\n",
      "807 5 True\n",
      "x_t:  4 [0.015625   0.37083333 0.11875    0.27083333]\n",
      "Q values:  tensor([[-5.4126, -5.0151, -5.1868, -5.3886, -4.7306, -4.2298]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19700 745 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2389\n",
      "807 10 True\n",
      "x_t:  1 [0.33125    0.32083333 0.115625   0.34166667]\n",
      "Q values:  tensor([[-5.0121, -5.1154, -5.0022, -5.8063, -5.0867, -4.4958]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22530 1238 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  1225\n",
      "807 12 True\n",
      "x_t:  3 [0.796875   0.34583333 0.075      0.45416667]\n",
      "Q values:  tensor([[-4.9174, -4.3686, -4.7166, -4.8059, -4.4840, -3.7545]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17853 710 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3075\n",
      "startIDX:  1285\n",
      "807 22 True\n",
      "x_t:  3 [0.065625   0.26666667 0.078125   0.2625    ]\n",
      "Q values:  tensor([[-5.3557, -4.9905, -5.0135, -5.5053, -5.0744, -4.2495]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15202 1287 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  143\n",
      "808 0 True\n",
      "x_t:  1 [0.584375   0.32083333 0.146875   0.425     ]\n",
      "Q values:  tensor([[-4.4902, -4.3527, -4.4472, -4.3553, -4.1693, -3.3684]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1640 697 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 808: ep_len:697 episode reward: total was -50.600000. running mean: -99.639301\n",
      "startIDX:  1046\n",
      "808 1 True\n",
      "x_t:  3 [0.63125    0.29166667 0.10625    0.37083333]\n",
      "Q values:  tensor([[-6.2401, -6.1231, -5.4716, -6.0215, -5.5481, -4.7046]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35935 213 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 808: ep_len:213 episode reward: total was -4.500000. running mean: -98.687908\n",
      "startIDX:  205\n",
      "808 5 True\n",
      "x_t:  1 [0.746875 0.2875   0.125    0.5875  ]\n",
      "Q values:  tensor([[-4.3627, -4.2752, -4.1752, -4.2378, -4.3712, -3.3927]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2560 244 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 808: ep_len:244 episode reward: total was -18.700000. running mean: -97.888029\n",
      "startIDX:  813\n",
      "808 10 True\n",
      "x_t:  0 [0.896875   0.4        0.096875   0.32916667]\n",
      "Q values:  tensor([[-3.1214, -3.3098, -3.1478, -3.3127, -3.1639, -2.6050]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8107 497 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 808: ep_len:497 episode reward: total was -21.500000. running mean: -97.124149\n",
      "startIDX:  983\n",
      "808 12 True\n",
      "x_t:  2 [0.146875 0.4125   0.09375  0.25    ]\n",
      "Q values:  tensor([[-3.8028, -3.6244, -3.5507, -3.7143, -3.6524, -2.7798]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13672 368 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 808: ep_len:368 episode reward: total was -40.100000. running mean: -96.553907\n",
      "startIDX:  86\n",
      "808 15 True\n",
      "x_t:  3 [0.834375   0.35833333 0.15       0.425     ]\n",
      "Q values:  tensor([[-4.2322, -4.3406, -4.1553, -4.4516, -3.8776, -3.3515]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 521 209 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 808: ep_len:209 episode reward: total was -3.300000. running mean: -95.621368\n",
      "startIDX:  1609\n",
      "808 22 True\n",
      "x_t:  3 [0.6875     0.3375     0.128125   0.37916667]\n",
      "Q values:  tensor([[-4.9510, -4.6228, -4.4157, -4.6066, -4.7127, -3.6468]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16868 260 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 808: ep_len:260 episode reward: total was 45.700000. running mean: -94.208155\n",
      "startIDX:  1699\n",
      "809 0 False\n",
      "x_t:  3 [0.225      0.27083333 0.0875     0.29166667]\n",
      "Q values:  tensor([[-0.4708,  2.4690,  1.9211,  5.8522,  2.3279,  0.5492]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16915 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  452\n",
      "809 1 True\n",
      "x_t:  1 [0.84375    0.26666667 0.084375   0.45833333]\n",
      "Q values:  tensor([[-3.7350, -3.7008, -4.0099, -3.9572, -3.8183, -3.0610]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30686 786 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2932\n",
      "startIDX:  676\n",
      "809 10 True\n",
      "x_t:  1 [0.075      0.34583333 0.075      0.375     ]\n",
      "Q values:  tensor([[-2.5642, -2.7328, -2.6710, -2.7863, -2.6085, -2.0379]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7112 255 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1455\n",
      "809 12 True\n",
      "x_t:  3 [0.303125   0.28333333 0.084375   0.30833333]\n",
      "Q values:  tensor([[-3.3405, -3.7310, -3.2748, -3.5172, -3.2056, -2.4967]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17930 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  838\n",
      "809 15 True\n",
      "x_t:  3 [0.15       0.2375     0.05       0.24166667]\n",
      "Q values:  tensor([[-2.5531, -2.7359, -2.4493, -2.8956, -2.7036, -2.2147]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8539 1270 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2295\n",
      "809 22 True\n",
      "x_t:  1 [0.721875   0.31666667 0.153125   0.45      ]\n",
      "Q values:  tensor([[-2.8560, -2.6261, -2.6738, -2.7868, -2.7947, -2.1445]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22946 1073 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  8717.995463609695\n",
      "startIDX:  201\n",
      "810 0 True\n",
      "x_t:  2 [0.325      0.40833333 0.103125   0.30833333]\n",
      "Q values:  tensor([[-2.4537, -2.6593, -2.5899, -2.6760, -2.4257, -2.0020]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2394 369 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 810: ep_len:369 episode reward: total was -36.800000. running mean: -90.646135\n",
      "startIDX:  569\n",
      "810 1 True\n",
      "x_t:  1 [0.578125   0.28333333 0.09375    0.46666667]\n",
      "Q values:  tensor([[-3.1650, -2.8488, -2.8618, -2.9696, -2.8911, -2.3450]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30714 746 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 810: ep_len:746 episode reward: total was -45.500000. running mean: -90.194673\n",
      "startIDX:  2284\n",
      "810 5 True\n",
      "x_t:  2 [0.328125   0.3875     0.05       0.27916667]\n",
      "Q values:  tensor([[-2.5979, -2.5150, -2.6609, -2.6888, -2.3758, -2.0856]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21599 1033 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 810: ep_len:1033 episode reward: total was -86.600000. running mean: -90.158727\n",
      "startIDX:  1335\n",
      "810 10 True\n",
      "x_t:  4 [0.10625    0.36666667 0.1        0.25833333]\n",
      "Q values:  tensor([[-3.3559, -3.2312, -3.2838, -3.1739, -2.9345, -2.4128]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15722 563 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 810: ep_len:563 episode reward: total was 33.200000. running mean: -88.925139\n",
      "startIDX:  1274\n",
      "810 12 True\n",
      "x_t:  4 [0.303125   0.37083333 0.096875   0.225     ]\n",
      "Q values:  tensor([[-2.6806, -2.7324, -2.5712, -3.0315, -2.5440, -2.0710]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17502 508 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 810: ep_len:508 episode reward: total was -67.200000. running mean: -88.707888\n",
      "startIDX:  317\n",
      "810 15 True\n",
      "x_t:  1 [0.528125   0.325      0.128125   0.54583333]\n",
      "Q values:  tensor([[-2.7775, -2.8441, -2.3230, -2.8533, -2.6992, -2.0544]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2790 278 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 810: ep_len:278 episode reward: total was -15.600000. running mean: -87.976809\n",
      "startIDX:  257\n",
      "810 22 True\n",
      "x_t:  3 [0.221875   0.2625     0.071875   0.28333333]\n",
      "Q values:  tensor([[-2.5465, -2.3983, -2.4215, -2.2281, -2.1474, -1.8166]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4919 1323 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 810: ep_len:1323 episode reward: total was -37.700000. running mean: -87.474041\n",
      "startIDX:  2103\n",
      "811 0 True\n",
      "x_t:  1 [0.68125    0.325      0.21875    0.50833333]\n",
      "Q values:  tensor([[-2.8072, -2.8289, -2.9446, -2.7768, -2.7212, -2.2607]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22931 1147 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  333\n",
      "811 1 True\n",
      "x_t:  1 [0.74375    0.2875     0.16875    0.58333333]\n",
      "Q values:  tensor([[-2.6368, -2.4186, -2.6993, -2.6724, -2.4718, -1.9518]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28117 315 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2068\n",
      "811 5 True\n",
      "x_t:  3 [0.109375   0.25833333 0.0875     0.30416667]\n",
      "Q values:  tensor([[-2.5925, -2.7139, -2.6784, -2.6148, -2.4146, -2.0172]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18216 1209 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  402\n",
      "811 10 True\n",
      "x_t:  3 [0.278125   0.24583333 0.090625   0.29583333]\n",
      "Q values:  tensor([[-3.1049, -3.0960, -3.0751, -2.9681, -2.9651, -2.3349]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5126 229 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1390\n",
      "811 12 True\n",
      "x_t:  3 [0.14375    0.25833333 0.075      0.275     ]\n",
      "Q values:  tensor([[-3.1762, -2.8506, -2.9125, -2.6372, -2.6113, -2.2092]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17971 253 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2823\n",
      "811 15 True\n",
      "x_t:  1 [0.359375   0.35416667 0.14375    0.50833333]\n",
      "Q values:  tensor([[-2.6357, -2.5202, -2.1625, -2.6423, -2.4793, -1.9187]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22067 260 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3016\n",
      "startIDX:  308\n",
      "812 0 True\n",
      "x_t:  3 [0.153125   0.2375     0.053125   0.25833333]\n",
      "Q values:  tensor([[-2.6543, -2.7418, -3.1441, -2.9653, -2.7651, -2.2358]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4866 1262 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 812: ep_len:1262 episode reward: total was -52.800000. running mean: -83.541495\n",
      "startIDX:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "812 1 True\n",
      "x_t:  3 [0.678125   0.29583333 0.134375   0.40416667]\n",
      "Q values:  tensor([[3.4554, 5.8818, 4.5979, 6.3681, 6.4707, 3.7802]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 25656 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 812: ep_len:200 episode reward: total was 32.900000. running mean: -82.377080\n",
      "startIDX:  2068\n",
      "812 5 True\n",
      "x_t:  3 [0.2        0.27083333 0.0875     0.33333333]\n",
      "Q values:  tensor([[-3.0120, -3.1458, -3.1271, -3.2529, -3.0396, -2.4515]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18240 1218 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 812: ep_len:1218 episode reward: total was -79.700000. running mean: -82.350309\n",
      "startIDX:  2336\n",
      "812 10 True\n",
      "x_t:  1 [0.671875   0.29583333 0.134375   0.325     ]\n",
      "Q values:  tensor([[-3.3987, -3.3910, -3.1142, -3.3321, -3.2450, -2.5613]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22491 1239 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 812: ep_len:1239 episode reward: total was -151.300000. running mean: -83.039806\n",
      "startIDX:  1727\n",
      "812 12 True\n",
      "x_t:  1 [0.303125   0.34583333 0.134375   0.3625    ]\n",
      "Q values:  tensor([[-2.9756, -2.8934, -3.1024, -2.8571, -2.9487, -2.2561]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19903 215 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 812: ep_len:215 episode reward: total was -35.600000. running mean: -82.565408\n",
      "startIDX:  1041\n",
      "812 15 True\n",
      "x_t:  4 [0.003125   0.39583333 0.084375   0.29166667]\n",
      "Q values:  tensor([[-3.1771, -3.1180, -3.1504, -3.0838, -3.0931, -2.5132]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9810 600 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 812: ep_len:600 episode reward: total was 41.800000. running mean: -81.321754\n",
      "startIDX:  1104\n",
      "812 22 True\n",
      "x_t:  1 [0.10625    0.37083333 0.096875   0.49166667]\n",
      "Q values:  tensor([[-2.9346, -2.9430, -3.1442, -3.0534, -2.4898, -2.2780]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11979 759 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 812: ep_len:759 episode reward: total was -115.200000. running mean: -81.660536\n",
      "startIDX:  1586\n",
      "813 0 True\n",
      "x_t:  3 [0.53125    0.3125     0.109375   0.37083333]\n",
      "Q values:  tensor([[-3.0044, -2.8432, -3.1070, -3.2574, -2.9051, -2.3860]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16854 234 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  503\n",
      "813 1 True\n",
      "x_t:  1 [0.19375    0.32083333 0.2        0.49583333]\n",
      "Q values:  tensor([[-2.8468, -2.7667, -2.5804, -2.6646, -2.7856, -2.2072]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30748 779 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2312\n",
      "813 5 True\n",
      "x_t:  1 [0.490625   0.30416667 0.08125    0.52083333]\n",
      "Q values:  tensor([[-3.8692, -3.7079, -3.6768, -3.6932, -3.4731, -2.7115]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22145 1301 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2441\n",
      "813 10 True\n",
      "x_t:  1 [0.515625   0.3        0.071875   0.33333333]\n",
      "Q values:  tensor([[-3.8423, -3.7070, -3.7841, -4.0111, -3.6581, -2.9408]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22511 1193 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  817\n",
      "813 12 True\n",
      "x_t:  0 [0.878125 0.4125   0.05625  0.3     ]\n",
      "Q values:  tensor([[-3.5622, -3.4318, -3.6044, -3.4440, -3.1206, -2.7558]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11642 648 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  845\n",
      "813 15 True\n",
      "x_t:  3 [0.16875    0.2375     0.05625    0.24583333]\n",
      "Q values:  tensor([[-3.1196, -3.3202, -3.3763, -3.5679, -2.9423, -2.6770]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8556 1279 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1645\n",
      "813 22 True\n",
      "x_t:  3 [0.090625   0.25       0.05625    0.27083333]\n",
      "Q values:  tensor([[-3.8731, -3.7894, -3.9566, -4.0592, -3.9351, -2.9899]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16990 303 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2192\n",
      "814 0 True\n",
      "x_t:  2 [0.51875    0.40416667 0.05       0.2625    ]\n",
      "Q values:  tensor([[-4.1021, -3.8441, -4.3909, -4.2639, -3.8713, -3.2815]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23639 1477 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 814: ep_len:1477 episode reward: total was -110.100000. running mean: -81.987860\n",
      "startIDX:  804\n",
      "814 1 True\n",
      "x_t:  4 [0.275      0.375      0.09375    0.40833333]\n",
      "Q values:  tensor([[-3.6827, -3.3219, -3.3764, -3.4103, -3.5904, -2.7172]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35460 581 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 814: ep_len:581 episode reward: total was 30.700000. running mean: -80.860981\n",
      "startIDX:  628\n",
      "814 5 True\n",
      "x_t:  3 [0.278125   0.2875     0.11875    0.36666667]\n",
      "Q values:  tensor([[-5.1304, -5.0144, -5.2201, -5.2144, -5.3433, -4.0973]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8802 1391 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 814: ep_len:1391 episode reward: total was -95.400000. running mean: -81.006371\n",
      "startIDX:  606\n",
      "814 10 True\n",
      "x_t:  2 [0.521875   0.40416667 0.08125    0.24583333]\n",
      "Q values:  tensor([[-4.5961, -4.1023, -4.2135, -4.5842, -4.2445, -3.3670]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6670 762 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 814: ep_len:762 episode reward: total was -59.000000. running mean: -80.786308\n",
      "startIDX:  764\n",
      "814 12 True\n",
      "x_t:  0 [0.8875     0.40833333 0.08125    0.30833333]\n",
      "Q values:  tensor([[-4.6080, -4.3137, -4.5401, -4.6175, -4.3127, -3.5776]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11638 852 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 814: ep_len:852 episode reward: total was -76.800000. running mean: -80.746445\n",
      "startIDX:  909\n",
      "814 15 True\n",
      "x_t:  3 [0.159375   0.24166667 0.053125   0.24166667]\n",
      "Q values:  tensor([[-5.2006, -4.5128, -4.6144, -4.8694, -4.4385, -3.8240]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8548 1234 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 814: ep_len:1234 episode reward: total was -78.100000. running mean: -80.719980\n",
      "startIDX:  1435\n",
      "814 22 True\n",
      "x_t:  4 [0.475      0.37916667 0.08125    0.29583333]\n",
      "Q values:  tensor([[-4.0845, -4.3013, -4.1823, -4.5341, -4.1853, -3.3436]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16409 600 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 814: ep_len:600 episode reward: total was -23.300000. running mean: -80.145780\n",
      "startIDX:  237\n",
      "815 0 True\n",
      "x_t:  3 [0.19375    0.24166667 0.075      0.275     ]\n",
      "Q values:  tensor([[-5.1106, -4.9546, -5.0205, -4.4850, -5.0043, -3.9950]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4882 1620 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  572\n",
      "815 1 True\n",
      "x_t:  2 [0.746875   0.37916667 0.1        0.31666667]\n",
      "Q values:  tensor([[-4.1188, -3.7086, -3.7946, -4.1544, -3.7189, -3.0377]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31471 395 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3053\n",
      "startIDX:  566\n",
      "815 10 True\n",
      "x_t:  2 [0.65       0.4        0.103125   0.25833333]\n",
      "Q values:  tensor([[-5.6945, -5.1319, -5.3775, -5.3223, -4.9591, -4.2763]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6692 796 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  497\n",
      "815 12 True\n",
      "x_t:  3 [0.80625    0.3625     0.171875   0.42083333]\n",
      "Q values:  tensor([[-4.5425, -4.0731, -4.5259, -4.3410, -3.7185, -3.4230]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7714 209 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2372\n",
      "815 15 True\n",
      "x_t:  4 [0.23125    0.38333333 0.06875    0.30416667]\n",
      "Q values:  tensor([[-4.7530, -4.2971, -4.2127, -4.2655, -3.8530, -3.4045]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19288 529 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1833\n",
      "815 22 True\n",
      "x_t:  2 [0.46875    0.40833333 0.071875   0.25833333]\n",
      "Q values:  tensor([[-4.4370, -4.5297, -4.1404, -4.6328, -4.4239, -3.6287]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18524 828 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1760\n",
      "816 0 True\n",
      "x_t:  2 [0.246875   0.4        0.05625    0.25416667]\n",
      "Q values:  tensor([[-3.9026, -3.8025, -4.0070, -4.0101, -3.5538, -3.0460]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18426 775 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 816: ep_len:775 episode reward: total was -8.600000. running mean: -75.935886\n",
      "startIDX:  748\n",
      "816 1 True\n",
      "x_t:  3 [0.29375    0.26666667 0.0875     0.3375    ]\n",
      "Q values:  tensor([[-5.3514, -5.4366, -5.3586, -5.7690, -5.4492, -4.2430]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34369 1419 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 816: ep_len:1419 episode reward: total was -80.900000. running mean: -75.985527\n",
      "startIDX:  2009\n",
      "816 5 True\n",
      "x_t:  3 [0.078125   0.25416667 0.096875   0.29583333]\n",
      "Q values:  tensor([[-4.9855, -4.5349, -4.4769, -5.2658, -4.6356, -3.9780]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18209 1249 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 816: ep_len:1249 episode reward: total was -48.600000. running mean: -75.711672\n",
      "startIDX:  781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816 10 True\n",
      "x_t:  0 [0.9        0.39583333 0.09375    0.325     ]\n",
      "Q values:  tensor([[-3.8327, -3.7168, -3.7063, -4.0212, -3.5346, -3.1088]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8105 695 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 816: ep_len:695 episode reward: total was -67.900000. running mean: -75.633555\n",
      "startIDX:  619\n",
      "816 12 True\n",
      "x_t:  2 [0.1625     0.42083333 0.109375   0.24166667]\n",
      "Q values:  tensor([[-4.0961, -3.9620, -4.3157, -4.2942, -4.2214, -3.2874]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9854 1033 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 816: ep_len:1033 episode reward: total was -37.900000. running mean: -75.256220\n",
      "startIDX:  240\n",
      "816 15 True\n",
      "x_t:  2 [0.509375   0.40416667 0.11875    0.35416667]\n",
      "Q values:  tensor([[-3.4800, -3.6047, -3.7289, -3.8320, -3.6381, -2.8482]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2259 809 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 816: ep_len:809 episode reward: total was -48.100000. running mean: -74.984657\n",
      "startIDX:  1283\n",
      "816 22 True\n",
      "x_t:  3 [0.58125    0.32083333 0.078125   0.38333333]\n",
      "Q values:  tensor([[-6.4265, -5.8890, -5.8580, -6.2807, -5.8758, -4.8866]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15305 1669 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 816: ep_len:1669 episode reward: total was -199.600000. running mean: -76.230811\n",
      "startIDX:  372\n",
      "817 0 True\n",
      "x_t:  3 [0.15       0.24583333 0.053125   0.25      ]\n",
      "Q values:  tensor([[-4.2774, -3.8822, -3.9833, -3.8902, -3.6801, -3.2818]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4865 1189 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  662\n",
      "817 1 True\n",
      "x_t:  2 [0.634375   0.37916667 0.084375   0.32083333]\n",
      "Q values:  tensor([[-3.8112, -3.9872, -3.7859, -3.6414, -3.7650, -2.9900]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31492 366 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1876\n",
      "817 5 True\n",
      "x_t:  2 [0.69375    0.39583333 0.084375   0.25416667]\n",
      "Q values:  tensor([[-4.2442, -4.0942, -3.8978, -3.9307, -3.5926, -3.0633]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15668 339 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  385\n",
      "817 10 True\n",
      "x_t:  3 [0.61875 0.3     0.13125 0.3625 ]\n",
      "Q values:  tensor([[-4.0461, -3.5854, -3.9385, -3.9835, -3.7229, -3.0477]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5062 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  41\n",
      "817 12 True\n",
      "x_t:  1 [0.671875   0.31666667 0.075      0.45      ]\n",
      "Q values:  tensor([[-3.8221, -3.3838, -3.4481, -3.5630, -3.4820, -2.9083]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2235 636 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  822\n",
      "817 15 True\n",
      "x_t:  3 [0.1625     0.2375     0.053125   0.24583333]\n",
      "Q values:  tensor([[-4.4197, -4.8280, -4.7738, -4.5639, -4.5284, -3.7487]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8551 1279 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  543\n",
      "817 22 True\n",
      "x_t:  3 [0.234375   0.23333333 0.0625     0.225     ]\n",
      "Q values:  tensor([[-4.3751, -4.2244, -4.2079, -4.4824, -4.3730, -3.4154]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7236 1094 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  163\n",
      "818 0 True\n",
      "x_t:  2 [0.103125   0.40833333 0.065625   0.3       ]\n",
      "Q values:  tensor([[-3.9915, -4.0638, -3.8950, -3.9813, -3.7857, -3.0570]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2426 408 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 818: ep_len:408 episode reward: total was -42.300000. running mean: -74.277994\n",
      "startIDX:  375\n",
      "818 1 True\n",
      "x_t:  0 [0.66875    0.37916667 0.11875    0.40416667]\n",
      "Q values:  tensor([[-3.0213, -3.0319, -3.0201, -2.9936, -2.8480, -2.5145]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29126 792 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 818: ep_len:792 episode reward: total was -59.500000. running mean: -74.130214\n",
      "startIDX:  2262\n",
      "818 5 False\n",
      "x_t:  3 [0.625      0.3125     0.14375    0.42916667]\n",
      "Q values:  tensor([[4.2214, 4.3745, 3.2689, 5.7174, 2.2803, 3.8112]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 19907 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 818: ep_len:200 episode reward: total was 61.800000. running mean: -72.770912\n",
      "startIDX:  1388\n",
      "818 10 True\n",
      "x_t:  4 [0.021875   0.36666667 0.109375   0.275     ]\n",
      "Q values:  tensor([[-4.1061, -3.7425, -4.1304, -4.1053, -3.9935, -3.0462]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15709 534 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 818: ep_len:534 episode reward: total was 4.300000. running mean: -72.000203\n",
      "startIDX:  1932\n",
      "818 12 True\n",
      "x_t:  0 [0.45625    0.4125     0.09375    0.38333333]\n",
      "Q values:  tensor([[-4.0435, -3.8155, -3.8597, -3.9499, -3.5640, -3.0968]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23025 905 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 818: ep_len:905 episode reward: total was -42.100000. running mean: -71.701201\n",
      "startIDX:  444\n",
      "818 15 True\n",
      "x_t:  0 [0.2625     0.43333333 0.071875   0.27916667]\n",
      "Q values:  tensor([[-3.7290, -3.4621, -3.5742, -3.5030, -3.6356, -2.7435]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3759 479 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 818: ep_len:479 episode reward: total was -57.600000. running mean: -71.560189\n",
      "startIDX:  2566\n",
      "818 22 True\n",
      "x_t:  4 [0.45625    0.37083333 0.08125    0.32083333]\n",
      "Q values:  tensor([[-6.7010, -6.1180, -6.0803, -6.3124, -6.4079, -5.1063]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27344 1792 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 818: ep_len:1792 episode reward: total was -168.900000. running mean: -72.533587\n",
      "startIDX:  1254\n",
      "819 0 True\n",
      "x_t:  4 [0.4        0.36666667 0.0875     0.275     ]\n",
      "Q values:  tensor([[-5.7947, -5.4035, -6.2537, -5.8546, -5.7282, -4.5150]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16350 1829 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1008\n",
      "819 1 True\n",
      "x_t:  3 [0.509375   0.28333333 0.109375   0.34166667]\n",
      "Q values:  tensor([[-3.7603, -3.7204, -3.6360, -3.4961, -3.4531, -2.9371]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35955 256 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1026\n",
      "819 5 True\n",
      "x_t:  3 [0.23125    0.24166667 0.109375   0.29583333]\n",
      "Q values:  tensor([[-3.8112, -3.5099, -3.4879, -3.5846, -3.4348, -2.8821]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10574 218 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1418\n",
      "819 10 True\n",
      "x_t:  4 [0.15625    0.35       0.05       0.27916667]\n",
      "Q values:  tensor([[-4.0327, -3.5523, -3.9549, -3.9344, -3.5458, -2.9471]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15726 523 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1661\n",
      "819 12 True\n",
      "x_t:  1 [0.003125 0.375    0.071875 0.3625  ]\n",
      "Q values:  tensor([[-4.0266, -3.8802, -4.0661, -3.9333, -3.9484, -3.1535]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19868 239 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  825\n",
      "819 15 True\n",
      "x_t:  3 [0.6625     0.30416667 0.09375    0.36666667]\n",
      "Q values:  tensor([[-7.1342, -6.8515, -7.7147, -7.0725, -7.5402, -5.7904]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8747 1366 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  500\n",
      "819 22 True\n",
      "x_t:  4 [0.021875   0.42083333 0.09375    0.3625    ]\n",
      "Q values:  tensor([[-4.8170, -3.9824, -4.0229, -4.6205, -4.4192, -3.4456]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 6640 830 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  8974.788497924805\n",
      "startIDX:  1899\n",
      "820 0 True\n",
      "x_t:  0 [0.715625 0.4      0.1      0.3875  ]\n",
      "Q values:  tensor([[-6.1891, -6.2601, -6.0758, -6.0610, -6.2098, -4.9955]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20712 1142 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 820: ep_len:1142 episode reward: total was -112.100000. running mean: -71.263327\n",
      "startIDX:  572\n",
      "820 1 True\n",
      "x_t:  3 [0.29375    0.2625     0.084375   0.34166667]\n",
      "Q values:  tensor([[-10.6488,  -9.6783, -10.3515, -10.1085,  -9.5545,  -8.3824]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34368 1842 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 820: ep_len:1842 episode reward: total was -173.500000. running mean: -72.285694\n",
      "startIDX:  1412\n",
      "820 5 True\n",
      "x_t:  1 [0.284375   0.325      0.134375   0.39166667]\n",
      "Q values:  tensor([[-4.2031, -4.0376, -3.9431, -4.0719, -4.1309, -3.3786]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12534 224 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 820: ep_len:224 episode reward: total was -27.400000. running mean: -71.836837\n",
      "startIDX:  843\n",
      "820 10 True\n",
      "x_t:  0 [0.540625   0.39583333 0.065625   0.2875    ]\n",
      "Q values:  tensor([[-6.0552, -5.5119, -5.9589, -5.6037, -5.6326, -4.5756]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8203 514 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 820: ep_len:514 episode reward: total was -59.600000. running mean: -71.714469\n",
      "startIDX:  23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820 12 True\n",
      "x_t:  2 [0.00625    0.40833333 0.08125    0.25416667]\n",
      "Q values:  tensor([[-8.2445, -7.7564, -7.9290, -7.7095, -7.8533, -6.4695]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2927 980 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 820: ep_len:980 episode reward: total was -142.200000. running mean: -72.419324\n",
      "startIDX:  2954\n",
      "ep 820: ep_len:102 episode reward: total was -96.700000. running mean: -72.662131\n",
      "startIDX:  1212\n",
      "820 22 True\n",
      "x_t:  2 [0.46875    0.41666667 0.09375    0.25      ]\n",
      "Q values:  tensor([[-7.7095, -6.9117, -7.6742, -7.6175, -7.0544, -5.8134]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12641 1045 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 820: ep_len:1045 episode reward: total was -82.700000. running mean: -72.762509\n",
      "startIDX:  2231\n",
      "821 0 True\n",
      "x_t:  3 [0.20625    0.25416667 0.078125   0.275     ]\n",
      "Q values:  tensor([[-10.6953, -10.0808,  -9.7871, -10.9678, -10.3768,  -8.4866]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26133 1611 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1076\n",
      "startIDX:  121\n",
      "821 5 True\n",
      "x_t:  1 [0.709375   0.30416667 0.146875   0.5625    ]\n",
      "Q values:  tensor([[-8.4315, -8.4015, -8.4322, -8.5338, -8.1811, -6.6576]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2559 1107 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1642\n",
      "821 10 True\n",
      "x_t:  3 [0.63125    0.30416667 0.1375     0.35833333]\n",
      "Q values:  tensor([[-4.5955, -4.2356, -4.0699, -4.4951, -4.3603, -3.5300]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16432 282 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1783\n",
      "821 12 True\n",
      "x_t:  0 [0.534375 0.4125   0.1125   0.3375  ]\n",
      "Q values:  tensor([[-9.2398, -8.5102, -9.1003, -8.5184, -7.9717, -7.0874]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23044 1547 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  280\n",
      "821 15 True\n",
      "x_t:  1 [0.675      0.31666667 0.109375   0.52083333]\n",
      "Q values:  tensor([[-4.5728, -4.1790, -4.2902, -4.7645, -4.6174, -3.6611]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2803 301 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1182\n",
      "821 22 True\n",
      "x_t:  1 [0.446875   0.34166667 0.146875   0.49583333]\n",
      "Q values:  tensor([[-5.0178, -5.0858, -4.8591, -5.2652, -5.1932, -4.1259]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11952 705 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1277\n",
      "822 0 True\n",
      "x_t:  3 [0.121875   0.24583333 0.059375   0.28333333]\n",
      "Q values:  tensor([[-8.1482, -7.6218, -7.3700, -8.5008, -7.5523, -6.0947]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15175 1222 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 822: ep_len:1222 episode reward: total was -48.400000. running mean: -71.476274\n",
      "startIDX:  733\n",
      "822 1 True\n",
      "x_t:  3 [0.296875   0.25833333 0.0875     0.34583333]\n",
      "Q values:  tensor([[-8.0061, -7.1921, -7.5439, -7.4237, -7.3790, -5.8537]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34370 1427 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 822: ep_len:1427 episode reward: total was -63.800000. running mean: -71.399511\n",
      "startIDX:  2518\n",
      "822 5 True\n",
      "x_t:  2 [0.346875 0.3875   0.065625 0.2875  ]\n",
      "Q values:  tensor([[-4.5216, -3.9252, -3.9934, -4.1870, -3.8789, -3.2578]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21601 822 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 822: ep_len:822 episode reward: total was -36.700000. running mean: -71.052516\n",
      "startIDX:  426\n",
      "822 10 False\n",
      "x_t:  3 [0.31875    0.2625     0.1        0.30833333]\n",
      "Q values:  tensor([[3.2827, 3.8457, 2.5842, 4.8131, 4.4510, 2.7302]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 5112 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 822: ep_len:201 episode reward: total was 7.800000. running mean: -70.263991\n",
      "startIDX:  464\n",
      "822 12 True\n",
      "x_t:  3 [0.103125   0.25833333 0.0875     0.26666667]\n",
      "Q values:  tensor([[-3.3009, -3.3435, -2.8948, -3.1426, -2.9181, -2.5322]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7829 286 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 822: ep_len:286 episode reward: total was -53.000000. running mean: -70.091351\n",
      "startIDX:  443\n",
      "822 15 True\n",
      "x_t:  0 [0.6        0.41666667 0.159375   0.4875    ]\n",
      "Q values:  tensor([[-3.8587, -3.6363, -3.6820, -3.6452, -4.0894, -3.0835]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3851 524 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 822: ep_len:524 episode reward: total was -103.700000. running mean: -70.427438\n",
      "startIDX:  1157\n",
      "822 22 True\n",
      "x_t:  2 [0.78125    0.40833333 0.09375    0.2625    ]\n",
      "Q values:  tensor([[-5.7395, -5.3326, -4.9946, -5.2779, -5.4506, -4.2465]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12589 1023 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 822: ep_len:1023 episode reward: total was -111.300000. running mean: -70.836163\n",
      "startIDX:  1126\n",
      "823 0 True\n",
      "x_t:  4 [0.14375    0.38333333 0.0875     0.2875    ]\n",
      "Q values:  tensor([[-7.8268, -6.7766, -7.7277, -7.7733, -7.4725, -5.4794]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16306 2169 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  280\n",
      "823 1 True\n",
      "x_t:  2 [0.15625    0.3625     0.121875   0.45833333]\n",
      "Q values:  tensor([[-2.9983, -3.0921, -2.5735, -2.7883, -3.0189, -2.3992]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27456 817 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  562\n",
      "823 5 True\n",
      "x_t:  3 [0.2125     0.27083333 0.103125   0.35416667]\n",
      "Q values:  tensor([[-6.4435, -5.7609, -5.8229, -6.1992, -5.3245, -4.7397]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8787 1833 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  72\n",
      "823 10 True\n",
      "x_t:  3 [0.59375    0.3        0.075      0.35833333]\n",
      "Q values:  tensor([[-5.3647, -4.7245, -5.3885, -4.8920, -5.1285, -4.0070]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3683 1120 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1988\n",
      "startIDX:  2231\n",
      "823 15 True\n",
      "x_t:  3 [0.3        0.30416667 0.1125     0.34166667]\n",
      "Q values:  tensor([[-4.8284, -4.3182, -4.6577, -4.2559, -4.1142, -3.2170]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18221 1315 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1221\n",
      "823 22 True\n",
      "x_t:  3 [0.065625   0.25833333 0.065625   0.25833333]\n",
      "Q values:  tensor([[-5.8156, -5.7358, -5.5955, -5.5152, -5.3034, -4.1804]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15197 1638 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  484\n",
      "824 0 True\n",
      "x_t:  3 [0.325      0.30833333 0.1        0.3625    ]\n",
      "Q values:  tensor([[-4.1995, -4.0579, -3.7354, -3.8840, -3.9311, -3.2265]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7063 1060 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 824: ep_len:1060 episode reward: total was -52.200000. running mean: -72.293121\n",
      "startIDX:  178\n",
      "824 1 True\n",
      "x_t:  2 [0.678125   0.37083333 0.121875   0.44583333]\n",
      "Q values:  tensor([[-4.1726, -4.1669, -3.8663, -4.4932, -4.1070, -3.2531]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27529 907 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 824: ep_len:907 episode reward: total was -96.400000. running mean: -72.534190\n",
      "startIDX:  2632\n",
      "824 5 True\n",
      "x_t:  1 [0.925      0.2625     0.06875    0.53333333]\n",
      "Q values:  tensor([[-3.2426, -3.2906, -3.1132, -2.9213, -2.9764, -2.4447]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22186 297 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 824: ep_len:297 episode reward: total was -30.600000. running mean: -72.114848\n",
      "startIDX:  1281\n",
      "824 10 True\n",
      "x_t:  3 [0.14375    0.22916667 0.06875    0.27083333]\n",
      "Q values:  tensor([[-3.9516, -3.6942, -3.5856, -3.9135, -3.7417, -2.7881]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14600 1217 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 824: ep_len:1217 episode reward: total was -59.800000. running mean: -71.991699\n",
      "startIDX:  1765\n",
      "824 12 True\n",
      "x_t:  0 [0.2625     0.42083333 0.0875     0.28333333]\n",
      "Q values:  tensor([[-3.4592, -3.5432, -3.0054, -3.2754, -3.3104, -2.6094]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21174 648 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 824: ep_len:648 episode reward: total was -30.700000. running mean: -71.578782\n",
      "startIDX:  1811\n",
      "824 15 True\n",
      "x_t:  1 [0.8875     0.29583333 0.078125   0.3125    ]\n",
      "Q values:  tensor([[-4.2185, -4.0116, -4.0710, -3.9883, -4.0875, -3.0494]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14843 1141 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 824: ep_len:1141 episode reward: total was -117.800000. running mean: -72.040994\n",
      "startIDX:  2888\n",
      "ep 824: ep_len:64 episode reward: total was 20.000000. running mean: -71.120585\n",
      "startIDX:  1579\n",
      "825 0 True\n",
      "x_t:  2 [0.61875    0.4        0.103125   0.24166667]\n",
      "Q values:  tensor([[-4.4182, -3.7869, -4.0678, -3.8238, -4.2942, -3.2570]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18490 1058 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  474\n",
      "825 1 True\n",
      "x_t:  2 [0.69375    0.37916667 0.078125   0.32083333]\n",
      "Q values:  tensor([[-4.8129, -4.1555, -4.3224, -4.3344, -4.2605, -3.3515]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31483 1156 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  3055\n",
      "startIDX:  1586\n",
      "825 10 True\n",
      "x_t:  3 [0.46875    0.28333333 0.090625   0.31666667]\n",
      "Q values:  tensor([[-3.7751, -3.5552, -3.9724, -3.9694, -3.9591, -2.9486]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16461 323 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  507\n",
      "825 12 True\n",
      "x_t:  3 [0.425      0.30416667 0.1125     0.32916667]\n",
      "Q values:  tensor([[-4.3502, -4.0631, -4.0284, -4.3259, -4.2006, -3.1988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7768 236 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1267\n",
      "825 15 True\n",
      "x_t:  3 [0.321875   0.27083333 0.0875     0.29166667]\n",
      "Q values:  tensor([[-4.0348, -3.5208, -4.1365, -3.9706, -3.7472, -2.9447]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10437 293 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2540\n",
      "825 22 True\n",
      "x_t:  4 [0.371875   0.38333333 0.078125   0.30416667]\n",
      "Q values:  tensor([[-7.6801, -7.3209, -7.3127, -7.6350, -7.2075, -6.1178]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27323 1799 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  495\n",
      "826 0 True\n",
      "x_t:  3 [0.571875   0.35833333 0.1625     0.44583333]\n",
      "Q values:  tensor([[-4.5465, -4.1911, -4.2127, -4.6346, -4.5540, -3.6178]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7019 1035 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 826: ep_len:1035 episode reward: total was -52.500000. running mean: -70.918989\n",
      "startIDX:  560\n",
      "826 1 True\n",
      "x_t:  2 [0.290625 0.375    0.084375 0.3     ]\n",
      "Q values:  tensor([[-8.3646, -8.1211, -7.9891, -8.0442, -8.4012, -6.3280]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31546 1149 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 826: ep_len:1149 episode reward: total was -125.100000. running mean: -71.460799\n",
      "startIDX:  754\n",
      "826 5 True\n",
      "x_t:  4 [0.5875     0.35       0.071875   0.30416667]\n",
      "Q values:  tensor([[-5.1579, -5.0195, -5.1972, -4.8073, -5.1096, -4.0144]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10107 679 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 826: ep_len:679 episode reward: total was -88.500000. running mean: -71.631191\n",
      "startIDX:  255\n",
      "826 10 True\n",
      "x_t:  4 [0.41875    0.34166667 0.0625     0.23333333]\n",
      "Q values:  tensor([[-5.4170, -5.0539, -5.2456, -5.3880, -5.4183, -4.1628]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4697 501 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 826: ep_len:501 episode reward: total was -100.200000. running mean: -71.916879\n",
      "startIDX:  960\n",
      "826 12 True\n",
      "x_t:  1 [0.015625 0.3875   0.165625 0.4875  ]\n",
      "Q values:  tensor([[-5.1308, -5.0405, -4.9008, -5.0309, -4.9217, -4.1077]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12976 610 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 826: ep_len:610 episode reward: total was -45.900000. running mean: -71.656710\n",
      "startIDX:  304\n",
      "826 15 True\n",
      "x_t:  1 [0.565625   0.3375     0.159375   0.53333333]\n",
      "Q values:  tensor([[-4.3321, -4.3838, -4.1069, -4.0701, -4.2395, -3.3120]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2796 305 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 826: ep_len:305 episode reward: total was -6.000000. running mean: -71.000143\n",
      "startIDX:  2130\n",
      "826 22 True\n",
      "x_t:  0 [0.75625  0.4      0.109375 0.35    ]\n",
      "Q values:  tensor([[-5.2866, -5.1028, -5.1757, -5.0732, -4.9604, -4.1393]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20834 912 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 826: ep_len:912 episode reward: total was -69.200000. running mean: -70.982142\n",
      "startIDX:  901\n",
      "827 0 True\n",
      "x_t:  0 [0.88125    0.4        0.1125     0.37083333]\n",
      "Q values:  tensor([[-5.0369, -4.7531, -4.3498, -4.8572, -4.6242, -3.7220]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10331 449 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  973\n",
      "827 1 True\n",
      "x_t:  3 [0.46875    0.27916667 0.071875   0.33333333]\n",
      "Q values:  tensor([[-5.5454, -5.2711, -5.7265, -5.2598, -5.4993, -4.3922]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35969 265 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2693\n",
      "827 5 True\n",
      "x_t:  1 [0.45       0.30833333 0.11875    0.50833333]\n",
      "Q values:  tensor([[-4.5222, -4.2369, -4.0703, -4.3615, -4.1688, -3.5523]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22144 249 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  632\n",
      "827 10 True\n",
      "x_t:  2 [0.75       0.40416667 0.1        0.25416667]\n",
      "Q values:  tensor([[-6.9627, -6.6219, -6.4223, -6.2422, -6.4418, -5.0490]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6709 767 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1904\n",
      "startIDX:  1648\n",
      "827 15 True\n",
      "x_t:  1 [0.371875   0.33333333 0.115625   0.3625    ]\n",
      "Q values:  tensor([[-4.3334, -4.3079, -4.4388, -4.3248, -4.0942, -3.4583]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12485 284 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  877\n",
      "827 22 True\n",
      "x_t:  1 [0.765625   0.30833333 0.175      0.40833333]\n",
      "Q values:  tensor([[-5.1212, -5.0307, -5.0214, -4.9926, -4.6421, -3.9770]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9564 289 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1802\n",
      "828 0 True\n",
      "x_t:  2 [0.003125   0.40833333 0.103125   0.25      ]\n",
      "Q values:  tensor([[-8.2239, -7.4314, -7.9299, -7.8359, -7.6285, -6.4838]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18392 748 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 828: ep_len:748 episode reward: total was -20.600000. running mean: -68.021450\n",
      "startIDX:  959\n",
      "828 1 True\n",
      "x_t:  4 [0.2125     0.3875     0.121875   0.39583333]\n",
      "Q values:  tensor([[-7.4514, -6.7225, -7.4550, -7.1696, -6.7355, -6.0159]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35453 487 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 828: ep_len:487 episode reward: total was -22.900000. running mean: -67.570236\n",
      "startIDX:  581\n",
      "828 5 True\n",
      "x_t:  2 [0.75       0.39583333 0.046875   0.29166667]\n",
      "Q values:  tensor([[-6.0647, -5.7248, -5.9154, -5.5079, -6.1398, -5.0927]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6050 470 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 828: ep_len:470 episode reward: total was -24.800000. running mean: -67.142534\n",
      "startIDX:  90\n",
      "828 10 True\n",
      "x_t:  3 [0.10625    0.24166667 0.06875    0.275     ]\n",
      "Q values:  tensor([[-9.0459, -7.9205, -8.5621, -8.4095, -7.9803, -6.9315]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3596 1081 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 828: ep_len:1081 episode reward: total was -30.800000. running mean: -66.779108\n",
      "startIDX:  785\n",
      "828 12 True\n",
      "x_t:  1 [0.546875   0.3375     0.1125     0.52916667]\n",
      "Q values:  tensor([[-5.5143, -5.6484, -5.2437, -4.9753, -4.9428, -4.2338]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10338 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 828: ep_len:201 episode reward: total was -23.200000. running mean: -66.343317\n",
      "startIDX:  3134\n",
      "ep 828: ep_len:15 episode reward: total was -13.900000. running mean: -65.818884\n",
      "startIDX:  192\n",
      "828 22 True\n",
      "x_t:  2 [0.2        0.40833333 0.05625    0.25      ]\n",
      "Q values:  tensor([[-6.7140, -5.7671, -5.8440, -6.1182, -6.7323, -5.3824]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2385 384 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 828: ep_len:384 episode reward: total was -61.300000. running mean: -65.773695\n",
      "startIDX:  2231\n",
      "829 0 True\n",
      "x_t:  2 [0.70625    0.40833333 0.0875     0.25      ]\n",
      "Q values:  tensor([[-6.2482, -5.9637, -6.3771, -5.9702, -6.3753, -5.0768]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23606 341 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  17\n",
      "829 1 False\n",
      "x_t:  3 [0.565625   0.275      0.125      0.38333333]\n",
      "Q values:  tensor([[-1.0711,  1.9701,  0.3701,  2.0962,  0.6868, -0.2656]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25674 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2353\n",
      "829 5 False\n",
      "x_t:  3 [0.084375   0.24583333 0.128125   0.29166667]\n",
      "Q values:  tensor([[0.0926, 2.0339, 1.2873, 2.7773, 2.0528, 0.5025]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 20002 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1163\n",
      "829 10 True\n",
      "x_t:  2 [0.74375    0.39583333 0.06875    0.25      ]\n",
      "Q values:  tensor([[-5.0831, -5.1396, -5.2883, -5.2548, -5.3683, -4.1831]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12072 309 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1617\n",
      "829 12 True\n",
      "x_t:  1 [0.096875   0.35833333 0.0875     0.36666667]\n",
      "Q values:  tensor([[-9.7475, -8.6289, -9.0019, -9.1876, -9.1537, -7.4300]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19880 942 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  173\n",
      "829 15 True\n",
      "x_t:  2 [0.26875    0.39166667 0.0625     0.34583333]\n",
      "Q values:  tensor([[-6.7364, -6.3596, -6.9591, -6.4012, -6.3641, -5.3504]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2226 833 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1352\n",
      "829 22 True\n",
      "x_t:  3 [0.71875  0.35     0.146875 0.4125  ]\n",
      "Q values:  tensor([[-10.1496,  -9.9432,  -8.7653, -10.5355, -10.1814,  -7.9224]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15325 1345 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed:  9224.199455738068\n",
      "startIDX:  413\n",
      "830 0 True\n",
      "x_t:  3 [0.646875   0.37083333 0.159375   0.44583333]\n",
      "Q values:  tensor([[-9.4754, -9.1300, -9.4775, -9.5302, -8.6953, -7.3715]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7010 1076 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 830: ep_len:1076 episode reward: total was -44.200000. running mean: -63.425332\n",
      "startIDX:  1171\n",
      "ep 830: ep_len:19 episode reward: total was 11.000000. running mean: -62.681079\n",
      "startIDX:  1435\n",
      "830 5 True\n",
      "x_t:  1 [0.384375   0.30416667 0.06875    0.39583333]\n",
      "Q values:  tensor([[-4.7793, -4.3550, -4.5111, -4.0341, -4.1881, -3.7398]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12543 212 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 830: ep_len:212 episode reward: total was -39.500000. running mean: -62.449268\n",
      "startIDX:  2061\n",
      "830 10 True\n",
      "x_t:  1 [0.6        0.29166667 0.103125   0.33333333]\n",
      "Q values:  tensor([[-4.5045, -4.2817, -4.0005, -4.0767, -4.5395, -3.3062]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18897 317 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 830: ep_len:317 episode reward: total was -45.200000. running mean: -62.276775\n",
      "startIDX:  561\n",
      "830 12 True\n",
      "x_t:  2 [0.571875   0.40833333 0.053125   0.25416667]\n",
      "Q values:  tensor([[-6.1463, -5.1584, -5.5207, -5.4998, -5.8354, -4.4123]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9912 1095 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 830: ep_len:1095 episode reward: total was -28.000000. running mean: -61.934008\n",
      "startIDX:  1874\n",
      "830 15 True\n",
      "x_t:  1 [0.94375  0.2875   0.053125 0.325   ]\n",
      "Q values:  tensor([[-5.9262, -5.0209, -4.9758, -5.1962, -5.2345, -4.0851]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14836 726 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 830: ep_len:726 episode reward: total was -97.800000. running mean: -62.292667\n",
      "startIDX:  2917\n",
      "ep 830: ep_len:50 episode reward: total was 32.000000. running mean: -61.349741\n",
      "startIDX:  154\n",
      "831 0 True\n",
      "x_t:  2 [0.79375    0.40416667 0.075      0.28333333]\n",
      "Q values:  tensor([[-5.6227, -5.8987, -5.5574, -5.7291, -5.6817, -4.4907]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2325 1035 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  853\n",
      "831 1 True\n",
      "x_t:  4 [0.21875    0.375      0.1125     0.37083333]\n",
      "Q values:  tensor([[-6.3806, -6.1729, -6.0578, -6.0863, -5.8836, -4.6434]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35527 588 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  741\n",
      "831 5 True\n",
      "x_t:  4 [0.003125   0.41666667 0.13125    0.37083333]\n",
      "Q values:  tensor([[-9.7433, -8.5160, -8.6568, -9.7598, -8.9450, -6.9563]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10012 1951 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1644\n",
      "831 10 True\n",
      "x_t:  2 [0.15625    0.4        0.06875    0.24583333]\n",
      "Q values:  tensor([[-5.4423, -5.3910, -5.1506, -5.3589, -5.1490, -4.1682]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18172 1159 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  429\n",
      "831 12 True\n",
      "x_t:  3 [0.4125     0.29583333 0.103125   0.3375    ]\n",
      "Q values:  tensor([[-3.1271, -3.1527, -3.4087, -3.4894, -3.3626, -2.4702]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7770 276 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2997\n",
      "startIDX:  1270\n",
      "831 22 True\n",
      "x_t:  2 [0.775      0.40833333 0.075      0.25833333]\n",
      "Q values:  tensor([[-3.7511, -3.9697, -3.5300, -3.9055, -3.8532, -2.8662]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12594 313 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  614\n",
      "832 0 True\n",
      "x_t:  2 [0.015625   0.40833333 0.08125    0.275     ]\n",
      "Q values:  tensor([[-5.5007, -5.4219, -5.7483, -5.2761, -5.4522, -4.2287]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8871 894 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 832: ep_len:894 episode reward: total was 3.700000. running mean: -61.153851\n",
      "startIDX:  340\n",
      "832 1 True\n",
      "x_t:  0 [0.86875    0.37916667 0.10625    0.4       ]\n",
      "Q values:  tensor([[-4.6801, -4.1784, -4.3129, -4.3259, -4.3630, -3.3900]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29093 816 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 832: ep_len:816 episode reward: total was -37.300000. running mean: -60.915312\n",
      "startIDX:  1056\n",
      "832 5 True\n",
      "x_t:  3 [0.196875   0.24166667 0.096875   0.2875    ]\n",
      "Q values:  tensor([[-3.1171, -3.3214, -3.2044, -3.2999, -2.9948, -2.4762]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10582 220 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 832: ep_len:220 episode reward: total was -9.200000. running mean: -60.398159\n",
      "startIDX:  1252\n",
      "832 10 True\n",
      "x_t:  4 [0.00625    0.37083333 0.121875   0.26666667]\n",
      "Q values:  tensor([[-6.4785, -5.9072, -5.4794, -6.2363, -5.2367, -4.5138]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15706 1789 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 832: ep_len:1789 episode reward: total was -122.200000. running mean: -61.016178\n",
      "startIDX:  748\n",
      "832 12 True\n",
      "x_t:  1 [0.234375   0.38333333 0.203125   0.49166667]\n",
      "Q values:  tensor([[-4.3803, -4.4125, -4.2250, -3.6632, -4.1519, -3.0673]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10322 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 832: ep_len:204 episode reward: total was -3.000000. running mean: -60.436016\n",
      "startIDX:  1257\n",
      "832 15 True\n",
      "x_t:  3 [0.4125     0.27916667 0.06875    0.3       ]\n",
      "Q values:  tensor([[-3.9024, -3.5685, -3.7992, -3.8490, -3.3931, -2.8385]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10420 292 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 832: ep_len:292 episode reward: total was 3.400000. running mean: -59.797656\n",
      "startIDX:  1836\n",
      "832 22 True\n",
      "x_t:  2 [0.3375     0.4        0.059375   0.27083333]\n",
      "Q values:  tensor([[-4.1758, -3.9757, -3.5241, -4.0221, -3.7468, -2.7983]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18503 822 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 832: ep_len:822 episode reward: total was -23.300000. running mean: -59.432679\n",
      "startIDX:  1836\n",
      "833 0 True\n",
      "x_t:  2 [0.753125   0.40416667 0.046875   0.2375    ]\n",
      "Q values:  tensor([[-3.7418, -3.6924, -3.5184, -3.5500, -3.5708, -2.6777]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18509 785 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  674\n",
      "833 1 True\n",
      "x_t:  3 [0.084375   0.23333333 0.08125    0.29166667]\n",
      "Q values:  tensor([[-4.9934, -4.8486, -5.0541, -4.6097, -4.8897, -3.4389]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34309 1418 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  477\n",
      "833 5 True\n",
      "x_t:  2 [0.453125   0.3875     0.0625     0.31666667]\n",
      "Q values:  tensor([[-3.9215, -3.7867, -3.9664, -3.7995, -3.8669, -3.0493]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6088 1178 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1132\n",
      "833 10 True\n",
      "x_t:  2 [0.253125   0.39583333 0.08125    0.25      ]\n",
      "Q values:  tensor([[-3.4571, -3.6277, -3.3937, -3.3571, -3.3664, -2.6267]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12149 364 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  560\n",
      "833 12 True\n",
      "x_t:  2 [0.003125   0.41666667 0.096875   0.24583333]\n",
      "Q values:  tensor([[-4.1930, -4.1876, -3.9891, -3.9454, -4.0387, -3.2114]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9827 1045 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  3045\n",
      "startIDX:  1207\n",
      "833 22 True\n",
      "x_t:  1 [0.45625    0.34583333 0.165625   0.49166667]\n",
      "Q values:  tensor([[-5.0241, -4.6409, -4.0650, -4.3869, -4.6695, -3.4336]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11951 698 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1521\n",
      "834 0 True\n",
      "x_t:  3 [0.878125   0.34166667 0.115625   0.43333333]\n",
      "Q values:  tensor([[-3.6658, -3.6524, -3.6184, -3.5089, -3.3249, -2.6266]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16811 233 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 834: ep_len:233 episode reward: total was 45.700000. running mean: -57.898337\n",
      "startIDX:  230\n",
      "834 1 True\n",
      "x_t:  2 [0.628125   0.35833333 0.0875     0.45416667]\n",
      "Q values:  tensor([[-4.4649, -4.4693, -4.4514, -4.7644, -4.5214, -3.3494]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27518 891 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 834: ep_len:891 episode reward: total was -60.100000. running mean: -57.920353\n",
      "startIDX:  412\n",
      "834 5 True\n",
      "x_t:  1 [0.825      0.27916667 0.084375   0.38333333]\n",
      "Q values:  tensor([[-4.1676, -4.2421, -4.0166, -4.0103, -3.7746, -2.9285]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5035 677 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 834: ep_len:677 episode reward: total was -63.600000. running mean: -57.977150\n",
      "startIDX:  1277\n",
      "834 10 True\n",
      "x_t:  3 [0.728125 0.3      0.075    0.3875  ]\n",
      "Q values:  tensor([[-4.2894, -4.6092, -4.1917, -4.4271, -4.3550, -3.1738]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14716 1294 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 834: ep_len:1294 episode reward: total was -92.700000. running mean: -58.324378\n",
      "startIDX:  403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "834 12 True\n",
      "x_t:  3 [0.846875   0.3625     0.13125    0.42083333]\n",
      "Q values:  tensor([[-3.4901, -3.1196, -3.0669, -2.8959, -3.1581, -2.4035]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7712 256 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 834: ep_len:256 episode reward: total was 30.300000. running mean: -57.438135\n",
      "startIDX:  1312\n",
      "834 15 True\n",
      "x_t:  3 [0.390625   0.275      0.0875     0.30833333]\n",
      "Q values:  tensor([[-4.2947, -4.0879, -4.0603, -4.2512, -4.0725, -3.0533]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10422 251 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 834: ep_len:251 episode reward: total was -16.200000. running mean: -57.025753\n",
      "startIDX:  2161\n",
      "834 22 True\n",
      "x_t:  0 [0.646875   0.40416667 0.071875   0.33333333]\n",
      "Q values:  tensor([[-4.6632, -4.6722, -4.6528, -4.3906, -4.6504, -3.6304]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20787 874 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 834: ep_len:874 episode reward: total was -45.700000. running mean: -56.912496\n",
      "startIDX:  728\n",
      "835 0 True\n",
      "x_t:  0 [0.634375   0.40833333 0.078125   0.35      ]\n",
      "Q values:  tensor([[-4.2607, -3.9079, -3.6277, -3.8829, -3.8274, -2.8955]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10396 761 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  712\n",
      "835 1 True\n",
      "x_t:  3 [0.203125   0.24583333 0.0875     0.32083333]\n",
      "Q values:  tensor([[-6.0904, -5.7824, -5.7190, -6.4607, -6.0401, -4.4500]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34347 1411 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1353\n",
      "835 5 True\n",
      "x_t:  1 [0.384375   0.30416667 0.06875    0.39583333]\n",
      "Q values:  tensor([[-3.0664, -2.8579, -2.8409, -2.7176, -2.7617, -2.1672]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12543 246 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1986\n",
      "835 10 True\n",
      "x_t:  1 [0.390625   0.30833333 0.10625    0.35      ]\n",
      "Q values:  tensor([[-3.4385, -3.5740, -3.3033, -3.4687, -3.0584, -2.5428]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18863 325 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1142\n",
      "835 12 True\n",
      "x_t:  3 [0.134375   0.27916667 0.1        0.30833333]\n",
      "Q values:  tensor([[-6.1307, -6.1173, -5.4588, -5.7635, -5.6530, -4.2757]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16391 1367 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2260\n",
      "835 15 True\n",
      "x_t:  3 [0.26875    0.3        0.078125   0.32916667]\n",
      "Q values:  tensor([[-5.4557, -5.2493, -5.1801, -5.0704, -5.2087, -3.7991]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18215 1265 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2076\n",
      "835 22 True\n",
      "x_t:  1 [0.665625   0.30416667 0.128125   0.375     ]\n",
      "Q values:  tensor([[-3.5569, -3.5962, -3.3680, -3.6635, -3.5712, -2.6573]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19066 244 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  944\n",
      "836 0 True\n",
      "x_t:  0 [0.640625   0.4125     0.0875     0.37916667]\n",
      "Q values:  tensor([[-3.7038, -3.8216, -3.5445, -3.6447, -3.6371, -2.7791]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10407 460 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 836: ep_len:460 episode reward: total was -63.300000. running mean: -55.753167\n",
      "startIDX:  441\n",
      "836 1 True\n",
      "x_t:  1 [0.353125   0.3        0.1875     0.49166667]\n",
      "Q values:  tensor([[-4.3379, -4.6191, -4.1280, -4.4252, -4.2945, -3.1819]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30731 808 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 836: ep_len:808 episode reward: total was -103.200000. running mean: -56.227635\n",
      "startIDX:  874\n",
      "836 5 True\n",
      "x_t:  4 [0.33125    0.39166667 0.140625   0.36666667]\n",
      "Q values:  tensor([[-4.2353, -3.8360, -3.5960, -4.0244, -4.1945, -2.9436]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10058 612 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 836: ep_len:612 episode reward: total was -47.300000. running mean: -56.138359\n",
      "startIDX:  435\n",
      "836 10 True\n",
      "x_t:  3 [0.0625     0.225      0.059375   0.24166667]\n",
      "Q values:  tensor([[-4.1431, -3.8727, -4.0138, -4.0733, -3.8806, -3.1772]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5191 244 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 836: ep_len:244 episode reward: total was -63.700000. running mean: -56.213975\n",
      "startIDX:  1855\n",
      "836 12 True\n",
      "x_t:  0 [0.284375   0.42083333 0.090625   0.27083333]\n",
      "Q values:  tensor([[-3.9581, -3.7909, -3.7891, -3.9683, -4.1273, -3.1152]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23000 946 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 836: ep_len:946 episode reward: total was -91.500000. running mean: -56.566835\n",
      "startIDX:  999\n",
      "836 15 True\n",
      "x_t:  4 [0.340625   0.35416667 0.071875   0.225     ]\n",
      "Q values:  tensor([[-4.7689, -4.7968, -4.8263, -4.3634, -4.5206, -3.3867]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9946 697 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 836: ep_len:697 episode reward: total was -43.600000. running mean: -56.437167\n",
      "startIDX:  1915\n",
      "836 22 True\n",
      "x_t:  0 [0.646875   0.4        0.065625   0.34166667]\n",
      "Q values:  tensor([[-8.7950, -8.5446, -8.4986, -9.3187, -8.4723, -6.7593]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20792 1908 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 836: ep_len:1908 episode reward: total was -228.300000. running mean: -58.155795\n",
      "startIDX:  1394\n",
      "837 0 True\n",
      "x_t:  4 [0.196875   0.375      0.08125    0.29583333]\n",
      "Q values:  tensor([[-4.2824, -4.1699, -4.4895, -4.0872, -4.2225, -3.2809]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16316 543 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  516\n",
      "837 1 True\n",
      "x_t:  2 [0.621875   0.37916667 0.071875   0.31666667]\n",
      "Q values:  tensor([[-4.9128, -4.5017, -4.5016, -4.3110, -4.7996, -3.4937]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31494 1164 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1507\n",
      "837 5 True\n",
      "x_t:  0 [0.38125    0.40833333 0.059375   0.30416667]\n",
      "Q values:  tensor([[-4.6473, -4.6735, -4.0376, -4.0045, -4.2887, -3.4552]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13618 507 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1203\n",
      "837 10 True\n",
      "x_t:  3 [0.3375   0.2625   0.090625 0.3     ]\n",
      "Q values:  tensor([[-6.7053, -6.4705, -5.7275, -5.7981, -6.1422, -4.8460]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14654 1283 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1477\n",
      "837 12 False\n",
      "x_t:  3 [0.2375   0.275    0.053125 0.275   ]\n",
      "Q values:  tensor([[-5.7169, -4.9308, -5.4508, -4.1286, -5.7427, -4.2609]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17949 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1627\n",
      "837 15 True\n",
      "x_t:  0 [0.590625   0.41666667 0.11875    0.33333333]\n",
      "Q values:  tensor([[-5.9792, -5.3158, -4.9721, -5.3304, -5.4554, -4.0891]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13410 745 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1217\n",
      "837 22 True\n",
      "x_t:  2 [0.209375   0.40833333 0.040625   0.27916667]\n",
      "Q values:  tensor([[-4.8804, -4.5579, -4.3817, -4.8278, -4.9117, -3.6776]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12686 383 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  906\n",
      "838 0 True\n",
      "x_t:  0 [0.765625   0.40833333 0.125      0.34583333]\n",
      "Q values:  tensor([[-4.8008, -4.8574, -4.7250, -4.7701, -4.6843, -3.6999]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10348 437 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 838: ep_len:437 episode reward: total was -6.500000. running mean: -57.214820\n",
      "startIDX:  403\n",
      "838 1 True\n",
      "x_t:  0 [0.86875    0.37916667 0.10625    0.4       ]\n",
      "Q values:  tensor([[-5.0112, -4.5894, -4.3436, -4.6975, -4.8592, -4.0539]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29093 502 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 838: ep_len:502 episode reward: total was -23.100000. running mean: -56.873672\n",
      "startIDX:  2717\n",
      "838 5 True\n",
      "x_t:  1 [0.825      0.29166667 0.16875    0.50833333]\n",
      "Q values:  tensor([[-5.1572, -5.1442, -4.8639, -4.4619, -4.6974, -3.9928]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22182 254 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 838: ep_len:254 episode reward: total was -57.600000. running mean: -56.880935\n",
      "startIDX:  141\n",
      "838 10 True\n",
      "x_t:  4 [0.046875   0.35416667 0.090625   0.25833333]\n",
      "Q values:  tensor([[-5.0728, -5.0402, -4.2681, -5.0245, -4.7889, -3.7967]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4551 494 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 838: ep_len:494 episode reward: total was 29.300000. running mean: -56.019126\n",
      "startIDX:  2063\n",
      "ep 838: ep_len:3 episode reward: total was -1.900000. running mean: -55.477935\n",
      "startIDX:  1307\n",
      "838 15 True\n",
      "x_t:  3 [0.490625   0.29166667 0.103125   0.325     ]\n",
      "Q values:  tensor([[-5.1851, -5.1471, -4.7718, -4.5312, -4.9151, -3.8071]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10402 261 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 838: ep_len:261 episode reward: total was 6.500000. running mean: -54.858156\n",
      "startIDX:  1243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "838 22 True\n",
      "x_t:  2 [0.7375     0.40416667 0.065625   0.25833333]\n",
      "Q values:  tensor([[-4.2549, -4.7863, -4.3963, -4.6214, -4.7963, -3.7658]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12600 318 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 838: ep_len:318 episode reward: total was -13.600000. running mean: -54.445574\n",
      "startIDX:  861\n",
      "839 0 True\n",
      "x_t:  0 [0.728125 0.4      0.115625 0.4125  ]\n",
      "Q values:  tensor([[-6.3001, -5.9445, -5.8883, -5.7526, -5.7220, -4.9539]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10431 505 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  615\n",
      "839 1 True\n",
      "x_t:  2 [0.725      0.37916667 0.096875   0.31666667]\n",
      "Q values:  tensor([[-4.7820, -4.6934, -4.5918, -4.6074, -4.1539, -3.7353]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31477 371 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1388\n",
      "839 5 True\n",
      "x_t:  1 [0.16875    0.3375     0.14375    0.38333333]\n",
      "Q values:  tensor([[-4.3456, -4.8248, -4.1056, -4.5039, -4.8601, -3.6743]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12523 215 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1825\n",
      "839 10 True\n",
      "x_t:  2 [0.20625    0.40416667 0.096875   0.24583333]\n",
      "Q values:  tensor([[-6.7038, -6.6717, -6.8303, -7.3728, -6.8068, -5.6171]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18183 849 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  902\n",
      "839 12 True\n",
      "x_t:  1 [0.33125    0.4        0.15625    0.46666667]\n",
      "Q values:  tensor([[-6.3604, -6.1493, -6.2495, -6.5341, -5.3907, -4.8911]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12940 632 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1031\n",
      "839 15 True\n",
      "x_t:  4 [0.134375   0.38333333 0.06875    0.30416667]\n",
      "Q values:  tensor([[-5.9432, -6.2109, -5.3894, -6.2714, -5.5078, -4.8611]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9835 606 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1791\n",
      "839 22 True\n",
      "x_t:  3 [0.1875     0.26666667 0.06875    0.27916667]\n",
      "Q values:  tensor([[-6.6446, -6.2767, -5.9587, -6.3469, -6.1749, -4.8490]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16964 219 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  9444.729364156723\n",
      "startIDX:  2572\n",
      "ep 840: ep_len:7 episode reward: total was 3.000000. running mean: -51.757268\n",
      "startIDX:  655\n",
      "840 1 True\n",
      "x_t:  3 [0.0625     0.23333333 0.059375   0.275     ]\n",
      "Q values:  tensor([[-10.4083,  -9.5316,  -8.8331,  -9.5057,  -9.6848,  -7.5545]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34301 1743 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 840: ep_len:1743 episode reward: total was -143.300000. running mean: -52.672695\n",
      "startIDX:  652\n",
      "840 5 True\n",
      "x_t:  3 [0.76875    0.36666667 0.153125   0.4375    ]\n",
      "Q values:  tensor([[-8.1348, -6.7824, -6.7761, -6.4147, -6.9020, -5.8403]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8887 1430 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 840: ep_len:1430 episode reward: total was -81.400000. running mean: -52.959968\n",
      "startIDX:  1137\n",
      "840 10 True\n",
      "x_t:  2 [0.784375   0.40416667 0.0875     0.23333333]\n",
      "Q values:  tensor([[-5.8378, -5.7757, -5.2424, -5.8273, -6.2094, -5.0046]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12065 328 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 840: ep_len:328 episode reward: total was -7.800000. running mean: -52.508369\n",
      "startIDX:  1797\n",
      "840 12 True\n",
      "x_t:  0 [0.840625   0.40833333 0.103125   0.35833333]\n",
      "Q values:  tensor([[-5.4042, -5.4631, -4.9949, -5.0082, -5.2904, -4.0406]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21098 586 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 840: ep_len:586 episode reward: total was -10.800000. running mean: -52.091285\n",
      "startIDX:  2821\n",
      "840 15 True\n",
      "x_t:  1 [0.78125    0.30416667 0.134375   0.475     ]\n",
      "Q values:  tensor([[-5.1561, -5.2652, -5.2110, -5.5186, -5.0724, -4.4302]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22105 282 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 840: ep_len:282 episode reward: total was -37.900000. running mean: -51.949372\n",
      "startIDX:  2174\n",
      "840 22 True\n",
      "x_t:  0 [0.9        0.39583333 0.084375   0.3375    ]\n",
      "Q values:  tensor([[-5.4351, -5.2987, -5.1173, -5.6363, -5.3088, -4.4191]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20691 807 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 840: ep_len:807 episode reward: total was -28.300000. running mean: -51.712878\n",
      "startIDX:  1083\n",
      "841 0 True\n",
      "x_t:  1 [0.190625   0.35833333 0.1125     0.4875    ]\n",
      "Q values:  tensor([[-5.6811, -5.8867, -5.5205, -6.1194, -6.1911, -4.6345]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12013 786 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  575\n",
      "841 1 True\n",
      "x_t:  2 [0.553125   0.38333333 0.125      0.31666667]\n",
      "Q values:  tensor([[-3.8042, -4.0234, -3.6070, -3.7411, -3.6565, -3.0096]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31500 412 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1441\n",
      "841 5 True\n",
      "x_t:  0 [0.278125   0.40833333 0.059375   0.275     ]\n",
      "Q values:  tensor([[-4.6530, -4.4648, -4.5904, -4.8354, -4.4052, -3.6893]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13643 561 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  496\n",
      "841 10 True\n",
      "x_t:  2 [0.4125     0.40416667 0.103125   0.25      ]\n",
      "Q values:  tensor([[-4.9963, -4.7878, -4.9612, -4.7933, -4.8365, -3.9370]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6652 937 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1727\n",
      "841 12 True\n",
      "x_t:  1 [0.03125    0.37083333 0.125      0.3625    ]\n",
      "Q values:  tensor([[-3.7528, -3.7271, -3.4987, -3.4563, -3.5218, -2.7035]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19873 207 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1357\n",
      "841 15 True\n",
      "x_t:  3 [0.11875 0.2375  0.06875 0.2625 ]\n",
      "Q values:  tensor([[-4.1503, -3.7073, -3.8080, -3.6456, -3.7443, -3.1325]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10490 271 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  194\n",
      "841 22 True\n",
      "x_t:  2 [0.66875    0.40833333 0.096875   0.24583333]\n",
      "Q values:  tensor([[-3.6962, -3.7217, -3.6482, -3.6262, -3.2992, -2.9080]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2302 343 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1048\n",
      "842 0 True\n",
      "x_t:  2 [0.125  0.4    0.075  0.3125]\n",
      "Q values:  tensor([[-6.5370, -6.1006, -6.2199, -5.7026, -5.6793, -4.7205]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12739 1159 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 842: ep_len:1159 episode reward: total was -143.900000. running mean: -52.612035\n",
      "startIDX:  405\n",
      "842 1 True\n",
      "x_t:  0 [0.934375   0.37083333 0.059375   0.40416667]\n",
      "Q values:  tensor([[-4.0972, -4.0816, -4.0459, -3.8859, -3.9555, -3.2699]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29087 496 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 842: ep_len:496 episode reward: total was -16.900000. running mean: -52.254915\n",
      "startIDX:  1872\n",
      "842 5 True\n",
      "x_t:  3 [0.45       0.32916667 0.11875    0.40833333]\n",
      "Q values:  tensor([[-5.8860, -5.5006, -5.5655, -5.7024, -5.1269, -4.5122]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18292 1669 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 842: ep_len:1669 episode reward: total was -173.600000. running mean: -53.468365\n",
      "startIDX:  1937\n",
      "842 10 True\n",
      "x_t:  1 [0.659375   0.2875     0.0625     0.33333333]\n",
      "Q values:  tensor([[-4.4581, -4.2765, -4.1007, -4.0909, -4.1191, -3.3740]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18902 384 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 842: ep_len:384 episode reward: total was -1.700000. running mean: -52.950682\n",
      "startIDX:  824\n",
      "842 12 True\n",
      "x_t:  0 [0.603125   0.41666667 0.078125   0.34583333]\n",
      "Q values:  tensor([[-4.4589, -3.9665, -4.1158, -4.1522, -3.6430, -3.3579]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11699 679 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 842: ep_len:679 episode reward: total was -61.200000. running mean: -53.033175\n",
      "startIDX:  898\n",
      "842 15 True\n",
      "x_t:  3 [0.159375   0.24166667 0.053125   0.24166667]\n",
      "Q values:  tensor([[-5.2284, -5.2834, -5.0887, -5.1585, -5.1333, -4.0494]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8548 1240 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 842: ep_len:1240 episode reward: total was -70.800000. running mean: -53.210843\n",
      "startIDX:  170\n",
      "842 22 True\n",
      "x_t:  2 [0.609375   0.40833333 0.0875     0.25      ]\n",
      "Q values:  tensor([[-4.0607, -4.2565, -4.3460, -3.9909, -3.9694, -3.3052]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2313 361 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 842: ep_len:361 episode reward: total was -11.800000. running mean: -52.796735\n",
      "startIDX:  1458\n",
      "843 0 True\n",
      "x_t:  4 [0.003125 0.4      0.09375  0.275   ]\n",
      "Q values:  tensor([[-4.0913, -3.6940, -4.0657, -3.8518, -4.0442, -3.2224]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16284 497 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "843 1 True\n",
      "x_t:  3 [0.159375   0.24583333 0.075      0.30416667]\n",
      "Q values:  tensor([[-7.3702, -7.5954, -6.9361, -7.2342, -7.3011, -5.8243]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34333 1836 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  536\n",
      "843 5 True\n",
      "x_t:  2 [0.6625     0.39166667 0.065625   0.3       ]\n",
      "Q values:  tensor([[-4.4975, -4.7291, -4.4332, -4.7666, -4.1909, -3.5760]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6061 502 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2624\n",
      "startIDX:  80\n",
      "843 12 True\n",
      "x_t:  2 [0.190625   0.40416667 0.0625     0.25      ]\n",
      "Q values:  tensor([[-5.1290, -5.3890, -4.9983, -5.4597, -6.0685, -4.3575]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2901 954 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  916\n",
      "843 15 True\n",
      "x_t:  4 [0.1125     0.3875     0.06875    0.29166667]\n",
      "Q values:  tensor([[-5.0222, -5.1332, -4.9453, -4.9154, -4.9418, -3.9447]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9831 664 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  113\n",
      "843 22 True\n",
      "x_t:  1 [0.325   0.3375  0.08125 0.4    ]\n",
      "Q values:  tensor([[-4.8492, -4.9607, -4.4937, -5.1522, -5.1571, -3.9410]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1636 690 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  614\n",
      "844 0 True\n",
      "x_t:  1 [0.865625   0.3        0.13125    0.42916667]\n",
      "Q values:  tensor([[-5.2332, -5.5286, -5.4003, -5.4432, -5.2510, -4.1886]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9503 1235 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 844: ep_len:1235 episode reward: total was -140.600000. running mean: -53.465959\n",
      "startIDX:  1205\n",
      "ep 844: ep_len:2 episode reward: total was 0.000000. running mean: -52.931299\n",
      "startIDX:  1992\n",
      "844 5 True\n",
      "x_t:  3 [0.26875    0.28333333 0.096875   0.36666667]\n",
      "Q values:  tensor([[-5.5484, -5.8238, -5.4363, -6.2159, -6.0752, -4.8156]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18256 1276 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 844: ep_len:1276 episode reward: total was -78.600000. running mean: -53.187986\n",
      "startIDX:  1808\n",
      "844 10 True\n",
      "x_t:  2 [0.19375    0.39583333 0.065625   0.25833333]\n",
      "Q values:  tensor([[-5.0489, -4.8038, -4.8740, -4.7883, -5.1863, -4.0979]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18177 885 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 844: ep_len:885 episode reward: total was -26.100000. running mean: -52.917106\n",
      "startIDX:  330\n",
      "844 12 True\n",
      "x_t:  4 [0.40625    0.38333333 0.078125   0.3125    ]\n",
      "Q values:  tensor([[-4.4544, -4.2247, -3.9060, -3.9951, -4.0334, -3.4032]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7249 771 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 844: ep_len:771 episode reward: total was -73.200000. running mean: -53.119935\n",
      "startIDX:  2507\n",
      "844 15 False\n",
      "x_t:  3 [0.571875 0.3      0.1      0.35    ]\n",
      "Q values:  tensor([[3.7453, 4.8438, 3.8757, 5.2940, 3.7509, 3.1689]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 19702 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 844: ep_len:200 episode reward: total was 5.300000. running mean: -52.535736\n",
      "startIDX:  2650\n",
      "844 22 True\n",
      "x_t:  4 [0.2375  0.3875  0.06875 0.3125 ]\n",
      "Q values:  tensor([[-4.4194, -4.5516, -4.4944, -4.5276, -4.7853, -3.8783]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27297 563 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 844: ep_len:563 episode reward: total was -46.600000. running mean: -52.476379\n",
      "startIDX:  1445\n",
      "845 0 True\n",
      "x_t:  4 [0.003125 0.4      0.09375  0.275   ]\n",
      "Q values:  tensor([[-4.9005, -4.7053, -4.4501, -4.8625, -4.3800, -3.9156]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16284 492 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  705\n",
      "845 1 True\n",
      "x_t:  3 [0.1        0.23333333 0.075      0.3       ]\n",
      "Q values:  tensor([[-6.3265, -6.0760, -5.9884, -6.2145, -5.9911, -5.2325]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34315 1381 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  152\n",
      "845 5 True\n",
      "x_t:  2 [0.240625   0.3875     0.134375   0.42083333]\n",
      "Q values:  tensor([[-4.3151, -3.9598, -3.9395, -3.8415, -3.9964, -3.2423]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2077 888 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1043\n",
      "845 10 True\n",
      "x_t:  1 [0.64375    0.2875     0.06875    0.34583333]\n",
      "Q values:  tensor([[-9.5766, -9.4234, -8.9699, -9.0038, -9.6757, -7.4025]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11361 1554 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1101\n",
      "845 12 True\n",
      "x_t:  3 [0.0625     0.26666667 0.065625   0.23333333]\n",
      "Q values:  tensor([[-5.4959, -6.0575, -6.6050, -6.2026, -5.4934, -5.0382]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16371 1377 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  706\n",
      "845 15 True\n",
      "x_t:  2 [0.76875    0.4        0.071875   0.30416667]\n",
      "Q values:  tensor([[-4.5473, -4.6424, -4.8462, -4.4393, -4.5577, -3.8323]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5974 387 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1363\n",
      "845 22 True\n",
      "x_t:  4 [0.375      0.37916667 0.10625    0.29583333]\n",
      "Q values:  tensor([[-8.9581, -8.8773, -7.8288, -8.7855, -8.3008, -6.6990]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16391 1892 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  151\n",
      "846 0 True\n",
      "x_t:  1 [0.690625   0.30833333 0.078125   0.41666667]\n",
      "Q values:  tensor([[-4.6142, -4.8323, -4.9254, -5.1272, -4.6081, -4.0511]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1631 685 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 846: ep_len:685 episode reward: total was -57.100000. running mean: -52.281958\n",
      "startIDX:  410\n",
      "846 1 True\n",
      "x_t:  0 [0.85625    0.375      0.09375    0.40416667]\n",
      "Q values:  tensor([[-3.6501, -3.5201, -3.4142, -3.5937, -3.4315, -2.7550]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29102 491 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 846: ep_len:491 episode reward: total was -18.300000. running mean: -51.942138\n",
      "startIDX:  2245\n",
      "846 5 True\n",
      "x_t:  3 [0.53125    0.29583333 0.109375   0.4       ]\n",
      "Q values:  tensor([[-4.6140, -4.7474, -4.3118, -4.3516, -4.6063, -3.5535]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19922 211 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 846: ep_len:211 episode reward: total was 47.300000. running mean: -50.949717\n",
      "startIDX:  921\n",
      "846 10 True\n",
      "x_t:  1 [0.8625     0.28333333 0.128125   0.3375    ]\n",
      "Q values:  tensor([[-5.3763, -4.9963, -4.8282, -4.7344, -5.3736, -4.0441]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11328 1594 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 846: ep_len:1594 episode reward: total was -117.500000. running mean: -51.615220\n",
      "startIDX:  1086\n",
      "846 12 True\n",
      "x_t:  3 [0.190625   0.28333333 0.09375    0.31666667]\n",
      "Q values:  tensor([[-5.3210, -5.4353, -5.1979, -5.5918, -5.3430, -4.5326]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16403 1388 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 846: ep_len:1388 episode reward: total was -28.400000. running mean: -51.383067\n",
      "startIDX:  2232\n",
      "846 15 True\n",
      "x_t:  3 [0.371875   0.3125     0.075      0.35416667]\n",
      "Q values:  tensor([[-4.9400, -4.3817, -4.6218, -4.7846, -4.7373, -3.6927]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18230 1344 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 846: ep_len:1344 episode reward: total was -59.800000. running mean: -51.467237\n",
      "startIDX:  2811\n",
      "ep 846: ep_len:109 episode reward: total was 77.000000. running mean: -50.182564\n",
      "startIDX:  633\n",
      "847 0 True\n",
      "x_t:  2 [0.290625   0.4        0.046875   0.27083333]\n",
      "Q values:  tensor([[-3.8927, -4.1814, -3.5296, -3.6551, -3.8799, -3.0870]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8909 911 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  561\n",
      "847 1 True\n",
      "x_t:  1 [0.46875    0.29166667 0.109375   0.475     ]\n",
      "Q values:  tensor([[-3.4361, -3.7314, -3.2917, -3.4689, -3.2758, -2.7123]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30725 755 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  133\n",
      "847 5 True\n",
      "x_t:  2 [0.521875   0.3875     0.134375   0.43333333]\n",
      "Q values:  tensor([[-4.2230, -4.0814, -3.8963, -4.1470, -3.8031, -3.1816]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2101 888 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1139\n",
      "847 10 True\n",
      "x_t:  2 [0.76875    0.39583333 0.046875   0.25      ]\n",
      "Q values:  tensor([[-3.5078, -3.3882, -3.1978, -3.2236, -3.2642, -2.7236]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12070 332 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  977\n",
      "847 12 True\n",
      "x_t:  2 [0.621875   0.40416667 0.04375    0.25416667]\n",
      "Q values:  tensor([[-3.7588, -4.0477, -3.8444, -3.7293, -3.7481, -2.9956]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13606 344 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1005\n",
      "847 15 True\n",
      "x_t:  4 [0.3875     0.37083333 0.05625    0.28333333]\n",
      "Q values:  tensor([[-3.4378, -3.4905, -3.4079, -3.4469, -3.4757, -2.6303]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9883 662 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  1055\n",
      "847 22 True\n",
      "x_t:  3 [0.4        0.30416667 0.0875     0.3375    ]\n",
      "Q values:  tensor([[-5.8784, -6.3725, -5.9434, -6.2640, -6.7204, -4.6786]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15277 2427 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1700\n",
      "848 0 True\n",
      "x_t:  3 [0.1125     0.24583333 0.0625     0.27083333]\n",
      "Q values:  tensor([[-2.3712, -2.3089, -2.3208, -2.1936, -2.3349, -1.8426]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16943 204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 848: ep_len:204 episode reward: total was -48.200000. running mean: -52.705286\n",
      "startIDX:  120\n",
      "848 1 True\n",
      "x_t:  2 [0.54375    0.37083333 0.140625   0.4375    ]\n",
      "Q values:  tensor([[-3.1641, -3.3254, -2.8898, -3.1880, -3.2237, -2.4692]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27509 942 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 848: ep_len:942 episode reward: total was -93.500000. running mean: -53.113233\n",
      "startIDX:  2939\n",
      "ep 848: ep_len:62 episode reward: total was -56.000000. running mean: -53.142101\n",
      "startIDX:  2396\n",
      "848 10 True\n",
      "x_t:  1 [0.825      0.28333333 0.096875   0.3375    ]\n",
      "Q values:  tensor([[-4.0978, -4.0403, -3.8947, -3.4455, -3.9354, -2.9517]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22475 1192 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 848: ep_len:1192 episode reward: total was -114.400000. running mean: -53.754680\n",
      "startIDX:  1330\n",
      "848 12 True\n",
      "x_t:  3 [0.81875    0.37083333 0.171875   0.43333333]\n",
      "Q values:  tensor([[-3.1417, -2.9003, -2.6837, -2.7663, -2.7891, -2.1771]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17844 215 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 848: ep_len:215 episode reward: total was 47.400000. running mean: -52.743133\n",
      "startIDX:  901\n",
      "848 15 True\n",
      "x_t:  4 [0.434375   0.3625     0.065625   0.26666667]\n",
      "Q values:  tensor([[-5.0360, -5.0244, -4.8012, -4.5355, -4.9044, -4.0065]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9907 1916 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 848: ep_len:1916 episode reward: total was -268.300000. running mean: -54.898702\n",
      "startIDX:  1880\n",
      "848 22 True\n",
      "x_t:  2 [0.74375    0.40833333 0.1        0.25      ]\n",
      "Q values:  tensor([[-3.1789, -3.0299, -2.7768, -2.9226, -3.1106, -2.3040]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18570 834 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 848: ep_len:834 episode reward: total was -62.000000. running mean: -54.969715\n",
      "startIDX:  972\n",
      "849 0 True\n",
      "x_t:  2 [0.771875   0.40833333 0.084375   0.2875    ]\n",
      "Q values:  tensor([[-4.0817, -4.0459, -3.7518, -4.0863, -4.2086, -3.2596]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12636 1143 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  300\n",
      "849 1 True\n",
      "x_t:  0 [0.759375   0.375      0.115625   0.39166667]\n",
      "Q values:  tensor([[-3.6780, -3.4451, -3.1108, -3.8849, -3.2646, -2.7589]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29110 825 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  798\n",
      "849 5 True\n",
      "x_t:  4 [0.396875   0.37083333 0.084375   0.375     ]\n",
      "Q values:  tensor([[-3.1994, -3.4567, -3.5363, -3.8190, -3.6961, -2.8178]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10066 637 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  333\n",
      "849 10 True\n",
      "x_t:  3 [0.703125   0.3        0.134375   0.37916667]\n",
      "Q values:  tensor([[-3.5852, -3.4092, -3.3561, -3.4801, -3.4913, -2.7046]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5052 225 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  963\n",
      "849 12 True\n",
      "x_t:  4 [0.01875    0.42916667 0.10625    0.37083333]\n",
      "Q values:  tensor([[-10.1846, -10.2111, -10.3209,  -9.4285, -10.4135,  -8.2058]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17391 2819 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2100\n",
      "849 15 True\n",
      "x_t:  2 [0.084375   0.40416667 0.059375   0.275     ]\n",
      "Q values:  tensor([[-3.2780, -3.2719, -3.4626, -3.3383, -3.3777, -2.7879]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15675 395 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  601\n",
      "849 22 True\n",
      "x_t:  3 [0.44375    0.27916667 0.059375   0.29166667]\n",
      "Q values:  tensor([[-2.8179, -3.1302, -2.7751, -3.1501, -2.7780, -2.1881]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7141 233 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  9712.694855928421\n",
      "startIDX:  1611\n",
      "850 0 True\n",
      "x_t:  3 [0.340625   0.27916667 0.06875    0.31666667]\n",
      "Q values:  tensor([[-4.4470, -4.2489, -4.5091, -3.9274, -3.8529, -3.2892]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16890 233 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 850: ep_len:233 episode reward: total was -11.700000. running mean: -56.008714\n",
      "startIDX:  854\n",
      "850 1 True\n",
      "x_t:  4 [0.3375     0.36666667 0.115625   0.39166667]\n",
      "Q values:  tensor([[-4.3700, -4.5654, -4.1973, -4.3841, -3.9059, -3.4101]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35499 571 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 850: ep_len:571 episode reward: total was -111.100000. running mean: -56.559627\n",
      "startIDX:  2793\n",
      "850 5 True\n",
      "x_t:  0 [0.284375   0.40416667 0.071875   0.2875    ]\n",
      "Q values:  tensor([[-4.6613, -4.8366, -4.4548, -4.5962, -4.6934, -3.8329]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23279 557 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 850: ep_len:557 episode reward: total was -88.600000. running mean: -56.880031\n",
      "startIDX:  2224\n",
      "850 10 True\n",
      "x_t:  0 [0.871875   0.38333333 0.075      0.3625    ]\n",
      "Q values:  tensor([[-4.1492, -4.2290, -3.8401, -3.9750, -4.4056, -3.3423]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19940 508 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 850: ep_len:508 episode reward: total was -16.400000. running mean: -56.475230\n",
      "startIDX:  818\n",
      "850 12 True\n",
      "x_t:  0 [0.6125     0.41666667 0.08125    0.30416667]\n",
      "Q values:  tensor([[-4.2502, -4.5996, -4.4834, -4.4447, -4.3686, -3.5987]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11683 661 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 850: ep_len:661 episode reward: total was -40.600000. running mean: -56.316478\n",
      "startIDX:  756\n",
      "850 15 True\n",
      "x_t:  2 [0.684375   0.40833333 0.059375   0.29166667]\n",
      "Q values:  tensor([[-4.8194, -5.2176, -4.8794, -5.0892, -4.8258, -3.7644]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5988 363 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 850: ep_len:363 episode reward: total was -15.100000. running mean: -55.904313\n",
      "startIDX:  2856\n",
      "ep 850: ep_len:82 episode reward: total was 60.000000. running mean: -54.745270\n",
      "startIDX:  2024\n",
      "851 0 True\n",
      "x_t:  0 [0.840625   0.39583333 0.059375   0.35416667]\n",
      "Q values:  tensor([[-3.9351, -3.6206, -3.6840, -3.7271, -3.5917, -2.9871]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20640 849 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  400\n",
      "851 1 True\n",
      "x_t:  1 [0.003125   0.32916667 0.11875    0.54166667]\n",
      "Q values:  tensor([[-5.5704, -5.8090, -5.8557, -5.7604, -5.7373, -4.4717]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30768 1337 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1098\n",
      "851 5 False\n",
      "x_t:  3 [0.0875     0.23333333 0.0875     0.26666667]\n",
      "Q values:  tensor([[-3.3177, -3.4833, -2.8400, -2.8161, -3.6699, -3.2399]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10608 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2440\n",
      "851 10 True\n",
      "x_t:  1 [0.453125 0.3125   0.134375 0.325   ]\n",
      "Q values:  tensor([[-5.0166, -5.3306, -5.3893, -5.5688, -5.0517, -4.4041]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22514 1202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1826\n",
      "startIDX:  2169\n",
      "851 15 True\n",
      "x_t:  2 [0.65       0.40833333 0.0625     0.25833333]\n",
      "Q values:  tensor([[-3.6330, -3.6233, -4.1011, -3.7364, -3.7828, -3.1063]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15590 330 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  992\n",
      "851 22 True\n",
      "x_t:  0 [0.575      0.40833333 0.071875   0.34166667]\n",
      "Q values:  tensor([[-4.5900, -4.9056, -4.5895, -5.1434, -4.5470, -3.9014]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10493 503 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1969\n",
      "852 0 True\n",
      "x_t:  0 [0.84375    0.4        0.09375    0.35833333]\n",
      "Q values:  tensor([[-4.5346, -4.6644, -4.6943, -4.8186, -4.7853, -3.9037]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20637 1079 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 852: ep_len:1079 episode reward: total was -79.700000. running mean: -56.724045\n",
      "startIDX:  1115\n",
      "ep 852: ep_len:202 episode reward: total was -44.000000. running mean: -56.596805\n",
      "startIDX:  659\n",
      "852 5 True\n",
      "x_t:  3 [0.075      0.2625     0.090625   0.31666667]\n",
      "Q values:  tensor([[-5.9695, -5.8707, -5.4602, -6.0854, -5.6487, -4.7638]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8753 1346 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 852: ep_len:1346 episode reward: total was -29.900000. running mean: -56.329837\n",
      "startIDX:  58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "852 10 True\n",
      "x_t:  3 [0.275      0.26666667 0.08125    0.32083333]\n",
      "Q values:  tensor([[-5.2270, -5.3411, -5.3886, -5.3570, -5.2980, -4.5009]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3642 1108 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 852: ep_len:1108 episode reward: total was -57.700000. running mean: -56.343538\n",
      "startIDX:  1793\n",
      "852 12 False\n",
      "x_t:  0 [0.39375    0.41666667 0.125      0.37083333]\n",
      "Q values:  tensor([[-4.0836, -5.0056, -5.4936, -4.5912, -4.8836, -4.0872]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 23018 1548 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 852: ep_len:1548 episode reward: total was -91.000000. running mean: -56.690103\n",
      "startIDX:  1731\n",
      "852 15 True\n",
      "x_t:  1 [0.5875     0.32083333 0.13125    0.35833333]\n",
      "Q values:  tensor([[-4.1557, -4.1628, -4.1319, -4.0975, -3.9190, -3.3272]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12511 244 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 852: ep_len:244 episode reward: total was -43.200000. running mean: -56.555202\n",
      "startIDX:  2673\n",
      "852 22 True\n",
      "x_t:  4 [0.128125   0.39583333 0.1        0.30833333]\n",
      "Q values:  tensor([[-4.6047, -5.0001, -4.7932, -4.4118, -4.4973, -3.9168]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 27283 536 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 852: ep_len:536 episode reward: total was -19.600000. running mean: -56.185650\n",
      "startIDX:  1599\n",
      "853 0 True\n",
      "x_t:  3 [0.603125   0.33333333 0.1375     0.37916667]\n",
      "Q values:  tensor([[-4.8087, -4.9032, -4.8167, -4.7333, -4.6703, -3.8689]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16840 213 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  10\n",
      "853 1 True\n",
      "x_t:  3 [0.40625  0.2625   0.096875 0.3375  ]\n",
      "Q values:  tensor([[-4.1988, -4.0575, -3.7830, -4.2332, -4.1631, -3.2998]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25704 214 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  301\n",
      "853 5 True\n",
      "x_t:  0 [0.828125   0.375      0.165625   0.52083333]\n",
      "Q values:  tensor([[-4.9467, -5.2576, -5.1569, -4.7629, -5.1149, -4.1263]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3746 598 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1226\n",
      "853 10 True\n",
      "x_t:  3 [0.15       0.24166667 0.075      0.25833333]\n",
      "Q values:  tensor([[-4.8447, -4.1651, -4.5900, -4.4698, -4.4670, -3.6552]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 14603 1244 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1391\n",
      "853 12 True\n",
      "x_t:  3 [0.496875   0.3125     0.103125   0.36666667]\n",
      "Q values:  tensor([[-5.9338, -5.9126, -5.9269, -5.8160, -5.8496, -4.8435]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17888 209 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2162\n",
      "853 15 True\n",
      "x_t:  3 [0.309375 0.3125   0.10625  0.3375  ]\n",
      "Q values:  tensor([[-4.9448, -4.9221, -5.0543, -5.2082, -4.9552, -4.1610]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18224 1635 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2379\n",
      "853 22 True\n",
      "x_t:  2 [0.440625   0.40416667 0.0625     0.25416667]\n",
      "Q values:  tensor([[-4.7091, -5.4494, -5.2776, -5.2274, -5.0118, -4.2571]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23700 1407 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  340\n",
      "854 0 True\n",
      "x_t:  3 [0.4        0.27916667 0.0875     0.32916667]\n",
      "Q values:  tensor([[-4.8841, -5.0695, -5.0806, -4.6250, -4.6113, -4.2990]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4935 1258 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 854: ep_len:1258 episode reward: total was -77.100000. running mean: -56.677297\n",
      "startIDX:  602\n",
      "854 1 True\n",
      "x_t:  3 [0.140625   0.24166667 0.08125    0.3125    ]\n",
      "Q values:  tensor([[-6.7823, -6.6726, -6.6609, -6.6706, -6.7416, -5.4050]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34330 1813 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 854: ep_len:1813 episode reward: total was -146.600000. running mean: -57.576524\n",
      "startIDX:  2147\n",
      "854 5 True\n",
      "x_t:  4 [0.003125   0.375      0.08125    0.27916667]\n",
      "Q values:  tensor([[-3.9142, -4.0101, -3.8080, -4.0692, -4.0560, -3.2156]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19704 729 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 854: ep_len:729 episode reward: total was -128.300000. running mean: -58.283759\n",
      "startIDX:  2209\n",
      "854 10 True\n",
      "x_t:  0 [0.471875   0.39166667 0.0875     0.29583333]\n",
      "Q values:  tensor([[-4.3895, -4.7273, -4.7194, -4.5066, -4.4200, -3.7438]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20074 573 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 854: ep_len:573 episode reward: total was -90.700000. running mean: -58.607921\n",
      "startIDX:  1155\n",
      "854 12 True\n",
      "x_t:  3 [0.809375   0.38333333 0.159375   0.43333333]\n",
      "Q values:  tensor([[-5.0864, -5.4841, -5.1692, -4.9831, -4.9937, -4.1244]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16497 1417 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 854: ep_len:1417 episode reward: total was -104.500000. running mean: -59.066842\n",
      "startIDX:  2134\n",
      "854 15 True\n",
      "x_t:  3 [0.084375   0.27083333 0.065625   0.30833333]\n",
      "Q values:  tensor([[-5.3407, -5.0037, -4.6467, -5.1352, -4.9260, -4.1761]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18177 1645 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 854: ep_len:1645 episode reward: total was -103.700000. running mean: -59.513173\n",
      "startIDX:  54\n",
      "854 22 True\n",
      "x_t:  1 [0.3625     0.34583333 0.140625   0.4       ]\n",
      "Q values:  tensor([[-4.9960, -4.5999, -4.7701, -4.6761, -4.7826, -3.8759]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1631 713 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 854: ep_len:713 episode reward: total was -90.600000. running mean: -59.824042\n",
      "startIDX:  2385\n",
      "startIDX:  1199\n",
      "startIDX:  2034\n",
      "855 5 True\n",
      "x_t:  3 [0.21875    0.26666667 0.09375    0.3375    ]\n",
      "Q values:  tensor([[-4.7876, -5.2237, -4.9239, -5.0141, -4.7998, -4.0860]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18245 1259 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  738\n",
      "855 10 True\n",
      "x_t:  0 [0.540625   0.39166667 0.075      0.29583333]\n",
      "Q values:  tensor([[-4.0269, -4.3069, -4.1415, -4.2655, -4.2117, -3.4547]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8209 802 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  455\n",
      "855 12 True\n",
      "x_t:  2 [0.659375   0.40416667 0.053125   0.2625    ]\n",
      "Q values:  tensor([[-6.5511, -6.2335, -6.3264, -6.4149, -6.1725, -5.1416]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9925 1342 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1027\n",
      "855 15 True\n",
      "x_t:  4 [0.353125   0.375      0.0875     0.29583333]\n",
      "Q values:  tensor([[-4.7042, -5.1783, -4.8971, -4.9263, -5.2351, -4.0893]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9876 626 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1010\n",
      "855 22 True\n",
      "x_t:  0 [0.75625    0.40833333 0.1125     0.32083333]\n",
      "Q values:  tensor([[-5.6602, -5.8227, -4.7416, -5.2619, -5.2422, -4.2041]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10421 438 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2517\n",
      "ep 856: ep_len:32 episode reward: total was -6.900000. running mean: -60.560280\n",
      "startIDX:  33\n",
      "856 1 False\n",
      "x_t:  3 [0.403125   0.2625     0.109375   0.34166667]\n",
      "Q values:  tensor([[-5.6692, -5.6712, -5.0101, -4.7670, -5.9788, -4.8161]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25703 201 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 856: ep_len:201 episode reward: total was -18.600000. running mean: -60.140677\n",
      "startIDX:  2117\n",
      "856 5 False\n",
      "x_t:  4 [0.490625   0.38333333 0.1125     0.39166667]\n",
      "Q values:  tensor([[-5.5410, -5.7336, -5.4743, -5.4466, -4.6875, -4.6971]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19509 633 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 856: ep_len:633 episode reward: total was -47.800000. running mean: -60.017270\n",
      "startIDX:  1446\n",
      "856 10 True\n",
      "x_t:  4 [0.10625    0.36666667 0.1        0.25833333]\n",
      "Q values:  tensor([[-6.0161, -6.1820, -5.8329, -5.9695, -5.6101, -4.8914]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15722 502 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 856: ep_len:502 episode reward: total was -8.300000. running mean: -59.500098\n",
      "startIDX:  1291\n",
      "856 12 True\n",
      "x_t:  4 [0.43125    0.36666667 0.053125   0.25833333]\n",
      "Q values:  tensor([[-5.3312, -5.6022, -5.5069, -6.1664, -5.5872, -4.5629]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 17467 483 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 856: ep_len:483 episode reward: total was -45.500000. running mean: -59.360097\n",
      "startIDX:  310\n",
      "856 15 True\n",
      "x_t:  0 [0.43125    0.40833333 0.09375    0.47916667]\n",
      "Q values:  tensor([[-5.3935, -6.1828, -5.5038, -5.3632, -5.5169, -4.6484]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3831 807 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 856: ep_len:807 episode reward: total was -109.100000. running mean: -59.857496\n",
      "startIDX:  858\n",
      "856 22 True\n",
      "x_t:  1 [0.121875 0.35     0.10625  0.4125  ]\n",
      "Q values:  tensor([[-6.8743, -6.9148, -6.2941, -6.4235, -6.6920, -5.3549]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9495 273 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 856: ep_len:273 episode reward: total was 12.100000. running mean: -59.137921\n",
      "startIDX:  367\n",
      "857 0 True\n",
      "x_t:  3 [0.109375   0.2375     0.05625    0.24166667]\n",
      "Q values:  tensor([[-7.1542, -7.0453, -7.0950, -6.9894, -6.8566, -5.6552]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4853 1210 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1169\n",
      "startIDX:  848\n",
      "857 5 True\n",
      "x_t:  4 [0.1        0.39583333 0.103125   0.40416667]\n",
      "Q values:  tensor([[-6.6209, -7.1415, -6.2897, -6.8560, -6.7204, -5.5219]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10023 592 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2153\n",
      "857 10 True\n",
      "x_t:  0 [0.790625 0.3875   0.05625  0.3375  ]\n",
      "Q values:  tensor([[-6.8599, -7.3767, -7.2916, -6.8939, -6.6641, -5.7787]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19957 544 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1379\n",
      "857 12 True\n",
      "x_t:  3 [0.065625   0.25       0.053125   0.24583333]\n",
      "Q values:  tensor([[-7.2685, -7.4543, -7.0207, -7.8316, -7.6007, -6.1162]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18000 285 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  766\n",
      "857 15 True\n",
      "x_t:  2 [0.79375 0.4125  0.08125 0.2875 ]\n",
      "Q values:  tensor([[-5.6168, -6.1490, -5.5895, -5.8473, -5.9877, -4.7103]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5967 346 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1755\n",
      "857 22 True\n",
      "x_t:  3 [0.375      0.29166667 0.1        0.3125    ]\n",
      "Q values:  tensor([[-8.4540, -8.5515, -7.8820, -7.4487, -8.6027, -7.1486]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16921 205 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2406\n",
      "858 0 True\n",
      "x_t:  3 [0.259375   0.25416667 0.078125   0.29583333]\n",
      "Q values:  tensor([[-8.9852, -8.9446, -8.8569, -8.4712, -9.0104, -7.4949]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26146 1237 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 858: ep_len:1237 episode reward: total was -59.500000. running mean: -56.459321\n",
      "startIDX:  51\n",
      "858 1 True\n",
      "x_t:  0 [0.559375   0.37916667 0.115625   0.4125    ]\n",
      "Q values:  tensor([[-8.2329, -7.7898, -8.8827, -9.1110, -7.9526, -7.3367]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29147 1933 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 858: ep_len:1933 episode reward: total was -254.500000. running mean: -58.439728\n",
      "startIDX:  2935\n",
      "ep 858: ep_len:72 episode reward: total was -66.900000. running mean: -58.524331\n",
      "startIDX:  2157\n",
      "858 10 True\n",
      "x_t:  0 [0.5125     0.4        0.053125   0.29166667]\n",
      "Q values:  tensor([[-6.8513, -7.0405, -7.2646, -6.6480, -6.9926, -5.7980]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20044 585 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 858: ep_len:585 episode reward: total was -58.100000. running mean: -58.520087\n",
      "startIDX:  222\n",
      "858 12 True\n",
      "x_t:  4 [0.4        0.40416667 0.115625   0.33333333]\n",
      "Q values:  tensor([[-10.1300,  -9.2078,  -9.8960,  -8.8590, -10.1666,  -8.3781]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7227 2158 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 858: ep_len:2158 episode reward: total was -141.800000. running mean: -59.352887\n",
      "startIDX:  1984\n",
      "858 15 True\n",
      "x_t:  1 [0.034375   0.35416667 0.125      0.35833333]\n",
      "Q values:  tensor([[-6.4499, -6.6251, -6.3023, -6.3913, -6.1151, -5.2156]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14948 726 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 858: ep_len:726 episode reward: total was -116.100000. running mean: -59.920358\n",
      "startIDX:  886\n",
      "858 22 True\n",
      "x_t:  1 [0.153125   0.35833333 0.159375   0.40833333]\n",
      "Q values:  tensor([[-5.4343, -5.7866, -5.4823, -5.5540, -5.6974, -4.6594]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9500 252 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 858: ep_len:252 episode reward: total was -3.300000. running mean: -59.354154\n",
      "startIDX:  1664\n",
      "859 0 True\n",
      "x_t:  1 [0.66875    0.30416667 0.146875   0.36666667]\n",
      "Q values:  tensor([[-5.6609, -5.9706, -6.3275, -6.1153, -5.7402, -5.1178]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18995 1251 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  920\n",
      "859 1 True\n",
      "x_t:  4 [0.321875   0.37083333 0.10625    0.40416667]\n",
      "Q values:  tensor([[-4.8011, -5.1278, -4.8434, -5.1655, -4.8375, -4.1708]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35469 519 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  437\n",
      "859 5 True\n",
      "x_t:  1 [0.428125   0.30833333 0.09375    0.36666667]\n",
      "Q values:  tensor([[-5.9882, -6.2029, -6.4682, -6.1891, -5.7241, -5.0635]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5086 697 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1627\n",
      "859 10 True\n",
      "x_t:  3 [0.165625   0.24166667 0.090625   0.28333333]\n",
      "Q values:  tensor([[-6.0623, -6.9620, -6.7369, -6.7198, -6.5974, -5.5283]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16526 332 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1126\n",
      "859 12 True\n",
      "x_t:  3 [0.6125     0.34583333 0.125      0.41666667]\n",
      "Q values:  tensor([[-6.8128, -7.2014, -7.1189, -6.5859, -6.8667, -5.6454]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16473 1418 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1863\n",
      "859 15 True\n",
      "x_t:  1 [0.775      0.3        0.053125   0.30416667]\n",
      "Q values:  tensor([[-5.2886, -5.6981, -5.7714, -5.5168, -5.7805, -4.6849]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 14858 742 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2186\n",
      "859 22 True\n",
      "x_t:  0 [0.884375   0.39583333 0.053125   0.33333333]\n",
      "Q values:  tensor([[-4.9411, -4.7554, -4.6260, -5.1408, -4.6802, -3.8815]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20700 814 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  9964.808750867844\n",
      "startIDX:  1577\n",
      "860 0 True\n",
      "x_t:  0 [0.75625    0.39583333 0.1125     0.34583333]\n",
      "Q values:  tensor([[-6.4688, -6.7586, -6.2001, -6.4832, -6.7047, -5.5008]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20654 2161 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 860: ep_len:2161 episode reward: total was -239.700000. running mean: -62.816200\n",
      "startIDX:  767\n",
      "860 1 True\n",
      "x_t:  3 [0.21875    0.25416667 0.1        0.325     ]\n",
      "Q values:  tensor([[-6.2023, -5.8474, -6.0859, -5.8082, -6.2825, -5.0038]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 34355 1376 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 860: ep_len:1376 episode reward: total was -71.300000. running mean: -62.901038\n",
      "startIDX:  2144\n",
      "860 5 True\n",
      "x_t:  4 [0.040625   0.4125     0.09375    0.42083333]\n",
      "Q values:  tensor([[-4.7998, -4.4205, -4.4098, -4.8702, -4.6371, -3.9868]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19469 592 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 860: ep_len:592 episode reward: total was -4.300000. running mean: -62.315027\n",
      "startIDX:  612\n",
      "860 10 True\n",
      "x_t:  1 [0.88125 0.2875  0.1125  0.35   ]\n",
      "Q values:  tensor([[-5.1372, -4.9577, -5.2268, -4.7106, -4.8756, -4.2962]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 7207 1043 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 860: ep_len:1043 episode reward: total was -124.000000. running mean: -62.931877\n",
      "startIDX:  1817\n",
      "860 12 True\n",
      "x_t:  0 [0.259375   0.42083333 0.090625   0.27083333]\n",
      "Q values:  tensor([[-6.2650, -6.0320, -5.8832, -6.0843, -5.7353, -5.1225]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21172 627 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 860: ep_len:627 episode reward: total was -58.100000. running mean: -62.883558\n",
      "startIDX:  1265\n",
      "860 15 True\n",
      "x_t:  3 [0.853125   0.34583333 0.1375     0.39583333]\n",
      "Q values:  tensor([[-4.3380, -4.7260, -4.4056, -4.4919, -4.6215, -3.9804]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10339 244 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 860: ep_len:244 episode reward: total was 60.100000. running mean: -61.653723\n",
      "startIDX:  1620\n",
      "860 22 True\n",
      "x_t:  3 [0.06875    0.25       0.06875    0.25833333]\n",
      "Q values:  tensor([[-6.7037, -6.5267, -6.8274, -6.4804, -6.0519, -5.5739]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16995 306 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 860: ep_len:306 episode reward: total was -7.500000. running mean: -61.112185\n",
      "startIDX:  108\n",
      "861 0 True\n",
      "x_t:  1 [0.675      0.3125     0.09375    0.41666667]\n",
      "Q values:  tensor([[-5.1804, -5.6053, -5.6871, -5.3258, -5.4278, -4.5744]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1632 712 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  182\n",
      "861 1 True\n",
      "x_t:  2 [0.646875   0.37083333 0.15       0.44583333]\n",
      "Q values:  tensor([[-5.3100, -5.3074, -4.7197, -5.1541, -5.1909, -4.5278]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27523 915 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  227\n",
      "861 5 True\n",
      "x_t:  0 [0.603125   0.4        0.14375    0.37916667]\n",
      "Q values:  tensor([[-4.6592, -4.8187, -4.1688, -4.6678, -4.8055, -3.9409]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3589 751 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  2196\n",
      "861 10 True\n",
      "x_t:  0 [0.5125     0.4        0.053125   0.29166667]\n",
      "Q values:  tensor([[-5.7914, -5.8286, -5.7430, -5.8235, -5.6344, -4.7838]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20044 564 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  372\n",
      "861 12 True\n",
      "x_t:  4 [0.384375   0.40833333 0.128125   0.34583333]\n",
      "Q values:  tensor([[-5.7907, -6.1955, -6.3243, -6.0075, -5.6370, -4.9094]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 7223 725 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2342\n",
      "861 15 True\n",
      "x_t:  4 [0.2        0.39166667 0.0875     0.32916667]\n",
      "Q values:  tensor([[-3.8441, -4.0398, -3.8925, -3.9653, -4.1235, -3.4102]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19281 551 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2250\n",
      "861 22 True\n",
      "x_t:  1 [0.49375    0.33333333 0.146875   0.44166667]\n",
      "Q values:  tensor([[-5.4511, -6.1942, -5.8142, -5.4321, -5.5756, -4.7876]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22967 1111 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1830\n",
      "862 0 True\n",
      "x_t:  1 [0.303125   0.34166667 0.14375    0.38333333]\n",
      "Q values:  tensor([[-4.8544, -4.7610, -4.6427, -4.9353, -4.5574, -3.9530]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18955 1036 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 862: ep_len:1036 episode reward: total was -107.600000. running mean: -61.067677\n",
      "startIDX:  446\n",
      "862 1 True\n",
      "x_t:  1 [0.765625   0.275      0.15625    0.45416667]\n",
      "Q values:  tensor([[-5.0455, -5.4518, -4.9240, -5.0634, -5.3779, -4.4166]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30689 793 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 862: ep_len:793 episode reward: total was -82.700000. running mean: -61.284000\n",
      "startIDX:  1914\n",
      "862 5 True\n",
      "x_t:  3 [0.171875   0.25833333 0.090625   0.325     ]\n",
      "Q values:  tensor([[-5.4870, -5.6592, -5.9224, -5.6817, -5.3022, -4.5350]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18232 1589 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 862: ep_len:1589 episode reward: total was -134.700000. running mean: -62.018160\n",
      "startIDX:  1502\n",
      "862 10 True\n",
      "x_t:  3 [0.578125   0.29166667 0.10625    0.3625    ]\n",
      "Q values:  tensor([[-4.6820, -4.8627, -4.9839, -4.3072, -4.8955, -4.0769]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16442 357 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 862: ep_len:357 episode reward: total was 50.600000. running mean: -60.891978\n",
      "startIDX:  1014\n",
      "862 12 True\n",
      "x_t:  2 [0.878125   0.40416667 0.046875   0.20416667]\n",
      "Q values:  tensor([[-5.0259, -4.8430, -4.9159, -4.8077, -4.7787, -4.2040]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13566 313 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 862: ep_len:313 episode reward: total was -11.600000. running mean: -60.399058\n",
      "startIDX:  2450\n",
      "862 15 True\n",
      "x_t:  3 [0.83125    0.34583333 0.134375   0.37916667]\n",
      "Q values:  tensor([[-4.4273, -4.2958, -4.2904, -4.3799, -4.2957, -3.6129]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19660 215 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 862: ep_len:215 episode reward: total was 28.500000. running mean: -59.510068\n",
      "startIDX:  1276\n",
      "862 22 True\n",
      "x_t:  2 [0.484375   0.40833333 0.078125   0.25416667]\n",
      "Q values:  tensor([[-5.8453, -5.5354, -5.4368, -4.8968, -5.4706, -4.6006]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12639 345 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 862: ep_len:345 episode reward: total was -41.300000. running mean: -59.327967\n",
      "startIDX:  88\n",
      "863 0 True\n",
      "x_t:  1 [0.853125   0.3        0.1        0.43333333]\n",
      "Q values:  tensor([[-6.4488, -6.5487, -6.3987, -6.5378, -6.4122, -5.3625]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 1614 715 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  605\n",
      "863 1 True\n",
      "x_t:  2 [0.7125     0.37916667 0.065625   0.3125    ]\n",
      "Q values:  tensor([[-4.6822, -4.8280, -5.1751, -4.4939, -4.7123, -4.1342]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31481 390 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  833\n",
      "863 5 True\n",
      "x_t:  4 [0.5125     0.36666667 0.096875   0.34166667]\n",
      "Q values:  tensor([[-5.5639, -5.4225, -5.7966, -5.3923, -5.4321, -4.5992]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 10083 614 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  825\n",
      "863 10 True\n",
      "x_t:  0 [0.603125   0.40416667 0.09375    0.28333333]\n",
      "Q values:  tensor([[-4.1863, -4.4776, -3.9680, -3.9851, -4.1107, -3.7347]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 8159 525 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  789\n",
      "863 12 True\n",
      "x_t:  0 [0.625      0.40416667 0.078125   0.3625    ]\n",
      "Q values:  tensor([[-5.6725, -5.3107, -5.8579, -4.8077, -5.2931, -4.5388]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 11710 709 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2665\n",
      "863 15 True\n",
      "x_t:  2 [0.6125  0.4     0.06875 0.3125 ]\n",
      "Q values:  tensor([[-5.5762, -5.8101, -5.5179, -5.8620, -5.4790, -4.7177]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21555 908 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2064\n",
      "863 22 True\n",
      "x_t:  1 [0.2125     0.35       0.1375     0.37916667]\n",
      "Q values:  tensor([[-4.4268, -4.2800, -4.4899, -3.7804, -3.9912, -3.4118]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19015 231 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  492\n",
      "864 0 True\n",
      "x_t:  3 [0.384375   0.30416667 0.09375    0.39166667]\n",
      "Q values:  tensor([[-4.6939, -4.6501, -4.3583, -4.4492, -4.7947, -3.7987]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7052 1061 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 864: ep_len:1061 episode reward: total was -79.600000. running mean: -58.734779\n",
      "startIDX:  974\n",
      "864 1 True\n",
      "x_t:  3 [0.6375     0.29166667 0.1        0.375     ]\n",
      "Q values:  tensor([[-5.1812, -5.0624, -5.2103, -5.1841, -4.9096, -4.1897]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35934 250 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 864: ep_len:250 episode reward: total was 31.600000. running mean: -57.831432\n",
      "startIDX:  1174\n",
      "864 5 True\n",
      "x_t:  2 [0.3375     0.39583333 0.10625    0.2875    ]\n",
      "Q values:  tensor([[-5.1649, -5.1505, -5.4185, -4.8758, -4.9473, -4.3481]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12051 885 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 864: ep_len:885 episode reward: total was -94.600000. running mean: -58.199117\n",
      "startIDX:  404\n",
      "864 10 True\n",
      "x_t:  2 [0.803125   0.39583333 0.05       0.2625    ]\n",
      "Q values:  tensor([[-5.3025, -5.0011, -5.5743, -5.2663, -4.8366, -4.4080]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 6712 1020 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 864: ep_len:1020 episode reward: total was -165.100000. running mean: -59.268126\n",
      "startIDX:  1346\n",
      "864 12 True\n",
      "x_t:  1 [0.0375     0.36666667 0.13125    0.36666667]\n",
      "Q values:  tensor([[-6.5600, -6.7379, -6.9761, -6.7275, -6.5822, -5.4919]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 19874 1235 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 864: ep_len:1235 episode reward: total was -143.500000. running mean: -60.110445\n",
      "startIDX:  2954\n",
      "ep 864: ep_len:110 episode reward: total was -80.700000. running mean: -60.316340\n",
      "startIDX:  1042\n",
      "864 22 True\n",
      "x_t:  0 [0.646875   0.40833333 0.103125   0.3625    ]\n",
      "Q values:  tensor([[-5.0038, -5.3208, -5.2617, -5.1583, -4.9083, -4.3195]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10520 466 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 864: ep_len:466 episode reward: total was -57.400000. running mean: -60.287177\n",
      "startIDX:  996\n",
      "865 0 True\n",
      "x_t:  1 [0.4125     0.33333333 0.15625    0.46666667]\n",
      "Q values:  tensor([[-6.7239, -6.5963, -6.9629, -6.4144, -6.6147, -5.8199]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11990 823 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  649\n",
      "865 1 True\n",
      "x_t:  2 [0.459375   0.38333333 0.059375   0.30833333]\n",
      "Q values:  tensor([[-5.7246, -5.9423, -5.7365, -5.4707, -5.3169, -4.7824]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31521 365 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2117\n",
      "865 5 True\n",
      "x_t:  4 [0.484375   0.34166667 0.05       0.23333333]\n",
      "Q values:  tensor([[-6.4088, -7.0762, -6.2544, -6.4740, -6.6296, -5.4453]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19619 697 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1663\n",
      "865 10 True\n",
      "x_t:  3 [0.86875    0.32916667 0.125      0.4       ]\n",
      "Q values:  tensor([[-6.0155, -6.7928, -6.4543, -6.2335, -6.5650, -5.2723]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16401 256 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  54\n",
      "865 12 True\n",
      "x_t:  1 [0.94375    0.3        0.05       0.43333333]\n",
      "Q values:  tensor([[-6.0299, -5.7905, -6.2888, -5.7745, -6.5104, -5.4698]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2214 611 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1793\n",
      "865 15 True\n",
      "x_t:  0 [0.928125   0.40416667 0.065625   0.32916667]\n",
      "Q values:  tensor([[-6.4499, -7.1578, -6.2703, -7.3066, -6.6285, -5.6103]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13363 452 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  804\n",
      "865 22 True\n",
      "x_t:  2 [0.315625 0.4125   0.09375  0.2625  ]\n",
      "Q values:  tensor([[-9.6245, -8.6895, -9.4433, -8.8664, -9.4796, -8.1284]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8968 863 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  716\n",
      "866 0 True\n",
      "x_t:  1 [0.328125   0.34583333 0.146875   0.4125    ]\n",
      "Q values:  tensor([[-5.7843, -6.1832, -5.9792, -6.1581, -6.3984, -5.3912]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9444 278 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 866: ep_len:278 episode reward: total was 12.000000. running mean: -58.298092\n",
      "startIDX:  333\n",
      "866 1 True\n",
      "x_t:  1 [0.565625   0.30833333 0.2375     0.5625    ]\n",
      "Q values:  tensor([[-5.6796, -6.3690, -5.8975, -5.8989, -5.9280, -5.1982]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28102 311 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 866: ep_len:311 episode reward: total was -15.300000. running mean: -57.868111\n",
      "startIDX:  73\n",
      "866 5 False\n",
      "x_t:  2 [0.74375  0.3875   0.159375 0.475   ]\n",
      "Q values:  tensor([[-8.1832, -8.4917, -7.1573, -8.3233, -7.7996, -7.1796]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2122 902 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 866: ep_len:902 episode reward: total was -44.700000. running mean: -57.736430\n",
      "startIDX:  2\n",
      "866 10 True\n",
      "x_t:  3 [0.059375   0.24166667 0.05625    0.25      ]\n",
      "Q values:  tensor([[ -9.2741, -10.0231,  -9.6874,  -9.0704,  -9.1325,  -8.0503]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 3577 1129 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 866: ep_len:1129 episode reward: total was -12.200000. running mean: -57.281066\n",
      "startIDX:  610\n",
      "866 12 True\n",
      "x_t:  1 [0.075      0.39166667 0.175      0.47916667]\n",
      "Q values:  tensor([[ -9.0853,  -9.3108, -10.3958,  -9.7609,  -9.1653,  -8.2326]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10310 1242 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 866: ep_len:1242 episode reward: total was -142.300000. running mean: -58.131255\n",
      "startIDX:  1112\n",
      "866 15 True\n",
      "x_t:  4 [0.4375   0.3625   0.059375 0.25    ]\n",
      "Q values:  tensor([[-6.6408, -6.6971, -7.0554, -6.8996, -7.6352, -6.3462]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9911 611 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 866: ep_len:611 episode reward: total was -64.200000. running mean: -58.191942\n",
      "startIDX:  464\n",
      "866 22 True\n",
      "x_t:  3 [0.38125    0.25833333 0.06875    0.2625    ]\n",
      "Q values:  tensor([[-8.1922, -8.3391, -8.8648, -8.4561, -8.5722, -7.1913]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7172 1123 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 866: ep_len:1123 episode reward: total was -117.100000. running mean: -58.781023\n",
      "startIDX:  232\n",
      "867 0 True\n",
      "x_t:  3 [0.1375     0.24583333 0.059375   0.24583333]\n",
      "Q values:  tensor([[-8.7413, -9.1457, -8.5909, -9.1988, -9.4151, -7.5566]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4864 1580 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  657\n",
      "867 1 True\n",
      "x_t:  2 [0.3875     0.37916667 0.096875   0.31666667]\n",
      "Q values:  tensor([[-5.9839, -6.0738, -6.4219, -6.0948, -6.2445, -5.5173]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31531 390 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1391\n",
      "867 5 True\n",
      "x_t:  0 [0.76875    0.3875     0.1125     0.34166667]\n",
      "Q values:  tensor([[-5.9216, -6.5871, -6.1917, -6.5378, -6.7942, -5.3176]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13518 709 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1694\n",
      "867 10 True\n",
      "x_t:  2 [0.046875   0.4        0.1        0.25416667]\n",
      "Q values:  tensor([[-7.1196, -7.9756, -7.4304, -7.7307, -7.1762, -6.4005]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18153 1133 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  270\n",
      "867 12 True\n",
      "x_t:  3 [0.0875  0.25    0.06875 0.2625 ]\n",
      "Q values:  tensor([[-7.8219, -7.8454, -7.6027, -7.4435, -7.6154, -6.5725]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7837 1074 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1327\n",
      "867 15 True\n",
      "x_t:  2 [0.675      0.40416667 0.053125   0.29166667]\n",
      "Q values:  tensor([[-7.8568, -7.8646, -7.8073, -7.8309, -7.9430, -6.6564]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12009 1042 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  45\n",
      "867 22 True\n",
      "x_t:  2 [0.5875     0.40416667 0.046875   0.25      ]\n",
      "Q values:  tensor([[-7.5085, -6.9710, -7.2116, -6.7872, -7.3222, -6.2866]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2321 1084 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  678\n",
      "868 0 True\n",
      "x_t:  2 [0.634375 0.4      0.05     0.2625  ]\n",
      "Q values:  tensor([[-7.2360, -7.4557, -8.1061, -7.2611, -7.1628, -6.4783]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8963 935 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 868: ep_len:935 episode reward: total was -80.700000. running mean: -62.808103\n",
      "startIDX:  636\n",
      "868 1 True\n",
      "x_t:  2 [0.734375   0.38333333 0.109375   0.3125    ]\n",
      "Q values:  tensor([[-6.6843, -5.9955, -6.0363, -6.0196, -5.9002, -5.2301]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 31475 362 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 868: ep_len:362 episode reward: total was -16.400000. running mean: -62.344022\n",
      "startIDX:  91\n",
      "868 5 True\n",
      "x_t:  1 [0.3375   0.3125   0.078125 0.35    ]\n",
      "Q values:  tensor([[-11.6996, -11.9626, -11.8759, -10.4567, -11.6009,  -9.6767]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5098 2413 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 868: ep_len:2413 episode reward: total was -242.600000. running mean: -64.146582\n",
      "startIDX:  1658\n",
      "868 10 False\n",
      "x_t:  3 [0.86875    0.32916667 0.125      0.4       ]\n",
      "Q values:  tensor([[-4.4786, -4.5716, -5.1196, -4.1266, -4.9526, -4.1794]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16401 255 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 868: ep_len:255 episode reward: total was 19.700000. running mean: -63.308116\n",
      "startIDX:  1805\n",
      "868 12 True\n",
      "x_t:  0 [0.6875     0.41666667 0.128125   0.3375    ]\n",
      "Q values:  tensor([[-6.3633, -6.9308, -6.3066, -6.1661, -6.3638, -5.5682]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21119 590 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 868: ep_len:590 episode reward: total was -34.000000. running mean: -63.015035\n",
      "startIDX:  1284\n",
      "868 15 True\n",
      "x_t:  3 [0.484375   0.29583333 0.1125     0.3125    ]\n",
      "Q values:  tensor([[-5.3366, -5.4421, -5.3767, -5.5327, -5.3132, -4.4638]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10401 252 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 868: ep_len:252 episode reward: total was -69.600000. running mean: -63.080884\n",
      "startIDX:  1642\n",
      "868 22 True\n",
      "x_t:  3 [0.103125   0.25       0.084375   0.26666667]\n",
      "Q values:  tensor([[-6.3851, -5.9547, -5.9181, -6.5932, -6.1987, -5.3518]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16983 290 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 868: ep_len:290 episode reward: total was -28.500000. running mean: -62.735075\n",
      "startIDX:  1122\n",
      "869 0 True\n",
      "x_t:  2 [0.446875   0.40416667 0.075      0.30416667]\n",
      "Q values:  tensor([[-4.9907, -5.0766, -5.2989, -4.7139, -4.8126, -4.2820]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12683 349 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  415\n",
      "869 1 True\n",
      "x_t:  0 [0.53125    0.375      0.125      0.42916667]\n",
      "Q values:  tensor([[-5.4511, -5.8900, -6.2612, -5.7760, -5.8419, -4.9217]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29152 524 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  226\n",
      "869 5 True\n",
      "x_t:  1 [0.20625    0.34583333 0.140625   0.52083333]\n",
      "Q values:  tensor([[-3.9217, -4.0011, -3.8140, -4.0016, -4.2258, -3.6055]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 2527 220 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1314\n",
      "869 10 True\n",
      "x_t:  4 [0.4        0.34583333 0.084375   0.2375    ]\n",
      "Q values:  tensor([[-5.2548, -5.3109, -5.0573, -5.3949, -5.2959, -4.2328]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15777 597 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1962\n",
      "startIDX:  1628\n",
      "869 15 True\n",
      "x_t:  0 [0.203125   0.42083333 0.075      0.3625    ]\n",
      "Q values:  tensor([[-5.4080, -5.7619, -5.6166, -5.7647, -5.6487, -4.7645]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13489 787 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1031\n",
      "869 22 True\n",
      "x_t:  0 [0.56875    0.40416667 0.06875    0.32916667]\n",
      "Q values:  tensor([[-5.6419, -5.1749, -5.4525, -5.6032, -5.3607, -4.7704]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 10469 453 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  10206.081054925919\n",
      "startIDX:  2399\n",
      "ep 870: ep_len:1286 episode reward: total was -124.100000. running mean: -61.613468\n",
      "startIDX:  319\n",
      "870 1 False\n",
      "x_t:  0 [0.596875   0.38333333 0.1125     0.39583333]\n",
      "Q values:  tensor([[-4.8796, -5.5843, -5.8976, -5.2451, -5.4771, -4.9739]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29139 843 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 870: ep_len:843 episode reward: total was -60.000000. running mean: -61.597333\n",
      "startIDX:  1446\n",
      "870 5 True\n",
      "x_t:  0 [0.584375 0.3875   0.078125 0.325   ]\n",
      "Q values:  tensor([[-5.7779, -6.5315, -6.4756, -6.8791, -6.2048, -5.5096]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13554 527 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 870: ep_len:527 episode reward: total was -17.900000. running mean: -61.160360\n",
      "startIDX:  417\n",
      "870 10 True\n",
      "x_t:  3 [0.065625   0.22083333 0.059375   0.25      ]\n",
      "Q values:  tensor([[-3.2984, -3.7872, -3.7122, -3.7291, -3.4513, -3.0477]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 5188 246 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 870: ep_len:246 episode reward: total was -49.200000. running mean: -61.040756\n",
      "startIDX:  2015\n",
      "ep 870: ep_len:42 episode reward: total was -15.200000. running mean: -60.582348\n",
      "startIDX:  2951\n",
      "ep 870: ep_len:105 episode reward: total was -49.000000. running mean: -60.466525\n",
      "startIDX:  1620\n",
      "870 22 False\n",
      "x_t:  3 [0.878125   0.35416667 0.11875    0.40833333]\n",
      "Q values:  tensor([[-5.3375, -5.3201, -5.3578, -5.0041, -5.1296, -5.0426]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16842 238 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 870: ep_len:238 episode reward: total was 41.900000. running mean: -59.442860\n",
      "startIDX:  1347\n",
      "871 0 False\n",
      "x_t:  4 [0.0375     0.3875     0.1375     0.29166667]\n",
      "Q values:  tensor([[-7.0216, -6.4961, -6.9131, -6.5848, -5.8163, -5.9310]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16295 554 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  945\n",
      "871 1 True\n",
      "x_t:  4 [0.203125   0.38333333 0.125      0.39166667]\n",
      "Q values:  tensor([[-8.8795, -9.4618, -9.0942, -9.0706, -9.5821, -7.9919]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35451 493 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2970\n",
      "startIDX:  2390\n",
      "871 10 True\n",
      "x_t:  1 [0.546875   0.30833333 0.1125     0.32916667]\n",
      "Q values:  tensor([[-9.3182, -9.9817, -9.3216, -9.8115, -8.2923, -8.5626]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 22506 1204 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1974\n",
      "startIDX:  465\n",
      "871 15 False\n",
      "x_t:  1 [0.190625   0.34583333 0.115625   0.32916667]\n",
      "Q values:  tensor([[-7.8949, -7.3101, -7.8398, -7.4534, -7.4199, -7.3455]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5264 803 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  710\n",
      "871 22 True\n",
      "x_t:  2 [0.509375   0.40833333 0.05       0.2625    ]\n",
      "Q values:  tensor([[-11.2983, -10.5965, -10.6962, -11.5631, -10.3043,  -9.9040]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8997 922 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1595\n",
      "872 0 True\n",
      "x_t:  3 [0.803125   0.34166667 0.159375   0.4125    ]\n",
      "Q values:  tensor([[-8.0658, -8.6786, -8.2103, -8.4742, -8.2200, -7.2384]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16819 215 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 872: ep_len:215 episode reward: total was -9.800000. running mean: -60.570128\n",
      "startIDX:  852\n",
      "872 1 True\n",
      "x_t:  4 [0.00625    0.39583333 0.11875    0.4       ]\n",
      "Q values:  tensor([[-7.6742, -8.6385, -8.0924, -8.4138, -8.5813, -7.1867]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 35424 541 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 872: ep_len:541 episode reward: total was -65.400000. running mean: -60.618426\n",
      "startIDX:  1077\n",
      "872 5 False\n",
      "x_t:  3 [0.19375    0.24166667 0.096875   0.2875    ]\n",
      "Q values:  tensor([[-2.1061, -2.4953, -2.8817, -1.5340, -2.5269, -2.9670]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 10583 200 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 872: ep_len:200 episode reward: total was -6.600000. running mean: -60.078242\n",
      "startIDX:  1326\n",
      "872 10 False\n",
      "x_t:  4 [0.259375   0.3625     0.1        0.24166667]\n",
      "Q values:  tensor([[-7.5158, -7.8666, -8.2889, -7.8070, -7.0652, -7.3924]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15750 575 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 872: ep_len:575 episode reward: total was -71.400000. running mean: -60.191460\n",
      "startIDX:  929\n",
      "872 12 True\n",
      "x_t:  1 [0.06875    0.38333333 0.159375   0.4875    ]\n",
      "Q values:  tensor([[-7.8635, -8.7741, -8.3553, -8.3539, -7.9798, -7.3378]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 12970 642 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 872: ep_len:642 episode reward: total was -144.000000. running mean: -61.029545\n",
      "startIDX:  2673\n",
      "872 15 True\n",
      "x_t:  2 [0.5        0.40416667 0.1        0.3125    ]\n",
      "Q values:  tensor([[-10.3184, -10.8482, -11.6978, -10.2516, -11.8358,  -9.9365]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21541 891 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 872: ep_len:891 episode reward: total was -206.100000. running mean: -62.480250\n",
      "startIDX:  2540\n",
      "872 22 True\n",
      "x_t:  3 [0.11875    0.25       0.053125   0.24583333]\n",
      "Q values:  tensor([[ -9.3250, -10.0298,  -9.8738,  -9.3113,  -8.9994,  -8.5395]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26190 1249 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 872: ep_len:1249 episode reward: total was -301.000000. running mean: -64.865447\n",
      "startIDX:  1602\n",
      "873 0 True\n",
      "x_t:  2 [0.559375   0.39583333 0.08125    0.25      ]\n",
      "Q values:  tensor([[-10.2660,  -9.2681,  -9.9523, -10.8630, -10.3493,  -9.2439]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 18478 1018 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  397\n",
      "873 1 False\n",
      "x_t:  0 [0.734375   0.37083333 0.121875   0.4125    ]\n",
      "Q values:  tensor([[-8.3791, -9.3414, -9.8837, -8.7669, -9.8745, -8.4633]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 29115 504 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  258\n",
      "873 5 False\n",
      "x_t:  0 [0.896875   0.38333333 0.059375   0.375     ]\n",
      "Q values:  tensor([[-8.8796, -9.4125, -9.7892, -9.8534, -9.9429, -8.9526]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 3560 510 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  183\n",
      "873 10 False\n",
      "x_t:  4 [0.325      0.34583333 0.059375   0.22916667]\n",
      "Q values:  tensor([[-8.1654, -7.9652, -8.5575, -7.8854, -7.0985, -7.8067]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 4600 485 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1030\n",
      "873 12 True\n",
      "x_t:  2 [0.759375 0.4125   0.06875  0.2375  ]\n",
      "Q values:  tensor([[ -9.8369, -10.7267,  -9.8213, -11.2124, -10.3930,  -9.6878]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 13582 308 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  753\n",
      "873 15 False\n",
      "x_t:  3 [0.103125   0.24166667 0.05625    0.23333333]\n",
      "Q values:  tensor([[-14.6705, -16.1346, -15.7663, -14.2691, -14.4370, -14.2696]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 8513 1614 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2471\n",
      "873 22 False\n",
      "x_t:  3 [0.078125 0.2375   0.0625   0.25    ]\n",
      "Q values:  tensor([[-21.3931, -22.2348, -20.9673, -19.1321, -20.8417, -19.7316]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 26180 1590 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1678\n",
      "874 0 True\n",
      "x_t:  3 [0.353125   0.28333333 0.096875   0.32916667]\n",
      "Q values:  tensor([[-13.7149, -14.3095, -14.3564, -14.7835, -15.0885, -13.1699]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16887 207 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 874: ep_len:207 episode reward: total was -72.700000. running mean: -81.130921\n",
      "startIDX:  536\n",
      "874 1 True\n",
      "x_t:  1 [0.79375    0.275      0.125      0.45416667]\n",
      "Q values:  tensor([[-13.1375, -13.7247, -12.7710, -12.4231, -14.1719, -12.5625]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30688 738 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 874: ep_len:738 episode reward: total was -360.200000. running mean: -83.921612\n",
      "startIDX:  2452\n",
      "874 5 False\n",
      "x_t:  2 [0.25625    0.39583333 0.053125   0.26666667]\n",
      "Q values:  tensor([[-16.0341, -16.5039, -15.6580, -16.0576, -16.5408, -15.7238]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21587 960 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 874: ep_len:960 episode reward: total was -545.900000. running mean: -88.541396\n",
      "startIDX:  1448\n",
      "874 10 False\n",
      "x_t:  4 [0.021875   0.36666667 0.109375   0.275     ]\n",
      "Q values:  tensor([[-19.6533, -18.3422, -19.1638, -19.2100, -17.2409, -17.4139]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15709 496 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 874: ep_len:496 episode reward: total was -285.300000. running mean: -90.508982\n",
      "startIDX:  1465\n",
      "874 12 True\n",
      "x_t:  3 [0.228125   0.27083333 0.0625     0.275     ]\n",
      "Q values:  tensor([[-20.0094, -19.7768, -19.6407, -21.4757, -21.7500, -20.0493]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17950 205 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 874: ep_len:205 episode reward: total was -117.900000. running mean: -90.782892\n",
      "startIDX:  973\n",
      "874 15 False\n",
      "x_t:  4 [0.134375   0.38333333 0.06875    0.30416667]\n",
      "Q values:  tensor([[-18.8343, -18.8785, -18.2475, -19.4476, -18.1351, -18.3738]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9835 641 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 874: ep_len:641 episode reward: total was -238.000000. running mean: -92.255063\n",
      "startIDX:  892\n",
      "874 22 False\n",
      "x_t:  1 [0.25625    0.34583333 0.153125   0.4       ]\n",
      "Q values:  tensor([[-20.6474, -18.5248, -20.5655, -20.4662, -20.6873, -19.0145]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9511 255 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 874: ep_len:255 episode reward: total was -100.000000. running mean: -92.332513\n",
      "startIDX:  1680\n",
      "875 0 False\n",
      "x_t:  3 [0.2      0.2625   0.071875 0.2875  ]\n",
      "Q values:  tensor([[-18.7111, -19.3076, -18.1364, -16.7180, -19.3916, -16.9962]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16920 212 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  94\n",
      "875 1 False\n",
      "x_t:  3 [0.0875     0.22083333 0.08125    0.275     ]\n",
      "Q values:  tensor([[-24.3164, -22.6907, -22.3669, -22.1241, -23.3484, -22.1482]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 25785 209 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2388\n",
      "875 5 False\n",
      "x_t:  2 [0.225      0.39583333 0.090625   0.27083333]\n",
      "Q values:  tensor([[-25.7929, -27.6616, -23.5082, -25.1200, -25.8763, -24.0527]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21584 970 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1611\n",
      "875 10 False\n",
      "x_t:  3 [0.846875   0.33333333 0.146875   0.4       ]\n",
      "Q values:  tensor([[-21.1764, -19.6830, -21.6179, -19.3773, -22.4818, -19.6186]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16402 286 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  434\n",
      "875 12 False\n",
      "x_t:  3 [0.68125    0.32916667 0.08125    0.37916667]\n",
      "Q values:  tensor([[-22.2073, -21.4749, -22.7770, -20.8262, -23.3030, -21.1772]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7734 247 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  604\n",
      "875 15 True\n",
      "x_t:  1 [0.884375   0.29583333 0.08125    0.275     ]\n",
      "Q values:  tensor([[-26.4675, -25.6444, -24.7496, -26.7551, -27.4818, -25.0014]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 5168 683 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2180\n",
      "875 22 False\n",
      "x_t:  0 [0.903125   0.40833333 0.090625   0.3375    ]\n",
      "Q values:  tensor([[-27.0925, -28.3742, -28.4582, -30.8681, -28.0436, -27.5070]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20688 812 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1861\n",
      "876 0 False\n",
      "x_t:  1 [0.290625   0.34583333 0.15625    0.375     ]\n",
      "Q values:  tensor([[-25.2724, -24.0457, -24.2399, -25.3207, -26.6476, -24.2412]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 18953 278 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 876: ep_len:278 episode reward: total was -122.900000. running mean: -102.727210\n",
      "startIDX:  543\n",
      "876 1 False\n",
      "x_t:  1 [0.859375   0.25833333 0.1375     0.46666667]\n",
      "Q values:  tensor([[-25.9042, -24.4917, -26.3134, -25.2328, -26.4647, -24.6199]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30677 742 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 876: ep_len:742 episode reward: total was -433.300000. running mean: -106.032938\n",
      "startIDX:  2060\n",
      "876 5 False\n",
      "x_t:  3 [0.06875    0.25       0.08125    0.29583333]\n",
      "Q values:  tensor([[-17.9692, -16.9690, -17.7378, -15.6836, -17.6892, -16.9654]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18207 1229 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 876: ep_len:1229 episode reward: total was -774.800000. running mean: -112.720609\n",
      "startIDX:  1164\n",
      "876 10 False\n",
      "x_t:  2 [0.784375   0.4        0.090625   0.24583333]\n",
      "Q values:  tensor([[-24.5405, -24.9897, -22.9843, -23.0644, -24.2627, -23.9194]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12064 315 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 876: ep_len:315 episode reward: total was -183.800000. running mean: -113.431402\n",
      "startIDX:  2048\n",
      "ep 876: ep_len:9 episode reward: total was 3.000000. running mean: -112.267088\n",
      "startIDX:  1852\n",
      "876 15 False\n",
      "x_t:  0 [0.865625   0.4125     0.096875   0.31666667]\n",
      "Q values:  tensor([[-26.0703, -28.9390, -29.0449, -28.6008, -26.7920, -27.0625]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13370 414 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 876: ep_len:414 episode reward: total was -249.200000. running mean: -113.636418\n",
      "startIDX:  297\n",
      "876 22 False\n",
      "x_t:  3 [0.0625     0.24166667 0.046875   0.23333333]\n",
      "Q values:  tensor([[-23.5373, -24.3101, -25.0724, -22.6172, -23.6690, -22.7000]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 4868 1267 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 876: ep_len:1267 episode reward: total was -844.100000. running mean: -120.941053\n",
      "startIDX:  2084\n",
      "877 0 True\n",
      "x_t:  0 [0.74375    0.4        0.103125   0.33333333]\n",
      "Q values:  tensor([[-29.3306, -29.6553, -29.4047, -27.8352, -28.4784, -27.0654]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 20658 836 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  997\n",
      "877 1 False\n",
      "x_t:  3 [0.878125   0.30833333 0.115625   0.42916667]\n",
      "Q values:  tensor([[-29.0723, -30.2486, -29.1904, -28.4956, -31.3258, -28.9605]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35894 220 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2231\n",
      "877 5 False\n",
      "x_t:  3 [0.85       0.34583333 0.14375    0.42916667]\n",
      "Q values:  tensor([[-34.2437, -36.3868, -35.5309, -33.6461, -35.8513, -35.2187]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19883 209 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1657\n",
      "877 10 True\n",
      "x_t:  3 [0.74375    0.32083333 0.13125    0.37916667]\n",
      "Q values:  tensor([[-33.4697, -34.1599, -34.2970, -32.5456, -33.5458, -33.5217]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 16416 259 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  734\n",
      "877 12 True\n",
      "x_t:  1 [0.075      0.39166667 0.175      0.47916667]\n",
      "Q values:  tensor([[-30.8615, -33.8328, -33.6675, -34.1505, -31.5774, -32.1599]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 10310 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  58\n",
      "877 15 False\n",
      "x_t:  3 [0.8375     0.36666667 0.159375   0.42083333]\n",
      "Q values:  tensor([[-34.1188, -33.9850, -32.2965, -30.7449, -35.0517, -32.3262]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 519 227 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  631\n",
      "877 22 False\n",
      "x_t:  2 [0.065625   0.4125     0.096875   0.25416667]\n",
      "Q values:  tensor([[-28.2913, -27.1756, -26.4509, -26.7953, -28.3908, -26.5934]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 8926 930 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1168\n",
      "878 0 False\n",
      "x_t:  2 [0.775      0.4125     0.09375    0.27916667]\n",
      "Q values:  tensor([[-30.4409, -31.6114, -29.3033, -29.7554, -30.6137, -29.9658]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12634 314 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 878: ep_len:314 episode reward: total was -181.300000. running mean: -128.215292\n",
      "startIDX:  1013\n",
      "878 1 False\n",
      "x_t:  3 [0.790625   0.29583333 0.1125     0.42916667]\n",
      "Q values:  tensor([[-31.8989, -34.1029, -34.1531, -28.6358, -30.5855, -31.0286]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35908 215 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 878: ep_len:215 episode reward: total was -73.200000. running mean: -127.665139\n",
      "startIDX:  2127\n",
      "878 5 False\n",
      "x_t:  4 [0.028125   0.42083333 0.10625    0.40833333]\n",
      "Q values:  tensor([[-31.3539, -30.1948, -31.3672, -31.1149, -28.2191, -29.7369]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 19468 597 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 878: ep_len:597 episode reward: total was -276.200000. running mean: -129.150488\n",
      "startIDX:  1380\n",
      "878 10 False\n",
      "x_t:  4 [0.165625   0.35416667 0.05       0.28333333]\n",
      "Q values:  tensor([[-32.6849, -30.9981, -33.4653, -30.8249, -30.2733, -30.9423]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15727 549 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 878: ep_len:549 episode reward: total was -223.500000. running mean: -130.093983\n",
      "startIDX:  1397\n",
      "878 12 False\n",
      "x_t:  3 [0.59375    0.32916667 0.115625   0.39583333]\n",
      "Q values:  tensor([[-23.8564, -23.9009, -24.8390, -22.6293, -23.1950, -23.7743]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 17875 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 878: ep_len:202 episode reward: total was -69.800000. running mean: -129.491043\n",
      "startIDX:  751\n",
      "878 15 False\n",
      "x_t:  2 [0.76875    0.4        0.071875   0.30416667]\n",
      "Q values:  tensor([[-29.1829, -27.5719, -26.2512, -27.7913, -27.3787, -26.5055]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 5974 369 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 878: ep_len:369 episode reward: total was -174.400000. running mean: -129.940133\n",
      "startIDX:  587\n",
      "878 22 False\n",
      "x_t:  3 [0.459375   0.27916667 0.05625    0.29583333]\n",
      "Q values:  tensor([[-27.4872, -25.7015, -26.4514, -24.1847, -26.2480, -24.8247]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 7133 243 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 878: ep_len:243 episode reward: total was -125.600000. running mean: -129.896731\n",
      "startIDX:  1177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "879 0 False\n",
      "x_t:  2 [0.7375     0.40833333 0.071875   0.28333333]\n",
      "Q values:  tensor([[-26.5665, -25.8559, -24.3753, -26.3002, -24.6666, -24.4120]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 12642 298 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  388\n",
      "879 1 False\n",
      "x_t:  1 [0.63125    0.29166667 0.18125    0.57916667]\n",
      "Q values:  tensor([[-27.0294, -24.0307, -25.4877, -25.4965, -24.9088, -24.0684]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 28106 278 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2389\n",
      "879 5 False\n",
      "x_t:  2 [0.109375   0.39583333 0.109375   0.27083333]\n",
      "Q values:  tensor([[-21.7124, -20.3557, -19.8412, -22.4557, -20.0414, -20.0198]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 21567 943 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1464\n",
      "879 10 False\n",
      "x_t:  4 [0.0125     0.36666667 0.11875    0.27916667]\n",
      "Q values:  tensor([[-20.8944, -20.7583, -21.6162, -21.7148, -20.0198, -20.4763]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 15708 504 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1794\n",
      "879 12 True\n",
      "x_t:  0 [0.6875     0.41666667 0.128125   0.3375    ]\n",
      "Q values:  tensor([[-21.7048, -22.4940, -22.0534, -20.6341, -21.9271, -20.9771]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 21119 608 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1165\n",
      "879 15 False\n",
      "x_t:  4 [0.003125 0.4      0.078125 0.2875  ]\n",
      "Q values:  tensor([[-15.9194, -15.1170, -15.7903, -15.2252, -13.8493, -14.6648]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9809 534 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  1173\n",
      "879 22 True\n",
      "x_t:  1 [0.890625 0.3      0.10625  0.5     ]\n",
      "Q values:  tensor([[-15.3759, -17.2154, -17.0777, -17.7842, -15.5723, -15.0298]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11915 684 0.0001\n",
      "isPresent 1\n",
      "\n",
      "Time elapsed:  10394.514289617538\n",
      "startIDX:  2252\n",
      "880 0 False\n",
      "x_t:  2 [0.9125     0.37916667 0.046875   0.15833333]\n",
      "Q values:  tensor([[-15.1945, -14.4856, -13.5041, -14.8426, -15.0878, -13.9833]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 23569 303 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 880: ep_len:303 episode reward: total was -117.900000. running mean: -136.032077\n",
      "startIDX:  253\n",
      "880 1 False\n",
      "x_t:  2 [0.03125    0.37083333 0.15       0.44166667]\n",
      "Q values:  tensor([[-15.7679, -15.4731, -15.0437, -15.9478, -15.1165, -15.1653]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 27440 824 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 880: ep_len:824 episode reward: total was -352.300000. running mean: -138.194756\n",
      "startIDX:  1464\n",
      "880 5 True\n",
      "x_t:  0 [0.678125   0.40416667 0.115625   0.325     ]\n",
      "Q values:  tensor([[-15.3144, -16.0382, -15.1700, -16.1377, -15.1254, -14.3029]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 13535 499 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 880: ep_len:499 episode reward: total was -209.300000. running mean: -138.905808\n",
      "startIDX:  2112\n",
      "880 10 False\n",
      "x_t:  0 [0.803125   0.3875     0.06875    0.34166667]\n",
      "Q values:  tensor([[-15.0864, -15.9372, -17.3113, -18.6272, -18.2822, -16.1768]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0 0 19955 564 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 880: ep_len:564 episode reward: total was -252.000000. running mean: -140.036750\n",
      "startIDX:  147\n",
      "880 12 True\n",
      "x_t:  2 [0.80625    0.41666667 0.06875    0.23333333]\n",
      "Q values:  tensor([[-20.8086, -17.9251, -18.8634, -19.5309, -18.0971, -17.5079]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 2807 294 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 880: ep_len:294 episode reward: total was -108.900000. running mean: -139.725383\n",
      "startIDX:  968\n",
      "880 15 False\n",
      "x_t:  4 [0.290625   0.37916667 0.090625   0.3       ]\n",
      "Q values:  tensor([[-21.4934, -20.3691, -20.4289, -21.5375, -19.5441, -19.8253]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 9863 661 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 880: ep_len:661 episode reward: total was -252.600000. running mean: -140.854129\n",
      "startIDX:  939\n",
      "880 22 False\n",
      "x_t:  1 [0.00625    0.36666667 0.175      0.39583333]\n",
      "Q values:  tensor([[-16.3901, -16.3192, -16.8894, -17.8374, -17.7752, -16.4872]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9485 221 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 880: ep_len:221 episode reward: total was -69.500000. running mean: -140.140588\n",
      "startIDX:  831\n",
      "881 0 True\n",
      "x_t:  1 [0.328125   0.34583333 0.146875   0.4125    ]\n",
      "Q values:  tensor([[-20.8838, -19.4857, -19.7953, -20.5594, -22.3118, -19.3864]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 9444 217 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  524\n",
      "881 1 False\n",
      "x_t:  1 [0.853125   0.26666667 0.14375    0.4625    ]\n",
      "Q values:  tensor([[-16.2645, -15.1285, -16.5463, -17.8842, -17.6691, -16.0895]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 30681 737 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2237\n",
      "881 5 False\n",
      "x_t:  3 [0.7375     0.32916667 0.10625    0.425     ]\n",
      "Q values:  tensor([[-16.9983, -16.3115, -15.3580, -14.8131, -16.3816, -15.3146]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 19898 210 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2617\n",
      "startIDX:  572\n",
      "881 12 False\n",
      "x_t:  2 [0.003125   0.4125     0.06875    0.25416667]\n",
      "Q values:  tensor([[-18.0056, -17.3171, -16.6628, -18.2217, -17.0343, -16.7362]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 9824 1033 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2120\n",
      "881 15 False\n",
      "x_t:  2 [0.6875     0.4125     0.1        0.25833333]\n",
      "Q values:  tensor([[-17.7845, -17.5135, -17.4762, -17.7489, -18.7547, -17.6167]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "2 2 15581 343 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  2835\n",
      "startIDX:  1235\n",
      "882 0 False\n",
      "x_t:  3 [0.125      0.25416667 0.06875    0.275     ]\n",
      "Q values:  tensor([[-18.0135, -16.5878, -15.2333, -15.0856, -18.4602, -16.0434]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 15177 1256 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 882: ep_len:1256 episode reward: total was -704.400000. running mean: -144.219614\n",
      "startIDX:  1063\n",
      "882 1 True\n",
      "x_t:  3 [0.7625     0.30416667 0.13125    0.41666667]\n",
      "Q values:  tensor([[-22.5522, -21.0737, -21.7482, -20.3557, -23.0430, -20.5837]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 35910 202 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 882: ep_len:202 episode reward: total was -76.100000. running mean: -143.538418\n",
      "startIDX:  1936\n",
      "882 5 False\n",
      "x_t:  3 [0.1625     0.25833333 0.103125   0.32916667]\n",
      "Q values:  tensor([[-17.0771, -16.5821, -16.9561, -15.8590, -17.7377, -16.7640]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "3 3 18229 1283 0.0001\n",
      "isPresent 1\n",
      "\n",
      "ep 882: ep_len:1283 episode reward: total was -807.600000. running mean: -150.179033\n",
      "startIDX:  899\n",
      "882 10 True\n",
      "x_t:  1 [0.859375 0.2875   0.125    0.3375  ]\n",
      "Q values:  tensor([[-23.1735, -21.9262, -21.0626, -22.6916, -21.6291, -21.2132]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "1 1 11330 1618 0.0001\n",
      "isPresent 1\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ad244b8e161d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    204\u001b[0m                             \u001b[0mrew\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtmp_i\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mni\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mni\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrew\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrew\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "policy_net.train()\n",
    "max_ep_len = 200\n",
    "\n",
    "while epoch < numEpoch:\n",
    "#for epoch in range(numEpoch):\n",
    "    # repeat for all pedestrians\n",
    "    #disp(pALL)\n",
    "     \n",
    "    for p in range(pALL.shape[0]): #range(pInLoop.shape[0])\n",
    "        \n",
    "        # load p'th person data\n",
    "        ped = np.copy(pALL[p])\n",
    "\n",
    "        # camera index and frame index starts from zero\n",
    "        ped[:,0] -= 1\n",
    "        ped[:,1] -= 1\n",
    "        #print (np.unique(ped[:,0]))\n",
    "        \n",
    "        # check if camera number is correct\n",
    "        if (ped[:,0] >= num_camera).any():\n",
    "            print ('Error in person ', p)\n",
    "            break\n",
    "            \n",
    "        if ped.shape[0] < 2*max_ep_len:\n",
    "            continue\n",
    "        \n",
    "        # select a camera uniformly\n",
    "        uniq_cam = np.unique(ped[:,0])\n",
    "        if len(uniq_cam) < 2: # and np.random.rand() < 0.9:\n",
    "            continue\n",
    "        rand_cam = uniq_cam[np.random.randint(len(uniq_cam))]\n",
    "        index_of_rand_cam = np.nonzero( ped[:,0]==rand_cam )[0]\n",
    "        len_indices_rand_cam = len(index_of_rand_cam)\n",
    "        \n",
    "        # Initialize with current state with start frame\n",
    "        #tranIDX = np.where(ped[1:,0]-ped[0:-1,0])[0]\n",
    "        #startIDX = np.random.choice(tranIDX) if np.random.rand(1) < 0.6 else np.random.randint( 0,ped.shape[0]-max_ep_len )\n",
    "        startIDX = index_of_rand_cam[np.random.randint(len_indices_rand_cam)]\n",
    "        print ('startIDX: ',startIDX)\n",
    "        myPos = ped[startIDX,0:]\n",
    "        #print (myPos)\n",
    "        \n",
    "        curr_camera = myPos[0]\n",
    "        curr_frame = myPos[1]\n",
    "        tmp_ep = []\n",
    "        rs = []\n",
    "        \n",
    "        # Initialize history variable (one-hot encoding)\n",
    "        ch = np.zeros((h_len,num_camera))\n",
    "        ch[:,curr_camera] = 1\n",
    "        \n",
    "        # initialize total time target was occluded\n",
    "        num_steps = 0\n",
    "        occ_len = 0.0001\n",
    "        \n",
    "        # create initial state (ct,rt,tau_t)\n",
    "        #bbox = myPos[2:]\n",
    "        #rt = afc.find_curr_rt(bbox)\n",
    "        _,state,rt=make_state_vector(ped, curr_camera,curr_frame,ch,occ_len)\n",
    "        stCam = curr_camera\n",
    "        count_curr_c = 0\n",
    "        prev_camera = curr_camera\n",
    "\n",
    "        if render: # show current location\n",
    "            plt.imshow(x.reshape(input_size))\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(plt.gcf())\n",
    "                       \n",
    "        while(curr_frame <= ped[-1,1]):\n",
    "            \n",
    "            if use_cuda:\n",
    "                state_in = Variable(state)\n",
    "                value_c = policy_net(state_in)\n",
    "            else:\n",
    "                state_in = Variable(state)\n",
    "                value_c = policy_net(state_in)\n",
    "            \n",
    "            # epsilon annealing\n",
    "            #gamma = np.min([np.log(epoch+1.1),0.9])\n",
    "            #gamma = gamma.item(0)\n",
    "            epsilon = 1 / np.log(epoch + 0.0000001)\n",
    "                 \n",
    "            # initialize action\n",
    "            one_hot_action = torch.zeros([num_camera], dtype=torch.float32)\n",
    "            if use_cuda:  # put on GPU if CUDA is available\n",
    "                one_hot_action = one_hot_action.cuda()\n",
    "\n",
    "            # epsilon greedy exploration\n",
    "            random_action = np.random.random() <= epsilon\n",
    "            camera_index = [torch.randint(num_camera, torch.Size([]), dtype=torch.int)\n",
    "                            if random_action\n",
    "                            else torch.argmax(value_c)][0]\n",
    "\n",
    "            if use_cuda:  # put on GPU if CUDA is available\n",
    "                camera_index = camera_index.cuda()\n",
    "\n",
    "            one_hot_action[camera_index] = 1\n",
    "            one_hot_action = one_hot_action.unsqueeze(0)\n",
    "            c = camera_index.detach().cpu().numpy()\n",
    "            \n",
    "            # generate random steps\n",
    "            if np.random.rand(1) < 0.2:\n",
    "                rsteps = np.random.randint(5)\n",
    "            else:\n",
    "                rsteps = fpsc\n",
    "            \n",
    "            # find target for the next frame\n",
    "            curr_frame += rsteps #fpsc\n",
    "            num_steps += 1\n",
    "            M[stCam,c] += 1\n",
    "            \n",
    "            # get the current bounding box\n",
    "            bbox = ped[ np.logical_and(ped[:,0]==c,ped[:,1]==curr_frame),2:]\n",
    "            if bbox.shape[0] > 0:\n",
    "                #rt = afc.find_curr_rt(bbox[0]) \n",
    "                bbox = bbox[0]\n",
    "                rt = np.zeros((4))\n",
    "                rt[0] = bbox[0]/320\n",
    "                rt[1] = bbox[1]/240\n",
    "                rt[2] = bbox[2]/320\n",
    "                rt[3] = bbox[3]/240\n",
    "                #print (rt, np.where(rt))\n",
    "                curr_camera = c\n",
    "                #ch = np.zeros((h_len,num_camera))\n",
    "                #num_steps = 0\n",
    "                ispresent = 1\n",
    "                stCam = c\n",
    "            else:\n",
    "                ispresent = 0\n",
    "                \n",
    "            # count the time of prev_camera selection\n",
    "            if ispresent:\n",
    "                occ_len = 0.0001\n",
    "            else:\n",
    "                occ_len += 0.1*rsteps\n",
    "            #if occ_len > occ_max_val:\n",
    "            #    occ_len = occ_max_val+1\n",
    "            #hcount = np.array(-occ_max_val + (occ_len/500)*(occ_max_val-(-occ_max_val)))\n",
    "            hcount = occ_len #np.array(np.log(occ_len))\n",
    "            #hcount = np.array(-2 + (occ_len/occ_max_val)*(2-(-2)))\n",
    "            \n",
    "            # update current state and history\n",
    "            ch[1:,] = ch[0:-1,]\n",
    "            ch[0,0:] = afc.make_one_hot_camera(c)\n",
    "            \n",
    "            # get next camera using policy network\n",
    "            this_cam = np.zeros((num_camera+1))\n",
    "            this_cam[0:num_camera] = afc.make_one_hot_camera(curr_camera)\n",
    "            this_cam[num_camera] = hcount\n",
    "            # make next_state vector\n",
    "            next_state = np.concatenate((this_cam, rt.ravel()))\n",
    "            #next_state = np.concatenate((next_state, hcount)) #.ravel()))\n",
    "            next_state = np.concatenate((next_state, ch.ravel()))\n",
    "\n",
    "            if use_cuda:\n",
    "                next_state = torch.from_numpy(next_state.astype(np.float32)).unsqueeze(0).cuda()\n",
    "            else:\n",
    "                next_state = torch.from_numpy(next_state.astype(np.float32)).unsqueeze(0)\n",
    "                \n",
    "            # get correct label from ground truth\n",
    "            y = afc.find_target_camera(ped, curr_frame)\n",
    "            # get reward (give reward at end of episode)\n",
    "            if y == num_camera-1 and y == c:\n",
    "                reward = 0.1\n",
    "            elif y == c:\n",
    "                reward = 1\n",
    "            else:\n",
    "                reward = -1\n",
    "                 \n",
    "            if np.random.rand() < 0.2 and epoch > 50000:\n",
    "                print (epoch, p, random_action, rsteps)\n",
    "                print ('x_t: ', curr_camera,rt)\n",
    "                #print ( np.where(ch))\n",
    "                print ('Q values: ', value_c)\n",
    "                print (y,c, curr_frame, num_steps, hcount)\n",
    "                print ('isPresent', ispresent)\n",
    "                print ('')\n",
    "                \n",
    "            reward_sum += reward\n",
    "            rs.append(reward)\n",
    "                \n",
    "            # save transition to replay memory\n",
    "            tmp_ep.append((state, one_hot_action, reward, next_state, ispresent))\n",
    "            \n",
    "            state = next_state\n",
    "            \n",
    "            if num_steps >= max_ep_len and c!=num_camera-1 and y == c:  # break the episode\n",
    "                #replay_memory.append((state, one_hot_action, reward, next_state, ispresent))\n",
    "                print (epoch, p, random_action)\n",
    "                print ('x_t: ', curr_camera,rt)\n",
    "                #print ( np.where(ch)[1])\n",
    "                print ('Q values: ', value_c)\n",
    "                print (y,c, curr_frame, num_steps, hcount)\n",
    "                print ('isPresent', ispresent)\n",
    "                print ('')\n",
    "                \n",
    "                # Append to the experience buffer\n",
    "                for tmp_i in range(0,len(tmp_ep)):\n",
    "                    this_tmp = tmp_ep[tmp_i]\n",
    "                    # compute n-step return\n",
    "                    rew = 0\n",
    "                    for ni in range(NBoot):\n",
    "                        if (tmp_i+ni) < len(tmp_ep):\n",
    "                            rew += rs[tmp_i+ni]*(gamma**ni)\n",
    "                    if use_cuda:\n",
    "                        reward = torch.from_numpy(np.array([rew], dtype=np.float32)).unsqueeze(0).cuda()\n",
    "                    else:\n",
    "                        reward = torch.from_numpy(np.array([rew], dtype=np.float32)).unsqueeze(0)\n",
    "                    # get the next state\n",
    "                    next_state = tmp_ep[np.min([tmp_i+NBoot-1,len(tmp_ep)-1])]\n",
    "                    next_state = next_state[3]\n",
    "                    \n",
    "                    replay_memory.append((this_tmp[0],this_tmp[1],reward,next_state,np.min([NBoot,len(tmp_ep)-tmp_i])))\n",
    "                    if len(replay_memory) > replay_memory_size:\n",
    "                        replay_memory.pop(0)\n",
    "                tmp_ep = []\n",
    "                break\n",
    "        \n",
    "        # update value_function\n",
    "        if len(replay_memory) > 0:\n",
    "            loss = backward_network(replay_memory)\n",
    "        \n",
    "        # store episodic reward\n",
    "        rs = append_reward(rs,num_steps)\n",
    "        \n",
    "        # boring book-keeping\n",
    "        running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "        if epoch % 2 == 0:\n",
    "            print ('ep %d: ep_len:%d episode reward: total was %f. running mean: %f' % (epoch, num_steps, reward_sum, running_reward))\n",
    "        #if epoch % 1000 == 1: \n",
    "        #    torch.save(policy_net, backup_fname)\n",
    "        #    #hkl.dump([[episode_reward,validation_reward, running_reward]], backup_fname+'_variables.hkl')\n",
    "            \n",
    "        reward_sum = 0\n",
    "        num_steps = 0\n",
    "        rs = []\n",
    "        \n",
    "    #print (M)\n",
    "    epoch += 1\n",
    "    if epoch % 10 == 0:\n",
    "        t.toc()\n",
    "        print('Time elapsed: ', t.elapsed)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10,2):\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reward received during training\n",
    "rpR = np.vstack(episode_reward)\n",
    "from scipy.signal import savgol_filter\n",
    "yhat = savgol_filter(rpR[:,2], 261, 2) # window size 51, polynomial order 3\n",
    "#plt.plot(rpR[:,4])\n",
    "plt.plot(yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reward received during training\n",
    "vpR = np.vstack(validation_reward)\n",
    "plt.plot(vpR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial position:  [    4 25224    92    91    22    71]\n",
      "Initial position:  [  0 955 225  92  44  85]\n",
      "Initial position:  [    2 23684   215    92    24    73]\n",
      "Initial position:  [   3 2899   23   59   30   72]\n",
      "Initial position:  [  3  25 231  76  34 100]\n",
      "Initial position:  [    4 32615   149    71    10    29]\n",
      "Initial position:  [   3 1365  207   77   34  113]\n",
      "Initial position:  [    4 27660   232    93    34    69]\n",
      "Initial position:  [    3 18808   164    77    61   114]\n",
      "Initial position:  [   4 8496  139   74   25   50]\n",
      "Initial position:  [    2 23134   190    97    41   115]\n",
      "Initial position:  [   1 8903  200   78   55  111]\n",
      "Initial position:  [   4 6802  244   83   33   73]\n",
      "Initial position:  [   4 8320  125   70   20   48]\n",
      "Initial position:  [   0 3868  231  100   25   86]\n",
      "Initial position:  [    0 13845   250    95    19    52]\n",
      "Initial position:  [    4 12847   107    87    24    69]\n",
      "Initial position:  [    4 20597   144    68    12    35]\n",
      "Initial position:  [    4 34388    50    91    26    73]\n",
      "Initial position:  [  4  25 137  73  18  40]\n",
      "Initial position:  [   4 2818  149   69   13   35]\n",
      "Initial position:  [   3 3354   55   58   24   80]\n",
      "Initial position:  [  0 571 241  89  31  90]\n",
      "Initial position:  [   2 6427   53   96   20   52]\n",
      "Person:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.9832214765100671 0.9832214765100671 1.0\n",
      "Num frames:  (298, 5)\n",
      "Accuracy:  0.9832214765100671\n",
      "Person:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.8845052719782138 0.42016806722689076 0.03058103975535168\n",
      "Num frames:  (119, 69)\n",
      "Accuracy:  0.8845052719782138\n",
      "Person:  2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.9081364829396326 0.6533333333333333 0.08404802744425385\n",
      "Num frames:  (75, 26)\n",
      "Accuracy:  0.9081364829396326\n",
      "Person:  3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACOMAAACZCAYAAABn9GyuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFgRJREFUeJzt3XuQZmV9J/DvLzNcAlnkokFk2B2CqEu5UuqoCLUqzK6XxASyIYq1MRNDirileK/VNckSdzVlar1DSjPljVU3SGGyaJaEuIirLoYIRgyChpGAglxEhKjEAeJv/3jPZNumG2b6Pd399vD5VE2dPs95nnOe80//5un3+55T3R0AAAAAAAAAAGB6P7HaEwAAAAAAAAAAgN2FMA4AAAAAAAAAAIxEGAcAAAAAAAAAAEYijAMAAAAAAAAAACMRxgEAAAAAAAAAgJEI4wAAAAAAAAAAwEgeMIxTVe+vqlur6so5bQdW1Ser6pphe8DQXlX1rqraVlVfrqonLOfkAQAAAAAAAABgluzMk3E+mOTZ89pel+Si7j4yyUXDfpI8J8mRw7/Tkrx7nGkCAAAAAAAAAMDse8AwTnd/Jsnt85pPTHL28PPZSU6a0/7fe+Ivk+xfVYeMNVkAAAAAAAAAAJhlO/NknIUc3N03DT/fnOTg4edDk3xzTr8bhjYAAAAAAAAAANjtrZ/2BN3dVdW7Oq6qTsvkVVZZl3VP3Cf7TTuVmfGox9212lMAZtjffnmf1Z7Cgnb87lrN+fn9CQAAAAAAALNvVj/zXE6PetxdufzL22/r7oc9UN+lhnFuqapDuvum4TVUtw7tNyY5bE6/DUPbfXT31iRbk2S/OrCfUpuXOJXZc+GFV6z2FIAZ9qxHHL3aU1jQjt9dqzk/vz8BAAAAAABg9s3qZ57L6cILr8i6Q665fmf6LvU1VR9PsmX4eUuS8+e0/2pNHJPkzjmvswIAAAAAAAAAgN3aAz4Zp6r+KMkzkjy0qm5IckaSNyc5t6pOTXJ9kucN3S9I8rNJtiW5K8mLlmHOAAAAAAAAAAAwkx4wjNPdL1jk0H3eK9XdneQl004KAAAAAAAAAADWoqW+pgoAAAAAAAAAAJhHGAcAAAAAAAAAAEYijAMAAAAAAAAAACMRxgEAAAAAAAAAgJEI4wAAAAAAAAAAwEiEcQAAAAAAAAAAYCTCOAAAAAAAAAAAMBJhHAAAAAAAAAAAGIkwDgAAAAAAAAAAjEQYBwAAAAAAAAAARiKMAwAAAAAAAAAAIxHGAQAAAAAAAACAkQjjAAAAAAAAAADASKYK41TVK6vqK1V1ZVX9UVXtXVWHV9WlVbWtqj5aVXuONVkAAAAAAAAAAJhlSw7jVNWhSV6WZFN3PzbJuiSnJPn9JG/v7kcm+W6SU8eYKAAAAAAAAAAAzLppX1O1PslPVtX6JPskuSnJCUnOG46fneSkKa8BAAAAAAAAAABrwpLDON19Y5K3JPlGJiGcO5NcnuSO7r536HZDkkOnnSQAAAAAAAAAAKwF07ym6oAkJyY5PMkjkuyb5Nm7MP60qrqsqi67J9uXOg0AAAAAAAAAAJgZ07ym6t8k+bvu/nZ335Pkj5Mcl2T/4bVVSbIhyY0LDe7urd29qbs37ZG9ppgGAAAAAAAAAADMhmnCON9IckxV7VNVlWRzkquSXJzk5KHPliTnTzdFAAAAAAAAAABYG5YcxunuS5Ocl+SLSf5mONfWJK9N8qqq2pbkoCTvG2GeAAAAAAAAAAAw89Y/cJfFdfcZSc6Y13xtkidPc14AAAAAAAAAAFiLpnlNFQAAAAAAAAAAMIcwDgAAAAAAAAAAjEQYBwAAAAAAAAAARiKMAwAAAAAAAAAAIxHGAQAAAAAAAACAkQjjAAAAAAAAAADASIRxAAAAAAAAAABgJMI4AAAAAAAAAAAwEmEcAAAAAAAAAAAYiTAOAAAAAAAAAACMRBgHAAAAAAAAAABGIowDAAAAAAAAAAAjEcYBAAAAAAAAAICRTBXGqar9q+q8qvpqVV1dVU+tqgOr6pNVdc2wPWCsyQIAAAAAAAAAwCyb9sk470zy5939mCRHJ7k6yeuSXNTdRya5aNgHAAAAAAAAAIDd3pLDOFX1kCRPS/K+JOnuu7v7jiQnJjl76HZ2kpOmnSQAAAAAAAAAAKwF0zwZ5/Ak307ygar666p6b1Xtm+Tg7r5p6HNzkoOnnSQAAAAAAAAAAKwF04Rx1id5QpJ3d/fjk/wg815J1d2dpBcaXFWnVdVlVXXZPdk+xTQAAAAAAAAAAGA2TBPGuSHJDd196bB/XibhnFuq6pAkGba3LjS4u7d296bu3rRH9ppiGgAAAAAAAAAAMBuWHMbp7puTfLOqHj00bU5yVZKPJ9kytG1Jcv5UMwQAAAAAAAAAgDVi/ZTjT0/ykaraM8m1SV6UScDn3Ko6Ncn1SZ435TUAAAAAAAAAAGBNmCqM091fSrJpgUObpzkvAAAAAAAAAACsRUt+TRUAAAAAAAAAAPDjhHEAAAAAAAAAAGAkwjgAAAAAAAAAADASYRwAAAAAAAAAABiJMA4AAAAAAAAAAIxEGAcAAAAAAAAAAEZS3b3ac8h+dWA/pTav9jRmxoXfuiLPesTRufBbV6z2VAAAAAAAAAAASLLukGsu7+5ND9TPk3EAAAAAAAAAAGAkwjgAAAAAAAAAADASYRwAAAAAAAAAABiJMA4AAAAAAAAAAIxEGAcAAAAAAAAAAEYydRinqtZV1V9X1Z8O+4dX1aVVta2qPlpVe04/TQAAAAAAAAAAmH1jPBnn5UmunrP/+0ne3t2PTPLdJKeOcA0AAAAAAAAAAJh5U4VxqmpDkp9L8t5hv5KckOS8ocvZSU6a5hoAAAAAAAAAALBWTPtknHck+Y9JfjTsH5Tkju6+d9i/IcmhU14DAAAAAAAAAADWhCWHcarquUlu7e7Llzj+tKq6rKouuyfblzoNAAAAAAAAAACYGeunGHtckl+oqp9NsneS/ZK8M8n+VbV+eDrOhiQ3LjS4u7cm2Zok+9WBPcU8AAAAAAAAAABgJiz5yTjd/Z+6e0N3b0xySpJPdfe/T3JxkpOHbluSnD/1LAEAAAAAAAAAYA1Ychjnfrw2yauqaluSg5K8bxmuAQAAAAAAAAAAM2ea11T9k+7+dJJPDz9fm+TJY5wXAAAAAAAAAADWkuV4Mg4AAAAAAAAAADwoCeMAAAAAAAAAAMBIhHEAAAAAAAAAAGAkwjgAAAAAAAAAADASYRwAAAAAAAAAABiJMA4AAAAAAAAAAIxEGAcAAAAAAAAAAEYijAMAAAAAAAAAACMRxgEAAAAAAAAAgJEI4wAAAAAAAAAAwEiEcQAAAAAAAAAAYCTCOAAAAAAAAAAAMBJhHAAAAAAAAAAAGMmSwzhVdVhVXVxVV1XVV6rq5UP7gVX1yaq6ZtgeMN50AQAAAAAAAABgdk3zZJx7k7y6u49KckySl1TVUUlel+Si7j4yyUXDPgAAAAAAAAAA7PaWHMbp7pu6+4vDz99LcnWSQ5OcmOTsodvZSU6adpIAAAAAAAAAALAWTPNknH9SVRuTPD7JpUkO7u6bhkM3Jzl4jGsAAAAAAAAAAMCsmzqMU1U/leRjSV7R3X8/91h3d5JeZNxpVXVZVV12T7ZPOw0AAAAAAAAAAFh1U4VxqmqPTII4H+nuPx6ab6mqQ4bjhyS5daGx3b21uzd196Y9stc00wAAAAAAAAAAgJmw5DBOVVWS9yW5urvfNufQx5NsGX7ekuT8pU8PAAAAAAAAAADWjvVTjD0uyQuT/E1VfWloe32SNyc5t6pOTXJ9kudNN0UAAAAAAAAAAFgblhzG6e7PJalFDm9e6nkBAAAAAAAAAGCtWvJrqgAAAAAAAAAAgB8njAMAAAAAAAAAACMRxgEAAAAAAAAAgJEI4wAAAAAAAAAAwEiEcQAAAAAAAAAAYCTCOAAAAAAAAAAAMBJhHAAAAAAAAAAAGIkwDgAAAAAAAAAAjEQYBwAAAAAAAAAARiKMAwAAAAAAAAAAIxHGAQAAAAAAAACAkQjjAAAAAAAAAADASIRxAAAAAAAAAABgJMsSxqmqZ1fV16pqW1W9bjmuAQAAAAAAAAAAs2b0ME5VrUvyB0mek+SoJC+oqqPGvg4AAAAAAAAAAMya5XgyzpOTbOvua7v77iTnJDlxGa4DAAAAAAAAAAAzZTnCOIcm+eac/RuGNgAAAAAAAAAA2K2tX60LV9VpSU4bdrf/7z7vytWay6xZd0iSXDNsAWB0D01y22pPAgAeJNRdAFhZai8ArBx1F3gw+hc702k5wjg3Jjlszv6Goe3HdPfWJFuTpKou6+5NyzAXAGAedRcAVo66CwArS+0FgJWj7gIsbjleU/WFJEdW1eFVtWeSU5J8fBmuAwAAAAAAAAAAM2X0J+N0971V9dIkFyZZl+T93f2Vsa8DAAAAAAAAAACzZjleU5XuviDJBbswZOtyzAMAWJC6CwArR90FgJWl9gLAylF3ARZR3b3acwAAAAAAAAAAgN3CT6z2BAAAAAAAAAAAYHchjAMAAAAAAAAAACNZtTBOVW2oqvdX1beqantVXVdV76iqA1ZrTgAw64Z62Yv8u3mRMcdW1QVVdXtV/UNVfbmqXlFV6+7nOs+tqk9X1Z1V9f2qurSqtizfnQHA6qmqk6vqzKr6bFX9/VBXP/wAY1akvlbVlqr6q6H/ncP45y71XgFgte1K3a2qjfezBu6qOud+rrNLNbSq1lXVK4ea/g9Djb+gqo4d474BYKVV1UFV9RtV9SdVtW2ob3dW1eeq6tSqWvBzYutdgHFUd6/8RauOSHJJkp9Ocn6SryZ5cpLjk3wtyXHd/Z0VnxgAzLiqui7J/knescDh73f3W+b1PzHJx5L8MMlHk9ye5OeTPDrJed39ywtc46VJzkzynWHM3UlOTrIhyVu7+zVj3Q8AzIKq+lKSo5N8P8kNSR6T5CPd/SuL9F+R+lpVb0ny6mFO5yXZM8kpSQ5Mcnp3n7X0uwaA1bErdbeqNib5uyRXJPmfC5zuyu4+b4Fxu1RDq6qSnJtJbf5akk8MfZ+fZO8kv9Td5+/63QLA6qmqFyd5d5Kbklyc5BtJDk7y75I8JJN17S/3nA+LrXcBxrNaYZwLkzwzycu6+8w57W9L8sokf9jdL17xiQHAjBvCOOnujTvRd78k2zJZWB3X3ZcN7Xsn+VSSpyZ5QXefM2fMxkxCsj9I8sTuvm5oPyDJF5IckeTY7v78SLcEAKuuqo7P5A+A25I8PZM/Ui72oeCK1NfhW/j/N8nXkzypu78751yXJ9k3yWN2nAsA1opdrLsbMwnjnN3dv7aT59/lGlpVL0jyPzL5Aunm7v7h0P6kJJ9LcmeSI7r7e7t4uwCwaqrqhEzq3v/q7h/NaX94kr9KcliSk7v7Y0O79S7AiFb8NVXDU3GemeS6JH8w7/AZmfyyfmFV7bvCUwOA3c3JSR6W5JwdC6ckGf6o+NvD7n+YN+bXk+yV5Ky5i51hQfR7w67ALAC7le6+uLuvmfttwPuxUvV1x/6bdvxhchhzXSZr6b2SvGgn5gsAM2UX6+5SLKWG7qjdv70jiDOM+UIm3/B/WCb/BwCANaO7P9Xdn5gbxBnab07ynmH3GXMOWe8CjGjFwziZvIoqSf5igV/+38skCblPkmNWemIAsEbsVVW/UlWvr6qXV9Xxi7yv94Rh++cLHPtMkruSHFtVe+3kmD+b1wcAHoxWqr6qyQDw/z2iqn5zWAf/ZlU97n767lINHb7tf2wmNfyzOzMGAHYD9wzbe+e0We8CjGg1wjiPHrZ/u8jxa4bto1ZgLgCwFj08yYeSvCnJOzJ5ROg1VfX0ef0WrbndfW8mj/pen+RndnLMTZk8wW5DVe0zzQ0AwBq27PV1eFLsoUm+Pxyfz7oZgAebf5vJN/jfNGyvqKqLq+qfz+20xBp6RJJ1Sa4davnOjAGANauq1if51WF3biDGehdgRKsRxnnIsL1zkeM72vdfgbkAwFrzgSSbMwnk7JvkXyX5wyQbk/xZVR09p+9Sau7OjnnIIscBYHe3EvXVuhkAJu5K8l+TPDHJAcO/pye5OJPXalw0fKi3w3LWaXUXgN3Fm5M8NskF3X3hnHbrXYARrUYYBwBYou5+w/Cu31u6+67uvrK7X5zkbUl+Msnvru4MAQAAYBzdfWt3/+fu/mJ33zH8+0ySZya5NMkjk/zG6s4SANaOqnpZklcn+WqSF67ydAB2a6sRxnmgb9TvaL9jBeYCALuL9wzbp81pW0rN3dkxi31zAQB2dytRX62bAeB+DK/KeO+wu1LrYHUXgDWtql6a5J1JrkpyfHffPq+L9S7AiFYjjPO1YbvYu/6OHLb3ebcgALCobw/buY/nXrTmDu8FPjzJvUmu3ckxhwznv6G775p2wgCwRi17fe3uHyS5MclPDcfns24GgAXWwUusoV9P8o9Jfmao5TszBgDWlKp6RZIzk1yZSRDn5gW6We8CjGg1wjgXD9tnVtWPXb+q/lmS4zJ5F/BfrvTEAGANO2bYzl0IfWrYPnuB/k9Lsk+SS7p7+06Oec68PgDwYLRS9VVNBoD7t9A6ONnFGtrdP0xySSY1/F/vzBgAWEuq6rVJ3p7kS5kEcW5dpKv1LsCIVjyM091fT/IXSTYmecm8w2/IJCH5oSEZCQAMqupfVtW+C7RvTHLWsPvhOYfOS3JbklOqatOc/nsneeOw++55p/tAku1JXjqcd8eYA5K8fth9TwDgwWul6uuO/d8a+u0YszGTtfT24bwAsNuqqifM/0Ln0L45ySuH3Q/PO7yUGrqjdr9xqOk7xjwpyfMzeQrPx5Z2FwCweqrqd5K8OcnlSTZ392330916F2BE1d0rf9GqIzL5tsFPJzk/ydVJnpLk+EweO3Zsd39nxScGADOsqn43yauTfCbJ9Um+l+SIJD+XZO8kFyT5xe6+e86YkzJZRP0wyTlJbk/yC0kePbQ/r+f9Z6CqTk/yriTfSfLRJHcnOTnJhiRv7e7XLNtNAsAqGOrlScPuw5M8K5Nv2X92aLttbv1bqfpaVW9N8qokNwzn3TOTDwQPSnJ6d581fwwAzLpdqbtV9elMXldxSSb1MEkel+SE4eff6e4dHw7OvcYu1dCqqiTnZlKbv5rkE0Pf52ey3v6l7j5/mvsGgJVWVVuSfDCT1zGemeTOBbpd190fnDPGehdgJKsSxkmSqjosyX/J5BFkByW5KcmfJHlDd393VSYFADOsqp6e5MVJHp/JHyz3TXJHJo8X/VAmT5a7T2GvquOS/FaSp2byR8RtSd6f5F3d/Y+LXOvnk7wmyRMyeZLeVUnO6u6zR74tAFh1Q+D1jPvpcn13b5w3ZkXqa1X9WibfDDwqyY+SfDHJf+vuP92JWwOAmbMrdbeqTk3yi0kem+ShSfZIckuSz2dSQz+72El2tYZW1fokpyf59SSPzORDyM8neWN3X7LTNwgAM2Inam6S/J/ufsa8cda7ACNYtTAOAAAAAAAAAADsbu7zvl0AAAAAAAAAAGBphHEAAAAAAAAAAGAkwjgAAAAAAAAAADASYRwAAAAAAAAAABiJMA4AAAAAAAAAAIxEGAcAAAAAAAAAAEYijAMAAAAAAAAAACMRxgEAAAAAAAAAgJEI4wAAAAAAAAAAwEiEcQAAAAAAAAAAYCT/D+TpZQfFXu59AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.9344473007712082 0.7534246575342466 0.2894736842105263\n",
      "Num frames:  (73, 18)\n",
      "Accuracy:  0.9344473007712082\n",
      "Person:  4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.8852387969142758 0.8155339805825242 0.06047516198704104\n",
      "Num frames:  (103, 19)\n",
      "Accuracy:  0.8852387969142758\n",
      "Person:  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.991304347826087 0.991304347826087 1.0\n",
      "Num frames:  (115, 1)\n",
      "Accuracy:  0.991304347826087\n",
      "Person:  6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.9457496796240923 0.7816091954022989 0.38636363636363635\n",
      "Num frames:  (87, 19)\n",
      "Accuracy:  0.9457496796240923\n",
      "Person:  7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.945986124876115 0.8666666666666667 0.1984732824427481\n",
      "Num frames:  (60, 8)\n",
      "Accuracy:  0.945986124876115\n",
      "Person:  8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACOMAAACZCAYAAABn9GyuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAGPxJREFUeJzt3XmwbWV5J+Df670MAYPiRBAoQSQaytJSERUqTqRxjNIJKnSraIi0Xc5D1E4n0XR1Opp2xrSd22rE1oiIplFDREVwCAZFcQQNBKeLII44ICDx7T/WOtbmeC/3nLP3Ge/zVN1ae33rW3t9+/7x1lpn//b3VXcHAAAAAAAAAACY3s1WewAAAAAAAAAAALBRCOMAAAAAAAAAAMCMCOMAAAAAAAAAAMCMCOMAAAAAAAAAAMCMCOMAAAAAAAAAAMCMCOMAAAAAAAAAAMCM7DCMU1VvqqqrquqLE223qqoPVtUl43bvsb2q6rVVdWlVfb6q7rmcgwcAAAAAAAAAgLVkITPjvDnJQ+e1vSjJ2d19SJKzx/0keViSQ8Z/JyV5/WyGCQAAAAAAAAAAa98Owzjd/dEk35/X/Ogkp4yvT0lyzET7W3rwz0luWVX7zmqwAAAAAAAAAACwli1kZpxt2ae7rxhfX5lkn/H1fkm+OdFv69gGAAAAAAAAAAAb3uZp36C7u6p6sedV1UkZlrLKpmy61x7Za9qhrCu/ebdrVnsIAAAAAAAAAMAG8y+f32O1h7DhzGU8Pv35677b3bfdUf+lhnG+XVX7dvcV4zJUV43tlyc5YKLf/mPbr+juLUm2JMledau+Tx21xKGsT2ed9bnVHgIAAAAAAAAAsME85PZ3X+0hbDhzGY9N+17y9YX0X+oyVe9JcsL4+oQkZ0y0P7EG901y9cRyVgAAAAAAAAAAsKHtcGacqnp7kgcmuU1VbU3y4iQvTXJaVZ2Y5OtJHjt2PzPJw5NcmuSaJE9ehjEDAAAAAAAAAMCatMMwTncfv51Dv7KuVHd3kqdNOygAAAAAAAAAAFiPlrpMFQAAAAAAAAAAMI8wDgAAAAAAAAAAzIgwDgAAAAAAAAAAzIgwDgAAAAAAAAAAzIgwDgAAAAAAAAAAzIgwDgAAAAAAAAAAzIgwDgAAAAAAAAAAzIgwDgAAAAAAAAAAzIgwDgAAAAAAAAAAzIgwDgAAAAAAAAAAzIgwDgAAAAAAAAAAzIgwDgAAAAAAAAAAzIgwDgAAAAAAAAAAzMhUYZyqek5VfamqvlhVb6+q3avqoKo6v6ourap3VNWusxosAAAAAAAAAACsZUsO41TVfkmemeSw7r5rkk1JjkvysiSv6u47JflBkhNnMVAAAAAAAAAAAFjrpl2manOSX6uqzUn2SHJFkgcnOX08fkqSY6a8BgAAAAAAAAAArAtLDuN09+VJXp7kGxlCOFcn+XSSH3b3DWO3rUn2m3aQAAAAAAAAAACwHkyzTNXeSR6d5KAkt0+yZ5KHLuL8k6rqgqq64Oe5bqnDAAAAAAAAAACANWOaZap+J8lXu/s73f3zJO9OcmSSW47LViXJ/kku39bJ3b2luw/r7sN2yW5TDAMAAAAAAAAAANaGacI430hy36rao6oqyVFJLkpyTpJjxz4nJDljuiECAAAAAAAAAMD6sOQwTnefn+T0JJ9J8oXxvbYkeWGS51bVpUluneSNMxgnAAAAAAAAAACseZt33GX7uvvFSV48r/myJIdP874AAAAAAAAAALAeTbNMFQAAAAAAAAAAMEEYBwAAAAAAAAAAZkQYBwAAAAAAAAAAZkQYBwAAAAAAAAAAZkQYBwAAAAAAAAAAZkQYBwAAAAAAAAAAZkQYBwAAAAAAAAAAZkQYBwAAAAAAAAAAZkQYBwAAAAAAAAAAZkQYBwAAAAAAAAAAZkQYBwAAAAAAAAAAZkQYBwAAAAAAAAAAZkQYBwAAAAAAAAAAZmSqME5V3bKqTq+qL1fVxVV1v6q6VVV9sKouGbd7z2qwAAAAAAAAAACwlk07M85rkry/u++S5O5JLk7yoiRnd/chSc4e9wEAAAAAAAAAYMNbchinqm6R5P5J3pgk3X19d/8wyaOTnDJ2OyXJMdMOEgAAAAAAAAAA1oNpZsY5KMl3kvxtVV1YVW+oqj2T7NPdV4x9rkyyz7SDBAAAAAAAAACA9WCaMM7mJPdM8vruvkeSn2beklTd3Ul6WydX1UlVdUFVXfDzXDfFMAAAAAAAAAAAYG2YJoyzNcnW7j5/3D89Qzjn21W1b5KM26u2dXJ3b+nuw7r7sF2y2xTDAAAAAAAAAACAtWHJYZzuvjLJN6vqzmPTUUkuSvKeJCeMbSckOWOqEQIAAAAAAAAAwDqxecrzn5HkbVW1a5LLkjw5Q8DntKo6McnXkzx2ymsAAAAAAAAAAMC6MFUYp7s/m+SwbRw6apr3BQAAAAAAAACA9WjJy1QBAAAAAAAAAAA3JowDAAAAAAAAAAAzIowDAAAAAAAAAAAzIowDAAAAAAAAAAAzIowDAAAAAAAAAAAzIowDAAAAAAAAAAAzsnm1B7Czesjt774q1z3rW5/75fXnXgMAAAAAAAAAG4MswOozMw4AAAAAAAAAAMyIMA4AAAAAAAAAAMyIMA4AAAAAAAAAAMyIMA4AAAAAAAAAAMyIMA4AAAAAAAAAAMzI1GGcqtpUVRdW1fvG/YOq6vyqurSq3lFVu04/TAAAAAAAAAAAWPtmMTPOs5JcPLH/siSv6u47JflBkhNncA0AAAAAAAAAAFjzpgrjVNX+SR6R5A3jfiV5cJLTxy6nJDlmmmsAAAAAAAAAAMB6Me3MOK9O8oIkvxj3b53kh919w7i/Ncl+U14DAAAAAAAAAADWhSWHcarqkUmu6u5PL/H8k6rqgqq64Oe5bqnDAAAAAAAAAACANWPzFOcemeRRVfXwJLsn2SvJa5Lcsqo2j7Pj7J/k8m2d3N1bkmxJkr3qVj3FOAAAAAAAAAAAYE1Y8sw43f1funv/7j4wyXFJPtzd/zHJOUmOHbudkOSMqUcJAAAAAAAAAADrwJLDODfhhUmeW1WXJrl1kjcuwzUAAAAAAAAAAGDNmWaZql/q7nOTnDu+vizJ4bN4XwAAAAAAAAAAWE+WY2YcAAAAAAAAAADYKQnjAAAAAAAAAADAjAjjAAAAAAAAAADAjAjjAAAAAAAAAADAjAjjAAAAAAAAAADAjAjjAAAAAAAAAADAjAjjAAAAAAAAAADAjAjjAAAAAAAAAADAjAjjAAAAAAAAAADAjAjjAAAAAAAAAADAjAjjAAAAAAAAAADAjAjjAAAAAAAAAADAjAjjAAAAAAAAAADAjCw5jFNVB1TVOVV1UVV9qaqeNbbfqqo+WFWXjNu9ZzdcAAAAAAAAAABYu6aZGeeGJM/r7kOT3DfJ06rq0CQvSnJ2dx+S5OxxHwAAAAAAAAAANrwlh3G6+4ru/sz4+sdJLk6yX5JHJzll7HZKkmOmHSQAAAAAAAAAAKwH08yM80tVdWCSeyQ5P8k+3X3FeOjKJPvM4hoAAAAAAAAAALDWTR3GqaqbJ3lXkmd3948mj3V3J+ntnHdSVV1QVRf8PNdNOwwAAAAAAAAAAFh1U4VxqmqXDEGct3X3u8fmb1fVvuPxfZNcta1zu3tLdx/W3Yftkt2mGQYAAAAAAAAAAKwJSw7jVFUleWOSi7v7lROH3pPkhPH1CUnOWPrwAAAAAAAAAABg/dg8xblHJnlCki9U1WfHtj9O8tIkp1XViUm+nuSx0w0RAAAAAAAAAADWhyWHcbr740lqO4ePWur7AgAAAAAAAADAerXkZaoAAAAAAAAAAIAbE8YBAAAAAAAAAIAZEcYBAAAAAAAAAIAZEcYBAAAAAAAAAIAZEcYBAAAAAAAAAIAZEcYBAAAAAAAAAIAZEcYBAAAAAAAAAIAZEcYBAAAAAAAAAIAZEcYBAAAAAAAAAIAZEcYBAAAAAAAAAIAZEcYBAAAAAAAAAIAZEcYBAAAAAAAAAIAZEcYBAAAAAAAAAIAZWZYwTlU9tKq+UlWXVtWLluMaAAAAAAAAAACw1sw8jFNVm5L8dZKHJTk0yfFVdeisrwMAAAAAAAAAAGvNcsyMc3iSS7v7su6+PsmpSR69DNcBAAAAAAAAAIA1ZTnCOPsl+ebE/taxDQAAAAAAAAAANrTNq3XhqjopyUnj7nUf6tO/uFpj2Zls2nfu1SUTr4F15jZJvrvagwBYB9RLgIVTMwEWTs0EWBj1EmDh1ExYP+6wkE7LEca5PMkBE/v7j2030t1bkmxJkqq6oLsPW4axAGw4aibAwqiXAAunZgIsnJoJsDDqJcDCqZmw8SzHMlWfSnJIVR1UVbsmOS7Je5bhOgAAAAAAAAAAsKbMfGac7r6hqp6e5Kwkm5K8qbu/NOvrAAAAAAAAAADAWrMcy1Slu89McuYiTtmyHOMA2KDUTICFUS8BFk7NBFg4NRNgYdRLgIVTM2GDqe5e7TEAAAAAAAAAAMCGcLPVHgAAAAAAAAAAAGwUwjgAAAAAAAAAADAjqxbGqar9q+pNVfWtqrquqr5WVa+uqr1Xa0wAy6mqbl1Vf1hVf19Vl1bVz6rq6qr6eFWdWFXbrMlVdURVnVlV3x/P+XxVPbuqNt3EtR5ZVeeO7/+Tqjq/qk5Yvk8HsPyq6vFV1eO/P9xOn0XXv6o6oao+Ofa/ejz/kcvzKQCWT1UdNd5rXjk+Z3+rqs6qqodvo697TGCnVVWPqKoPVNXWsQZeVlXvrKr7bae/mglsWFV1bFWdXFUfq6ofjc/cb93BOStSFz2vA2vJYuplVR1SVS+sqg9X1Ter6vqq+nZVnVFVD9rBdRZV+6pqU1U9Z6zFPxtr85lVdcS0nxmYTnX3yl+06uAk5yW5XZIzknw5yeFJHpTkK0mO7O7vrfjAAJZRVT01yeuTXJHknCTfSLJPkt9Lcosk70rymJ4ozFX16LH92iTvSPL9JL+b5M5JTu/ux2zjOk9PcnKS743nXJ/k2CT7J3lFdz9/mT4iwLKpqgOSfCHJpiQ3T/KU7n7DvD6Lrn9V9fIkz0uyNcnpSXZNclySWyV5Rne/brk+E8AsVdVfJfmjDPXsH5N8N8ltk9wryYe6+wUTfd1jAjutqnpZkhdkqGf/L0O9vFOSRyXZnOSJ3f3Wif5qJrChVdVnk9w9yU8y3EveJcnbuvvx2+m/InXR8zqw1iymXlbVqUkel+SiJB/PUCvvnOGec1OSZ3X3a7dx3qJqX1VVktMy1NSvJHnv2PdxSXZP8vvdfca0nx1YmtUK45yV5Ogkz+zukyfaX5nkOUn+prufuuIDA1hGVfXgJHsm+Yfu/sVE+28k+WSSA5Ic293vGtv3SnJphqDOkd19wdi+e5IPJ7lfkuO7+9SJ9zowQ8Dxp0nu1d1fG9v3TvKpJAcnOaK7P7GcnxVglsaHyg8mOSjJu5M8P/PCOEupf+OvQ/4pyb8muXd3/2DivT6doWbfZe69ANaqqnpKki1JTklyUndfP+/4Lt398/G1e0xgpzU+f1+e5DtJ7tbdV00ce1CGOvjV7r7j2KZmAhveWP+2Zqh3D8jwI8Ltfbm8InXR8zqwFi2yXj4pyee6+8J57Q/I8HfOTnJgd18xcWzRta+qjk/ydxkmwTiqu68d2++dIQR0dZKDu/vHU/8HAIu24stUjbPiHJ3ka0n+et7hF2e4IXtCVe25wkMDWFbd/eHufu9kEGdsvzLJ/x53Hzhx6NgMv2Y+de7Bdux/bZI/GXf/87zL/EGS3ZK8bvKGbLxp+x/jrrAjsN48M8mDkzw5w73itiyl/s3t/8Xcw+14ztcy3KfuNl4TYM2qqt2S/EWGWRd/JYiTJHNBnJF7TGBndocMfw89fzKIkyTdfU6SH2eokXPUTGDD6+5zuvuSydm6b8JK1UXP68Cas5h62d1vnh/EGds/kuTcDDPezF9Gaim1b67m/slcEGc851MZZiK7bYbaDayCFQ/jZFiKKkk+sI0vpH+cIfG3R5L7rvTAAFbR3BckN0y0PXjcvn8b/T+a5JokR4xfwCzknH+c1wdgzauq30ry0iSv6e6P3kTXpdQ/NRPYCP5dhj+uvTvJL6rqEeO69M+qqvtto797TGBndkmGpVEOr6rbTB6oqvsn+fUkH5poVjMBbmyl6qJaCmxk2/o+KFlk7RtnJTsiQ+392ELOAVbWaoRx7jxu/2U7xy8Zt7+5AmMBWHVVtTnJE8fdyZus7dbL7r4hyVczrGd/xwWec0WGGSX2r6o9phw2wLIb6+P/zTDbwx/voPui6t84C+N+SX4yOR3sBPekwHpx73F7bZILk7wvQ4jx1UnOq6qPVNXkLA/uMYGdVnd/P8kLk+yT5KKq2lJVf1lVpyX5QIYlA/7TxClqJsCNLXtd9LwObGRVdYckR2UI0Hx0on0pte/gJJuSXDbW4IWcA6yg1Qjj3GLcXr2d43Ptt1yBsQCsBS9NctckZ3b3WRPtS6mXCz3nFts5DrCW/FmSeyR5Unf/bAd9F1v/3JMCG8Xtxu0fZVhz/rczzOxwtwxfLN8/yTsn+rvHBHZq3f3qJL+X4cvipyR5UZLHJPlmkjfPW75KzQS4sZWoi57XgQ1pnDXsbRmWm3rJ5FJUWd76ql7CKlmNMA4Ao6p6ZpLnJflykies8nAA1oyquk+G2XBe0d2fWO3xAKxhc8/1NyR5VHd/vLt/0t1fSPLvk2xN8oDtLFkFsNOpqhckOT3JmzP8mnjPJPdKclmSt1XVX63e6AAA2IiqalOGGcCPTPKOJC9f3REBK2E1wjg7+vXHXPsPV2AsAKumqp6e5DVJLkryoHG67ElLqZcLPWd7SWmAVTcuT/WWDFNY/+kCT1ts/XNPCmwUc3Xqwu7+2uSB7r4mydzMi4ePW/eYwE6rqh6Y5GVJ3tPdz+3uy7r7mu7+TIYA4+VJnldVc8urqJkAN7YSddHzOrChjEGct2aYjfG0JI/v7p7XbTnrq3oJq2Q1wjhfGbfbW5/ukHH7K+uHAmwUVfXsJCcn+WKGIM6V2+i23Xo5flF9UIZfQF+2wHP2zfCLv63jFzMAa9XNM9Sx30pybVX13L8kLx77/J+x7dXj/qLqX3f/NMOXLTcfj8/nnhRYL+bq3/b+uDY37fWvzevvHhPYGT1y3J4z/8BYwz6Z4e+l9xib1UyAG1v2uuh5HdhIqmqXJG9PclySv0vyH7r7hvn9llj7/jXJvyW541iDF3IOsIJWI4wz97B7dFXd6PpV9esZpue6Jsk/r/TAAFZCVb0wyauSfDZDEOeq7XT98Lh96DaO3T/JHknO6+7rFnjOw+b1AVirrkvyxu38u3Ds8/Fxf24Jq6XUPzUT2AjOTtJJDp3/jD2667j96rh1jwnszHYbt7fdzvG59uvHrZoJcGMrVRfVUmDdq6pdk7wzw4w4b0nyhO7+t5s4ZVG1r7uvTXJehtr72ws5B1hZ9auzYK3ARavOSnJ0kmd298kT7a9M8pwkf9PdT13xgQEss6r60yT/Lcmnkxy9jaWpJvvulSHZvFeSI7v7grF99ww3T/dLcnx3nzpxzkFJLk7y0yT3mluqoKr2TvKpJAcnOaK7PxGAdaiqXpJhdpyndPcbJtoXXf+q6ogk/5Sh1t67u38wth+YoU7vmeQu85d9AVhrquqMJI9K8tzuftVE+9FJ3p9h6uoDu/tq95jAzqyqHpvkHUm+naGeXT5x7GFJ/iFDMHz/7v6emgnsbMbl/M5J8rbufvw2jq9IXfS8Dqx1C6iXuyV5d5KHZ/hB4Und/YsdvOeia19VHZ9hxp3zkhw1BnRSVffO8GPGq5Pcqbt/tPRPCyzVaoVxDs5QFG6X5IwMN2L3SfKgDFNlHdHd31vxgQEso6o6IcmbM0wbeHK2vT7817r7zRPnHJPk9CTXJjk1yfczfNFy57H9sfPXFq2qZyR5bZLvZfgj4/VJjk2yf5JXdPfzZ/m5AFbS9sI447FF17+qekWS5ybZmqGu7prkcUluneQZ3f26ZfswADNSVftneMY+IMNMORdmWCLgmAyz5hzX3e+a6O8eE9gpjTOInZXkd5L8OMnfJ7kyw/Koj0xSSZ7d3a+ZOEfNBDa0sc4dM+7+RpKHZFhm6mNj23cn69ZK1UXP68Bas5h6WVV/m+RJSb6b5H9leDaf79zuPnfeNRZV+6qqkpyWoaZ+Ocl7x76PS7J7kt/v7jOW+pmB6axKGCdJquqADLNDPDRDUbgiwwPwn88l/QA2kokvkG/KR7r7gfPOOzLJf83wy5Ldk1ya5E1JXru9KQ2r6neTPD/JPTMsSXhRktd19ylTfASAVXdTYZzx+KLrX1U9KcnTkhya5BdJPpPkf3b3+2Y9foDlUlW3TfJnGb4I2TfJjzL8QfAvu/uT2+jvHhPYKVXVLhnu/Y7LcP+3R4Yvkj+ZoQZ+YBvnqJnAhrWAv1l+vbsPnHfOitRFz+vAWrKYellV5yZ5wA7e8s+7+yXbuM6TsojaV1WbkzwjyR8kuVOGsOQnkvz37j5vB2MAltGqhXEAAAAAAAAAAGCjudlqDwAAAAAAAAAAADYKYRwAAAAAAAAAAJgRYRwAAAAAAAAAAJgRYRwAAAAAAAAAAJgRYRwAAAAAAAAAAJgRYRwAAAAAAAAAAJgRYRwAAAAAAAAAAJgRYRwAAAAAAAAAAJgRYRwAAAAAAAAAAJgRYRwAAAAAAAAAAJiR/w9Fn3qN0bpjDAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.9478390461997019 0.6607142857142857 0.42045454545454547\n",
      "Num frames:  (56, 19)\n",
      "Accuracy:  0.9478390461997019\n",
      "Person:  9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.9883720930232558 0.9883720930232558 1.0\n",
      "Num frames:  (86, 1)\n",
      "Accuracy:  0.9883720930232558\n",
      "Person:  10\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.8754619958219508 0.4782608695652174 0.028460543337645538\n",
      "Num frames:  (46, 24)\n",
      "Accuracy:  0.8754619958219508\n",
      "Person:  11\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/auxiliary.py:323: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  P = np.sum([p[i]==g[i] and p[i]!=Cx for i in range(len(p))])/np.sum([x!=Cx for x in p])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.01818181818181818 nan 0.0\n",
      "Num frames:  (0, 0)\n",
      "Accuracy:  0.01818181818181818\n",
      "Person:  12\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACOMAAACZCAYAAABn9GyuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAGuZJREFUeJzt3X24b2VZJ/DvLUdAaFSwQgTrEKJlmZORLzClwkxpL0ITvjCjoVFUV5qaXWlvo05Ol02lqTQWiUJqoaGFFmqGoDYahaZmoIKIehAkXzNJELznj7W2s93sc87ev9/ar+fzua5zrb2e9TxrPb9zrn2fZ611/56nujsAAAAAAAAAAMD8brfRHQAAAAAAAAAAgO1CMg4AAAAAAAAAAExEMg4AAAAAAAAAAExEMg4AAAAAAAAAAExEMg4AAAAAAAAAAExEMg4AAAAAAAAAAExkr8k4VfXSqrqhqt6/qOzQqnpzVV05bg8Zy6uqXlhVV1XV+6rqfmvZeQAAAAAAAAAA2ExWMjPOOUketqTsGUku6u5jklw07ifJw5McM/45I8mLp+kmAAAAAAAAAABsfntNxunutyX5zJLik5KcO/58bpKTF5X/cQ/+Lsmdq+rwqToLAAAAAAAAAACb2UpmxlnOYd193fjz9UkOG38+IsnHF9XbNZYBAAAAAAAAAMC2t2PeE3R3V1Wvtl1VnZFhKavsl/2++6Dccd6ubEr3/M4bb1P2ofcdtAE92TwW/k42w9/Dcv8+AAAAAABsfZvhGTTb11Z4v+B3AACms/B//7ved9Onuvsb9lZ/1mScT1bV4d193bgM1Q1j+bVJ7r6o3pFj2W1091lJzkqSO9ah/YA6ccaubG5vetN7b1P2A3e77wb0ZPNY+DvZDH8Py/37AAAAAACw9W2GZ9BsX1vh/YLfAQCYzsL//fsdfuVHV1J/1mWqXpfktPHn05JcsKj8x2vwwCSfX7ScFQAAAAAAAAAAbGt7nRmnqv40yUOSfH1V7UryzCTPTfLqqjo9yUeTPGqsfmGSH0xyVZIbkzxhDfoMAAAAAAAAAACb0l6Tcbr71N0cus26Ut3dSX5u3k4BAAAAAAAAAMBWNOsyVQAAAAAAAAAAwBKScQAAAAAAAAAAYCKScQAAAAAAAAAAYCKScQAAAAAAAAAAYCKScQAAAAAAAAAAYCKScQAAAAAAAAAAYCKScQAAAAAAAAAAYCKScQAAAAAAAAAAYCKScQAAAAAAAAAAYCKScQAAAAAAAAAAYCKScQAAAAAAAAAAYCKScQAAAAAAAAAAYCKScQAAAAAAAAAAYCJzJeNU1VOr6p+r6v1V9adVdWBVHVVVl1bVVVX1qqraf6rOAgAAAAAAAADAZjZzMk5VHZHk55Mc293fkWS/JI9J8ltJnt/d90jy2SSnT9FRAAAAAAAAAADY7OZdpmpHkjtU1Y4kByW5LskJSc4fj5+b5OQ5rwEAAAAAAAAAAFvCzMk43X1tkt9J8rEMSTifT/KuJJ/r7lvGaruSHDFvJwEAAAAAAAAAYCuYZ5mqQ5KclOSoJHdLcnCSh62i/RlVdVlVXfbl3DRrNwAAAAAAAAAAYNOYZ5mq/5zkI939L9395SSvTXJ8kjuPy1YlyZFJrl2ucXef1d3Hdvext88Bc3QDAAAAAAAAAAA2h3mScT6W5IFVdVBVVZITk1ye5OIkp4x1TktywXxdBAAAAAAAAACArWHmZJzuvjTJ+UneneSfxnOdleTpSX6hqq5KcpckZ0/QTwAAAAAAAAAA2PR27L3K7nX3M5M8c0nx1UnuP895AQAAAAAAAABgK5pnmSoAAAAAAAAAAGARyTgAAAAAAAAAADARyTgAAAAAAAAAADARyTgAAAAAAAAAADARyTgAAAAAAAAAADARyTgAAAAAAAAAADARyTgAAAAAAAAAADARyTgAAAAAAAAAADARyTgAAAAAAAAAADARyTgAAAAAAAAAADARyTgAAAAAAAAAADARyTgAAAAAAAAAADARyTgAAAAAAAAAADCRuZJxqurOVXV+VX2gqq6oqgdV1aFV9eaqunLcHjJVZwEAAAAAAAAAYDObd2acFyR5Y3d/a5L7JrkiyTOSXNTdxyS5aNwHAAAAAAAAAIBtb+ZknKq6U5LvS3J2knT3zd39uSQnJTl3rHZukpPn7SQAAAAAAAAAAGwF88yMc1SSf0nysqr6x6p6SVUdnOSw7r5urHN9ksPm7SQAAAAAAAAAAGwF8yTj7EhyvyQv7u7vSvLFLFmSqrs7SS/XuKrOqKrLquqyL+emOboBAAAAAAAAAACbwzzJOLuS7OruS8f98zMk53yyqg5PknF7w3KNu/us7j62u4+9fQ6YoxsAAAAAAAAAALA5zJyM093XJ/l4Vd1rLDoxyeVJXpfktLHstCQXzNVDAAAAAAAAAADYInbM2f5JSV5ZVfsnuTrJEzIk+Ly6qk5P8tEkj5rzGgAAAAAAAAAAsCXMlYzT3e9Jcuwyh06c57wAAAAAAAAAALAVzbxMFQAAAAAAAAAA8LUk4wAAAAAAAAAAwEQk4wAAAAAAAAAAwEQk4wAAAAAAAAAAwEQk4wAAAAAAAAAAwEQk4wAAAAAAAAAAwESquze6D7ljHdoPqBM3uhuwV2/6xHs3ugsAAAAAAAAAwAbY7/Ar39Xdx+6tnplxAAAAAAAAAABgIpJxAAAAAAAAAABgIpJxAAAAAAAAAABgIpJxAAAAAAAAAABgIpJxAAAAAAAAAABgInMn41TVflX1j1X1l+P+UVV1aVVdVVWvqqr95+8mAAAAAAAAAABsflPMjPPkJFcs2v+tJM/v7nsk+WyS0ye4BgAAAAAAAAAAbHpzJeNU1ZFJfijJS8b9SnJCkvPHKucmOXmeawAAAAAAAAAAwFYx78w4v5fkl5J8Zdy/S5LPdfct4/6uJEfMeQ0AAAAAAAAAANgSZk7GqaofTnJDd79rxvZnVNVlVXXZl3PTrN0AAAAAAAAAAIBNY8ccbY9P8oiq+sEkBya5Y5IXJLlzVe0YZ8c5Msm1yzXu7rOSnJUkd6xDe45+AAAAAAAAAADApjDzzDjd/cvdfWR370zymCRv6e7/nuTiJKeM1U5LcsHcvQQAAAAAAAAAgC1g5mScPXh6kl+oqquS3CXJ2WtwDQAAAAAAAAAA2HTmWabqq7r7kiSXjD9fneT+U5wXAAAAAAAAAAC2krWYGQcAAAAAAAAAAPZJknEAAAAAAAAAAGAiknEAAAAAAAAAAGAiknEAAAAAAAAAAGAiknEAAAAAAAAAAGAiknEAAAAAAAAAAGAiknEAAAAAAAAAAGAiknEAAAAAAAAAAGAiknEAAAAAAAAAAGAiknEAAAAAAAAAAGAiknEAAAAAAAAAAGAiknEAAAAAAAAAAGAiknEAAAAAAAAAAGAiMyfjVNXdq+riqrq8qv65qp48lh9aVW+uqivH7SHTdRcAAAAAAAAAADaveWbGuSXJ07r73kkemOTnqureSZ6R5KLuPibJReM+AAAAAAAAAABsezMn43T3dd397vHnLyS5IskRSU5Kcu5Y7dwkJ8/bSQAAAAAAAAAA2ArmmRnnq6pqZ5LvSnJpksO6+7rx0PVJDpviGgAAAAAAAAAAsNnNnYxTVV+X5DVJntLd/7r4WHd3kt5NuzOq6rKquuzLuWnebgAAAAAAAAAAwIabKxmnqm6fIRHnld392rH4k1V1+Hj88CQ3LNe2u8/q7mO7+9jb54B5ugEAAAAAAAAAAJvCzMk4VVVJzk5yRXc/b9Gh1yU5bfz5tCQXzN49AAAAAAAAAADYOnbM0fb4JI9L8k9V9Z6x7FeSPDfJq6vq9CQfTfKo+boIAAAAAAAAAABbw8zJON39t0lqN4dPnPW8AAAAAAAAAACwVc28TBUAAAAAAAAAAPC1JOMAAAAAAAAAAMBEJOMAAAAAAAAAAMBEJOMAAAAAAAAAAMBEJOMAAAAAAAAAAMBEJOMAAAAAAAAAAMBEJOMAAAAAAAAAAMBEJOMAAAAAAAAAAMBEJOMAAAAAAAAAAMBEJOMAAAAAAAAAAMBEJOMAAAAAAAAAAMBEJOMAAAAAAAAAAMBEJOMAAAAAAAAAAMBE1iQZp6oeVlUfrKqrquoZa3ENAAAAAAAAAADYbCZPxqmq/ZL8fpKHJ7l3klOr6t5TXwcAAAAAAAAAADabtZgZ5/5Jruruq7v75iTnJTlpDa4DAAAAAAAAAACbylok4xyR5OOL9neNZQAAAAAAAAAAsK3t2KgLV9UZSc4Yd2/6mz7//RvVF1ip/Q7f6B6wjK9P8qmN7gSwJYkfwKzED2BW4gcwK/EDmJX4AcxK/ABmtd3jxzevpNJaJONcm+Tui/aPHMu+RnefleSsJKmqy7r72DXoC7DNiR/ArMQPYFbiBzAr8QOYlfgBzEr8AGYlfgCzEj8Ga7FM1T8kOaaqjqqq/ZM8Jsnr1uA6AAAAAAAAAACwqUw+M05331JVT0zypiT7JXlpd//z1NcBAAAAAAAAAIDNZi2WqUp3X5jkwlU0OWst+gHsE8QPYFbiBzAr8QOYlfgBzEr8AGYlfgCzEj+AWYkfSaq7N7oPAAAAAAAAAACwLdxuozsAAAAAAAAAAADbhWQcAAAAAAAAAACYyIYl41TVkVX10qr6RFXdVFXXVNXvVdUhG9UnYP1U1V2q6ier6s+r6qqq+veq+nxV/W1VnV5Vt1tSf2dV9R7+nLeHa51WVX9fVf82XuOSqvrhtf+UwFoZxw27iwfX76bNcVV1YVV9Zow576uqp1TVfnu4zg+PMePzYwy5tKpOW7tPBqylqnr8XsYTXVW3Lqpv/AH7mKo6papeVFVvr6p/HX/XX7GXNusyxhBXYHNbTfyoqmOq6ulV9Zaq+nhV3VxVn6yqC6rqobtps7dxzM/spt0dqurZVfXBqvpSVd1QVa+uqm+b8vMDs1tl/Fi3e5Sq2q+qnjqObf59HOtcWFXHTfG5gfmtMn6cs4JnIhctaWP8AdtQrfId7aJ2nn+s0o6NuGhVHZ3kHUm+MckFST6Q5P5JnpzkYVV1fHd/eiP6BqybRyZ5cZLrklyc5GNJDkvyX5O8JMnDq+qR3d1L2r03yV8sc773L3eRqvqdJE9LsivJHyXZP8ljkry+qp7U3WdO8FmAjfH5JL+3TPm/LS2oqpOSvCbJl5K8KslnkvxIkucnOT5DTFra5olJXpTk00lekeTmJKckOaeq7tPdvzjNxwDW0XuSPHs3x743yQlJ3rDMMeMP2Hf8WpL7ZhhP7EryrXuqvF5jDHEFtoTVxI/fSPLoJJcnuTBD7LhXkkckeURVPbm7X7ibthdkGNMsddnSgqo6IMmbM8Sjy5K8IMndM8SmH6qqE7r70r1/NGCNrWr8MVrTe5SqqiTnZRijfDDJmUkOzRC73lZVP9bdF6ygn8DaWk38+Isk1+zm2OOSfEuWfyaSGH/AdrPqd7Sef8ymbvueex0uWvWmJN+f5Oe7+0WLyp+X5KlJ/rC7l82mBLaHqjohycFJ/qq7v7Ko/K5J/j7D4OyU7n7NWL4zyUeSnNvdj1/hNY5L8n+TfDjJ93T3Zxed613j9b+1u6+Z4CMB66iqrkmS7t65grp3THJVkjslOb67LxvLD0zyliQPSnJqd5+3qM3ODMnCX0zy3QtxooYZ/P4hydFJjuvud070kYANVlXvTPLAJCd19+vGsp0x/oB9Sg0zUuzKMHZ4cIaHUq/s7scuU3ddxhjiCmwNq4wfj0/y3u7+xyXlD87w8qqT7Ozu65a0eVmSJ3T3OSvs0y8n+c0k5yd59MLzl/FB+l9kSAa6z+LnMsD6W2X82Jl1uEepqlOT/EmGL1Wf2N1fGsu/J8nfZviC1NHd/YVVflxgQquJH3s4x52TfCLJfkmO6O5PLTr2+Bh/wLYzwztazz9mtO7LVI2z4nx/huzL319y+JkZ/kEeV1UHr3PXgHXU3W/p7tcvHXB19/VJ/mDcfcicl1lI6vtfCwF7vMY1GeLPAUmeMOc1gM3vlCTfkOS8hUFikowPkn5t3P3ZJW1+IkOMOHPxwG6MJb857kochm2iqu6TIRHn2iR/NefpjD9gC+vui7v7ymVm6FzOeo0xxBXYAlYTP7r7nKWJOGP5W5NckuHbn3MtAzPOarEQP35p8fOXcTaLtye5d4YXd8AGWuX4YxazjCUWxjC/tpCIM7b5hwzfhv+GDGMhYANNFD8el+QOSV67OBFnFsYfsDXM8I7W848ZrXsyTpKFdY//epl/4C9kyHY6KMPDcGDf9OVxe8syx+5WVT9dVb8ybr9zD+c5Ydy+cZljb1hSB9h6Dqiqx47x4MlV9dDdrE26p1jwtiQ3JjlunEJ1JW3ED9h+zhi3Z3f3rcscN/4AlrNeYwxxBfYte3omkiT/saqeUlXPqKrHVdWRu6l3dJJvSvKh7v7IMsfFD9ja1uweZfyW+3EZxjJvX0kbYEv7qXF71h7qGH/AvmO5+xHPP2a0YwOuea9x+6HdHL8yw8w590xy0br0CNg0qmpHkh8fd5cLtv9l/LO4zSVJTuvujy0qOzjJEUn+bfG0zotcOW7vOW+fgQ1z1yQvX1L2kap6wviN0gW7HXt09y1V9ZEk355hXeQrVtDmuqr6YpIjq+qg7r5xng8BbKyqukOSxya5NcOayMsx/gCWs+ZjDHEF9i1V9c1JTszwMPttu6n25CX7t1bVS5I8ZfHsFVnZM9hE/ICtai3vUY7OsFzN1d29XGKg+AHbRFU9KMl9MiTPXLyHqsYfsA/Ywztazz9mtBEz49xp3H5+N8cXyu+8Dn0BNp/nJvmOJBd295sWld+Y5DeSfHeSQ8Y/C2ugPiTJRUuWtxNrYHt7WYaH1HfNsE7ofZL8YZKdSd5QVfddVHeWeLDSNnfazXFg63hUht//N3b3x5ccM/4A9mQ9xhjiCuwjxm+RvjLD1OvPWjwt++gjSZ6U4aH2wUnulmEcc02Sn07y0iX1xQ/YntbjHkX8gH3HwkzBf7Sb48YfsG/Z3Ttazz9mtBHJOADLqqqfT/K0JB/IsE7pV3X3Dd39P7r73d39ufHP2zLMpHVpknsk+cl17zSwIbr72eO6pp/s7hu7+/3d/TNJnpdhjeNnbWwPgS1k4cHTHy49YPwBAKyHcbndlyc5PsmrkvzO0jrd/dbuPrO7PzTeA13X3X+W5KFJPpvk1CVfSgC2IfcowFSq6k4ZEmtuTnLOcnWMP2Dfsad3tMxuI5Jx9vZN8oXyz61DX4BNoqqemOQFSS5P8tDu/sxK2o1TpS4sKfF9iw6JNbBv+oNxO288WGmb3WVpA1tAVX17kuOS7Epy4UrbGX8Ao/UYY4grsM2NiTivSPLIJK9O8tju7pW2H2f2WxjHGJfAPmriexTxA/YNj01yUJLXdvenVtPQ+AO2lxW8o/X8Y0YbkYzzwXG7u/W8jhm3u1tPENhmquopSV6U5P0Zgvz1qzzFv4zbr07B2t1fTHJtkq+rqsOXaSPWwPZ0m3iQPYw9xjVQj0pyS5KrV9jm8PH8u7r7xnk7DGyohVlxzu7uW1fZ1vgDWPMxhrgC21tV3T7JnyZ5TJI/SfLfxhfqq7Wq+6CR+AHbz1T3KB9OcmuSbxnHNCtpA2w9PzVubzNT8AoZf8A2sMJ3tJ5/zGgjknEuHrffX1Vfc/2q+g8ZpmO9McnfrXfHgPVXVU9P8vwk78kQ5G+Y4TQPHLdXLyl/y7h92DJtHr6kDrA9LBcP9hQLvi/DN0De0d03rbCN+AHbQFUdmGHK1VuTnD3DKYw/gPUaY4grsA1V1f5J/izDjDh/nORxMyQHL3jAuF08Lvlwko8luWdVHbVMG/EDtp9J7lG6+0tJ3pFhLPO9K2kDbC1V9YAk903yoe6+ZMbTGH/AFreKd7Sef8xo3ZNxuvvDSf46yc4kP7fk8LMzZEG9fMx+Araxqvr1JM9N8q4kJ+5pKsSqut/SBL6x/MQkTx13X7Hk8MJyNb9aVYcsarMzQ/y5KcnLZu0/sDGq6tuq6uBlyncmOXPcXRwPzk/yqSSPqapjF9U/MMlzxt0XLzndyzLEiCeO511oc0iSXxl3/yDAVvbIJIckecM4vfJtGH8Ae7FeYwxxBbaZqjogyZ8nOSlDUvATuvsre2lz7DJlt6uqX07yoAzx6I0Lx8alrhbix/9ePKapqpMyvGC/PMlb5/s0wHpax3uUhTHMc8axzUKb70ny6AwzYrxmtk8BbAILMwWftadKxh+wfa3mHW08/5hZrWIJ4ukuWnV0hszqb0xyQZIrMmRQPjTD1ELHdfen171jwLqpqtOSnJPh2+gvyv9fC3Cxa7r7nLH+JRmmIHtHkl3j8e9McsL4869393OWnqCqfjfJL4xtzk+yf4YbxrskeVJ3n7m0DbC5VdWzkjwtyduSfDTJF5IcneSHkhyYYb3iH+3umxe1OTlDDPhSkvOSfCbJI5Lcayx/VC8ZFFXVk5K8MMmnk7wqyc1JTklyZJLf7e5fXLMPCay5qnp7kv+U5BHd/frd1Lkkxh+wTxnHDCePu3dN8gMZvun59rHsU4vHAOs1xhBXYPNbTfyoqpcleXyGB9r/J8lyD2gvWfxN9arqDFPHvzfD9O13yjDD+HdkmGX8R7v7r5f06YAM3xw9LsllSS5K8k0ZkpJvTnJCd186x8cGJrDK+HFJ1uEepaoqyaszjFE+kOT1Y91HZ3j28mPdfcE8nxuY32rvX8Y2d0zyiSQ7khy5ly9JG3/ANrTad7RjG88/ZrAhyThJUlV3T/I/M0wzdJck12X4Rsizu/uzG9IpYN2ML9OfuZdqb+3uh4z1T0/yoxkGeV+f5PZJPpnknUnO7O637+4kVfX4DBmT907ylSTvTvLb3f2Xc30IYENU1YOT/EyS78pwk3lwks9lmErx5Rlm2LvNAKeqjk/yqxm+tXFgkquSvDTJC3c3HXxV/UiSX0xyvwwzCl6eIeacO/HHAtZRVX1bht/nXUl27iEGGH/APmYF9ykf7e6dS9qsyxhDXIHNbTXxY3yZ/uC9nPLZ3f2sRef/7ST3z/AS/tAMceBjSf4myfO6e+myNAvtDkryjCSnZngR9q9JLknyzO6+fC99ANbBKuPHut2jVNWOJE9K8hNJ7pHh5ds7kzynu9+x4g8IrJkZ719+NkMy8Hndfepezm/8AdvQat/RLmrn+ccqbVgyDgAAAAAAAAAAbDe3WVsUAAAAAAAAAACYjWQcAAAAAAAAAACYiGQcAAAAAAAAAACYiGQcAAAAAAAAAACYiGQcAAAAAAAAAACYiGQcAAAAAAAAAACYiGQcAAAAAAAAAACYiGQcAAAAAAAAAACYiGQcAAAAAAAAAACYiGQcAAAAAAAAAACYyP8DSJMmc7LWLHsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.7119883040935673 0.8860759493670886 0.19635343618513323\n",
      "Num frames:  (158, 18)\n",
      "Accuracy:  0.7119883040935673\n",
      "Person:  13\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.9873417721518988 0.9873417721518988 1.0\n",
      "Num frames:  (79, 1)\n",
      "Accuracy:  0.9873417721518988\n",
      "Person:  14\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.9523809523809523 0.9523809523809523 1.0\n",
      "Num frames:  (21, 1)\n",
      "Accuracy:  0.9523809523809523\n",
      "Person:  15\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.9 0.9 1.0\n",
      "Num frames:  (10, 1)\n",
      "Accuracy:  0.9\n",
      "Person:  16\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.9893617021276596 0.9893617021276596 1.0\n",
      "Num frames:  (94, 1)\n",
      "Accuracy:  0.9893617021276596\n",
      "Person:  17\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.8844455985458323 0.9338842975206612 0.1135678391959799\n",
      "Num frames:  (121, 8)\n",
      "Accuracy:  0.8844455985458323\n",
      "Person:  18\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACOMAAACZCAYAAABn9GyuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFRRJREFUeJzt3X2wbXV5H/Dv470KAcurCSKXKcSg0Th1NHcUxVGBjtEkBpohjk41txbD2ErURKZa25TYaVqcia+YIb0V9WqciIM60IZILGDUmtBcxSiCllsEgYCIiFGQt+TpH3vddHs493I9e+3z+vnMnFl7/dZv7fX8dZ6z9v6e9avuDgAAAAAAAAAAMLtHrHQBAAAAAAAAAACwXgjjAAAAAAAAAADASIRxAAAAAAAAAABgJMI4AAAAAAAAAAAwEmEcAAAAAAAAAAAYiTAOAAAAAAAAAACM5GHDOFX1vqq6vaqunho7rKo+VVXXDdtDh/GqqndX1a6q+nJVPX2exQMAAAAAAAAAwGqyL0/G+UCSFy4Ye1OSy7r7uCSXDftJ8qIkxw0/ZyQ5b5wyAQAAAAAAAABg9XvYME53fybJnQuGT0myY3i9I8mpU+Mf7Im/THJIVR05VrEAAAAAAAAAALCa7cuTcRZzRHffOry+LckRw+ujktw0Ne/mYQwAAAAAAAAAANa9zbO+QXd3VfWPe15VnZHJUlbZlE0/f0AOmrUUAAAAAAAAAADWqCf8k3tWuoS9+sKX77uju3/y4eYtNYzzrao6srtvHZahun0YvyXJ0VPztgxjD9Hd25NsT5KD6rB+Zp28xFIAAAAAAAAAAFjrLr30r1e6hL3adOR1N+7LvKUuU3Vxkm3D621JLpoa//WaOD7J96aWswIAAAAAAAAAgHXtYZ+MU1V/nOT5SR5TVTcnOTvJOUk+WlWnJ7kxyUuG6Zck+cUku5Lck+SVc6gZAAAAAAAAAABWpYcN43T3y/Zw6CHrSnV3J3nNrEUBAAAAAAAAAMBatNRlqgAAAAAAAAAAgAWEcQAAAAAAAAAAYCTCOAAAAAAAAAAAMBJhHAAAAAAAAAAAGIkwDgAAAAAAAAAAjEQYBwAAAAAAAAAARiKMAwAAAAAAAAAAIxHGAQAAAAAAAACAkQjjAAAAAAAAAADASIRxAAAAAAAAAABgJMI4AAAAAAAAAAAwEmEcAAAAAAAAAAAYiTAOAAAAAAAAAACMZKYwTlX9VlV9taqurqo/rqr9q+rYqrqyqnZV1QVV9aixigUAAAAAAAAAgNVsyWGcqjoqyWuTbO3upyTZlOSlSd6a5B3d/TNJvpvk9DEKBQAAAAAAAACA1W7WZao2J/mJqtqc5IAktyY5KcmFw/EdSU6d8RoAAAAAAAAAALAmLDmM0923JPn9JN/MJITzvSRfSHJXdz84TLs5yVGzFgkAAAAAAAAAAGvBLMtUHZrklCTHJnlckgOTvPDHOP+MqtpZVTsfyH1LLQMAAAAAAAAAAFaNWZap+qdJvtHd3+7uB5J8PMkJSQ4Zlq1Kki1Jblns5O7e3t1bu3vrI7PfDGUAAAAAAAAAAMDqMEsY55tJjq+qA6qqkpyc5JokVyQ5bZizLclFs5UIAAAAAAAAAABrw5LDON19ZZILk3wxyVeG99qe5I1JfruqdiU5PMn5I9QJAAAAAAAAAACr3uaHn7Jn3X12krMXDF+f5BmzvC8AAAAAAAAAAKxFsyxTBQAAAAAAAAAATBHGAQAAAAAAAACAkQjjAAAAAAAAAADASIRxAAAAAAAAAABgJMI4AAAAAAAAAAAwEmEcAAAAAAAAAAAYiTAOAAAAAAAAAACMRBgHAAAAAAAAAABGIowDAAAAAAAAAAAjEcYBAAAAAAAAAICRCOMAAAAAAAAAAMBIhHEAAAAAAAAAAGAkwjgAAAAAAAAAADCSmcI4VXVIVV1YVV+rqmur6llVdVhVfaqqrhu2h45VLAAAAAAAAAAArGazPhnnXUk+2d0/m+SpSa5N8qYkl3X3cUkuG/YBAAAAAAAAAGDdW3IYp6oOTvLcJOcnSXff3913JTklyY5h2o4kp85aJAAAAAAAAAAArAWzPBnn2CTfTvL+qrqqqt5bVQcmOaK7bx3m3JbkiFmLBAAAAAAAAACAtWCWMM7mJE9Pcl53Py3J3VmwJFV3d5Je7OSqOqOqdlbVzgdy3wxlAAAAAAAAAADA6jBLGOfmJDd395XD/oWZhHO+VVVHJsmwvX2xk7t7e3dv7e6tj8x+M5QBAAAAAAAAAACrw5LDON19W5KbquqJw9DJSa5JcnGSbcPYtiQXzVQhAAAAAAAAAACsEZtnPP83k3y4qh6V5Pokr8wk4PPRqjo9yY1JXjLjNQAAAAAAAAAAYE2YKYzT3V9KsnWRQyfP8r4AAAAAAAAAALAWLXmZKgAAAAAAAAAA4EcJ4wAAAAAAAAAAwEiEcQAAAAAAAAAAYCTCOAAAAAAAAAAAMBJhHAAAAAAAAAAAGIkwDgAAAAAAAAAAjGTzShcAAAAAAAAAAAC/8LinrnQJD+O6fZrlyTgAAAAAAAAAADASYRwAAAAAAAAAABiJMA4AAAAAAAAAAIxEGAcAAAAAAAAAAEYijAMAAAAAAAAAACOZOYxTVZuq6qqq+h/D/rFVdWVV7aqqC6rqUbOXCQAAAAAAAAAAq98YT8Z5XZJrp/bfmuQd3f0zSb6b5PQRrgEAAAAAAAAAAKveTGGcqtqS5JeSvHfYryQnJblwmLIjyamzXAMAAAAAAAAAANaKWZ+M884k/ybJ3w/7hye5q7sfHPZvTnLUjNcAAAAAAAAAAIA1YclhnKr65SS3d/cXlnj+GVW1s6p2PpD7lloGAAAAAAAAAACsGptnOPeEJL9SVb+YZP8kByV5V5JDqmrz8HScLUluWezk7t6eZHuSHFSH9Qx1AAAAAAAAAADAqrDkJ+N097/t7i3dfUySlya5vLv/eZIrkpw2TNuW5KKZqwQAAAAAAAAAgDVgyWGcvXhjkt+uql1JDk9y/hyuAQAAAAAAAAAAq84sy1T9g+7+dJJPD6+vT/KMMd4XAAAAAAAAAADWknk8GQcAAAAAAAAAADYkYRwAAAAAAAAAABiJMA4AAAAAAAAAAIxEGAcAAAAAAAAAAEYijAMAAAAAAAAAACMRxgEAAAAAAAAAgJEI4wAAAAAAAAAAwEiEcQAAAAAAAAAAYCTCOAAAAAAAAAAAMBJhHAAAAAAAAAAAGIkwDgAAAAAAAAAAjEQYBwAAAAAAAAAARiKMAwAAAAAAAAAAI1lyGKeqjq6qK6rqmqr6alW9bhg/rKo+VVXXDdtDxysXAAAAAAAAAABWr1mejPNgkjd095OTHJ/kNVX15CRvSnJZdx+X5LJhHwAAAAAAAAAA1r0lh3G6+9bu/uLw+vtJrk1yVJJTkuwYpu1IcuqsRQIAAAAAAAAAwFowy5Nx/kFVHZPkaUmuTHJEd986HLotyRFjXAMAAAAAAAAAAFa7mcM4VfXoJB9L8vru/tvpY93dSXoP551RVTuraucDuW/WMgAAAAAAAAAAYMXNFMapqkdmEsT5cHd/fBj+VlUdORw/Msnti53b3du7e2t3b31k9pulDAAAAAAAAAAAWBWWHMapqkpyfpJru/vtU4cuTrJteL0tyUVLLw8AAAAAAAAAANaOzTOce0KSVyT5SlV9aRh7c5Jzkny0qk5PcmOSl8xWIgAAAAAAAAAArA1LDuN09+eS1B4On7zU9wUAAAAAAAAAgLVqyctUAQAAAAAAAAAAP0oYBwAAAAAAAAAARiKMAwAAAAAAAAAAIxHGAQAAAAAAAACAkQjjAAAAAAAAAADASIRxAAAAAAAAAABgJMI4AAAAAAAAAAAwEmEcAAAAAAAAAAAYiTAOAAAAAAAAAACMRBgHAAAAAAAAAABGIowDAAAAAAAAAAAjEcYBAAAAAAAAAICRCOMAAAAAAAAAAMBI5hLGqaoXVtXXq2pXVb1pHtcAAAAAAAAAAIDVZvQwTlVtSvIHSV6U5MlJXlZVTx77OgAAAAAAAAAAsNrM48k4z0iyq7uv7+77k3wkySlzuA4AAAAAAAAAAKwq8wjjHJXkpqn9m4cxAAAAAAAAAABY1zav1IWr6owkZwy79/3PvvDqlaoFgFXrMUnuWOkiAFhV9AYAFqM/ALCQ3gDAYvQHYFb/eF8mzSOMc0uSo6f2twxjP6K7tyfZniRVtbO7t86hFgDWMP0BgIX0BgAWoz8AsJDeAMBi9Adgucxjmaq/SnJcVR1bVY9K8tIkF8/hOgAAAAAAAAAAsKqM/mSc7n6wqs5McmmSTUne191fHfs6AAAAAAAAAACw2sxjmap09yVJLvkxTtk+jzoAWPP0BwAW0hsAWIz+AMBCegMAi9EfgGVR3b3SNQAAAAAAAAAAwLrwiJUuAAAAAAAAAAAA1gthHAAAAAAAAAAAGMmKhXGqaktVva+q/qaq7quqG6rqnVV16ErVBMD8VdVpVXVuVX22qv62qrqq/uhhznl2VV1SVXdW1Q+r6stV9fqq2rRcdQMwP1V1eFW9qqo+UVW7ht/136uqz1XV6VW16H2L/gCw/lXVW6vqsqq6afhdf2dVXVVVZ1fV4Xs4R38A2GCq6uXDZ0xdVa/aw5xfrqpPD/caP6iqK6tq23LXCsB8DN819x5+btvDOe4dgLmp7l7+i1Y9Psnnk/xUkouSfC3JM5KcmOTrSU7o7u8se2EAzF1VfSnJU5P8IMnNSX42yYe7++V7mH9Kko8luTfJBUnuTPLiJE9McmF3/9py1A3A/FTVq5Ocl+TWJFck+WaSI5L8apKDM+kDv9ZTNy/6A8DGUFX3J/likmuS3J7kwCTHJ9ma5G+SHN/dN03N1x8ANpiqOjrJV5JsSvLoJL/R3e9dMOfMJOcm+U4m/eH+JKcl2ZLkbd191rIWDcDoquqGJIckeecih3/Q3b+/YL57B2CuViqMc2mSFyR5bXefOzX+9iS/leS/dverl70wAOauqk7MJISzK8nzMvnSddEwTlUdNMw7OJOg5s5hfP8klyd5VpKXdfdHlql8AOagqk7K5MvVP+nuv58af2yS/53k6CSndffHhnH9AWCDqKr9u/veRcZ/L8mbk5zX3f96GNMfADaYqqokn0pybJKPJzkrC8I4VXVMJv8QfHeSn+/uG4bxQ5P8VZLHJ3l2d//FctYOwLiGME66+5h9mOveAZi7ZV+mangqzguS3JDkDxYcPjuTP4hfUVUHLnNpACyD7r6iu6/rfUuDnpbkJ5N8ZPcfw8N73Jvk3w+7/2oOZQKwjLr78u7+79NBnGH8tiR/OOw+f+qQ/gCwQSwWxBl8dNgeNzWmPwBsPK9NclKSV2by3cJi/mWS/ZK8Z3cQJ0m6+7tJ/vOw65+DATYW9w7A3C17GCeTpaiS5M8W+bD9+0n+V5IDMnnkMAAb20nD9pOLHPtMknuSPLuq9lu+kgBYZg8M2wenxvQHAF48bL88NaY/AGwgVfWkJOckeVd3f2YvU/fWH/50wRwA1rb9qurlVfXmqnpdVZ1YVZsWmefeAZi7zStwzScO2/+zh+PXZfLknCckuWxZKgJgtdpjz+juB6vqG0l+LslPJ7l2OQsDYP6qanOSXx92pz8c0R8ANpiqOivJozN5jPzWJM/JJIhzztQ0/QFggxjuFT6U5JuZLFu4N3vrD7dW1d1JtlTVAd19z7iVArDMHptJf5j2jap6ZXf/+dSYewdg7lYijHPwsP3eHo7vHj9kGWoBYHXTMwA2tnOSPCXJJd196dS4/gCw8ZyV5Iip/U8m+Rfd/e2pMf0BYOP4D0meluQ53f3Dh5m7L/3hwGGeMA7A2vX+JJ9N8tUk388kSHNmkjOS/GlVPau7/3qY694BmLuVWKYKAABgr6rqtUnekORrSV6xwuUAsMK6+7HdXZn8p+uvZvLB+lVV9fSVrQyA5VZVz8zkaThv6+6/WOl6AFgduvst3X15d3+ru+/p7qu7+9VJ3p7kJ5L87spWCGw0KxHG2Z0kPHgPx3eP37UMtQCwuukZABtQVZ2Z5F1JrklyYnffuWCK/gCwQQ0frH8ikyXOD0/ywanD+gPAOjcsT/XBTJYV+Z19PG1f+8Oeno4AwNr2h8P2uVNj7h2AuVuJMM7Xh+0T9nD8uGH7kDX6ANhw9tgzhg9fjk3yYJLrl7MoAOanql6f5NwkV2cSxLltkWn6A8AG1903ZhLa/LmqeswwrD8ArH+PzuT3/JOS3FtVvfsnydnDnP82jL1z2N9bfzgykyWqbu5uS1QBrE+7l7Y9cGrMvQMwdysRxrli2L6gqn7k+lX1j5KckMm6rH+53IUBsOpcPmxfuMix5yY5IMnnu/u+5SsJgHmpqjcmeUeSL2USxLl9D1P1BwCS5HHD9u+Grf4AsP7dl+T8PfxcNcz53LC/ewmrvfWHFy2YA8D6c/ywnQ7WuHcA5m7Zwzjd/X+T/FmSY5K8ZsHht2SSSvxQd9+9zKUBsPpcmOSOJC+tqq27B6tq/yT/adg9byUKA2BcVfU7Sc5J8oUkJ3f3HXuZrj8AbABV9YSqeshj46vqEVX1e0l+KpMPyL87HNIfANa57v5hd79qsZ8kFw/TdgxjFwz7788kxHNmVR2z+72q6tAkbx52dy9hAsAaVFVPqqoDFxk/Jsl7ht0/mjrk3gGYu+ru5b9o1eOTfD6TD00uSnJtkmcmOTGT5ame3d3fWfbCAJi7qjo1yanD7mOT/EImifTPDmN3dPdZC+ZfmOTeJB9JcmeSX0nyxGH8Jb0SzQyA0VTVtiQfyOTJBufm/6/bPe2G7v7A1Dn6A8A6Nyxd+F8yecLBN5J8J8kRSZ6X5KeT3JZJgPOaqXP0B4ANqqp+N5Olqn6ju9+74NhvJnl3Jr3kgiT3JzktyZYkb5v+LAqAtWfoAW9I8pkkNyb5fpLHJ/mlJPsnuSTJP+vu+6fOce8AzNWKhHGSpKqOTvIfM3n81+FJbk3yiSRvmfqPJgDWmakPRvbkxu4+ZsE5JyT5d0melckfzruSvC/Ju7v77x7yDgCsKfvQG5Lkz7v7+QvO0x8A1rGqekqSVyd5TiZflh6S5O5M/pHrTzL5fX/nIufpDwAb0N7COMPxFyc5K8nTM1k14Jok7+nuHctZJwDjq6rnZXLv8LRM/gn4wCR3ZbIU+ocyWZXlIV+Ku3cA5mnFwjgAAAAAAAAAALDePGKlCwAAAAAAAAAAgPVCGAcAAAAAAAAAAEYijAMAAAAAAAAAACMRxgEAAAAAAAAAgJEI4wAAAAAAAAAAwEiEcQAAAAAAAAAAYCTCOAAAAAAAAAAAMBJhHAAAAAAAAAAAGIkwDgAAAAAAAAAAjEQYBwAAAAAAAAAARvL/AJnkOh/LnvqGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.9824561403508771 0.9824561403508771 1.0\n",
      "Num frames:  (57, 1)\n",
      "Accuracy:  0.9824561403508771\n",
      "Person:  19\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.9824561403508771 0.9824561403508771 1.0\n",
      "Num frames:  (57, 1)\n",
      "Accuracy:  0.9824561403508771\n",
      "Person:  20\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.9925373134328358 0.9925373134328358 1.0\n",
      "Num frames:  (134, 1)\n",
      "Accuracy:  0.9925373134328358\n",
      "Person:  21\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.9848484848484849 0.9848484848484849 1.0\n",
      "Num frames:  (66, 1)\n",
      "Accuracy:  0.9848484848484849\n",
      "Person:  22\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.8727650727650728 0.37254901960784315 0.020994475138121547\n",
      "Num frames:  (102, 64)\n",
      "Accuracy:  0.8727650727650728\n",
      "Person:  23\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.8828125 0.7857142857142857 0.8073394495412844\n",
      "Num frames:  (112, 24)\n",
      "Accuracy:  0.8828125\n",
      "0.8929932673214367\n",
      "Average A,P,R,F, ttr 0.8929932673214364 nan 0.5681910467106778 13.791666666666666 [3, 47, 23, 7, 41, 1, 3, 13, 3, 1, 23, 1, 9, 1, 1, 1, 1, 27, 1, 1, 1, 1, 57, 3]\n",
      "2460\n"
     ]
    }
   ],
   "source": [
    "policy_net.eval()\n",
    "req_inc = 0\n",
    "_,acc = test_func(pTest,iloc='fix',eloc='last', fixLoc=25, isdebug=0, req_inc=req_inc)\n",
    "tr_acc = 0\n",
    "A,P,R,F, ttr = [],[],[],[],[]\n",
    "nfr = []\n",
    "for i in range(len(acc)):\n",
    "    print ('Person: ',i)\n",
    "    gt = np.array([d[0] for d in acc[i]])\n",
    "    pr = np.array([d[1] for d in acc[i]])\n",
    "    g = gt #t[gt != num_camera-1]\n",
    "    p = pr #r[gt != num_camera-1]\n",
    "    \n",
    "    # plot transitions\n",
    "    afc.plot_color_transitions(p,g)\n",
    "    # MCTA and number of frames\n",
    "    if req_inc == 1:\n",
    "        ac,pr,re,fr,tr = afc.compute_APRF_one_person_sct_ict(p,g)\n",
    "    else:\n",
    "        ac,pr,re,fr,tr = afc.compute_APRF_one_person_sct_ict(p,g)\n",
    "    A.append(ac)\n",
    "    P.append(pr)\n",
    "    R.append(re)\n",
    "    F.append(fr)\n",
    "    ttr.append(tr)\n",
    "    print ('A,P,R: ', ac,pr,re)\n",
    "    f = afc.compute_num_frames(p,g)\n",
    "    nfr.append(f)\n",
    "    print ('Num frames: ', f)\n",
    "    # Accuracy\n",
    "    tacc = np.sum(g==p, dtype=np.float)/g.shape[0]\n",
    "    tr_acc += tacc\n",
    "    print ('Accuracy: ',tacc)\n",
    "print (tr_acc/len(A))\n",
    "print ('Average A,P,R,F, ttr', np.mean(A),np.mean(P),np.mean(R),np.mean(F), ttr)\n",
    "print (np.sum(nfr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tr_acc = 0\n",
    "for i in range(5):\n",
    "    print ('Person: ',i)\n",
    "    g = np.array([d[0] for d in acc[i]])\n",
    "    p = np.array([d[1] for d in acc[i]])\n",
    "    print (g)\n",
    "    print (p)\n",
    "    tr_acc += np.sum(g==p, dtype=np.float)/g.shape[0]\n",
    "tr_acc/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcta = []\n",
    "nfr = []\n",
    "for i in range(5):\n",
    "    g = np.array([d[0] for d in acc[i]])\n",
    "    p = np.array([d[1] for d in acc[i]])\n",
    "    mcta.append(afc.compute_MCTA(p,g))\n",
    "    nfr.append(afc.compute_num_frames(p,g))\n",
    "print (np.mean(mcta))\n",
    "print (np.sum(nfr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_fname = '/media/win/HRLhkl/Q_CamSel_3L_l4_st200_db3_1tCont_2'\n",
    "hkl.dump([[episode_reward, running_reward]], backup_fname+'_variables.hkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43429448190325176"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "1/np.log(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = 1\n",
    "np.max(pTest[pp][1:,1] - pTest[pp][0:-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
