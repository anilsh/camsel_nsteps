{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as spio\n",
    "#from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from ttictoc import TicToc\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from IPython import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#import cv2 as cv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "import time, math\n",
    " \n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if use_cuda:\n",
    "    print ('CUDA is available')\n",
    "#use_cuda=False   #uncomment this if you dont want to use cuda variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import collections\n",
    "import hickle as hkl\n",
    "\n",
    "sys.path.insert(0, '../data/')\n",
    "import get_pid_train_test as db\n",
    "import auxiliary as af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.path.insert(0,'../py-MDNet/modules')\n",
    "#from sample_generator import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "batch_size = 500\n",
    "replay_memory_size = 4000\n",
    "#epsilon = 0.1\n",
    "gamma = 0.95\n",
    "\n",
    "resume = False # resume from previous checkpoint?\n",
    "render = False\n",
    "eps = np.finfo(np.float32).eps.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of person in data set:  (1, 49)\n",
      "Total number of person in data set:  (1, 49)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "db_no = 4\n",
    "[pALL,num_camera,alltime,fps] = db.get_pid(set_no=db_no, train_flag='train')\n",
    "num_camera += 1  # occlusion is also considered as a FOV\n",
    "fpsc = 2\n",
    "pALL = np.array(pALL)\n",
    "\n",
    "# load test set for current data set\n",
    "[pTest,num_camera,alltime,fps] = db.get_pid(set_no=db_no, train_flag='test')\n",
    "num_camera += 1  # occlusion is also considered as a FOV\n",
    "fpsc = 2\n",
    "pTest = np.array(pTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpoch = 100000\n",
    "d = 10\n",
    "region_size = (d,d)\n",
    "\n",
    "h_len = 200\n",
    "input_size = h_len*(num_camera) + num_camera+4+1\n",
    "\n",
    "# Load auxiliary functions using an object\n",
    "afc = af.AuxiliaryFunction(num_camera=num_camera, d=d, h_len=h_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize required parameters\n",
    "hidden_size1 = 4096+2048\n",
    "hidden_size2 = 2048+1024\n",
    "hidden_size3 = 256+256\n",
    "\n",
    "# Required network\n",
    "class NextCamera(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NextCamera, self).__init__()\n",
    "        \n",
    "        # make decoder layers\n",
    "        self.fch1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fch2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fch3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        #self.fch4 = nn.Linear(hidden_size3, hidden_size4)\n",
    "        self.fco = nn.Linear(hidden_size3, num_camera)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        \n",
    "        # Activation function \n",
    "        #self.tanh = nn.Tanh() #ReLU()\n",
    "        self.relu = nn.ReLU() #ReLU()\n",
    "        #self.linear = nn.Linear() \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.relu(self.fch1(x))\n",
    "        x = self.relu(self.fch2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fch3(x))\n",
    "        x = self.dropout(x)\n",
    "        #x = self.relu(self.fch4(x))\n",
    "        #x = self.dropout(x)\n",
    "        x = self.fco(x)\n",
    "            \n",
    "        return x # nn.functional.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "if use_cuda:\n",
    "    policy_net = NextCamera().cuda()\n",
    "    policy_net.float().cuda()\n",
    "    criterion = nn.MSELoss().cuda()\n",
    "else:\n",
    "    policy_net = NextCamera()\n",
    "    policy_net.float()\n",
    "    criterion = nn.MSELoss()\n",
    "# use ADAM as optimizer since we can load the whole data to train\n",
    "#cls_weights = [1.0,1.0,1.0,1.0,0.1 ]\n",
    "#cls_weights = torch.FloatTensor(cls_weights).cuda()\n",
    "#criterion = nn.CrossEntropyLoss(weight=cls_weights)\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_network(replay_memory):\n",
    "    # sample random minibatch\n",
    "    minibatch = random.sample(replay_memory, min(len(replay_memory), batch_size))\n",
    "    \n",
    "    # unpack minibatch\n",
    "    state = torch.cat(tuple(d[0] for d in minibatch))\n",
    "    action = torch.cat(tuple(d[1] for d in minibatch))\n",
    "    reward = torch.cat(tuple(d[2] for d in minibatch))\n",
    "    next_state = torch.cat(tuple(d[3] for d in minibatch))\n",
    "    nSteps_boot = tuple(d[4] for d in minibatch)\n",
    "    \n",
    "    #print (state.size(), next_state.size(), reward.size(), action.size())\n",
    "\n",
    "    if use_cuda:  # put on GPU if CUDA is available\n",
    "        state = state.cuda()\n",
    "        action = action.cuda()\n",
    "        reward = reward.cuda()\n",
    "        next_state = next_state.cuda()\n",
    "\n",
    "    # get output for the next state\n",
    "    next_output = policy_net(next_state)\n",
    "\n",
    "    # set y_j to r_j for terminal state, otherwise to r_j + gamma*max(Q)\n",
    "    y = torch.cat(tuple(reward[i] if minibatch[i][4]\n",
    "                              else reward[i] + (gamma**(nSteps_boot[i])) * torch.max(next_output[i])\n",
    "                              for i in range(len(minibatch))))\n",
    "\n",
    "    # extract Q-value\n",
    "    q_value = torch.sum(policy_net(state) * action, dim=1)\n",
    "\n",
    "    # PyTorch accumulates gradients by default, so they need to be reset in each pass\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # returns a new Tensor, detached from the current graph, the result will never require gradient\n",
    "    y = y.detach()\n",
    "\n",
    "    #print (y, q_value)\n",
    "    # calculate loss\n",
    "    loss = criterion(q_value, y)\n",
    "\n",
    "    # do backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "def plot_current_state(ped, c,fno):\n",
    "    # load image for current location\n",
    "    img,bb = load_image(ped,c,fno,db_no)\n",
    "\n",
    "    dpi = 80.0\n",
    "    #figsize = (img.size[0]/dpi, img.size[1]/dpi)\n",
    "    figsize = (img.shape[0]/dpi, img.shape[1]/dpi)\n",
    "    fig = plt.figure(frameon=False, figsize=figsize, dpi=dpi)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "\n",
    "    # get image and rect handle\n",
    "    imAX = ax.imshow(img, aspect='normal')\n",
    "    rect = plt.Rectangle(tuple(bb[0,:2]),bb[0,2],bb[0,3], \n",
    "        linewidth=3, edgecolor=\"#ff0000\", zorder=1, fill=False)\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    plt.pause(.01)\n",
    "    plt.draw()\n",
    "    #fig.savefig(os.path.join(savefig_dir,'0000.jpg'),dpi=dpi)\n",
    "    \n",
    "    return imAX, rect\n",
    "    \n",
    "def plot_second(ped,c,curr_frame, imAX,rect):\n",
    "    img,bb =  load_image(ped,c,curr_frame,db_no)\n",
    "    #if np.array(img).shape[0] > 0:\n",
    "    if img != []:\n",
    "        imAX.set_data(img)\n",
    "    #print (bb)\n",
    "\n",
    "    #if bb.shape[0] > 0:\n",
    "    if bb != []:\n",
    "        rect.set_xy(bb[0,:2])\n",
    "        rect.set_width(bb[0,2])\n",
    "        rect.set_height(bb[0,3])\n",
    "        print ('Correct camera')\n",
    "    elif c!= num_camera-1:\n",
    "        print ('Wrong camera')\n",
    "\n",
    "    \n",
    "    display.display(plt.gcf())\n",
    "    plt.pause(1)\n",
    "    plt.draw()\n",
    "    #fig.savefig(os.path.join(savefig_dir,'%04d.jpg'%(i)),dpi=dpi)\n",
    "\n",
    "def get_reward_gt(ped, curr_frame, c):\n",
    "    y = afc.find_target_camera(ped,curr_frame)\n",
    "    # get reward (give reward at end of episode)\n",
    "    if y == num_camera-1 and y == c:\n",
    "        reward = 0.1\n",
    "    elif y == c:\n",
    "        reward = 1\n",
    "    else:\n",
    "        reward = -1\n",
    "        \n",
    "    return reward,y\n",
    "\n",
    "def get_next_step(ped,c,curr_frame, state):\n",
    "    # update current state and history\n",
    "    ispresent,this_state = get_state_vector(ped, c,curr_frame)\n",
    "    if ispresent:\n",
    "        next_state = this_state\n",
    "    else:\n",
    "        # use previous state\n",
    "        next_state = state\n",
    "    \n",
    "    # get correct label from ground truth\n",
    "    reward,y = get_reward_gt(ped, curr_frame,c)\n",
    "\n",
    "    return next_state,reward,y,ispresent\n",
    "\n",
    "def test_func(pTest, iloc='first', eloc='last', fixLoc=-1, isdebug=0, req_inc=1):\n",
    "    policy_net.eval()\n",
    "    rsT,accT = [],[]\n",
    "    \n",
    "    for p in range(pTest.shape[0]): \n",
    "        reward_sum = 0\n",
    "        accP = []\n",
    "        inc = 1\n",
    "        \n",
    "        # load p'th person data\n",
    "        ped = np.copy(pTest[p])\n",
    "        # camera index and frame index starts from zero\n",
    "        ped[:,0] -= 1\n",
    "        ped[:,1] -= 1\n",
    "        \n",
    "        # Initialize with current state with start frame\n",
    "        if iloc == 'first':\n",
    "            startIDX = 0\n",
    "        elif iloc == 'rand':\n",
    "            startIDX = np.random.randint( 0,ped.shape[0]-20 )\n",
    "        elif iloc == 'fix':\n",
    "            startIDX = fixLoc\n",
    "        myPos = ped[startIDX,0:]\n",
    "        print ('Initial position: ',myPos)\n",
    "        \n",
    "        curr_camera = myPos[0]\n",
    "        curr_frame = myPos[1]\n",
    "        \n",
    "        # Initialize history variable (one-hot encoding)\n",
    "        ch = np.zeros((h_len,num_camera))\n",
    "        ch[:,curr_camera] = 1\n",
    "        occ_len = 0.0001\n",
    "        # Make initial state\n",
    "        _,state,rt = make_state_vector(ped, curr_camera,curr_frame, ch,occ_len)\n",
    "        #print (state.size())\n",
    "        num_steps = 0\n",
    "        #prev_camera = curr_camera\n",
    "        count_curr_c = 0\n",
    "        \n",
    "        if render: # show current location\n",
    "            plot_current_state(ped, curr_camera,curr_frame)\n",
    "\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(plt.gcf())\n",
    "\n",
    "\n",
    "        while(curr_frame <= ped[-1,1]): # alltime-6):\n",
    "            if use_cuda:\n",
    "                state_in = Variable(state)\n",
    "                value_c = policy_net(state_in)\n",
    "            else:\n",
    "                state_in = Variable(state)\n",
    "                value_c = policy_net(state_in)\n",
    "                \n",
    "            # Only exploitation for testing\n",
    "            camera_index = torch.argmax(value_c)\n",
    "            c = camera_index.detach().cpu().numpy()\n",
    "\n",
    "            # find target for the next frame\n",
    "            curr_frame += fpsc\n",
    "            num_steps += 1\n",
    "            \n",
    "            # get correct label from ground truth\n",
    "            reward,y = get_reward_gt(ped, curr_frame,c)\n",
    "            if req_inc:\n",
    "                if inc==1 and y!=num_camera-1:\n",
    "                     # inside a camera\n",
    "                    accP.append((y,y))\n",
    "                elif inc==0 and y==c.item(0) and y!=num_camera-1:\n",
    "                    # transitioning to second camera\n",
    "                    accP.append((y,c.item(0)))\n",
    "                    inc = 1\n",
    "                elif inc==1 and y==num_camera-1:\n",
    "                    # moving out of a camera FOV\n",
    "                    inc = 0\n",
    "                    accP.append((y,c.item(0)))\n",
    "                else:\n",
    "                    # Making transition\n",
    "                    accP.append((y,c.item(0)))\n",
    "                    #print ('Another case',y,c.item(0))\n",
    "                    \n",
    "            else:\n",
    "                    accP.append((y,c.item(0)))\n",
    "            \n",
    "            # get the current bounding box\n",
    "            bbox = ped[ np.logical_and(ped[:,0]==c,ped[:,1]==curr_frame),2:]\n",
    "            if bbox.shape[0] > 0: # and np.random.rand < 0.95:\n",
    "                bbox = bbox[0]\n",
    "                rt = np.zeros((4))\n",
    "                rt[0] = bbox[0]/320\n",
    "                rt[1] = bbox[1]/240\n",
    "                rt[2] = bbox[2]/320\n",
    "                rt[3] = bbox[3]/240\n",
    "                curr_camera = c\n",
    "                \n",
    "                ispresent = 1\n",
    "                \n",
    "            else:\n",
    "                ispresent = 0\n",
    "                \n",
    "            # count the time of prev_camera selection\n",
    "            if ispresent:\n",
    "                occ_len = 0.0001\n",
    "            else:\n",
    "                occ_len += fpsc\n",
    "            if occ_len > occ_max_val:\n",
    "                occ_len = occ_max_val+1\n",
    "                \n",
    "            #hcount = np.array(-2 + (occ_len/occ_max_val)*(2-(-2)))\n",
    "            hcount = occ_len #np.array(np.log(occ_len))\n",
    "            # update current state and history\n",
    "            ch[1:,] = ch[0:-1,]\n",
    "            ch[0,0:] = afc.make_one_hot_camera(c)\n",
    "                \n",
    "            if isdebug:\n",
    "                print ('x_t: ', curr_camera,rt)\n",
    "                print ( np.where(ch))\n",
    "                print ('Q values: ', value_c)\n",
    "                print (c, curr_frame, hcount)\n",
    "                print ('isPresent', ispresent)\n",
    "                print ('')\n",
    "            \n",
    "            # get next camera using policy network\n",
    "            this_cam = np.zeros((num_camera+1))\n",
    "            this_cam[0:num_camera] = afc.make_one_hot_camera(curr_camera)\n",
    "            this_cam[num_camera] = hcount\n",
    "            # make next_state vector\n",
    "            next_state = np.concatenate((this_cam, rt.ravel()))\n",
    "            #next_state = np.concatenate((next_state, hcount)) #.ravel()))\n",
    "            next_state = np.concatenate((next_state, ch.ravel()))\n",
    "            if use_cuda:\n",
    "                next_state = torch.from_numpy(next_state.astype(np.float32)).unsqueeze(0).cuda()\n",
    "            else:\n",
    "                next_state = torch.from_numpy(next_state.astype(np.float32)).unsqueeze(0)\n",
    "                \n",
    "            # get next state\n",
    "            #next_state,reward,y,ispresent = get_next_step(ped,c,curr_frame, state)\n",
    "            \n",
    "            # store current reward\n",
    "            reward_sum += reward\n",
    "                        \n",
    "            state = next_state\n",
    "            prev_camera = c\n",
    "            \n",
    "            if render:\n",
    "                plot_second()\n",
    "            if eloc != 'last':\n",
    "                if num_steps > eloc:\n",
    "                    break\n",
    "            \n",
    "        # stack episodic reward \n",
    "        rsT.append((reward_sum,num_steps))\n",
    "        accT.append(accP)\n",
    "        \n",
    "    return rsT, accT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_sum = 0\n",
    "running_reward = None\n",
    "xs,rs,cprs = [],[],[]\n",
    "episode_number = 0\n",
    "episode_durations = []\n",
    "episode_reward = []\n",
    "validation_reward= []\n",
    "replay_memory = []\n",
    "M = np.zeros((num_camera,num_camera))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model if required\n",
    "resume = False\n",
    "backup_fname = './models/Q_db4_xywh_10log'\n",
    "if resume:\n",
    "    policy_net = torch.load(backup_fname)\n",
    "    policy_net.eval()\n",
    "    print ('Model loaded')\n",
    "    #episode_reward,running_reward = hkl.load(backup_fname+'_variables.hkl')\n",
    "    print ('episodic reward loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_state_vector(ped, curr_camera,curr_frame, ch,occ_len):\n",
    "    numSamples = 30\n",
    "    overlap_thres = [0.9, 1]\n",
    "        \n",
    "    # read image\n",
    "    img,bbox,p = afc.load_image(ped,curr_camera,curr_frame,db_no)\n",
    "    imw, imh = (320,240) #img.size\n",
    "    #print (img.size)\n",
    "    #hc = np.array(-occ_max_val + (occ_len/500)*(occ_max_val-(-occ_max_val)))\n",
    "    #hc = np.array(-2 + (occ_len/occ_max_val)*(2-(-2)))\n",
    "    hc = occ_len #np.array(np.log(occ_len))\n",
    "    \n",
    "    if p:\n",
    "        ## Draw samples\n",
    "        #examples = gen_samples(SampleGenerator('gaussian', img.size, 0.1, 1.2),\n",
    "        #                       bbox, numSamples, overlap_thres)  # 50 samples with 0.8 overlap\n",
    "        ##print (examples.shape)\n",
    "        #samples = examples[np.random.randint(len(examples))].reshape(1,4)\n",
    "        ##print (samples)\n",
    "        ##rt = afc.find_curr_rt(samples[0])\n",
    "        #bbox = samples[0]\n",
    "        rt = np.zeros((4))\n",
    "        rt[0] = bbox[0]/imw\n",
    "        rt[1] = bbox[1]/imh\n",
    "        rt[2] = bbox[2]/imw\n",
    "        rt[3] = bbox[3]/imh\n",
    "        #print (np.where(rt.ravel()))\n",
    "        \n",
    "        # make next_state vector\n",
    "        this_cam = np.zeros((num_camera+1))\n",
    "        this_cam[0:num_camera] = afc.make_one_hot_camera(curr_camera)\n",
    "        this_cam[num_camera] = hc\n",
    "        state = np.concatenate((this_cam, rt.ravel()))\n",
    "        #state = np.concatenate((state, hc)) #.ravel()))\n",
    "        state = np.concatenate((state, ch.ravel()))\n",
    "        state = state.reshape(1,-1)\n",
    "        \n",
    "        if use_cuda:\n",
    "            state = torch.from_numpy(state).float().cuda()\n",
    "        else:\n",
    "            state = torch.from_numpy(state).float()\n",
    "    else:\n",
    "        print ('Target is not present in ',c,curr_frame)\n",
    "        state = []\n",
    "    \n",
    "    return p,state,rt\n",
    "\n",
    "def append_reward(rs,num_steps):\n",
    "    if len(rs) > 0:\n",
    "        # stack episodic reward \n",
    "        epR = np.vstack(rs)\n",
    "        rs = []\n",
    "\n",
    "        # append the episodic reward\n",
    "        #episode_number += 1\n",
    "        #episode_durations.append(num_steps)\n",
    "        reward_stat = [num_steps,np.std(epR),np.sum(epR)]\n",
    "        episode_reward.append(reward_stat)\n",
    "    \n",
    "    return rs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "occ_max_val = 50\n",
    "NBoot = 20\n",
    "t = TicToc('episodic')\n",
    "t.tic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startIDX:  1413\n",
      "1111 0 False 1\n",
      "x_t:  3 [0.4375     0.3        0.1        0.34583333]\n",
      "Q values:  tensor([[3.5345, 4.3643, 4.1254, 6.1037, 3.9695, 2.9076]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 15251 3 0.0001\n",
      "isPresent 1\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.475      0.2875     0.103125   0.36666667]\n",
      "Q values:  tensor([[3.1821, 3.8578, 4.9484, 6.2487, 3.7394, 2.2121]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 15255 5 0.0001\n",
      "isPresent 1\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.4875     0.3        0.11875    0.37083333]\n",
      "Q values:  tensor([[1.8992, 2.6415, 4.9116, 6.1752, 3.8076, 2.5078]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 15257 6 0.0001\n",
      "isPresent 1\n",
      "\n",
      "1111 0 True 2\n",
      "x_t:  3 [0.4875     0.3125     0.13125    0.35416667]\n",
      "Q values:  tensor([[4.5338, 4.0793, 4.1983, 6.4546, 4.5000, 3.4729]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 15259 7 0.0001\n",
      "isPresent 1\n",
      "\n",
      "1111 0 True 2\n",
      "x_t:  3 [0.5625     0.30833333 0.121875   0.38333333]\n",
      "Q values:  tensor([[4.4888, 4.4598, 5.2397, 6.5281, 5.1838, 3.1796]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 0 15272 12 2.0001\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.678125   0.325      0.13125    0.40416667]\n",
      "Q values:  tensor([[4.4890, 4.5222, 5.6472, 8.1440, 5.2817, 3.7543]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 15285 18 0.0001\n",
      "isPresent 1\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.69375    0.33333333 0.15       0.40833333]\n",
      "Q values:  tensor([[4.1191, 3.8042, 4.4524, 6.8969, 4.9747, 3.3334]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 15289 20 0.0001\n",
      "isPresent 1\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.7875     0.34583333 0.178125   0.40833333]\n",
      "Q values:  tensor([[4.4746, 4.1359, 4.6439, 7.0206, 5.1755, 3.4379]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 15300 25 0.0001\n",
      "isPresent 1\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.79375 0.35    0.18125 0.4125 ]\n",
      "Q values:  tensor([[2.2696, 2.3010, 4.2457, 5.0006, 2.8464, 1.2988]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 15302 26 0.0001\n",
      "isPresent 1\n",
      "\n",
      "1111 0 True 2\n",
      "x_t:  3 [0.79375 0.35    0.18125 0.4125 ]\n",
      "Q values:  tensor([[2.1512, 2.6795, 3.7987, 4.3285, 2.8606, 2.3816]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 5 15304 27 2.0001\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[4.3697, 3.4082, 5.5622, 6.6979, 3.5965, 2.8589]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "3 3 15308 29 0.0001\n",
      "isPresent 1\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[3.6849, 3.3979, 3.6206, 4.5714, 3.7188, 3.1575]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "5 3 15310 30 2.0001\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.7417, -3.0566, -2.6805, -2.2547, -3.1454, -1.9192]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15318 34 10.0001\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-3.1415, -2.7034, -2.9964, -2.2471, -3.8217, -1.4935]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15322 36 14.0001\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-3.2653, -3.1949, -3.0996, -2.7133, -3.3960, -1.2855]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15328 38 20.0001\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.9325, -2.5252, -2.7994, -1.9809, -2.9353, -0.5992]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15338 43 30.0001\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.2178, -2.1343, -2.4582, -2.1623, -2.2174, -0.4759]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15358 53 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 0\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.7151, -2.2836, -2.5542, -2.4560, -2.4465, -0.5380]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15360 56 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 True 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.5430, -1.7739, -2.0726, -1.9404, -1.9862, -0.2927]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 1 15367 59 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.3601, -1.6732, -1.5980, -1.4927, -1.9131, -0.2288]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15398 76 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.3721, -1.3932, -1.6915, -1.6443, -1.6771, -0.2854]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15402 78 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.7897, -1.4974, -1.6942, -1.6107, -1.7070, -0.1701]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15410 82 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.6055, -1.4457, -1.4584, -1.5730, -1.6724, -0.2748]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15414 85 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 True 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.5002, -1.2654, -1.6081, -1.5637, -1.8295, -0.0639]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 0 15439 98 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 True 0\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.2000, -1.0779, -1.3685, -1.3521, -1.5145,  0.0073]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 4 15445 102 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 0\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-0.9987, -1.0588, -1.1488, -1.0897, -1.0500, -0.0680]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15458 110 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 True 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.3588, -1.2778, -1.3468, -1.3400, -1.6137, -0.2267]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15470 117 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 1\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.0984, -0.9101, -1.3347, -1.0576, -1.2395, -0.0651]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15475 120 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.4265, -1.1000, -1.4212, -1.2331, -1.4329, -0.1560]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15487 126 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.2329, -1.2091, -1.2915, -1.3311, -1.4916, -0.1279]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15491 128 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 4\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.3531, -1.0545, -1.1270, -1.0135, -1.1933, -0.2955]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15499 131 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.0726, -1.0521, -1.0523, -1.0833, -1.1602, -0.1684]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15503 133 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.3784, -1.1026, -1.1428, -1.3182, -1.3766, -0.1883]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15507 135 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.2980, -1.1789, -1.2936, -1.2717, -1.4726, -0.0864]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15511 137 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.2229, -1.2210, -1.3253, -1.3500, -1.4581,  0.0043]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15515 139 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 4\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.3301, -0.9401, -1.3568, -1.1861, -1.3233, -0.2876]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15527 144 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.1957, -0.9980, -1.2269, -0.9536, -1.1580, -0.3115]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15531 146 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-0.9816, -0.9608, -1.2689, -1.0632, -1.1792, -0.0976]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15533 147 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.4965, -1.2013, -1.5093, -1.2710, -1.4144, -0.1033]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15539 150 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.2976, -1.1778, -1.2307, -1.2974, -1.5504, -0.2491]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15541 151 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 4\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-0.8030, -0.9797, -0.9336, -1.0263, -0.9700, -0.3074]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15555 157 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.3467, -1.1704, -1.2510, -1.3748, -1.2548, -0.2544]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15563 162 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-0.9629, -1.0644, -1.0526, -1.0810, -1.2122, -0.2940]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15575 168 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.5131, -1.4962, -1.5602, -1.5377, -1.5482, -0.5102]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15585 174 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.1443, -1.0488, -1.0695, -1.1333, -1.2492, -0.3763]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15591 177 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.3461, -1.3834, -1.4521, -1.2659, -1.3679, -0.5140]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15597 180 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.4883, -1.3878, -1.5979, -1.5986, -1.4972, -0.5078]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15603 183 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q values:  tensor([[-1.6650, -1.5221, -1.6470, -1.5322, -1.5638, -0.6269]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15609 186 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.4217, -1.4510, -1.5537, -1.3507, -1.6259, -0.6029]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15623 193 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.4301, -1.5295, -1.4110, -1.4458, -1.4966, -0.5877]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15627 195 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.7069, -1.7430, -1.8822, -1.4899, -1.6478, -0.8061]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15637 200 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 True 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.8616, -2.3154, -1.9341, -1.8625, -2.0476, -0.9652]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 0 15653 209 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.1615, -1.7411, -2.4571, -1.5959, -2.2782, -1.0372]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15706 235 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 4\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.3754, -2.4715, -2.4268, -2.1576, -1.9473, -1.2895]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15724 244 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.1875, -2.4816, -2.0840, -2.2033, -2.3958, -1.2162]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15726 245 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.0112, -2.0200, -2.0492, -1.7157, -2.3967, -1.1739]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15730 247 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.2115, -2.3576, -2.6259, -2.1177, -2.5002, -1.1548]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15742 253 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 1\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.2920, -1.8486, -1.9104, -1.7181, -2.0918, -0.9056]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15743 254 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.1228, -2.2871, -2.4001, -2.2321, -2.2371, -1.1792]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15749 257 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.0107, -2.1069, -2.0402, -1.9790, -2.1044, -0.9537]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15771 267 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 True 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.2736, -2.4571, -2.6360, -2.0756, -2.5356, -1.1338]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 3 15775 269 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 1\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.2423, -2.4420, -2.4809, -2.1816, -2.3412, -1.2338]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15778 271 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.0619, -2.0593, -2.3857, -1.9095, -2.2731, -1.1369]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15782 273 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.1015, -2.0773, -2.0548, -2.0067, -2.1837, -1.0767]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15793 280 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.2342, -1.7554, -2.0456, -1.8000, -1.9588, -1.0022]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15797 282 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 4\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.3682, -2.2596, -2.5358, -2.4294, -2.4147, -1.1537]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15815 291 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.1570, -2.0597, -2.6822, -1.9257, -2.4716, -1.0932]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15820 294 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 True 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.2767, -2.4031, -2.3786, -2.3108, -1.9696, -1.1151]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 1 15838 302 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 True 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.2611, -1.7765, -2.5085, -1.8740, -1.9891, -1.0881]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 0 15852 308 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.3783, -2.2929, -2.6783, -1.8165, -2.5011, -1.1117]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15885 323 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.2198, -2.3276, -2.7442, -2.0197, -2.4193, -1.2661]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15893 327 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 True 1\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.2548, -1.9286, -2.0905, -1.9166, -2.4096, -1.0505]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 3 15904 334 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 4\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.4199, -1.8866, -1.7452, -1.8364, -1.7245, -0.8108]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15914 338 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.2594, -2.3209, -2.5355, -2.2422, -2.3126, -1.0980]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15927 345 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.1823, -2.2830, -2.0991, -1.9493, -1.8154, -1.1381]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15935 349 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 4\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.2403, -2.5934, -1.8970, -2.2355, -1.8969, -1.2084]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15965 361 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.3966, -2.2778, -2.1765, -2.3595, -2.0860, -1.0915]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 15975 366 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 True 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.1214, -1.8965, -2.0165, -1.9653, -1.9712, -1.0433]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 2 15993 373 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.4510, -2.5180, -2.3900, -2.2351, -2.3227, -1.2572]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16007 381 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.3350, -2.0050, -2.2143, -1.9727, -2.1811, -1.2905]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16013 384 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.9179, -1.6390, -1.9906, -1.7404, -2.0181, -1.0002]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16023 389 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.0510, -1.9062, -2.1573, -1.9247, -2.0228, -1.1018]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16029 392 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.4187, -1.9067, -1.4857, -1.5817, -2.0494, -1.0588]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16031 393 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.6007, -2.1624, -2.6256, -2.1398, -2.2778, -1.3017]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16037 397 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.9128, -2.1930, -1.6818, -2.0144, -2.0544, -0.9535]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16041 399 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 True 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.6105, -2.8783, -2.7438, -2.4366, -2.8330, -1.2912]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16063 411 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 True 1\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.6439, -1.6971, -1.9957, -1.7523, -1.9634, -1.0510]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16073 417 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.1670, -2.4843, -2.4632, -2.3405, -2.2345, -1.2161]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16075 418 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.6312, -2.3842, -2.2251, -2.2103, -2.0627, -1.1858]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16087 425 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.4583, -2.5872, -2.6518, -2.1464, -2.3529, -1.1466]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16089 426 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 3\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.1406, -2.4316, -1.8626, -2.2657, -2.3151, -1.1519]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16092 427 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.1956, -1.8746, -2.0381, -1.9013, -2.0261, -1.1240]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16100 431 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.2042, -2.0949, -2.2977, -1.8670, -2.3225, -1.0854]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16102 432 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 3\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.1545, -2.2854, -1.8209, -2.0705, -2.2196, -1.2126]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16107 434 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q values:  tensor([[-2.8921, -3.1583, -2.5605, -2.8654, -2.7833, -1.5071]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16111 436 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 True 3\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.9325, -1.5367, -1.3680, -1.5479, -1.3147, -0.8390]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16142 454 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.9461, -2.2698, -2.0495, -1.6377, -2.1942, -1.0513]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16146 456 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.4653, -2.1056, -2.6565, -1.9044, -2.1734, -1.1061]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16160 463 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.6561, -2.5858, -2.6835, -2.5301, -2.7632, -1.3761]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16167 466 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 4\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.3529, -2.1625, -2.2694, -2.1174, -2.2126, -1.3184]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16171 467 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.9852, -2.2250, -1.7582, -1.8474, -1.8571, -1.0477]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16173 468 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.3705, -2.1428, -2.4531, -2.0725, -2.1662, -1.2092]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16189 475 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.2306, -2.6426, -2.0439, -2.2516, -2.2008, -1.1950]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16200 481 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.3604, -2.2528, -2.4040, -2.0152, -1.9985, -1.1222]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16204 483 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.2896, -2.6201, -2.4968, -2.3906, -2.6060, -1.1910]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16208 485 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 True 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.4598, -2.8144, -2.4882, -2.3652, -2.6086, -1.2365]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 1 16228 496 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.7780, -2.3322, -2.6394, -2.2254, -2.5899, -1.1679]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16232 498 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 True 0\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.7559, -1.9147, -1.6075, -1.8499, -1.9114, -0.9649]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 3 16249 512 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.1255, -2.3728, -2.1023, -2.2310, -2.4030, -1.1486]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16251 513 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.8680, -1.8706, -1.9500, -1.9275, -1.9536, -0.9443]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16263 520 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 0\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.5132, -2.0570, -2.3900, -1.9599, -2.3085, -1.1633]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16263 521 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.2532, -2.4588, -2.0698, -2.6243, -1.9813, -1.1446]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16279 529 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.3428, -2.0978, -1.9639, -1.8448, -2.0143, -1.1341]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "5 5 16283 531 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.0430, -2.0000, -2.0565, -1.8186, -1.7759, -0.9668]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 5 16287 533 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.5225, -2.5784, -2.3899, -2.1262, -2.5389, -1.2599]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 5 16289 535 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 True 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.7765, -1.9089, -1.5206, -2.0159, -1.6815, -1.0660]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 3 16295 539 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 0\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-2.1903, -2.2359, -2.2070, -2.1266, -2.2066, -1.0617]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 5 16295 540 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 False 2\n",
      "x_t:  3 [0.915625 0.3375   0.078125 0.4375  ]\n",
      "Q values:  tensor([[-1.5144, -1.5839, -1.5056, -1.6231, -1.5218, -0.9138]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 5 16299 542 51\n",
      "isPresent 0\n",
      "\n",
      "1111 0 True\n",
      "x_t:  4 [0.15     0.3875   0.121875 0.275   ]\n",
      "Q values:  tensor([[-2.6429, -2.1603, -2.5822, -2.0361, -2.6721, -1.1753]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "4 4 16309 547 0.0001\n",
      "isPresent 1\n",
      "\n",
      "startIDX:  981\n",
      "1111 1 True 4\n",
      "x_t:  4 [0.046875   0.3875     0.09375    0.41666667]\n",
      "Q values:  tensor([[4.2906, 3.4899, 4.1347, 4.5532, 6.5484, 3.4750]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "4 3 35433 1 4.0001\n",
      "isPresent 0\n",
      "\n",
      "1111 1 False 2\n",
      "x_t:  4 [0.096875   0.37916667 0.134375   0.4125    ]\n",
      "Q values:  tensor([[3.1722, 3.1545, 3.2579, 3.9191, 4.7477, 3.4579]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "4 4 35439 4 0.0001\n",
      "isPresent 1\n",
      "\n",
      "1111 1 False 2\n",
      "x_t:  4 [0.13125    0.37916667 0.10625    0.4125    ]\n",
      "Q values:  tensor([[4.4506, 4.7850, 4.4783, 3.9615, 5.5067, 4.6126]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "4 4 35441 5 0.0001\n",
      "isPresent 1\n",
      "\n",
      "1111 1 True 3\n",
      "x_t:  4 [0.153125   0.37083333 0.08125    0.42083333]\n",
      "Q values:  tensor([[4.9450, 4.2555, 4.0304, 4.8673, 6.8043, 4.2582]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "4 0 35446 7 3.0001\n",
      "isPresent 0\n",
      "\n",
      "1111 1 False 4\n",
      "x_t:  4 [0.275      0.375      0.09375    0.40833333]\n",
      "Q values:  tensor([[4.1660, 4.3555, 3.4565, 3.1744, 5.4666, 3.8820]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "4 4 35460 13 0.0001\n",
      "isPresent 1\n",
      "\n",
      "1111 1 False 2\n",
      "x_t:  4 [0.2875     0.375      0.128125   0.40416667]\n",
      "Q values:  tensor([[4.1774, 3.7969, 3.4399, 4.2026, 5.8967, 3.8775]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "4 4 35462 14 0.0001\n",
      "isPresent 1\n",
      "\n",
      "1111 1 False 0\n",
      "x_t:  4 [0.2875     0.375      0.128125   0.40416667]\n",
      "Q values:  tensor([[4.5106, 4.4662, 4.7561, 4.3182, 5.7556, 4.3483]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "4 4 35462 15 0.0001\n",
      "isPresent 1\n",
      "\n",
      "1111 1 True 0\n",
      "x_t:  4 [0.3        0.38333333 0.128125   0.39166667]\n",
      "Q values:  tensor([[3.7483, 4.2544, 4.8292, 3.6505, 5.6962, 4.3804]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "4 2 35466 18 0.0001\n",
      "isPresent 0\n",
      "\n",
      "1111 1 False 1\n",
      "x_t:  4 [0.30625    0.37916667 0.121875   0.39166667]\n",
      "Q values:  tensor([[4.5222, 3.7852, 4.0239, 4.2251, 5.4211, 3.5680]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "4 4 35467 19 0.0001\n",
      "isPresent 1\n",
      "\n",
      "1111 1 False 2\n",
      "x_t:  4 [0.3625   0.375    0.103125 0.4     ]\n",
      "Q values:  tensor([[3.9793, 3.7102, 3.5394, 3.8320, 4.8825, 3.6565]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "4 4 35488 30 0.0001\n",
      "isPresent 1\n",
      "\n",
      "1111 1 False 2\n",
      "x_t:  4 [0.35625    0.37083333 0.103125   0.38333333]\n",
      "Q values:  tensor([[4.3387, 4.6016, 5.5287, 4.6983, 6.0028, 6.0574]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "4 5 35500 36 2.0001\n",
      "isPresent 0\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-2c7a358bc26b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mstate_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0mvalue_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mstate_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-d4c7255df5e4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfch1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfch2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "policy_net.train()\n",
    "max_ep_len = 200\n",
    "\n",
    "while epoch < numEpoch:\n",
    "#for epoch in range(numEpoch):\n",
    "    # repeat for all pedestrians\n",
    "    #disp(pALL)\n",
    "     \n",
    "    for p in range(pALL.shape[0]): #range(pInLoop.shape[0])\n",
    "        \n",
    "        # load p'th person data\n",
    "        ped = np.copy(pALL[p])\n",
    "\n",
    "        # camera index and frame index starts from zero\n",
    "        ped[:,0] -= 1\n",
    "        ped[:,1] -= 1\n",
    "        #print (np.unique(ped[:,0]))\n",
    "        \n",
    "        # check if camera number is correct\n",
    "        if (ped[:,0] >= num_camera).any():\n",
    "            print ('Error in person ', p)\n",
    "            break\n",
    "            \n",
    "        if ped.shape[0] < 2*max_ep_len:\n",
    "            continue\n",
    "        \n",
    "        # select a camera uniformly\n",
    "        uniq_cam = np.unique(ped[:,0])\n",
    "        if len(uniq_cam) < 2: # and np.random.rand() < 0.9:\n",
    "            continue\n",
    "        rand_cam = uniq_cam[np.random.randint(len(uniq_cam))]\n",
    "        index_of_rand_cam = np.nonzero( ped[:,0]==rand_cam )[0]\n",
    "        len_indices_rand_cam = len(index_of_rand_cam)\n",
    "        \n",
    "        # Initialize with current state with start frame\n",
    "        #tranIDX = np.where(ped[1:,0]-ped[0:-1,0])[0]\n",
    "        #startIDX = np.random.choice(tranIDX) if np.random.rand(1) < 0.6 else np.random.randint( 0,ped.shape[0]-max_ep_len )\n",
    "        startIDX = index_of_rand_cam[np.random.randint(len_indices_rand_cam)]\n",
    "        print ('startIDX: ',startIDX)\n",
    "        myPos = ped[startIDX,0:]\n",
    "        #print (myPos)\n",
    "        \n",
    "        curr_camera = myPos[0]\n",
    "        curr_frame = myPos[1]\n",
    "        tmp_ep = []\n",
    "        rs = []\n",
    "        \n",
    "        # Initialize history variable (one-hot encoding)\n",
    "        ch = np.zeros((h_len,num_camera))\n",
    "        ch[:,curr_camera] = 1\n",
    "        \n",
    "        # initialize total time target was occluded\n",
    "        num_steps = 0\n",
    "        occ_len = 0.0001\n",
    "        \n",
    "        # create initial state (ct,rt,tau_t)\n",
    "        #bbox = myPos[2:]\n",
    "        #rt = afc.find_curr_rt(bbox)\n",
    "        _,state,rt=make_state_vector(ped, curr_camera,curr_frame,ch,occ_len)\n",
    "        stCam = curr_camera\n",
    "        count_curr_c = 0\n",
    "        prev_camera = curr_camera\n",
    "\n",
    "        if render: # show current location\n",
    "            plt.imshow(x.reshape(input_size))\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(plt.gcf())\n",
    "                       \n",
    "        while(curr_frame <= ped[-1,1]):\n",
    "            \n",
    "            if use_cuda:\n",
    "                state_in = Variable(state)\n",
    "                value_c = policy_net(state_in)\n",
    "            else:\n",
    "                state_in = Variable(state)\n",
    "                value_c = policy_net(state_in)\n",
    "            \n",
    "            # epsilon annealing\n",
    "            epsilon = 1 / np.log(epoch + 0.0000001)\n",
    "                 \n",
    "            # initialize action\n",
    "            one_hot_action = torch.zeros([num_camera], dtype=torch.float32)\n",
    "            if use_cuda:  # put on GPU if CUDA is available\n",
    "                one_hot_action = one_hot_action.cuda()\n",
    "\n",
    "            # epsilon greedy exploration\n",
    "            random_action = np.random.random() <= epsilon\n",
    "            camera_index = [torch.randint(num_camera, torch.Size([]), dtype=torch.int)\n",
    "                            if random_action\n",
    "                            else torch.argmax(value_c)][0]\n",
    "\n",
    "            if use_cuda:  # put on GPU if CUDA is available\n",
    "                camera_index = camera_index.cuda()\n",
    "\n",
    "            one_hot_action[camera_index] = 1\n",
    "            one_hot_action = one_hot_action.unsqueeze(0)\n",
    "            c = camera_index.detach().cpu().numpy()\n",
    "            \n",
    "            # generate random steps\n",
    "            if np.random.rand(1) < 0.2:\n",
    "                rsteps = np.random.randint(5)\n",
    "            else:\n",
    "                rsteps = fpsc\n",
    "            \n",
    "            # find target for the next frame\n",
    "            curr_frame += rsteps #fpsc\n",
    "            num_steps += 1\n",
    "            M[stCam,c] += 1\n",
    "            \n",
    "            # get the current bounding box\n",
    "            bbox = ped[ np.logical_and(ped[:,0]==c,ped[:,1]==curr_frame),2:]\n",
    "            if bbox.shape[0] > 0:\n",
    "                #rt = afc.find_curr_rt(bbox[0]) \n",
    "                bbox = bbox[0]\n",
    "                rt = np.zeros((4))\n",
    "                rt[0] = bbox[0]/320\n",
    "                rt[1] = bbox[1]/240\n",
    "                rt[2] = bbox[2]/320\n",
    "                rt[3] = bbox[3]/240\n",
    "                #print (rt, np.where(rt))\n",
    "                curr_camera = c\n",
    "                #ch = np.zeros((h_len,num_camera))\n",
    "                #num_steps = 0\n",
    "                ispresent = 1\n",
    "                stCam = c\n",
    "            else:\n",
    "                ispresent = 0\n",
    "                \n",
    "            # count the time of prev_camera selection\n",
    "            if ispresent:\n",
    "                occ_len = 0.0001\n",
    "            else:\n",
    "                occ_len += rsteps\n",
    "            if occ_len > occ_max_val:\n",
    "                occ_len = occ_max_val+1\n",
    "            #hcount = np.array(-occ_max_val + (occ_len/500)*(occ_max_val-(-occ_max_val)))\n",
    "            hcount = occ_len #np.array(np.log(occ_len))\n",
    "            #hcount = np.array(-2 + (occ_len/occ_max_val)*(2-(-2)))\n",
    "            \n",
    "            # update current state and history\n",
    "            ch[1:,] = ch[0:-1,]\n",
    "            ch[0,0:] = afc.make_one_hot_camera(c)\n",
    "            \n",
    "            # get next camera using policy network\n",
    "            this_cam = np.zeros((num_camera+1))\n",
    "            this_cam[0:num_camera] = afc.make_one_hot_camera(curr_camera)\n",
    "            this_cam[num_camera] = hcount\n",
    "            # make next_state vector\n",
    "            next_state = np.concatenate((this_cam, rt.ravel()))\n",
    "            #next_state = np.concatenate((next_state, hcount)) #.ravel()))\n",
    "            next_state = np.concatenate((next_state, ch.ravel()))\n",
    "\n",
    "            if use_cuda:\n",
    "                next_state = torch.from_numpy(next_state.astype(np.float32)).unsqueeze(0).cuda()\n",
    "            else:\n",
    "                next_state = torch.from_numpy(next_state.astype(np.float32)).unsqueeze(0)\n",
    "                \n",
    "            # get correct label from ground truth\n",
    "            y = afc.find_target_camera(ped, curr_frame)\n",
    "            # get reward (give reward at end of episode)\n",
    "            if y == num_camera-1 and y == c:\n",
    "                reward = 0.1\n",
    "            elif y == c:\n",
    "                reward = 1\n",
    "            else:\n",
    "                reward = -1\n",
    "                 \n",
    "            if np.random.rand() < 0.2 and epoch > 500:\n",
    "                print (epoch, p, random_action, rsteps)\n",
    "                print ('x_t: ', curr_camera,rt)\n",
    "                #print ( np.where(ch))\n",
    "                print ('Q values: ', value_c)\n",
    "                print (y,c, curr_frame, num_steps, hcount)\n",
    "                print ('isPresent', ispresent)\n",
    "                print ('')\n",
    "                \n",
    "            reward_sum += reward\n",
    "            rs.append(reward)\n",
    "                \n",
    "            # save transition to replay memory\n",
    "            tmp_ep.append((state, one_hot_action, reward, next_state, ispresent))\n",
    "            \n",
    "            state = next_state\n",
    "            \n",
    "            if num_steps >= max_ep_len and c!=num_camera-1 and y == c:  # break the episode\n",
    "                #replay_memory.append((state, one_hot_action, reward, next_state, ispresent))\n",
    "                print (epoch, p, random_action)\n",
    "                print ('x_t: ', curr_camera,rt)\n",
    "                #print ( np.where(ch)[1])\n",
    "                print ('Q values: ', value_c)\n",
    "                print (y,c, curr_frame, num_steps, hcount)\n",
    "                print ('isPresent', ispresent)\n",
    "                print ('')\n",
    "                \n",
    "                # Append to the experience buffer\n",
    "                for tmp_i in range(0,len(tmp_ep)):\n",
    "                    this_tmp = tmp_ep[tmp_i]\n",
    "                    # compute n-step return\n",
    "                    rew = 0\n",
    "                    for ni in range(NBoot):\n",
    "                        if (tmp_i+ni) < len(tmp_ep):\n",
    "                            rew += rs[tmp_i+ni]*(gamma**ni)\n",
    "                    if use_cuda:\n",
    "                        reward = torch.from_numpy(np.array([rew], dtype=np.float32)).unsqueeze(0).cuda()\n",
    "                    else:\n",
    "                        reward = torch.from_numpy(np.array([rew], dtype=np.float32)).unsqueeze(0)\n",
    "                    # get the next state\n",
    "                    next_state = tmp_ep[np.min([tmp_i+NBoot-1,len(tmp_ep)-1])]\n",
    "                    next_state = next_state[3]\n",
    "                    \n",
    "                    replay_memory.append((this_tmp[0],this_tmp[1],reward,next_state,np.min([NBoot,len(tmp_ep)-tmp_i])))\n",
    "                    if len(replay_memory) > replay_memory_size:\n",
    "                        replay_memory.pop(0)\n",
    "                tmp_ep = []\n",
    "                break\n",
    "        \n",
    "        # update value_function\n",
    "        if len(replay_memory) > 0:\n",
    "            loss = backward_network(replay_memory)\n",
    "        \n",
    "        # store episodic reward\n",
    "        rs = append_reward(rs,num_steps)\n",
    "        \n",
    "        # boring book-keeping\n",
    "        running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "        if epoch % 2 == 0:\n",
    "            print ('ep %d: ep_len:%d episode reward: total was %f. running mean: %f' % (epoch, num_steps, reward_sum, running_reward))\n",
    "        #if epoch % 1000 == 1: \n",
    "        #    torch.save(policy_net, backup_fname)\n",
    "        #    #hkl.dump([[episode_reward,validation_reward, running_reward]], backup_fname+'_variables.hkl')\n",
    "            \n",
    "        reward_sum = 0\n",
    "        num_steps = 0\n",
    "        rs = []\n",
    "        \n",
    "    #print (M)\n",
    "    epoch += 1\n",
    "    if epoch % 10 == 0:\n",
    "        t.toc()\n",
    "        print('Time elapsed: ', t.elapsed)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "nSteps_boot = tuple(d[4] for d in replay_memory)\n",
    "print ((nSteps_boot[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reward received during training\n",
    "rpR = np.vstack(episode_reward)\n",
    "from scipy.signal import savgol_filter\n",
    "yhat = savgol_filter(rpR[:,2], 261, 2) # window size 51, polynomial order 3\n",
    "#plt.plot(rpR[:,4])\n",
    "plt.plot(yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reward received during training\n",
    "vpR = np.vstack(validation_reward)\n",
    "plt.plot(vpR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial position:  [    4 25224    92    91    22    71]\n",
      "Initial position:  [  0 955 225  92  44  85]\n",
      "Initial position:  [    2 23684   215    92    24    73]\n",
      "Initial position:  [   3 2899   23   59   30   72]\n",
      "Initial position:  [  3  25 231  76  34 100]\n",
      "Initial position:  [    4 32615   149    71    10    29]\n",
      "Initial position:  [   3 1365  207   77   34  113]\n",
      "Initial position:  [    4 27660   232    93    34    69]\n",
      "Initial position:  [    3 18808   164    77    61   114]\n",
      "Initial position:  [   4 8496  139   74   25   50]\n",
      "Initial position:  [    2 23134   190    97    41   115]\n",
      "Initial position:  [   1 8903  200   78   55  111]\n",
      "Initial position:  [   4 6802  244   83   33   73]\n",
      "Initial position:  [   4 8320  125   70   20   48]\n",
      "Initial position:  [   0 3868  231  100   25   86]\n",
      "Initial position:  [    0 13845   250    95    19    52]\n",
      "Initial position:  [    4 12847   107    87    24    69]\n",
      "Initial position:  [    4 20597   144    68    12    35]\n",
      "Initial position:  [    4 34388    50    91    26    73]\n",
      "Initial position:  [  4  25 137  73  18  40]\n",
      "Initial position:  [   4 2818  149   69   13   35]\n",
      "Initial position:  [   3 3354   55   58   24   80]\n",
      "Initial position:  [  0 571 241  89  31  90]\n",
      "Initial position:  [   2 6427   53   96   20   52]\n",
      "Person:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.12751677852348994 0.47435897435897434 0.12627986348122866\n",
      "Num frames:  (78, 4)\n",
      "Accuracy:  0.12751677852348994\n",
      "Person:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.886739752810558 0.8095238095238095 0.010397553516819572\n",
      "Num frames:  (21, 4)\n",
      "Accuracy:  0.886739752810558\n",
      "Person:  2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d6b9e7168972>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# plot transitions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mafc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_color_transitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m# MCTA and number of frames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreq_inc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/win/anils/abstraction/data/auxiliary.py\u001b[0m in \u001b[0;36mplot_color_transitions\u001b[0;34m(self, p, g)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_major_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_fontsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_num_frames_pi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2051\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n\u001b[0;32m-> 2053\u001b[0;31m                             bbox_extra_artists=bbox_artists)\n\u001b[0m\u001b[1;32m   2054\u001b[0m                     \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pad_inches\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mpad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   2268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2269\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2270\u001b[0;31m             \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2271\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2272\u001b[0m                 \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, call_axes_locator, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   4394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4395\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbbox_artists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4396\u001b[0;31m             \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4397\u001b[0m             if (bbox is not None and\n\u001b[1;32m   4398\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \"\"\"\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_window_extent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_on\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mclip_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/collections.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# TODO:check to ensure that this does not fail for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;31m# cases other than scatter plot legend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_datalim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIdentityTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/collections.py\u001b[0m in \u001b[0;36mget_datalim\u001b[0;34m(self, transData)\u001b[0m\n\u001b[1;32m    203\u001b[0m             result = mpath.get_path_collection_extents(\n\u001b[1;32m    204\u001b[0m                 \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrozen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 offsets, transOffset.frozen())\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transformed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/path.py\u001b[0m in \u001b[0;36mget_path_collection_extents\u001b[0;34m(master_transform, paths, transforms, offsets, offset_transform)\u001b[0m\n\u001b[1;32m    988\u001b[0m     return Bbox.from_extents(*_path.get_path_collection_extents(\n\u001b[1;32m    989\u001b[0m         \u001b[0mmaster_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m         offsets, offset_transform))\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/path.py\u001b[0m in \u001b[0;36mvertices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mvertices\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0man\u001b[0m \u001b[0mNx2\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \"\"\"\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vertices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "policy_net.eval()\n",
    "req_inc = 0\n",
    "_,acc = test_func(pTest,iloc='fix',eloc='last', fixLoc=25, isdebug=0, req_inc=req_inc)\n",
    "tr_acc = 0\n",
    "A,P,R,F, ttr = [],[],[],[],[]\n",
    "nfr = []\n",
    "for i in range(len(acc)):\n",
    "    print ('Person: ',i)\n",
    "    gt = np.array([d[0] for d in acc[i]])\n",
    "    pr = np.array([d[1] for d in acc[i]])\n",
    "    g = gt #t[gt != num_camera-1]\n",
    "    p = pr #r[gt != num_camera-1]\n",
    "    \n",
    "    # plot transitions\n",
    "    afc.plot_color_transitions(p,g)\n",
    "    # MCTA and number of frames\n",
    "    if req_inc == 1:\n",
    "        ac,pr,re,fr,tr = afc.compute_APRF_one_person_sct_ict(p,g)\n",
    "    else:\n",
    "        ac,pr,re,fr,tr = afc.compute_APRF_one_person_sct_ict(p,g)\n",
    "    A.append(ac)\n",
    "    P.append(pr)\n",
    "    R.append(re)\n",
    "    F.append(fr)\n",
    "    ttr.append(tr)\n",
    "    print ('A,P,R: ', ac,pr,re)\n",
    "    f = afc.compute_num_frames(p,g)\n",
    "    nfr.append(f)\n",
    "    print ('Num frames: ', f)\n",
    "    # Accuracy\n",
    "    tacc = np.sum(g==p, dtype=np.float)/g.shape[0]\n",
    "    tr_acc += tacc\n",
    "    print ('Accuracy: ',tacc)\n",
    "print (tr_acc/len(A))\n",
    "print ('Average A,P,R,F, ttr', np.mean(A),np.mean(P),np.mean(R),np.mean(F), ttr)\n",
    "print (np.sum(nfr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tr_acc = 0\n",
    "for i in range(5):\n",
    "    print ('Person: ',i)\n",
    "    g = np.array([d[0] for d in acc[i]])\n",
    "    p = np.array([d[1] for d in acc[i]])\n",
    "    print (g)\n",
    "    print (p)\n",
    "    tr_acc += np.sum(g==p, dtype=np.float)/g.shape[0]\n",
    "tr_acc/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcta = []\n",
    "nfr = []\n",
    "for i in range(5):\n",
    "    g = np.array([d[0] for d in acc[i]])\n",
    "    p = np.array([d[1] for d in acc[i]])\n",
    "    mcta.append(afc.compute_MCTA(p,g))\n",
    "    nfr.append(afc.compute_num_frames(p,g))\n",
    "print (np.mean(mcta))\n",
    "print (np.sum(nfr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_fname = '/media/win/HRLhkl/Q_CamSel_3L_l4_st200_db3_1tCont_2'\n",
    "hkl.dump([[episode_reward, running_reward]], backup_fname+'_variables.hkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "1/np.log(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = 1\n",
    "np.max(pTest[pp][1:,1] - pTest[pp][0:-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
